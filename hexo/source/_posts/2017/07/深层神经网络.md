---
title: 深层神经网络
date: 2017-07-20 15:27:56
tags: [TensorFlow]
categories: 人工智能
---

<!-- more --> 

# 深度学习与深层神经网络

# 损失函数

## 经典损失函数
### 交叉熵
> 如何判断输出向量和期望向量之间的接近程度？
交叉熵是常用的评判方法，其刻画了两个概率分布之间的距离，它是分类问题中使用较广的一种损失函数；
### Softmax回归
> 如何将神经网络前向传播得到的结果也变成概率分布？
Softmax回归是一个非常常用的方法
公式：

tensorflow 实现交叉熵

```python
cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))
# y_：正确结果
# y:预测结果
# tf.clip_by_value：将一个张量的数值限制在一个范围内，避免一些运算错误，如log0
# tf.log：对张量中的数据依次就对数
# * ：乘法，每个位置上对应元素的乘积，不是矩阵乘法
```

因为交叉熵一般会与softmax回归一起使用，所以tensorflow对这两个功能进行了统一封装，并提供了`tf.nn.softmax_cross_entropy_with_logists(y,y_)`

对于回归问题，最常用的损失函数是均方差（MSE,mean squared error）；
