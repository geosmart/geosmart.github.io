<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>《三体》读书笔记</title>
    <url>/2015/07/21/%E3%80%8A%E4%B8%89%E4%BD%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>三体三部曲-刘慈欣  </p>
<p>给岁月以文明，给时光以生命。</p>
<hr>
<a id="more"></a>
<p>宇宙社会学：（1）生存是文明的第一需求；（2）文明不断增长和扩张，但宇宙中的物质总量不变。</p>
<p>【时间开始后约170亿年，我们的星星】</p>
<p>宇宙就是一座黑暗森林，每个文明都是带枪的猎人，像幽灵般潜行与林间，轻轻拨开挡路的树枝，竭力不让脚步发出一点儿声音，连呼吸都必须小心翼翼：他必须小心，因为林中到处都有与他一样潜行的猎人，如果他发现了别的生命，能做的只有一件事：开枪消灭之。在这片森林中，他人就是地狱，就是永恒的威胁，任何暴露自己存在的生命都将很快被消灭，这就是宇宙文明的图景，这就是对费米悖论的解释</p>
<p>2015-01-06 09:16:05<br>“城市就是森林，每一个男人都是猎手，每一个女人都是陷阱。”</p>
<p>2015-02-10 12:11:38<br>自由女神像基座上的埃玛·拉扎的诗原文为：把你们疲惫的人，你们贫穷的人，你们渴望呼吸自由空气的挤在一堆的人都给我/把那些无家可归、饱经风浪的人都送来/在这金色的大门旁，我要为他们把灯举起。</p>
<p>2015-02-10 13:57:09<br>给时光以生命，而不是给生命以时光。</p>
<p>2015-02-10 13:57:28<br>给岁月以文明，给时光以生命。</p>
<p>2015-02-11 21:58:25<br>精骛八极，心游万仞</p>
<p>2015-03-19 23:01:31<br>从科学角度讲，毁灭一词并不准确，没有真正毁掉什么，更没有灭掉什么，物质总量一点不少都还在，角动量也还在，只是物质的组合方式变了变，像一副扑克牌，仅仅重洗而已……可生命是一手同花顺，一洗什么都没了。”</p>
<p>2015-03-19 23:05:56<br>处于幼年的人类文明曾经打开家门向外看了一眼，外面无边的暗夜吓住了他，他面对黑暗中的广袤和深邃打了个寒战，紧紧地关上了门。</p>
<p>2015-03-31 20:09:40<br>这是一种放弃，她终于看清了，使自己这粒沙尘四处飘飞的，是怎样的天风；把自己这片小叶送向远方的，是怎样的大河。她彻底放弃了，让风吹透躯体，让阳光穿过灵魂。<br>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>小说</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo安装</title>
    <url>/2015/06/30/hexo%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h1 id="hexo环境搭建"><a href="#hexo环境搭建" class="headerlink" title="hexo环境搭建"></a>hexo环境搭建</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">hexo init</span><br><span class="line">npm install</span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">npm install hexo-server --save</span><br><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-feed --save</span><br><span class="line">npm install hexo-toc --save</span><br><span class="line">npm install hexo-html-minifier --save</span><br><span class="line">npm install hexo-filter-sequence --save </span><br><span class="line">npm install hexo-filter-flowchart --save </span><br><span class="line">npm install hexo-related-popular-posts --save</span><br></pre></td></tr></table></figure>
<h1 id="可选插件"><a href="#可选插件" class="headerlink" title="可选插件"></a>可选插件</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line">npm i hexo-renderer-markdown-it --save</span><br></pre></td></tr></table></figure>
<h1 id="next主题的数学公式配置"><a href="#next主题的数学公式配置" class="headerlink" title="next主题的数学公式配置"></a>next主题的数学公式配置</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Math Formulas Render Support</span></span><br><span class="line"><span class="attr">math:</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">mathjax:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">cdn:</span> <span class="string">//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</span></span><br><span class="line">    <span class="attr">mhchem:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g (generate)</span><br><span class="line">hexo s (server)</span><br><span class="line">hexo clean (clear public)</span><br><span class="line">hexo n  [layout] &lt;title &gt;(new post)</span><br><span class="line">eg:hexo n draft title</span><br><span class="line">hexo publish [layout] &lt;title&gt;</span><br><span class="line">eg:hexo publish draft title</span><br><span class="line">hexo d (deploy)</span><br><span class="line">hexo d -g (generate and deploy)</span><br><span class="line"></span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<h1 id="配置评论插件"><a href="#配置评论插件" class="headerlink" title="配置评论插件"></a>配置评论插件</h1><p>多说挂了，换gitment,参考</p>
<ul>
<li><a href="https://imsun.net/posts/gitment-introduction/">Gitment：使用 GitHub Issues 搭建评论系统</a></li>
<li><a href="http://yangq.me/post/ab9bb85a.html">hexo next主题集成gitment评论系统</a></li>
</ul>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="hexo部署错误"><a href="#hexo部署错误" class="headerlink" title="hexo部署错误"></a>hexo部署错误</h2><p>错误日志：Error: spawn git ENOENT<br>解决方案：<br>方案1）添加环境变量C:\Program Files (x86)\Git\bin;C:\Program Files (x86)\Git\libexec\git-core<br>方案2）安装github windows&gt;在项目中Open in Gitshell&gt;执行hexo d -g</p>
<h2 id="sequence插件配置"><a href="#sequence插件配置" class="headerlink" title="sequence插件配置"></a>sequence插件配置</h2><ol>
<li>在 _config.yml 中添加 sequence:相关配置<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">sequence:</span></span><br><span class="line">  <span class="attr">raphael:</span> <span class="string">https://cdn.bootcss.com/raphael/2.2.8/raphael.min.js</span></span><br><span class="line">  <span class="attr">webfont:</span> <span class="string">https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js</span></span><br><span class="line">  <span class="attr">snap:</span> <span class="string">https://cdn.bootcss.com/snap.svg/0.5.1/snap.svg-min.js</span></span><br><span class="line">  <span class="attr">underscore:</span> <span class="string">https://cdn.bootcss.com/underscore.js/1.9.1/underscore-min.js</span></span><br><span class="line">  <span class="attr">sequence:</span> <span class="string">https://cdn.bootcss.com/js-sequence-diagrams/1.0.6/sequence-diagram-min.js</span></span><br><span class="line">  <span class="comment"># css: # optional, the url for css, such as hand drawn theme </span></span><br><span class="line">  <span class="attr">options:</span> </span><br><span class="line">    <span class="attr">theme:</span> </span><br><span class="line">    <span class="attr">css_class:</span></span><br></pre></td></tr></table></figure></li>
<li>修改 node_modules/hexo-filter-sequence/index.js文件，将其彻底清空，然后将以下内容copy进去<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// index.js</span></span><br><span class="line"><span class="keyword">var</span> assign = <span class="built_in">require</span>(<span class="string">'deep-assign'</span>);</span><br><span class="line"><span class="keyword">var</span> renderer = <span class="built_in">require</span>(<span class="string">'./lib/renderer'</span>);</span><br><span class="line"></span><br><span class="line">hexo.config.sequence = assign(&#123;</span><br><span class="line">  webfont: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js'</span>,</span><br><span class="line">  <span class="comment">// sequence-diagram 1.x 版本依赖 raphael, 2.x版本依赖 snap</span></span><br><span class="line">  raphael: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js'</span>,</span><br><span class="line">  snap: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js'</span>,</span><br><span class="line">  underscore: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js'</span>,</span><br><span class="line">  sequence: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js'</span>,</span><br><span class="line">  css: <span class="string">''</span>,</span><br><span class="line">  options: &#123;</span><br><span class="line">    theme: <span class="string">'simple'</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;, hexo.config.sequence);</span><br><span class="line"></span><br><span class="line">hexo.extend.filter.register(<span class="string">'before_post_render'</span>, renderer.render, <span class="number">9</span>);</span><br></pre></td></tr></table></figure></li>
<li>修改 node_modules/hexo-filter-sequence/lib/renderer.js文件，将 26 - 31 行，var config = this.config.flowchart; 及以下的 data.content 等行做如下修改。<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (sequences.length) &#123;</span><br><span class="line">      <span class="keyword">var</span> config = <span class="keyword">this</span>.config.sequence;</span><br><span class="line">      <span class="comment">// resources</span></span><br><span class="line">      data.content += <span class="string">'&lt;script src="'</span> + config.webfont + <span class="string">'"&gt;&lt;/script&gt;'</span>;</span><br><span class="line">      <span class="comment">// sequence-diagram 1.x 版本依赖 raphael, 2.x版本依赖 snap</span></span><br><span class="line">      data.content += <span class="string">'&lt;script src="'</span> + config.raphael + <span class="string">'"&gt;&lt;/script&gt;'</span>;</span><br><span class="line">      data.content += <span class="string">'&lt;script src="'</span> + config.snap + <span class="string">'"&gt;&lt;/script&gt;'</span>;</span><br><span class="line">      data.content += <span class="string">'&lt;script src="'</span> + config.underscore + <span class="string">'"&gt;&lt;/script&gt;'</span>;</span><br><span class="line">      data.content += <span class="string">'&lt;script src="'</span> + config.sequence + <span class="string">'"&gt;&lt;/script&gt;'</span>;</span><br><span class="line">      ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>修改完毕后执行 hexo clean，hexo g，hexo s</li>
<li>时序图可以正常显示了</li>
</ol>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>jdk安装脚本</title>
    <url>/2015/06/28/jdk%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://download.oracle.com/otn-pub/java/jdk/7u80-b15/jdk-7u80-linux-x64.tar.gz">jdk7 X64安装包（官网版本：jdk-7u80-linux-x64.tar.gz）</a><br>下载后并重命名为jetty.tar.gz</li>
<li><a href="install-jdk.sh">jdk安装脚本</a></li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp/jdk</li>
<li>执行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /tmp/jdk</span><br><span class="line">chmod +x install-jdk.sh</span><br><span class="line">sudo ./install-jdk.sh</span><br></pre></td></tr></table></figure>
<ol>
<li>一路回车即可</li>
</ol>
<h1 id="附件-install-jdk-sh"><a href="#附件-install-jdk-sh" class="headerlink" title="附件 install-jdk.sh"></a>附件 install-jdk.sh</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">BASEDIR=$(<span class="built_in">cd</span> `dirname <span class="variable">$0</span>`; <span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#jdk-7u80-linux-x64</span></span><br><span class="line"><span class="built_in">read</span>  -p <span class="string">"Please select java tar package full path path[/tmp/jdk.tar.gz] "</span> INSTALL_FILE</span><br><span class="line"><span class="keyword">if</span> [ ! -f <span class="string">"<span class="variable">$INSTALL_FILE</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">trueINSTALL_FILE=<span class="string">"/tmp/jdk.tar.gz"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set install path</span></span><br><span class="line"><span class="built_in">read</span>  -p <span class="string">"Please select java install path path[/usr/local/java]: "</span> INSTALL_PATH</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$INSTALL_PATH</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></span><br><span class="line">trueINSTALL_PATH=<span class="string">"/usr/local/java"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$INSTALL_PATH</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"mkdir <span class="variable">$INSTALL_PATH</span>"</span></span><br><span class="line">    mkdir -p <span class="variable">$INSTALL_PATH</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"uncompress <span class="variable">$INSTALL_FILE</span> to <span class="variable">$INSTALL_PATH</span>"</span></span><br><span class="line"><span class="keyword">if</span> [ -w <span class="variable">$INSTALL_PATH</span> ]; <span class="keyword">then</span></span><br><span class="line">  tar -zxvf <span class="variable">$INSTALL_FILE</span> -C <span class="variable">$INSTALL_PATH</span> --strip-components=1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  sudo tar -zxvf <span class="variable">$INSTALL_FILE</span> -C <span class="variable">$INSTALL_PATH</span> --strip-components=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Setting java environment..."</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export JAVA_HOME=<span class="variable">$INSTALL_PATH</span>"</span> | sudo tee -a /etc/profile</span><br><span class="line"></span><br><span class="line">JAVA_HOME=<span class="variable">$INSTALL_PATH</span></span><br><span class="line"><span class="comment">#FIXME</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JAVA_HOME</span>/lib/dt.jar"</span> | sudo tee -a /etc/profile</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$JAVA_HOME/bin:$PATH'</span> | sudo tee -a /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"refresh java environment..."</span></span><br><span class="line"><span class="comment">#TODO what does "."  do? the same as "source" command?</span></span><br><span class="line">. /etc/profile</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line">java -version</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"$?"</span> = <span class="string">"0"</span> ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"\033[32m Installed, please source /etc/profile or relogin. \033[0m"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"\033[31m Install failed. \033[0m"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">unset</span> BASEDIR</span><br><span class="line"><span class="built_in">unset</span> INSTALL_PATH</span><br><span class="line"><span class="built_in">unset</span> INSTALL_FILE</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>
<ol>
<li>卸载JDK</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看系统已安装的jdk</span></span><br><span class="line">rpm -qa|grep jdk</span><br><span class="line">java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br><span class="line"><span class="meta">#</span><span class="bash">卸载指定版本的jdk</span></span><br><span class="line">rpm -e --nodeps  java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除JAVA_HOME，CLASSPATH等相关环境变量</span></span><br><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>J2EE</tag>
      </tags>
  </entry>
  <entry>
    <title>jetty一键安装脚本</title>
    <url>/2015/06/28/jetty%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://download.eclipse.org/jetty/9.2.11.v20150529/dist/jetty-distribution-9.2.11.v20150529.tar.gz">jetty安装包（官网版本：jetty-distribution-9.2.11.v20150529.tar）</a><br>下载后并重命名为jetty.tar.gz</li>
<li><a href="install-jetty.sh">jetty安装脚本</a></li>
<li>已安装JDK1.7</li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp/jetty</li>
<li><p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /tmp/jetty</span><br><span class="line">chmod +x install-jetty.sh</span><br><span class="line">sudo ./install-jetty.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>一路回车即可</p>
</li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Web服务器</tag>
        <tag>Jetty</tag>
      </tags>
  </entry>
  <entry>
    <title>jetty手动安装脚本</title>
    <url>/2015/06/28/jetty%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<h3 id="下载解压Jetty"><a href="#下载解压Jetty" class="headerlink" title="下载解压Jetty"></a>下载解压Jetty</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /tmp</span><br><span class="line">wget http://eclipse.org/downloads/download.php?file=/jetty/stable-9/dist/jetty-distribution-9.3.0.v20150612.tar.gz&amp;r=1</span><br><span class="line">tar -xzvf  jetty-distribution-9.3.0.v20150612.tar.gz</span><br><span class="line">mv jetty-distribution-9.1.1.v20140108 /usr/<span class="built_in">local</span>/jetty</span><br></pre></td></tr></table></figure>
<h3 id="新建用户-gt-配置jetty所属权限"><a href="#新建用户-gt-配置jetty所属权限" class="headerlink" title="新建用户&gt;配置jetty所属权限"></a>新建用户&gt;配置jetty所属权限</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd -m jetty</span><br><span class="line">chown -R jetty:jetty /usr/<span class="built_in">local</span>/jetty/</span><br></pre></td></tr></table></figure>
<h3 id="安装到系统服务"><a href="#安装到系统服务" class="headerlink" title="安装到系统服务"></a>安装到系统服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/jetty/bin/jetty.sh /etc/init.d/jetty</span><br><span class="line">chkconfig --add jetty</span><br><span class="line">chkconfig --level 345 jetty on</span><br></pre></td></tr></table></figure>
<h3 id="编辑启动脚本"><a href="#编辑启动脚本" class="headerlink" title="编辑启动脚本"></a>编辑启动脚本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/default/jetty</span><br><span class="line">JETTY_HOME=/usr/<span class="built_in">local</span>/jetty</span><br><span class="line">JETTY_USER=jetty</span><br><span class="line">JETTY_PORT=8080</span><br><span class="line">JETTY_LOGS=/usr/<span class="built_in">local</span>/jetty/logs/</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-gt-测试"><a href="#启动服务-gt-测试" class="headerlink" title="启动服务&gt;测试"></a>启动服务&gt;测试</h3><pre><code class="lang-bash">service jetty start
curl localhost:8080
</code></pre>
<h3 id="常用操作指令"><a href="#常用操作指令" class="headerlink" title="常用操作指令"></a>常用操作指令</h3><pre><code class="lang-bash">jetty [-d] {start|stop|run|restart|check|supervise} [ CONFIGS ... ]
</code></pre>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Web服务器</tag>
        <tag>Jetty</tag>
      </tags>
  </entry>
  <entry>
    <title>LNMP安装</title>
    <url>/2015/06/30/lnmp%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>具体参考<a href="http://lnmp.org/">LNMP一键安装官网</a></p>
<h2 id="NMP环境配置"><a href="#NMP环境配置" class="headerlink" title="NMP环境配置"></a>NMP环境配置</h2><p>LNMP:Linux+Nginx+Mysql+PHP</p>
<h2 id="LNMP相关软件安装目录"><a href="#LNMP相关软件安装目录" class="headerlink" title="LNMP相关软件安装目录"></a>LNMP相关软件安装目录</h2><p>Nginx 目录: /usr/local/nginx/<br>MySQL 目录 : /usr/local/mysql/<br>MySQL数据库所在目录：/usr/local/mysql/var/<br>MariaDB 目录 : /usr/local/mariadb/<br>MariaDB数据库所在目录：/usr/local/mariadb/var/<br>PHP目录 : /usr/local/php/<br>PHPMyAdmin目录 : 0.9版为/home/wwwroot/phpmyadmin/ 1.0版为 /home/wwwroot/default/phpmyadmin/ 强烈建议将此目录重命名为其不容易猜到的名字。phpmyadmin可自己从官网下载新版替换。<br>默认网站目录 : 0.9版为 /home/wwwroot/ 1.0版为 /home/wwwroot/default/<br>Nginx日志目录：/home/wwwlogs/<br>/root/vhost.sh添加的虚拟主机配置文件所在目录：/usr/local/nginx/conf/vhost/<br>PureFtpd 目录：/usr/local/pureftpd/<br>PureFtpd web管理目录： 0.9版为/home/wwwroot/default/ftp/ 1.0版为 /home/wwwroot/default/ftp/<br>Proftpd 目录：/usr/local/proftpd/<br>Redis 目录：/usr/local/redis/</p>
<h2 id="一键安装"><a href="#一键安装" class="headerlink" title="一键安装"></a>一键安装</h2><p>下载<br><code>wget  --no-check-certificate https://api.sinas3.com/v1/SAE_lnmp/soft/lnmp1.2-full.tar.gz</code><br>一键下载安装<br><code>wget -c http://soft.vpser.net/lnmp/lnmp1.2-full.tar.gz &amp;&amp; tar zxf lnmp1.2-full.tar.gz &amp;&amp; cd lnmp1.2-full &amp;&amp; ./install.sh lnmp</code></p>
<p>离线安装<br><code>cd /tmp/lnmp &amp;&amp; tar zxf lnmp1.2-full.tar.gz &amp;&amp; cd lnmp1.2-full &amp;&amp; ./install.sh lnmp</code><br>网络情况10M带宽耗时：45分钟</p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Web服务器</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title>mongodb手动安装脚本</title>
    <url>/2015/06/28/mongodb%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p><img src="nosql.png" alt="nosql">   </p>
<h1 id="准备事项"><a href="#准备事项" class="headerlink" title="准备事项"></a>准备事项</h1><h2 id="下载安装包文件（二进制编译版）"><a href="#下载安装包文件（二进制编译版）" class="headerlink" title="下载安装包文件（二进制编译版）"></a>下载安装包文件（二进制编译版）</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /usr/<span class="built_in">local</span>/mongodb</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/mongodb</span><br><span class="line">wget http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.6.3.tgz</span><br><span class="line">tar -zvxf mongodb-linux-x86_64-2.6.3.tgz</span><br></pre></td></tr></table></figure>
<h2 id="重命名-gt-新建数据-日志目录"><a href="#重命名-gt-新建数据-日志目录" class="headerlink" title="重命名&gt;新建数据/日志目录"></a>重命名&gt;新建数据/日志目录</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv mongodb-linux-x86_64-2.6.3 mongodb</span><br><span class="line">mkdir data</span><br><span class="line">mkdir <span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p>CentOs中配置path环境变量,确保mongodb的bin目录包含在path环境变量中。</p>
<h2 id="配置PATH"><a href="#配置PATH" class="headerlink" title="配置PATH"></a>配置PATH</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">　　<span class="comment">#set for mongodb</span></span><br><span class="line">　　<span class="built_in">export</span> MONGODB_HOME=/usr/<span class="built_in">local</span>/mongodb</span><br><span class="line">　　<span class="built_in">export</span> PATH=<span class="variable">$MONGODB_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h2 id="查看当前PATH"><a href="#查看当前PATH" class="headerlink" title="查看当前PATH"></a>查看当前PATH</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h2 id="让环境变量生效"><a href="#让环境变量生效" class="headerlink" title="让环境变量生效"></a>让环境变量生效</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line">//验证环境变量是否生效</span><br><span class="line">mongod -version</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 添加CentOS开机启动项</span></span><br></pre></td></tr></table></figure>
<p>vim  /etc/rc.d/rc.local<br>//将mongodb启动命令手动追加到本文件中：<br>/usr/local/mongodb/bin/mongod —dbpath /usr/local/mongodb/data —logpath /usr/local/mongodb/log/mongodb.log —maxConns=2000  —fork —smallfiles<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># 启动MongoDB</span><br><span class="line">## 配置文件形式</span><br><span class="line">&#96;&#96;&#96; bash</span><br><span class="line">vim  &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;mongodb.conf</span><br><span class="line">dbpath&#x3D;&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;data</span><br><span class="line">logpath&#x3D;&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;log&#x2F;mongodb.log</span><br><span class="line">logappend&#x3D;true</span><br><span class="line">port&#x3D;27017</span><br><span class="line">fork&#x3D;true</span><br><span class="line">noauth&#x3D;true</span><br><span class="line">journal&#x3D;true</span><br><span class="line">smallfiles&#x3D;true</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line">## 命令行形式</span><br><span class="line">&#96;&#96;&#96; Bash</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;bin&#x2F;mongod --dbpath &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;data --logpath &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;log&#x2F;mongodb.log  --fork --smallfiles</span><br><span class="line">&#x2F;&#x2F;可选：--auth</span><br></pre></td></tr></table></figure></p>
<h1 id="增加用户"><a href="#增加用户" class="headerlink" title="增加用户"></a>增加用户</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd mongodb -M -s /sbin/nologin</span><br></pre></td></tr></table></figure>
<h1 id="启动服务-测试服务状态"><a href="#启动服务-测试服务状态" class="headerlink" title="启动服务/测试服务状态"></a>启动服务/测试服务状态</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">service mongod start</span><br><span class="line">service mongod status</span><br><span class="line">shutdown -r now</span><br><span class="line">service mongod status</span><br><span class="line">mongo admin</span><br><span class="line">show dbs；</span><br><span class="line">db.test.find();</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<h1 id="部署问题记录"><a href="#部署问题记录" class="headerlink" title="部署问题记录"></a>部署问题记录</h1><h2 id="MongoVUE不能连接"><a href="#MongoVUE不能连接" class="headerlink" title="MongoVUE不能连接"></a>MongoVUE不能连接</h2><p>将27017端口加入信任列表；局域网测试直接关闭防火墙<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">//关闭防火墙</span><br><span class="line">service iptables stop</span><br><span class="line">//开启</span><br><span class="line">chkconfig iptables on</span><br><span class="line">//关闭</span><br><span class="line">chkconfig iptables off</span><br><span class="line">//查询TCP连接情况</span><br><span class="line"> netstat -n | awk <span class="string">'/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'</span></span><br><span class="line">//查询端口占用情况：</span><br><span class="line"> netstat   -anp   |   grep  portno</span><br><span class="line">//（例如：netstat –apn | grep 80）</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix-agent安装脚本</title>
    <url>/2015/06/29/zabbix-agent%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p><img src="zabbix.png" alt="zabbix"> </p>
<h1 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h1><ol>
<li><a href="http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.2.9/zabbix-2.2.9.tar.gz/download">zabbix安装包（官网版本：zabbix-2.2.9.tar.gz）</a></li>
<li>yum groupinstall “Development tools”</li>
<li><a href="install-zabbix_agent.sh">zabbix安装脚本</a> </li>
</ol>
<p> cd /tmp &amp;&amp; tar -zxf  zabbix.gz</p>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol>
<li><p>修改zabbix_server程序的磁盘路径<br>修改zabbix_server主程序路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /usr/local/zabbix/misc/init.d/tru64/zabbix_server</span></span><br><span class="line">DAEMON=/usr/<span class="built_in">local</span>/zabbix/sbin/zabbix_server</span><br></pre></td></tr></table></figure>
<p>添加下面两句到<code>#!/bin/bash</code>之后，解决<code>service myservicedoes not support chkconfig</code>问题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># chkconfig: 2345 10 90 </span></span><br><span class="line"><span class="comment"># description:zabbix....</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>编辑zabbix_agentd配置文件<br><code>vim /usr/local/zabbix/etc/zabbix_agentd.conf</code> </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogFile=/tmp/zabbix_agentd.log </span><br><span class="line"><span class="comment">#服务端IP  </span></span><br><span class="line">Server=192.168.1.80</span><br><span class="line"><span class="comment">#服务端IP   </span></span><br><span class="line">ServerActive= 192.168.1.80</span><br><span class="line"><span class="comment">#客户端IP与zabbix-web配置上的hostName一致   </span></span><br><span class="line">Hostname=localhost</span><br><span class="line">UnsafeUserParameters=1</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行安装脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/zabbix/script/install-zabbix_agentd.sh</span><br><span class="line">chmod +x install-zabbix_agentd.sh </span><br><span class="line">sudo ./install-zabbix_agentd.sh</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h1><ol>
<li><p>若zabbix的host无法访问，考虑防火墙是否需要关闭/加入信任端口</p>
<pre><code class="lang-bash">#查看防火墙状态
service iptables status 
#关闭防火墙 
service iptables stop  
#永久关闭防火墙 
chkconfig   iptables off
</code></pre>
</li>
<li><p>查看zabbix服务是否已启动</p>
<pre><code class="lang-bash">netstat -utlnp | grep zabbix
</code></pre>
</li>
<li><p>配置文件更新后，需重启客户端服务</p>
<pre><code class="lang-bash">service zabbix_agentd restart
</code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>监控</tag>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix-server安装脚本</title>
    <url>/2015/06/30/zabbix-server%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="关于zabbix"><a href="#关于zabbix" class="headerlink" title="关于zabbix"></a>关于zabbix</h1><ul>
<li>zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案，能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统工程师快速定位/解决存在的各种问题。zabbix由2部分构成，zabbix server与可选组件zabbix agent。</li>
<li>zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能。</li>
<li>zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。</li>
</ul>
<hr>
<a id="more"></a>
<p><img src="zabbix.png" alt="zabbix">  </p>
<h1 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h1><ol>
<li>LNMP/LNAP环境安装</li>
<li><a href="http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.2.9/zabbix-2.2.9.tar.gz/download">zabbix安装包（官网版本：zabbix-2.2.9.tar.gz）</a></li>
<li><a href="install-zabbix_server.sh">zabbix安装脚本</a> </li>
<li><a href="clear-zabbix_his.sh">zabbix清空历史监控数据脚本</a> </li>
</ol>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol>
<li><p>PHP参数配置<br>为安装zabbix监控WebUI，需要预先配置php<br><code>vim /usr/local/php/etc/php.ini</code>查找配置下列参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">memory_limit = 128M</span><br><span class="line">post_max_size = 50M</span><br><span class="line">upload_max_filesize =50M</span><br><span class="line">max_execution_time = 600</span><br><span class="line">max_input_time = 600</span><br><span class="line">date.timezone = Asia/Shanghai</span><br></pre></td></tr></table></figure>
<p>修改后执行<code>service php-fpm restart</code></p>
</li>
<li><p>修改zabbix_server程序的磁盘路径<br>修改zabbix_server主程序路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /usr/local/zabbix/misc/init.d/tru64/zabbix_server</span></span><br><span class="line">DAEMON=/usr/<span class="built_in">local</span>/zabbix/sbin/zabbix_server</span><br></pre></td></tr></table></figure>
<p>添加下面两句到<code>#!/bin/bash</code>之后，解决<code>service myservicedoes not support chkconfig</code>问题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># chkconfig: 2345 10 90 </span></span><br><span class="line"><span class="comment"># description:zabbix....</span></span><br></pre></td></tr></table></figure></li>
<li><p>编辑zabbix_server配置文件<br><code>vim /usr/local/zabbix/etc/zabbix_server.conf</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DBHost=localhost</span><br><span class="line">DBName = zabbix </span><br><span class="line">DBPassword =zabbix  </span><br><span class="line">DBUser = zabbix  </span><br><span class="line">LogFile=/tmp/zabbix_server.log</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加zabbix服务Service端口（不能重复操作）</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt;&#x2F;etc&#x2F;services&lt;&lt;EOF</span><br><span class="line">zabbix-agent 10050&#x2F;tcp Zabbix Agent</span><br><span class="line">zabbix-agent 10050&#x2F;udp Zabbix Agent</span><br><span class="line">zabbix-trapper 10051&#x2F;tcp Zabbix Trapper</span><br><span class="line">zabbix-trapper 10051&#x2F;udp Zabbix Trapper</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ol>
<li>Mysql中新建Zabbix数据库<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -proot</span><br><span class="line">create database zabbix;</span><br><span class="line">grant all privileges on zabbix.* to zabbix@localhost identified by &#39;zabbix&#39;;</span><br><span class="line">quit</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line"></span><br><span class="line">6. 执行安装脚本</span><br><span class="line">&#96;&#96;&#96; bash </span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;zabbix</span><br><span class="line">chmod +x configure</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;script</span><br><span class="line">chmod +x install-zabbix_server.sh </span><br><span class="line">sudo .&#x2F;install-zabbix_server.sh</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line"># 相关操作</span><br><span class="line">1. zabbix网站中的启用中文后乱码问题</span><br><span class="line">* 在zabbix网站目录下的include&#x2F;locales.inc.php文件中启用中文（&#39;display&#39;&#x3D;true）</span><br><span class="line">* 在windows下控制面板-&gt;字体-&gt;选择一种中文字库例如“楷体”，把它拷贝到zabbix的web端的fonts目录下例如：&#x2F;var&#x2F;www&#x2F;html&#x2F;zabbix&#x2F;fonts，并且把TTF后缀改为ttf</span><br><span class="line">* 修改zabbix的web端&#x2F;include&#x2F;defines.inc.php，如下</span><br><span class="line">&#96;&#96;&#96; php</span><br><span class="line">&#x2F;&#x2F;define(&#39;ZBX_GRAPH_FONT_NAME&#39;, &#39;DejaVuSans&#39;); &#x2F;&#x2F; origin name</span><br><span class="line">define(&#39;ZBX_GRAPH_FONT_NAME&#39;, &#39;simkai&#39;); &#x2F;&#x2F; custom  font name</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line">2. 若zabbix的host无法访问，考虑防火墙是否需要关闭&#x2F;加入信任端口</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96; bash</span><br><span class="line">#查看防火墙状态</span><br><span class="line">service iptables status </span><br><span class="line">#关闭防火墙 </span><br><span class="line">service iptables stop </span><br><span class="line">#永久关闭防火墙 </span><br><span class="line">chkconfig   iptables off</span><br></pre></td></tr></table></figure></li>
<li><p>编译问题<br>‘aclocal-1.14’ is missing on your system.You should only need it if you modified ‘acinclude.m4’ or ‘configure.ac’ or m4 files included by ‘configure.ac’.<br>解决方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch configure.ac aclocal.m4 configure Makefile.am Makefile.in</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看zabbix服务是否已启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -utlnp | grep zabbix </span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line">5. 配置文件更新后，需重启客户端服务</span><br><span class="line">``` bash</span><br><span class="line">service zabbix_server restart</span><br></pre></td></tr></table></figure></li>
<li>zabbix web配置简略，贴几张效果图<br><img src="filter.png" alt="zabbix监控"><br><img src="cpu.png" alt="zabbix监控CPU"><br><img src="network.png" alt="zabbix监控网络"></li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>监控</tag>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>常用git命令</title>
    <url>/2015/06/30/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>用github来搭建个人技术笔记，少不了记录一些常用的git命令</p>
<hr>
<a id="more"></a>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p><a href="http://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-Git-%E5%9F%BA%E7%A1%80">Git基础</a><br><a href="http://yanminx.com/blog/understand-git-by-drawing">用爱一起画Git</a><br><a href="https://www.atlassian.com/git/tutorials/">参考教程</a>  </p>
<h1 id="克隆库"><a href="#克隆库" class="headerlink" title="克隆库"></a>克隆库</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;geosmart&#x2F;geosmart.io</span><br></pre></td></tr></table></figure>
<h1 id="新建-‘gh-pages’分支，会自动生成github-pages"><a href="#新建-‘gh-pages’分支，会自动生成github-pages" class="headerlink" title="新建 ‘gh-pages’分支，会自动生成github pages"></a>新建 ‘gh-pages’分支，会自动生成github pages</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout --orphan gh-pages</span><br></pre></td></tr></table></figure>
<h1 id="本地提交"><a href="#本地提交" class="headerlink" title="本地提交"></a>本地提交</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git commit -a -m &quot;commit message&quot;</span><br></pre></td></tr></table></figure>
<h1 id="初始版本提交"><a href="#初始版本提交" class="headerlink" title="初始版本提交"></a>初始版本提交</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git push --set-upstream origin master</span><br><span class="line">或</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure>
<h1 id="推送到服务器"><a href="#推送到服务器" class="headerlink" title="推送到服务器"></a>推送到服务器</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git push origin  </span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line">#   git同步配置</span><br></pre></td></tr></table></figure>
<p>git sync<br>git config —global credential.helper store<br>git config —global push.default matching<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#  git bash记住密码</span><br><span class="line">## 设置环境变量</span><br><span class="line">在windows中添加一个HOME环境变量，变量名:HOME,变量值：%USERPROFILE%</span><br><span class="line">## 创建git用户名和密码存储文件</span><br><span class="line">进入%HOME%目录，新建一个名为 &quot;_netrc&quot; 的文件，文件中内容格式如下：</span><br><span class="line">&#96;&#96;&#96;yaml</span><br><span class="line">machine &#123;git account name&#125;.github.com</span><br><span class="line">login your-usernmae</span><br><span class="line">password your-password</span><br></pre></td></tr></table></figure><br>重新打开git bash即可，无需再输入用户名和密码</p>
<h1 id="查看git配置"><a href="#查看git配置" class="headerlink" title="查看git配置"></a>查看git配置</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --list</span><br></pre></td></tr></table></figure>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="CAfile-C-Program-Files-Git-mingw64-ssl-certs-ca-bundle-crt"><a href="#CAfile-C-Program-Files-Git-mingw64-ssl-certs-ca-bundle-crt" class="headerlink" title="CAfile: C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt"></a>CAfile: C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt</h2><p>You have to fix the path to bin/curl-ca-bundle.crt. I had to specify the absolute path, using back-slashes:<br><code>git config --system http.sslcainfo &quot;C:\Program Files (x86)\git\bin\curl-ca-bundle.crt&quot;``
or — not really recommended — you may choose to switch off SSL checks completely by executing:</code>git config —system http.sslverify false`</p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>日志分析工具</title>
    <url>/2015/06/30/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>最近需要对多台Web服务器/Java客户端程序的日志进行分析，比较了一些开源的日志分析产工具，目前在用的有OtrosLogViewer（olv）和LogExpert</p>
<hr>
<a id="more"></a>
<h2 id="AWStats"><a href="#AWStats" class="headerlink" title="AWStats"></a>AWStats</h2><ul>
<li>基于Perl，开源、简洁、强大的网站日志分析工具<br>Free real-time logfile analyzer to get advanced statistics (GNU GPL).<br>AWStats is a free powerful and featureful tool that generates advanced web, streaming, ftp or mail server statistics, graphically. This log analyzer works as a CGI or from command line and shows you all possible information your log contains, in few graphical web pages. It uses a partial information file to be able to process large log files, often and quickly. It can analyze log files from all major server tools like Apache log files (NCSA combined/XLF/ELF log format or common/CLF log format), WebStar, IIS (W3C log format) and a lot of other web, proxy, wap, streaming servers, mail servers and some ftp servers.<br>Take a look at this comparison table for an idea on features and differences between most famous statistics tools (AWStats, Analog, Webalizer,…).<br>AWStats is a free software distributed under the GNU General Public License. You can have a look at this license chart to know what you can/can’t do.<br>As AWStats works from the command line but also as a CGI, it can work with all web hosting providers which allow Perl, CGI and log access.</li>
</ul>
<h2 id="OtrosLogViewer"><a href="#OtrosLogViewer" class="headerlink" title="OtrosLogViewer"></a>OtrosLogViewer</h2><ul>
<li>基于Java开发的，开源、强大、可自定义日志语法规则进行解析、UI友好，可拖拽http日志进行分析，好评</li>
<li>问题1：在windows下切换log会非常卡顿，linux下正常，暂未找到原因</li>
<li>问题2： illegal character in schema name at index xxx<br>  不能直接拖拽文件（如<a href="http://192.168.1.81:8080/logs/uadb/uadb.log），需拖拽浏览器页面（如http://192.168.1.81:8080/logs/uadb）中的日志链接">http://192.168.1.81:8080/logs/uadb/uadb.log），需拖拽浏览器页面（如http://192.168.1.81:8080/logs/uadb）中的日志链接</a></li>
<li>问题3 按<code>%d{yyyy-MM-dd HH\:mm\:ss,SSS} [%t] [%c] [%p] - %m%n</code>规则拆分行存在问题，存在多行并在一起</li>
</ul>
<p>Useful software for analysing applications logs and traces.</p>
<h2 id="LogExpert"><a href="#LogExpert" class="headerlink" title="LogExpert"></a>LogExpert</h2><ul>
<li>小而美的单机日志分析工具，好评<br>  You are a developer needing a nice tail application for MS Windows?<br>  You are in the need for a powerful logfile analysis tool?<br>  You love logfiles?<br>  You live in your logfiles?<br>  Or at least: you have to work with them?<br>  Download LogExpert if you answered “yes” to any of the questions above!</li>
</ul>
<h2 id="Log-Parser"><a href="#Log-Parser" class="headerlink" title="Log Parser"></a>Log Parser</h2><ul>
<li>基于.NET平台<br>  Log Parser is a powerful, versatile tool that provides universal query access to text-based data such as log files, XML files and CSV files, as well as key data sources on the Windows operating system such as the Event Log, the Registry, the file system, and Active Directory. You tell Log Parser what information you need and how you want it processed. The results of your query can be custom-formatted in text based output, or they can be persisted to more specialty targets like SQL, SYSLOG, or a chart. Most software is designed to accomplish a limited number of specific tasks. Log Parser is different… the number of ways it can be used is limited only by the needs and imagination of the user. The world is your database with Log Parser.</li>
</ul>
<h2 id="Chainsaw"><a href="#Chainsaw" class="headerlink" title="Chainsaw"></a>Chainsaw</h2><ul>
<li>虽是apache官方的专业Log4j分析工具，2004年就没更新了,差评！<br>  Chainsaw v2 is a companion application to Log4j written by members of the Log4j development community. Like a number of Open Source projects, this new version was built upon inspirations, ideas and creations of others. Chainsaw v2 has it’s roots from the original Chainsaw utility written by Oliver Burn, and with inspiration from the Log Factor 5 utility contributed by ThoughtWorks Inc.</li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>日志分析</tag>
      </tags>
  </entry>
  <entry>
    <title>backbone.marionette学习要点</title>
    <url>/2015/07/28/backbone-marionette%E5%AD%A6%E4%B9%A0%E8%A6%81%E7%82%B9/</url>
    <content><![CDATA[<h1 id="Marionette（Backbone的牵线木偶）"><a href="#Marionette（Backbone的牵线木偶）" class="headerlink" title="Marionette（Backbone的牵线木偶）"></a>Marionette（Backbone的牵线木偶）</h1><p>提供rendering、template管理、UI对象</p>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>rest数据，event事件</p>
<h1 id="Collection：List"><a href="#Collection：List" class="headerlink" title="Collection：List"></a>Collection：List<model></h1><h1 id="View"><a href="#View" class="headerlink" title="View"></a>View</h1><h2 id="ItemView"><a href="#ItemView" class="headerlink" title="ItemView"></a>ItemView</h2><ul>
<li>Backbone.View的扩展，用于渲染Backbone.Model</li>
<li>拥有modelEvents属性，可绑定View方法</li>
</ul>
<h2 id="CollectionView"><a href="#CollectionView" class="headerlink" title="CollectionView"></a>CollectionView</h2><ul>
<li>用于渲染Backbone.Collection</li>
<li>可渲染List<ItemView></li>
<li>拥有collectionEvents/childEvents属性，</li>
<li>add/remove/reset/etc后自动更新视图</li>
<li>支持Filtering（filter方法）、Sorting（comparator属性）</li>
<li>支持Pagination</li>
</ul>
<h2 id="CompositeView"><a href="#CompositeView" class="headerlink" title="CompositeView"></a>CompositeView</h2><ul>
<li>renders a Collection within a template</li>
<li>ItemView（model）和CollectionView（collection）的组合</li>
<li>用于detail/table/nested lists/treeview类型的场景</li>
</ul>
<h1 id="View-Containers"><a href="#View-Containers" class="headerlink" title="View Containers"></a>View Containers</h1><h2 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h2><p>View容器，渲染至DOM，DOM和Backbone的桥梁</p>
<h2 id="LayoutView"><a href="#LayoutView" class="headerlink" title="LayoutView"></a>LayoutView</h2><ul>
<li>用于复杂嵌套布局，multi-view组成的widget</li>
<li>Region容器</li>
<li>render all in one call</li>
</ul>
<h1 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h1><p>initialization初始化和 bootstrapping引导程序</p>
<h1 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h1><p>类似Application，多个Modules组成Application<br>可控制start/stop模块（及其子模块）</p>
<h1 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h1><p>组件间的交互，用于复杂业务逻辑的业务场景</p>
<p>layouts/regions：动态create/display/dispose页面dom</p>
<h1 id="event-aggregrator"><a href="#event-aggregrator" class="headerlink" title="event aggregrator"></a>event aggregrator</h1><p>可bind/trigger事件<br>module/application级别的事件通道，其他所有模块都可监听，可用于如用户登陆成功的业务场景</p>
<h1 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h1><p>多处触发，一处处理</p>
<h1 id="Request-Response"><a href="#Request-Response" class="headerlink" title="Request/Response"></a>Request/Response</h1><p>用于提供Application Level Data，如购物车当前状态<br>提供全局状态，无需所有模块都做处理，但易被滥用，当全局可操作时难预测其影响</p>
<p>appRouter：</p>
]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>Backbone</tag>
        <tag>Marionette</tag>
      </tags>
  </entry>
  <entry>
    <title>mongodb一键安装脚本</title>
    <url>/2015/07/01/mongodb%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p><img src="logo-mongodb.png" alt="">   </p>
<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.6.3.tgz">mongodb安装包（官网版本：mongodb-linux-x86_64-2.6.3.tgz）</a><br>下载后并重命名为mongodb.tar.gz</li>
<li><a href="install-mongodb.sh">mongodb安装脚本</a></li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp </li>
<li><p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /tmp</span><br><span class="line">chmod +x install-mongodb.sh </span><br><span class="line">sudo ./install-mongodb.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>一路回车即可 </p>
</li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx负载均衡参数配置</title>
    <url>/2015/07/12/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>Nginx服务器返回大量502Bad Gateway和504 Time-Out，代理服务器Jetty端存在大量CLOSE_WAIT和TIME_WAIT状态的连接<br><img src="502-504.png" alt="502-504"><br>错误信息查看口令：<br><code>netstat -n | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39;</code></p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><ol>
<li><p>Linux中TCP/IP内核参数 优化<br>编辑参数：<code>vi /etc/sysctl.conf</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.core.somaxconn &#x3D; 4096</span><br><span class="line">net.ipv4.tcp_max_syn_backlog &#x3D; 8192</span><br><span class="line">net.ipv4.tcp_syn_retries&#x3D; 5</span><br><span class="line">net.ipv4.tcp_synack_retries &#x3D; 5</span><br><span class="line">net.ipv4.tcp_abort_on_overflow&#x3D;0</span><br><span class="line">net.ipv4.tcp_tw_reuse&#x3D;1</span><br><span class="line">net.ipv4.tcp_tw_recycle&#x3D;1 </span><br><span class="line">net.ipv4.tcp_timestamps&#x3D;1</span><br><span class="line">net.ipv4.tcp_syncookies&#x3D;1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets&#x3D;90000</span><br><span class="line">net.ipv4.tcp_fin_timeout&#x3D;30</span><br><span class="line">net.ipv4.ip_local_port_range&#x3D;10000 65000</span><br><span class="line">net.ipv4.tcp_keepalive_time&#x3D;1200</span><br></pre></td></tr></table></figure>
<p>让参数生效：<code>/sbin/sysctl -p</code></p>
</li>
<li><p>Nginx配置参数<br>主要配置三个proxy_超时控制参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream uadb_server&#123;   </span><br><span class="line">     server 192.168.1.81:8080  weight&#x3D;1 max_fails&#x3D;2 fail_timeout&#x3D;0; </span><br><span class="line">     server 192.168.1.82:8080  weight&#x3D;1 max_fails&#x3D;2 fail_timeout&#x3D;0;    </span><br><span class="line">&#125; </span><br><span class="line">server &#123;</span><br><span class="line">        listen       9090;</span><br><span class="line">        server_name  uadb_server;   </span><br><span class="line">        access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;uadb_server-access-ssl.log;</span><br><span class="line">        error_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;uadb_server-error-ssl.log;</span><br><span class="line">        location &#x2F;&#123; </span><br><span class="line">           proxy_pass http:&#x2F;&#x2F;uadb_server; </span><br><span class="line">           # time out settings</span><br><span class="line">           proxy_connect_timeout 60;</span><br><span class="line">           proxy_read_timeout  3600;</span><br><span class="line">           proxy_send_timeout  3600;</span><br><span class="line">           proxy_temp_file_write_size 64k;</span><br><span class="line">           proxy_redirect          off; </span><br><span class="line">        &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Nginx-upstream负载均衡-反向代理"><a href="#Nginx-upstream负载均衡-反向代理" class="headerlink" title="Nginx upstream负载均衡/反向代理"></a>Nginx upstream负载均衡/反向代理</h1><p><img src="proxy.png" alt="proxy">   </p>
<h2 id="upstream算法分析"><a href="#upstream算法分析" class="headerlink" title="upstream算法分析"></a>upstream算法分析</h2><ol>
<li>轮询每个请求按时间顺序分配到不同的后端服务器了，后端服务器down掉，自动切除；</li>
<li>weight：设定服务器权值：如weight=2，服务器性能不均时候使用。weight：默认为1，weight越大，负载的权重越大；</li>
<li>ip_hash ：每个请求按访问ip的hash结果分配，每个访客有固定的后端服务器，可以解决session问题；</li>
<li>fair（第三方）：按后端服务器的响应时间来分配，响应时间短的优先分配</li>
<li>url_hash (第三方)： 按访问的url的hash结果分配，使每个url定向到同一个后端服务器，后端为缓存服务器比较有效。</li>
</ol>
<h2 id="upstream参数介绍"><a href="#upstream参数介绍" class="headerlink" title="upstream参数介绍"></a>upstream参数介绍</h2><ol>
<li>down：当前的IP server暂时不参与负载，不进行反向代理；</li>
<li>max_fails：允许请求失败的次数默认为1，当超过最大次数时，返回proxy_next_upstream模块定义的错误；</li>
<li>fail_timeout：max_fails次失败后，暂停的时间；</li>
<li>backup：其它所有非backup机器down或者忙时候，请求backup机器，这台机器压力最轻。</li>
</ol>
<h1 id="netstat参数状态"><a href="#netstat参数状态" class="headerlink" title="netstat参数状态"></a>netstat参数状态</h1><p>查看口令：<code>netstat -an</code><br>参数说明：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LISTEN：侦听来自远方的TCP端口的连接请求；</span><br><span class="line">SYN-SENT：在发送连接请求后等待匹配的连接请求；</span><br><span class="line">SYN-RECEIVED：在收到和发送一个连接请求后等待对方对连接请求的确认；</span><br><span class="line">ESTABLISHED：代表一个打开的连接，我们常用此作为并发连接数；</span><br><span class="line">FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认；</span><br><span class="line">FIN-WAIT-2：从远程TCP等待连接中断请求；</span><br><span class="line">CLOSE-WAIT：等待从本地用户发来的连接中断请求；</span><br><span class="line">CLOSING：等待远程TCP对连接中断的确认；</span><br><span class="line">LAST-ACK：等待原来发向远程TCP的连接中断的确认；</span><br><span class="line">TIME-WAIT：等待足够的时间以确保远程TCP连接收到中断请求的确认；</span><br><span class="line">CLOSED：没有任何连接状态；</span><br></pre></td></tr></table></figure></p>
<h1 id="服务器TCP连接状态"><a href="#服务器TCP连接状态" class="headerlink" title="服务器TCP连接状态"></a>服务器TCP连接状态</h1><p>查看口令：<code>netstat -an|awk &#39;/^tcp/{++S[$NF]}END{for (a in S)print a,S[a]}&#39;</code></p>
<pre><code>CLOSED：没有连接活动或正在进行的；
LISTEN：服务器正在等待的进入呼叫；
SYN_RECV：一个连接请求已经到达，等待确认；
SYN_SENT：应用已经开始，打开一个连接；
ESTABLISHED：正常数据传输状态，也可以近似的理解为当前服务器的并发数；
FIN_WAIT1：应用已经完成；
FIN_WAIT2：另一边同意释放；
ITMED_WAIT：等待所有分组死掉；
CLOSING：两边同时尝试关闭；
TIME_WAIT：另一边已初始化一个释放；
LAST_ACK：等待所有分组死掉；
</code></pre>]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Web服务器</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>《MacTalk·人生元编程》读书笔记</title>
    <url>/2015/07/21/%E3%80%8AMacTalk%C2%B7%E4%BA%BA%E7%94%9F%E5%85%83%E7%BC%96%E7%A8%8B%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>MacTalk·人生元编程</p>
<p>生命中遇见的每一本书，都不是偶然</p>
<hr>
<a id="more"></a>
<h1 id="生命中遇见的每一本书，都不是偶然"><a href="#生命中遇见的每一本书，都不是偶然" class="headerlink" title="生命中遇见的每一本书，都不是偶然"></a>生命中遇见的每一本书，都不是偶然</h1><p>2015-07-09 08:10:15<br>如果你问我是否取得了最后的成功，答案是‘当然没有！’如果是的话，生活将会变得令人厌烦。</p>
<p>2015-07-09 08:10:42<br>我们是幸运的，因为我们的心灵是如此不可预知；正因为如此，生活才充满了情趣。尽管如此，我们仍在进行努力来科学地了解我们自身……”</p>
<h1 id="怀念2007"><a href="#怀念2007" class="headerlink" title="怀念2007"></a>怀念2007</h1><p>2015-07-09 10:58:44<br>一个产品从无到有是困难的，从有到精是艰难的，而当你站上一个巅峰之后，哪怕是做最微小的改进和提升，都需要花费大量的人力物力，同时还要承受失败的风险。我们都知道，从平庸到优秀是容易的，从优秀到卓越是痛苦的，可能很多人、公司穷尽一生都无法达到卓越的境地。</p>
<h1 id="趣谈个人建站"><a href="#趣谈个人建站" class="headerlink" title="趣谈个人建站"></a>趣谈个人建站</h1><p>2015-07-13 11:39:40<br>我们真的不能一心多用吗？或者说并发带给我们的到底是效率的提升还是状态的下降</p>
<p>2015-07-13 11:43:30<br>任务的并行，上下文的切换，注意力的分散，都会让你的效率大打折扣，所以设计模式中的职责单一原则不是盖的，一个类尽可能只做一件事情，无论是效率还是后期维护都会好很多，人脑其实也是一样。</p>
<p>2015-07-13 11:45:10</p>
<ol>
<li>简单任务的并发是大脑天生的nature，每个人都在不自觉的应用。</li>
<li>在宽松的环境中让简单机械的任务和复杂有机的任务并行完成是非常不错的做法，提高效率节省时间。</li>
<li>在高危环境中（驾驶、高空作业等等）我们应该专心致志的只做当前的工作。</li>
<li>对于复杂任务，我们最好一件一件完成，即使有些人能够同时处理多重任务，那也需要长期的艰苦训练，比如郭靖君，你能否做到，就得看有没有周伯通那样的大哥！</li>
</ol>
<p>2015-07-13 11:47:17<br>大牛领会了返璞归真和万物生长的道理，知行合一，遇事抖抖衣袖，不溅起一片涟漪”</p>
<p>2015-07-13 12:25:02<br>坊间流传，普通程序员用bash，文艺程序员用zsh，XX程序员直接用原生的sh，我建议大家文艺一点，用zsh好一些，功能也最强大。目前各个版本的Linux默认的shell都是bash，如果你想用zsh，需要安装一下，如下：<br>sudo apt-get install zsh<br>具体的配置我就不介绍了，感兴趣的读者，可以参考<a href="http://leeiio.me/bash-to-zsh-for-mac/">http://leeiio.me/bash-to-zsh-for-mac/</a></p>
<p>2015-07-13 12:55:42<br>第一个十年我才华横溢，“贼光闪现”，令周边黯然失色；第二个十年，我终于“宝光现形”，不再去抢风头，反而与身边的美丽相得益彰；进入第三个十年，繁华落尽见真醇，我进入了“醇光初现”的阶段，真正体味到了境界之美。——台湾作家林清玄</p>
<h1 id="锤子和钉子"><a href="#锤子和钉子" class="headerlink" title="锤子和钉子"></a>锤子和钉子</h1><p>2015-07-20 08:15:26<br>Hater，这种人对自己不了解或没有勇气尝试的事物永远持否定态度，如果你发现一个人大部分时间在否定着什么，那么他们的意见不听也罢，甚至于那些鼓励的建议也仅仅是建议而已，仅供参考，因为最终不是那些提建议的人去做事和承担后果</p>
<p>2015-07-21 08:10:42<br>所有人都是在试错中成长，那些不犯错的人充满了各种幻觉，其实是因为他不再成长了。</p>
<p>2015-07-21 08:11:00<br>他们一定要给你泼冷水的。泼冷水的愿望之强烈，你无法想象。那种强烈借助了太多的力量：怀疑、嫉妒、恐惧、愤怒。而在表现的过程中却又包装上另外一层表皮：关怀、爱护、友爱、帮助。</p>
<p>2015-07-21 08:13:44<br>不管是谈恋爱、做项目、创业、投资都会面临这沉没成本的问题，基本的句式就是『我们已经投入了这么多……』『我们已经走了这么远……』『我们已经牺牲了这么多……』。纠结于过去的沉没成本，会让人感到痛苦和犹豫不决，该放手时要放手，</p>
<p>2015-07-21 08:15:36<br>你一直坚持着最后失败了，就是固执不懂变通。中途转向失败了，就是没有再坚持最后一公里。相反，如果你一直坚持着最后成事了，那就是无所畏惧一往无前；转向成功了，那就是灵活柔性随需应变。可见选择是一件多么艰难而奇妙的事。是沉没的成本还是沉默的坚持，都是你自己的判断和选择，有时候是命数，有时候是形式，只要是自己选择，接受就好了，只能这样。</p>
<p>2015-07-21 22:48:25<br>曾经有位古人说过，如果你手里有一把锤子，所有东西看上去都像钉子。还有一位今人说过，如果你有一个钉子，就会满大街找锤子！</p>
<p>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>鸡汤</tag>
      </tags>
  </entry>
  <entry>
    <title>开放虚拟化格式之OVF-OVA</title>
    <url>/2015/07/12/%E5%BC%80%E6%94%BE%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A0%BC%E5%BC%8F%E4%B9%8BOVF-OVA/</url>
    <content><![CDATA[<p>遇到Sphere6.0 (esxi6 )导出的OVF虚拟机模板在Vmware WorkStation 9和VmWare WorkStation11中导入报错的问题，暂改成OVA格式进行数据交换。</p>
<hr>
<a id="more"></a>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p><img src="errorInfo.png" alt="导入失败，未通过 OVF 规范一致性或虚拟硬件合规性检查。请单击“重试”放松 OVF 规范与虚拟硬件合规性检查，并重新尝试导入"></p>
<h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p>以OVA格式进行数据交换<br>VMware导出时将后缀改为OVA后到处；ESXI导出时选OVA</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="OVF"><a href="#OVF" class="headerlink" title="OVF"></a>OVF</h2><p>OVF（Open Virtualization Format：开放虚拟化格式 ）<br>OVF是一种开源的文件规范，它描述了一个开源、安全、有效、可拓展的便携式虚拟打包以及软件分布格式，它一般有几个部分组成，分别是ovf文件、mf文件、cert文件、vmdk文件和iso文件。</p>
<h2 id="OVA"><a href="#OVA" class="headerlink" title="OVA"></a>OVA</h2><p>OVA（Open Virtualization Appliance：开放虚拟化设备）<br>OVA包是一个单一的文件，所有必要的信息都封装在里面。OVA文件则采用.tar文件扩展名,包含了一个OVF 包中所有文件类型。这样OVA单一的文件格式使得它非常便携。</p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>EXSI</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘阵列配置</title>
    <url>/2015/07/12/%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>新购进一台戴尔塔式服务器，机器3*300G的硬盘默认已做RAID5配置，新增硬盘需配置磁盘阵列  </p>
<h1 id="RAID容量计算器"><a href="#RAID容量计算器" class="headerlink" title="RAID容量计算器"></a>RAID容量计算器</h1><p>配置前，可根据硬盘数和RAID级别，可计算配置后的硬盘实际可用容量<br>参考计算工具</p>
<ul>
<li><a href="http://www.ab126.com/web/2879.html">RAID容量计算器</a></li>
<li><a href="http://www.raid-calculator.com/default.aspx">raid-calculator</a></li>
</ul>
<hr>
<a id="more"></a>
<h1 id="RAID基础知识"><a href="#RAID基础知识" class="headerlink" title="RAID基础知识"></a>RAID基础知识</h1><h2 id="RAID-0"><a href="#RAID-0" class="headerlink" title="RAID 0"></a>RAID 0</h2><p><img src="raid0.gif" alt="raid0"></p>
<ul>
<li>特点：高性能 低稳定性 中等成本</li>
<li>RAID0又称为Stripe（条带化）或Striping，它代表了所有RAID级别中最高的存储性能。</li>
<li>RAID0的缺点是不提供数据冗余，因此一旦用户数据损坏，损坏的数据将无法得到恢复。</li>
<li>RAID 0具有的特点，使其特别适用于对性能要求较高，而对数据安全不太在乎的领域，如图形工作站等。</li>
<li>对于个人用户，RAID 0也是提高硬盘存储性能的绝佳选择。</li>
</ul>
<h2 id="RAID-1"><a href="#RAID-1" class="headerlink" title="RAID 1"></a>RAID 1</h2><p><img src="raid1.gif" alt="raid1"></p>
<ul>
<li>特点：高稳定性 普通性能 中等成本</li>
<li>RAID 1又称为Mirror或Mirroring（镜像），它的宗旨是最大限度的保证用户数据的可用性和可修复性。 </li>
<li>RAID 1的操作方式是把用户写入硬盘的数据百分之百地自动复制到另外一个硬盘上。</li>
<li>Mirror虽不能提高存储性能，但由于其具有的高数据安全性，使其尤其适用于存放重要数据，如服务器和数据库存储等领域。</li>
</ul>
<h2 id="RAID-5"><a href="#RAID-5" class="headerlink" title="RAID 5"></a>RAID 5</h2><p><img src="raid5.gif" alt="raid5"></p>
<ul>
<li>特点：高性能 中等稳定性 中等成本</li>
<li>RAID 5 是一种存储性能、数据安全和存储成本兼顾的存储解决方案。 </li>
<li>RAID 5可以理解为是RAID 0和RAID 1的折衷方案。</li>
<li>RAID 5可以为系统提供数据安全保障，但保障程度要比Mirror低而磁盘空间利用率要比Mirror高。</li>
<li>RAID 5具有和RAID 0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，存储成本相对较低。</li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>RAID</tag>
        <tag>硬件</tag>
      </tags>
  </entry>
  <entry>
    <title>IIS与Tomcat共享80端口</title>
    <url>/2015/08/03/IIS%E4%B8%8ETomcat%E5%85%B1%E4%BA%AB80%E7%AB%AF%E5%8F%A3/</url>
    <content><![CDATA[<p>微信公众号有80端口要求，但是80端口已运行了一个项目，如何将后端J2EE实现的服务集成到80端口，即Tomcat集成进IIS。<br>调研了三种方案，Apache Tomcat Connector（isapi_redirect实现）、ARR（IIS中的反向代理）和 IIS2Tomcat(BonCode AJP实现)，按照最轻量最简洁的部署要求，最终采用AJP实现。</p>
<hr>
<a id="more"></a>
<h1 id="isapi-redirect"><a href="#isapi-redirect" class="headerlink" title="isapi_redirect"></a>isapi_redirect</h1><p><a href="http://tomcat.apache.org/connectors-doc/webserver_howto/iis.html">官方参考</a><br>实现思路： </p>
<ol>
<li>The IIS-Tomcat redirector is an IIS plugin (filter + extension), IIS load the redirector plugin and calls its filter function for each in-coming request.</li>
<li>The filter then tests the request URL against a list of URI-paths held inside uriworkermap.properties, If the current request matches one of the entries in the list of URI-paths, the filter transfers the request to the extension.</li>
<li>The extension collects the request parameters and forwards them to the appropriate worker using the defined protocol like ajp13.</li>
<li>The extension collects the response from the worker and returns it to the browser<br>配置注册表，DLL等步骤繁琐，易出错，如官方所说你很难一次性配置成功-_-</li>
</ol>
<h1 id="ARR"><a href="#ARR" class="headerlink" title="ARR"></a>ARR</h1><p>ARR：Application Request Routing，类似Nginx的反向代理<br><a href="http://www.iisadmin.co.uk/?p=326">配置教程</a><br>ARR is a good starting point if you want to connect Apache Tomcat to IIS 7, however, there are some issues especially under load that make this less than ideal solution. </p>
<ol>
<li>There are still differences in the way headers are handled between ARR and Tomcat and not all are transferred.  </li>
<li>ARR will be heavier on the network as it requires that http data is transferred in full byte length without being able to take advantage of binary compression and byte encoding the AJP protocol offers.  </li>
<li>Under load ARR will not be aware of Tomcat thread handling resulting in unnecessarily dropped connections. </li>
<li>Secure (https) connections cannot be easily handled if tomcat needs to be aware of certificates used. </li>
</ol>
<h1 id="AJP"><a href="#AJP" class="headerlink" title="AJP"></a>AJP</h1><p>AJP：Apache JServ Protocol version<br><a href="https://github.com/Bilal-S/iis2tomcat">项目地址</a><br><a href="http://tomcatiis.riaforge.org">下载地址（需翻墙）</a><br><a href="http://blog.csdn.net/zhang_hui_cs/article/details/9399373#reply">参考博客</a><br><a href="http://v.youku.com/v_show/id_XNTg1MTgyODgw.html">详细配置视频教程</a>  </p>
<h2 id="默认网站二级应用程序配置要点"><a href="#默认网站二级应用程序配置要点" class="headerlink" title="默认网站二级应用程序配置要点"></a>默认网站二级应用程序配置要点</h2><ol>
<li>在IIS下新增网站examples，或者在默认网站中新增应用程序examples,物理路径指向<code>｛catalina_home｝/webapps/examples</code>；</li>
<li>执行Connector_Setup.exe安装，默认参数即可，选择指定的IIS网站，如examples；</li>
<li>应用程序池的托管管道模式设置为集成；</li>
<li>在examples根目录新增配置BIN目录（包含BonCodeAJP13.dll、BonCodeIIS.dll），并在根目录新增web.config，内容如下：</li>
</ol>
<ul>
<li>完整配置</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">validation</span> <span class="attr">validateIntegratedModeConfiguration</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">handlers</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCodeForAll"</span> <span class="attr">path</span>=<span class="string">"*"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">resourceType</span>=<span class="string">"Unspecified"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-JSP-Handler"</span> <span class="attr">path</span>=<span class="string">"*.jsp"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-CFC-Handler"</span> <span class="attr">path</span>=<span class="string">"*.cfc"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-CFM-Handler"</span> <span class="attr">path</span>=<span class="string">"*.cfm"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">handlers</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">defaultDocument</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">files</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">add</span> <span class="attr">value</span>=<span class="string">"index.jsp"</span> /&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">add</span> <span class="attr">value</span>=<span class="string">"index.cfm"</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">files</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">defaultDocument</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>精简配置</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">validation</span> <span class="attr">validateIntegratedModeConfiguration</span>=<span class="string">"false"</span>/&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>若完整配置报错，采用精简配置即可。</p>
<h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><ol>
<li>在唯一密钥属性“name”设置为“BonCode-Tomcat-JSP-Handler”时，无法添加类型为“add”的重复集合项<br>解决：改用精简配置</li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>J2EE</tag>
        <tag>Web服务器</tag>
        <tag>IIS</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Python安装升级教程</title>
    <url>/2015/08/05/Python%E5%AE%89%E8%A3%85%E5%8D%87%E7%BA%A7%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="升级前安装依赖"><a href="#升级前安装依赖" class="headerlink" title="升级前安装依赖"></a>升级前安装依赖</h1><p><code>yum groupinstall &quot;Development tools&quot;</code></p>
<h1 id="Python-2-7-9-下载-gt-解压-gt-编译-gt-安装"><a href="#Python-2-7-9-下载-gt-解压-gt-编译-gt-安装" class="headerlink" title="Python 2.7.9 下载&gt;解压&gt;编译&gt;安装"></a>Python 2.7.9 下载&gt;解压&gt;编译&gt;安装</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;www.python.org&#x2F;ftp&#x2F;python&#x2F;2.7.9&#x2F;Python-2.7.9.tgz </span><br><span class="line">tar jxvf Python-2.7.9.tgz   </span><br><span class="line">mv Python-2.7.9  python</span><br><span class="line">cd python</span><br><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python</span><br><span class="line">make &amp;&amp; make altinstall</span><br></pre></td></tr></table></figure>
<ul>
<li>关于altinstall<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> Warning</span><br><span class="line">make install can overwrite or masquerade the python binary. make altinstall is therefore recommended instead of make install since it only installs exec_prefix&#x2F;bin&#x2F;pythonversion.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="修改系统默认Python"><a href="#修改系统默认Python" class="headerlink" title="修改系统默认Python"></a>修改系统默认Python</h1><ol>
<li>查看已有python版本<br><code>python -V</code></li>
<li>查看Python版本<br><code>/usr/local/python/bin/python2.7 -V</code></li>
<li>将系统默认Python改为新安装的Python<br><code>ln -fs /usr/local/python/bin/python2.7 /usr/bin/python</code></li>
</ol>
<h1 id="yum无法运行问题"><a href="#yum无法运行问题" class="headerlink" title="yum无法运行问题"></a>yum无法运行问题</h1><p>进行更改后，yum会无法运行了。修改/usr/bin/yum文件，将第一行的<br><code>#!/usr/bin/python</code><br>中的python改为系统原有的python版本，如下：<br><code>#!/usr/bin/python2.6</code>  </p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>《谜踪之国》读书笔记</title>
    <url>/2015/07/21/%E3%80%8A%E8%B0%9C%E8%B8%AA%E4%B9%8B%E5%9B%BD%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>谜踪之国-天下霸唱<br>探险类的，没有藏地密码写的精彩</p>
<hr>
<a id="more"></a>
<h1 id="第三话-海森堡不确定原理"><a href="#第三话-海森堡不确定原理" class="headerlink" title="第三话　海森堡不确定原理"></a>第三话　海森堡不确定原理</h1><p>2015-07-14 13:43:29<br>世事茫茫如大海，人生何处无风波。</p>
<p>2015-07-14 19:12:50<br>当可执其端而理其绪，举一隅而知三隅；随机生变，鬼神莫测；分寸即定，任意纵横；通篇玩熟，定教四海扬名</p>
<p>2015-07-17 13:47:09<br>好花不常开，好景不常在</p>
<p>2015-07-17 14:20:27<br>见不尽者，是天下之事；悟不尽者，是天下之理”</p>
<p>2015-07-22 13:01:01<br>万物的命运，皆是由无数个点所组成的一条曲线，没有人知道线的中间会发生什么，或是会遇到什么，只是所有的线，最终都会前往同一个终点，这个终点就是死亡，绝不存在例外，曲线中出现的任何一个点，也都不可能对终点产生影响。</p>
<p>2015-07-25 22:07:56<br>近代科学观念支持大爆炸形成宇宙的理论，“宇”和“宙”就是时间与空间的坐标，这和中国传统观念里“盘古开天地”之类的传说有些相似，据说以前只有一片混沌，清浊不分，从盘古产生时间的那一刻被称为“零秒”，而在“零秒坐标”出现之前，还没有时间存在。</p>
<p>2015-07-25 22:09:21<br>从前有句古话是“蝶梦庄周未可知”，是说庄周以为自己在梦中变为了蝴蝶，其实也有可能庄周自己才是蝴蝶做的一场梦，这句话可以用来比喻真实的不确定性，那些看得见摸得到的东西，却未必真实可信。</p>
<p>2015-07-26 17:44:31<br>说开天地怕、道破鬼神惊</p>
<p>2015-07-26 17:48:18<br>并不是出现了“原因”才会产生“结果”，而是结果造就了复杂的原因。没有结果的原因不能称为原因，正是由于结果的存在，才会使前边发生的事件成为原因。因果之间的关系就像一株参天大树，注定成为事实的结果是根，原因则是枝杈纵横交错的茂密树冠，事先掌握了结果的人，就能洞悉命运的规律。</p>
<p>2015-08-07 19:36:06<br>混沌定律，基本上分为三个部分。事物发展运行的轨迹好像是多元化的，存在着无数种可能性，不管你预先布置得如何周密，事到临头也总会出现意料之外的情况，所谓计划赶不上变化，是对第一定律的最好概括。第二定律说白了就是‘怕什么来什么’，你越是不想让它发生的事，它发生的概率就越大。比方说我有块面包，正面抹满了黄油，又不小心失手把它掉在了名贵的地毯上，面包正反两面朝下的概率看起来似乎差不多，其实不管面包掉落多少次，抹了黄油的那一面都会永远朝下，因为事情总是会往咱们最不想看到的方向发展，这既是摩非原理——宿命的重力。另外还有第三定律……”</p>
<p>2015-08-26 09:13:51<br>挫折只是成功者的勋章，疾风劲草，方显英雄本色，洪波汹涌，愈见生命不息。</p>
<p>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>小说</tag>
      </tags>
  </entry>
  <entry>
    <title>一路见识的SQL/NOSQL数据库ORM</title>
    <url>/2015/08/16/%E4%B8%80%E8%B7%AF%E8%A7%81%E8%AF%86%E7%9A%84SQL-NOSQL%E6%95%B0%E6%8D%AE%E5%BA%93ORM/</url>
    <content><![CDATA[<p>一路走来，关系数据库到非关系数据库，不觉已接触了不少的ORM框架也在这些ORM框架的基础上积累了一些通用的DAO，下面从 <em>学习笔记（原理、优势、劣势）</em> 和 <em>个人总结（踩过的坑，注意事项）</em> 两方面展开描述：</p>
<hr>
<a id="more"></a>
<h1 id="LINQ"><a href="#LINQ" class="headerlink" title="LINQ"></a>LINQ</h1><p>LINQ全称Language Integrated Query<br>大学期间接触DotNet/C#一般会对LINQ有所了解，印象中是封装了DAO层的数据库连接，可以通过一些如select/where/group by等关键词以熟悉的代码形式进行数据CRUD操作<br>下面是官方的LINQ的官方描述</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LINQ to SQL 是 .NET Framework 3.5 版的一个组件，提供了用于将关系数据作为对象管理的运行时基础结构。</span><br><span class="line">在 LINQ to SQL 中，关系数据库的数据模型映射到用开发人员所用的编程语言表示的对象模型。</span><br><span class="line">当应用程序运行时，LINQ to SQL 会将对象模型中的语言集成查询转换为 SQL，然后将它们发送到数据库进行执行。</span><br><span class="line">当数据库返回结果时，LINQ to SQL 会将它们转换回您可以用您自己的编程语言处理的对象。</span><br><span class="line">使用 Visual Studio 的开发人员通常使用对象关系设计器，它提供了用于实现许多 LINQ to SQL 功能的用户界面。</span><br></pre></td></tr></table></figure>
<p>后来DotNET没深入学习了，工作的技术选型都是J2EE和一敏捷脚本类（Python）的方案，不做太多总结</p>
<h1 id="Spring-JDBC"><a href="#Spring-JDBC" class="headerlink" title="Spring-JDBC"></a>Spring-JDBC</h1><p><a href="http://docs.spring.io/spring/docs/current/spring-framework-reference/html/jdbc.html">官方文档</a><br>Spring Framework JDBC会封装处理JDBC底层的细节，让JDBC更友好，具体如下</p>
<p>Spring-JDBC自动处理的</p>
<ul>
<li>Open  connection.</li>
<li>Prepare and execute the statement.</li>
<li>Set up the loop to iterate through the results (if any).</li>
<li>Process any exception.</li>
<li>Handle transactions.</li>
<li>Close the connection, statement and resultset.<br>用户需设置的</li>
<li>Define connection parameters.</li>
<li>Specify the SQL statement.</li>
<li>Declare parameters and provide parameter values</li>
<li>Do the work for each iteration.</li>
</ul>
<h2 id="Spring-JDBC的使用概要"><a href="#Spring-JDBC的使用概要" class="headerlink" title="Spring-JDBC的使用概要"></a>Spring-JDBC的使用概要</h2><ul>
<li><p>JdbcTemplate - 这是经典的也是最常用的Spring对于JDBC访问的方案。这也是最低级别的封装, 其他的工作模式事实上在底层使用了JdbcTemplate作为其底层的实现基础。JdbcTemplate在JDK 1.4以上的环境上工作得很好。</p>
</li>
<li><p>NamedParameterJdbcTemplate - 对JdbcTemplate做了封装，提供了更加便捷的基于命名参数的使用方式而不是传统的JDBC所使用的“?”作为参数的占位符。这种方式在你需要为某个SQL指定许多个参数时，显得更加直观而易用。该特性必须工作在JDK 1.4以上。</p>
</li>
<li><p>SimpleJdbcTemplate - 这个类结合了JdbcTemplate和NamedParameterJdbcTemplate的最常用的功能，同时它也利用了一些Java5的特性所带来的优势，例如泛型、varargs和autoboxing等，从而提供了更加简便的API访问方式。需要工作在Java 5以上的环境中。</p>
</li>
<li><p>SimpleJdbcInsert 和 SimpleJdbcCall - 这两个类可以充分利用数据库元数据的特性来简化配置。通过使用这两个类进行编程，你可以仅仅提供数据库表名或者存储过程的名称以及一个Map作为参数。其中Map的key需要与数据库表中的字段保持一致。这两个类通常和SimpleJdbcTemplate配合使用。这两个类需要工作在JDK 5以上，同时数据库需要提供足够的元数据信息。</p>
</li>
<li><p>RDBMS 对象包括MappingSqlQuery, SqlUpdate and StoredProcedure - 这种方式允许你在初始化你的数据访问层时创建可重用并且线程安全的对象。该对象在你定义了你的查询语句，声明查询参数并编译相应的Query之后被模型化。一旦模型化完成，任何执行函数就可以传入不同的参数对之进行多次调用。这种方式需要工作在JDK 1.4以上。</p>
</li>
</ul>
<p>优势：强大、优雅、轻量、持续更新维护，与JDBC相对，减少了大量的冗余DAO层代码</p>
<h2 id="setMaxRows和setFetchSize"><a href="#setMaxRows和setFetchSize" class="headerlink" title="setMaxRows和setFetchSize"></a>setMaxRows和setFetchSize</h2><p>They do different things.<br>The setMaxRows = number of rows that can be returned overall.<br>setFetchSize = number that will be returned in each database roundtrip i.e.<br>setFetchSize Gives the JDBC driver a hint as to the number of rows that should be fetched from the database when more rows are needed for ResultSet objects genrated by this Statement.<br>setMaxRows Sets the limit for the maximum number of rows that any ResultSet object generated by this Statement object can contain to the given number.</p>
<h2 id="Spring-JDBC-Spring-JPA"><a href="#Spring-JDBC-Spring-JPA" class="headerlink" title="Spring JDBC +Spring JPA"></a>Spring JDBC +Spring JPA</h2><p>缓存可以用第三方，例如ehcached,或者mc</p>
<h2 id="拼接SQL"><a href="#拼接SQL" class="headerlink" title="拼接SQL"></a>拼接SQL</h2><p>拼接SQL注意需特别注意字段值中存在转义字符（如”\”,”‘“）的情况，应使用类PreparedStatement中?方式替换变量执行CRUD操作</p>
<h1 id="Hibernate"><a href="#Hibernate" class="headerlink" title="Hibernate"></a>Hibernate</h1><h1 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h1><p>MyBatis的前身叫iBatis，本是apache的一个开源项目, 2010年这个项目由apache software foundation 迁移到了google code，并且改名为MyBatis。<br>MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。<br>Mybatis的功能架构分为三层：</p>
<ol>
<li>API接口层<br>提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。</li>
<li>数据处理层<br>负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。</li>
<li>基础支撑层<br>负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。</li>
</ol>
<h2 id="Mybatis与Hibernate比较"><a href="#Mybatis与Hibernate比较" class="headerlink" title="Mybatis与Hibernate比较"></a>Mybatis与Hibernate比较</h2><p>Mybatis：小巧、方便、高效、简单、直接、半自动、移植性低<br>Hibernate：强大、方便、高效、复杂、绕弯子、全自动、移植性高</p>
<h2 id="Mybatis应用场景"><a href="#Mybatis应用场景" class="headerlink" title="Mybatis应用场景"></a>Mybatis应用场景</h2><p>一直在用Hibnernate，抽取一个完善的DAO抽象类后会少很多工作，更受益与其更换数据库时超强的移植性，DAO层基本不作修改，更换数据库方言即可。但在以下场景时，Mybatis自有其可取之处：</p>
<ol>
<li>当无法对数据库结构做到控制和修改，Mybatis的灵活性将比hibernate更适合；</li>
<li>当系统数据处理量巨大，性能要求极为苛刻，这往往意味着我们必须通过经过高度优化的sql语句（或存储过程）才能达到系统性能设计指标，在这种情况下Mybatis会有更好的可控性和表现，可以进行细粒度的优化。</li>
</ol>
<h1 id="NOSQL"><a href="#NOSQL" class="headerlink" title="NOSQL"></a>NOSQL</h1><h2 id="Morphia"><a href="#Morphia" class="headerlink" title="Morphia"></a>Morphia</h2><h2 id="Jongo"><a href="#Jongo" class="headerlink" title="Jongo"></a>Jongo</h2><h2 id="Spring-Data-for-Hadoop"><a href="#Spring-Data-for-Hadoop" class="headerlink" title="Spring Data for Hadoop"></a>Spring Data for Hadoop</h2><h2 id="Kundera"><a href="#Kundera" class="headerlink" title="Kundera"></a>Kundera</h2><h1 id="Jackson-ObjectMapper"><a href="#Jackson-ObjectMapper" class="headerlink" title="Jackson-ObjectMapper"></a>Jackson-ObjectMapper</h1>]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>ORM</tag>
      </tags>
  </entry>
  <entry>
    <title>xmanager实现CentOS远程控制</title>
    <url>/2015/07/15/xmanager%E5%AE%9E%E7%8E%B0CentOS%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<p>本文主要介绍通过Xmanager连接CentOS远程桌面时，在CentOS远程机器和Windows客户端需要做的一些配置。</p>
<hr>
<a id="more"></a>
<h1 id="Xmanager简介"><a href="#Xmanager简介" class="headerlink" title="Xmanager简介"></a>Xmanager简介</h1><p>Xmanager 全称Netsarang Xmanager，是国外一套非常优秀的远程监控软件。在UNIX/Linux和Windows网络环境中，Xmanager是较好的连通解决方案。通过Xmanager连接Linux远程桌面进行图形化管理其实就是利用了Xmanager套装里面的Xbrowser程序。<br>Linux远程图形化管理除了Xbrowser，还有同样优秀的VNC。</p>
<p>特点包括：<br>可通过Xcongfig工具设置多个Xmanager设置；<br>支持多用户的Windows终端环境；<br>支持多个IP地址；<br>支持本地资源数据库；<br>通过热键转换键盘映射；<br>支持多窗口下的Windows打印功能等</p>
<h1 id="CentOS远程机器配置"><a href="#CentOS远程机器配置" class="headerlink" title="CentOS远程机器配置"></a>CentOS远程机器配置</h1><ol>
<li>安装gdm<br>yum -y install gdm<br>配置系统为图形模式，打开/etc/inittab，修改为id:5:initdefault: (若已为5则不需修改)</li>
<li>启用图形化界面<br><code>vim /etc/inittab</code>，3改为5<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">id:5:initdefault:</span><br></pre></td></tr></table></figure></li>
<li><p>配置gdm参数<br><code>vim /etc/gdm/custom.conf</code>，在[security]和[xdmcp]字段下分别添加如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[daemon]</span><br><span class="line">[security]</span><br><span class="line">AllowRemoteRoot&#x3D;true</span><br><span class="line">[xdmcp]</span><br><span class="line">Port&#x3D;177</span><br><span class="line">Enable&#x3D;1</span><br><span class="line">[greeter]</span><br><span class="line">[chooser]</span><br><span class="line">[debug]</span><br></pre></td></tr></table></figure>
</li>
<li><p>防火墙设置</p>
</li>
</ol>
<ul>
<li><p>关闭防火墙<br>临时关闭：<code>service iptables stop</code><br>永久关闭：<code>checkcfg iptables off</code></p>
</li>
<li><p>在防火墙上打开udp协议177 端口<br><code>iptables -A INPUT -p tcp --dport 177 -j ACCEPT</code><br><code>service iptables save</code></p>
</li>
</ul>
<ol>
<li>重启机器<br><code>reboot</code></li>
</ol>
<h1 id="Windows客户端配置"><a href="#Windows客户端配置" class="headerlink" title="Windows客户端配置"></a>Windows客户端配置</h1><ol>
<li><p>XManager远程桌面连接<br>在Windows上打开XBrowser通过IP即可远程连接CentOS<br>Xbrowser&gt;工具&gt;选项&gt;添加主机&gt;连接</p>
</li>
<li><p>Xshell远程桌面连接，<br>Xshell隧道连接&gt;执行<code>gnome-panel</code>命令<br>备注：只能访问用户文件夹</p>
</li>
</ol>
<h1 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h1><p><img src="Xbrowser主界面.png" alt="Xbrowser主界面"><br><img src="Xbrowser远程控制.png" alt="Xbrowser远程控制"></p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Xmanager</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown常用语法</title>
    <url>/2015/09/18/Markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<p>记录一些markdown的语法和使用示例</p>
<a id="more"></a>
<h1 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h1><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><h1 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h1><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><blockquote>
<p><code>![geosmart](https://avatars1.githubusercontent.com/u/3156608?v=3&amp;s=64)</code><br><img src="https://avatars1.githubusercontent.com/u/3156608?v=3&amp;s=64" alt="geosmart"></p>
</blockquote>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><blockquote>
<p><code>[geosmart](geosmart.github.io)</code><br><a href="geosmart.github.io">geosmart</a></p>
</blockquote>
<h1 id="粗体"><a href="#粗体" class="headerlink" title="粗体"></a>粗体</h1><h1 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h1><h1 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h1><blockquote>
<p><code>~~这是一条删除线~~</code><br><del>这是一条删除线</del></p>
</blockquote>
<h1 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h1><hr>
<hr>
<h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">|Header |Column 1 | Column 2 | Column 3  |</span><br><span class="line">|:--- |:---- |:----:| ----:|</span><br><span class="line">|1. Row| is | is | is  |</span><br><span class="line">|2. Row| left | nicely | right  |</span><br><span class="line">|3. Row| aligned | centered | aligned  |</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Header</th>
<th style="text-align:left">Column 1</th>
<th style="text-align:center">Column 2</th>
<th style="text-align:right">Column 3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1. Row</td>
<td style="text-align:left">is</td>
<td style="text-align:center">is</td>
<td style="text-align:right">is</td>
</tr>
<tr>
<td style="text-align:left">2. Row</td>
<td style="text-align:left">left</td>
<td style="text-align:center">nicely</td>
<td style="text-align:right">right</td>
</tr>
<tr>
<td style="text-align:left">3. Row</td>
<td style="text-align:left">aligned</td>
<td style="text-align:center">centered</td>
<td style="text-align:right">aligned</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven使用笔记</title>
    <url>/2015/09/15/Maven%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="关于Maven"><a href="#关于Maven" class="headerlink" title="关于Maven"></a>关于Maven</h1><p>Maven是基于项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。  </p>
<p>本文记录Maven开发过程中常用的脚本和遇到的问题。</p>
<hr>
<a id="more"></a>
<h1 id="Maven-Dependency"><a href="#Maven-Dependency" class="headerlink" title="Maven Dependency"></a>Maven Dependency</h1><p>在POM 4中，<dependency>中还引入了<scope>，它主要管理依赖的部署。目前<scope>可以使用5个值：</p>
<pre><code>* compile，缺省值，适用于所有阶段，会随着项目一起发布。
* provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。
* runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。
* test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。
* system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。
</code></pre><h1 id="Maven常用指令"><a href="#Maven常用指令" class="headerlink" title="Maven常用指令"></a>Maven常用指令</h1><p><code>package</code>：打包<br><code>war:exploded</code>：编译不生成war包<br><code>install</code>：安装到本地资源库<br>     eg：<code>mvn install:install-file -Dfile=lt.util-1.0.jar -DgroupId=com.lt -DartifactId=util -Dversion=1.0 -Dpackaging=jar</code><br><code>process-resources</code>：编译并打包资源<br>新建项目：<code>mvn archetype:generate -DgroupId=com.lt -DartifactId=uadb.etl -DarchetypeArtifactIdmaven-archetype-webapp -DinteractiveMode=false</code></p>
<h1 id="maven-dependency-exclusion"><a href="#maven-dependency-exclusion" class="headerlink" title="maven dependency exclusion"></a>maven dependency exclusion</h1><h1 id="maven远程库"><a href="#maven远程库" class="headerlink" title="maven远程库"></a>maven远程库</h1><ul>
<li><p><a href="https://search.maven.org/#search">https://search.maven.org/#search</a></p>
</li>
<li><p><a href="http://maven-repository.com/">http://maven-repository.com/</a></p>
</li>
<li><p><a href="http://mvnrepository.com/">http://mvnrepository.com/</a></p>
</li>
<li><p><a href="http://repository.apache.org/snapshots/">http://repository.apache.org/snapshots/</a></p>
</li>
<li><p><a href="http://maven.outofmemory.cn/">http://maven.outofmemory.cn/</a></p>
</li>
</ul>
<p>当然，在国内还是老实参考<a href="http://maven.oschina.net/help.html">开源中国社区的教程</a>配置maven<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-osc<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus osc<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.oschina.net/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-osc-thirdparty<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>thirdparty<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus osc thirdparty<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.oschina.net/content/repositories/thirdparty/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.1maven.com/index.html">maven依赖离线下载-1maven</a></p>
<h1 id="上传项目到Maven-Central-Repository"><a href="#上传项目到Maven-Central-Repository" class="headerlink" title="上传项目到Maven Central Repository"></a>上传项目到Maven Central Repository</h1><h2 id="Maven本地开发"><a href="#Maven本地开发" class="headerlink" title="Maven本地开发"></a>Maven本地开发</h2><ul>
<li>下载apache-maven</li>
<li>设置本地库路径<br>在maven\config\settings.xml中设置本地库路径：<code>&lt;localRepository&gt;D:\Dev\Maven-Respository&lt;/localRepository&gt;</code></li>
<li>在Myeclipse中设置安装路径<br>在<code>Window&gt;Preferences&gt;Myeclipse&gt;Maven4Myeclipse&gt;Installations</code>中执行Add加入本地maven路径<br>在<code>Window&gt;Preferences&gt;Myeclipse&gt;Maven4Myeclipse&gt;User Settings</code>中Browser选择maven\config\settings.xml，执行Update Settings，Reindex</li>
</ul>
<h2 id="maven引用本地jar包"><a href="#maven引用本地jar包" class="headerlink" title="maven引用本地jar包"></a>maven引用本地jar包</h2><p>假设将包htmlparser.jar放入了项目下的lib目录中 -&gt; ${project}/lib/htmlparser.jar,则pom.xml中应该配置如下：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.htmlparser<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>htmlparser<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;project.basedir&#125;/lib/htmlparser.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Maven项目聚合"><a href="#Maven项目聚合" class="headerlink" title="Maven项目聚合"></a>Maven项目聚合</h2><p>为解决多个依赖项目自动打包，可通过聚合maven项目解决<br>pom示例<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.util<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>util.aggregation<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>util.aggregation<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">modules</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.common<span class="tag">&lt;/<span class="name">module</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.jdbc<span class="tag">&lt;/<span class="name">module</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.web<span class="tag">&lt;/<span class="name">module</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.geo<span class="tag">&lt;/<span class="name">module</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.hibernate<span class="tag">&lt;/<span class="name">module</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">modules</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><br>通过<code>mvn clean install</code>进行打包</p>
<h2 id="Maven项目依赖继承"><a href="#Maven项目依赖继承" class="headerlink" title="Maven项目依赖继承"></a>Maven项目依赖继承</h2><p><code>uadb.parent</code>项目<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.uadb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">true<span class="comment">&lt;!-- 项目属性 --&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- framework --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">jdk.version</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">jdk.version</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- test --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.8.2<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- encode --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line"></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">truetruetrue<span class="comment">&lt;!--test --&gt;</span></span><br><span class="line">truetruetrue<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">truetruetruetrue<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">truetruetruetrue<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">truetruetruetrue<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;junit.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">truetruetruetrue<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">truetruetrue<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><br>child项目引用parent项目<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.etl.pre<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>uadb.etl.pre<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.uadb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">true<span class="comment">&lt;!-- 项目属性 --&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- framework --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">jdk.version</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">jdk.version</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- test --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.8.2<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></span><br><span class="line">truetrue<span class="comment">&lt;!-- encode --&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">true<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">truetruetrue<span class="comment">&lt;!--test --&gt;</span></span><br><span class="line">  		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="复制依赖项"><a href="#复制依赖项" class="headerlink" title="复制依赖项"></a>复制依赖项</h1><p>dependency:copy-dependencies<br>输出到target/deps</p>
<h1 id="在Github搭建个人Maven仓库"><a href="#在Github搭建个人Maven仓库" class="headerlink" title="在Github搭建个人Maven仓库"></a>在Github搭建个人Maven仓库</h1><h2 id="deploy到本地目录"><a href="#deploy到本地目录" class="headerlink" title="deploy到本地目录"></a>deploy到本地目录</h2><h2 id="本地目录提交到gtihub上"><a href="#本地目录提交到gtihub上" class="headerlink" title="本地目录提交到gtihub上"></a>本地目录提交到gtihub上</h2><h2 id="配置github地址为仓库地址"><a href="#配置github地址为仓库地址" class="headerlink" title="配置github地址为仓库地址"></a>配置github地址为仓库地址</h2><h1 id="Maven问题记录"><a href="#Maven问题记录" class="headerlink" title="Maven问题记录"></a>Maven问题记录</h1><ul>
<li>本地库有改jar包但是依旧无法编译<br>本地下载的Zip已损坏，删除本地库中的jar文件和目录，重新从远处库下载</li>
</ul>
<ul>
<li><p>远程库只能下载索引，不能下载jar！<br>日志：The container ‘Maven Dependencies’ references non existing library ‘D:\soft\Maven\Maven-Respository\org\apache\ant\ant\1.9.3\ant-1.9.3.jar’<br>解决：<br>So I get you are using Eclipse with the M2E plugin. Try to update your Maven configuration : In the Project Explorer, right-click on the project, Maven -&gt; Update project.<br>If the problem still remains, try to clean your project: right-click on your pom.xml, Run as -&gt; Maven build (the second one). Enter “clean package” in the Goals fields. Check the Skip Tests box. Click on the Run button.</p>
</li>
<li><p>cannot find maven installation embedded<br>Simply remove the external maven installation. When you restart eclipse, the embedded maven will reappear.</p>
</li>
<li><p>install offline问题<br>The repository system is offline but the artifact org.apache.maven.plugins:maven-install-plugin:pom:2.3.1 is not available in the local repository.<br>取消勾选offline选项,重新执行install</p>
</li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>J2EE</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP学习笔记</title>
    <url>/2015/09/11/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>记录一些NLP学习过程中的专业名词</p>
<hr>
<a id="more"></a>
<h1 id="专业名词"><a href="#专业名词" class="headerlink" title="专业名词"></a>专业名词</h1><ul>
<li>NLP(Natural Language Processing)：自然语言处理，主要涉及计算机处理人类语言的数据结构和算法的计算科学。</li>
<li><p>Ontology本体：本体是一种描述术语（包含哪些词汇）及术语间关系（描述苹果、香蕉、水果之间的关系）的概念模型。<em>符号到本体的某种映射</em><br>本体是表达概念之间关系的有效手段，它是共享概念模型的明确的形式化规范说明，它在共享范围内描述了领域中的概念及概念之间的关系，使其具有明确的、形式化的定义,从而实现人机之间以及机器之间的信息交互、知识共享与重用。</p>
</li>
<li><p>FSM(Finite-state machine)有限状态机：称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。</p>
</li>
<li><p>GATE(General Architecture for Text Engineering)文本工程通用框架</p>
</li>
<li><p>IR(Information Resolve)信息检索</p>
</li>
<li><p>IE(Information Extract)信息抽取</p>
</li>
<li><p>HMM(Hidden Markov Models)隐马尔科夫模型：一个隐马尔科夫模型它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。  </p>
</li>
</ul>
<blockquote>
<p>由一个向量和两个矩阵(pi,A,B)描述的隐马尔科夫模型对于实际系统有着巨大的价值，虽然经常只是一种近似，但它们却是经得起分析的。隐马尔科夫模型通常解决的问题包括：</p>
<ol>
<li>对于一个观察序列匹配最可能的系统——评估，使用前向算法（forward algorithm）解决；</li>
<li>对于已生成的一个观察序列，确定最可能的隐藏状态序列——解码，使用Viterbi 算法（Viterbi algorithm）解决；</li>
<li>对于已生成的观察序列，决定最可能的模型参数——学习，使用前向-后向算法（forward-backward algorithm）解决。<br><a href="http://www.cnblogs.com/skyme/p/4651331.html">HMM扩展阅读</a></li>
</ol>
</blockquote>
<h2 id="GATE专业名词"><a href="#GATE专业名词" class="headerlink" title="GATE专业名词"></a>GATE专业名词</h2><ul>
<li><p>LR(Language Resource)：语言资源，与数据相关的资源，比如词典、文档和本体(Ontology)等。其中一些语言组件需要和软件搭配使用（比如，WordNet 使用了 C 和 Prolog语言的 API 的用户查询接口），虽然其中涉及了软件，但是由于 API 也是为语言资源服务的，所以我们仍然把这些资源定义为语言组件。</p>
</li>
<li><p>PR(Processing Resource)：处理资源，表示主要算法实体，如，解析算法，生成算法或n-元模型（ngram）建模算法。</p>
</li>
<li><p>VR（Pisual Resource）: 可视化资源，指构成 GATE 的可视化界面 GUI 的相关资源。</p>
</li>
<li><p>CREOLE(a Collection of Reusable Objects for Language Engineering)可重用语言引擎对象集合，提供了文本解析、文本抽取、结果测算等众多插件</p>
</li>
<li><p>ANNIE</p>
</li>
<li><p>Corpus 语料库，文档的集合</p>
</li>
</ul>
<h2 id="行业名词"><a href="#行业名词" class="headerlink" title="行业名词"></a>行业名词</h2><ul>
<li><p>GTO：geography text ontology</p>
</li>
<li><p>iCERS ：Integrated Crime Emergency Response System</p>
</li>
</ul>
<blockquote>
<p>Integrated Crime Emergency Response System (iCERS) is a large-scale spatio-temporal system which integrates all sorts of crime emergency service resources and majors its features as common codes used for public emergency events reporting.</p>
</blockquote>
<ul>
<li>CE2M ：Crime Emergency Event Model</li>
</ul>
<blockquote>
<p>The ontology for Crime Emergency Event Model (CE2M) is recommended as an effective means to implement semantic level integration. CE2M is stratified into three levels: Event, Process and Action. CE2M constructs the vocabulary and the common model for exchange of iCERS information, thus it becomes the common comprehension of each business subsystems.</p>
</blockquote>
<h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><ul>
<li>《数学之美》科普阅读  </li>
<li>《统计自然语处理基础》阅读中…</li>
<li>《概率论》</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>SQLite数据库使用笔记</title>
    <url>/2015/09/15/SQLite%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="SQLite特点"><a href="#SQLite特点" class="headerlink" title="SQLite特点"></a>SQLite特点</h1><p>SQLite只支持库级锁，同时只能允许一个写操作。但SQLite尽量延迟申请X锁，直到数据块真正写盘时才申请X锁，非常巧妙而有效。</p>
<ol>
<li>SQLite支持3种线程模式:单线程,多线程,串行</li>
<li>可使用WAL（Write-Ahead Logging）模式时，写操作是append到WAL文件，而不直接改动数据库文件，因此数据库文件可以被同时读取。当执行checkpoint操作时，WAL文件的内容会被写回数据库文件。当WAL文件达到SQLITE_DEFAULT_WAL_AUTOCHECKPOINT（默认值是1000）页（默认大小是1KB）时，会自动使用当前COMMIT的线程来执行checkpoint操作。也可以关闭自动checkpoint，改为手动定期<br>checkpoint。jdbc可通过setJournalMode(JournalMode.WAL)/setJounalSizeLimit实现</li>
<li>事务是和数据库连接相关的，每个数据库连接（使用pager来）维护自己的事务，且同时只能有一个事务（但是可以用SAVEPOINT来实现内嵌事务）。</li>
</ol>
<hr>
<a id="more"></a>
<p><a href="http://www.sqlite.org/wal.html">官方文档</a><br><a href="http://www.cnblogs.com/wuhenke/archive/2011/11/20/2256618.html">sqlite在多线程下的应用</a></p>
<h2 id="WAL模式"><a href="#WAL模式" class="headerlink" title="WAL模式"></a>WAL模式</h2><ul>
<li>-shm文件包含-wal文件的数据索引，-shm文件提升-wal文件的读性能</li>
<li>如果-shm文件被删除，下次数据库连接时会自动新建一个-shm文件 </li>
<li>如果执行了checkpoint命令，-war文件可以删除</li>
</ul>
<h2 id="VACUUM命令"><a href="#VACUUM命令" class="headerlink" title="VACUUM命令"></a>VACUUM命令</h2><p>VACUUM命令用于重建数据库文件， 执行VACUUM 时，会拷贝整个数据库到Transient databases临时文件中，然后覆盖写回到原来的数据库文件中。<br>写回过程中会创建rollback journal or write-ahead log WAL file以保证transaction atomic。当vacuum执行完毕，临时文件被删除。   </p>
<p>重建数据库文件的原因有以下几点</p>
<ol>
<li>当大量数据被删除后，数据库文件中会有很多空块,空页和碎片，VACUUM rebuild数据库文件，移除这些空块，减少所占的磁盘空间</li>
<li>频繁的inserts, updates, and deletes 导致数据库文件中很多碎片，VACUUM 重建数据库文件使得表，索引连续的存储, 减少空闲页， 减少所占的磁盘空间</li>
<li>当page_size 或用pragma auto_vacuum 命令修改这两个值时， SQLite会自动执行VACUMM</li>
<li>VACUUM只对main数据库有效，对ATTACHED数据库无效</li>
<li>如果数据库中还有其他transaction， VACUUM将执行失败</li>
<li>除了使用VACUUM外，还可以使用PRAGMA auto_vacuum控制vacuum的执行<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PRAGMA auto_vacuum;</span><br><span class="line">PRAGMA auto_vacuum &#x3D; 0 | NONE | 1 | FULL | 2 | INCREMENTAL;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="synchronous参数"><a href="#synchronous参数" class="headerlink" title="synchronous参数"></a>synchronous参数</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PRAGMA synchronous &#x3D; FULL; (2)</span><br><span class="line">PRAGMA synchronous &#x3D; NORMAL; (1)</span><br><span class="line">PRAGMA synchronous &#x3D; OFF; (0)</span><br></pre></td></tr></table></figure>
<h2 id="FULL"><a href="#FULL" class="headerlink" title="FULL"></a>FULL</h2><p>当synchronous设置为FULL (2), SQLite数据库引擎在紧急时刻会暂停以确定数据已经写入磁盘。这使系统崩溃或电源出问题时能确保数据库在重起后不会损坏。FULL synchronous很安全但很慢。</p>
<h2 id="NORMAL"><a href="#NORMAL" class="headerlink" title="NORMAL"></a>NORMAL</h2><p>当synchronous设置为NORMAL, SQLite数据库引擎在大部分紧急时刻会暂停，但不像FULL模式下那么频繁。 NORMAL模式下有很小的几率(但不是不存在)发生电源故障导致数据库损坏的情况。但实际上，在这种情况 下很可能你的硬盘已经不能使用，或者发生了其他的不可恢复的硬件错误。</p>
<h2 id="OFF"><a href="#OFF" class="headerlink" title="OFF"></a>OFF</h2><p>设置为synchronous OFF (0)时，SQLite在传递数据给系统以后直接继续而不暂停。若运行SQLite的应用程序崩溃， 数据不会损伤，但在系统崩溃或写入数据时意外断电的情况下数据库可能会损坏。另一方面，在synchronous OFF时 一些操作可能会快50倍甚至更多。在SQLite 2中，缺省值为NORMAL.而在3中修改为FULL。  www.2cto.com</p>
<p>建议：<br>如果有定期备份的机制，而且少量数据丢失可接受，用OFF。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="提交-wal修改到数据库main文件"><a href="#提交-wal修改到数据库main文件" class="headerlink" title="提交-wal修改到数据库main文件"></a>提交-wal修改到数据库main文件</h2><p>执行<code>VACUUM</code>命令即可生成最新的数据库-db文件</p>
<h2 id="如何删除使用中的SQLite数据库"><a href="#如何删除使用中的SQLite数据库" class="headerlink" title="如何删除使用中的SQLite数据库"></a>如何删除使用中的SQLite数据库</h2><p><a href="http://stackoverflow.com/questions/991489/i-cant-delete-a-file-in-java">参考</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 添加System.gc()和Thread.sleep进行强制删除 </span></span><br><span class="line">System.gc();</span><br><span class="line">Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">FileDeleteStrategy.FORCE.delete(workFile);</span><br></pre></td></tr></table></figure>
<h2 id="SQLite开启WAL读写模式"><a href="#SQLite开启WAL读写模式" class="headerlink" title="SQLite开启WAL读写模式"></a>SQLite开启WAL读写模式</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SQLiteConfig config = <span class="keyword">new</span> SQLiteConfig();</span><br><span class="line">config.setOpenMode(SQLiteOpenMode.READWRITE);</span><br><span class="line">config.setJournalMode(JournalMode.WAL); </span><br><span class="line">dataSource.setConfig(config);</span><br></pre></td></tr></table></figure>
<h2 id="SQLite批量更新"><a href="#SQLite批量更新" class="headerlink" title="SQLite批量更新"></a>SQLite批量更新</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 批量更新</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> updateSqlList</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">batchUpdate</span><span class="params">(List&lt;String&gt; updateSqlList)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (updateSqlList.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123; </span><br><span class="line">trueConnection conn = dataSource.getConnection();</span><br><span class="line">trueStatement statement = conn.createStatement();</span><br><span class="line">true<span class="keyword">for</span> (String sql : updateSqlList) &#123;</span><br><span class="line">true  statement.addBatch(sql);</span><br><span class="line">true&#125;</span><br><span class="line">true<span class="keyword">int</span>[] count = statement.executeBatch();</span><br><span class="line"></span><br><span class="line">truelog.info(<span class="string">"SQLite-JDBC批量更新&#123;&#125;条"</span>, count.length);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">truee.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="sqlite除法运算保留小数问题"><a href="#sqlite除法运算保留小数问题" class="headerlink" title="sqlite除法运算保留小数问题"></a>sqlite除法运算保留小数问题</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span>  <span class="keyword">distinct</span> <span class="number">1</span>/<span class="number">100</span> <span class="keyword">from</span> 兴趣点</span><br><span class="line"><span class="comment"># 结果：0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span>  <span class="keyword">distinct</span> <span class="keyword">cast</span>(<span class="number">1</span> <span class="keyword">as</span> <span class="built_in">real</span>)/<span class="number">100</span>  <span class="keyword">from</span> 兴趣点</span><br><span class="line"><span class="comment"># 结果：0.01</span></span><br></pre></td></tr></table></figure>
<h2 id="sqlite存储number型时小于0的值会以0存储"><a href="#sqlite存储number型时小于0的值会以0存储" class="headerlink" title="sqlite存储number型时小于0的值会以0存储"></a>sqlite存储number型时小于0的值会以0存储</h2><h2 id="sqlite3-8-shell连接数据库"><a href="#sqlite3-8-shell连接数据库" class="headerlink" title="sqlite3.8-shell连接数据库"></a>sqlite3.8-shell连接数据库</h2><p><code>cd /usr/local/sqlite &amp;&amp;  sqlite3 /uadb/data/geocodingdb.db</code></p>
<h2 id="Cannot-change-read-only-flag-after-establishing-a-connection"><a href="#Cannot-change-read-only-flag-after-establishing-a-connection" class="headerlink" title="Cannot change read-only flag after establishing a connection"></a>Cannot change read-only flag after establishing a connection</h2><p>日志：<code>[org.hibernate.engine.jdbc.spi.SqlExceptionHelper] [ERROR] - Cannot change read-only flag after establishing a connection. Use SQLiteConfig#setReadOnly and SQLiteConfig.createConnection().</code><br>解决：</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>J2EE</tag>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title>SublimeText-Markdown书写利器</title>
    <url>/2015/09/26/SublimeText-Markdown%E4%B9%A6%E5%86%99%E5%88%A9%E5%99%A8/</url>
    <content><![CDATA[<p>曾尝试寻找在线平台写博客</p>
<ul>
<li>segmentfault：专栏文章模块markdown编写可检测剪贴板图片，且需要审核；但是笔记模块不支持</li>
<li>csdn：改版的markdown编辑器很好，但是不支持粘帖图片，且存在删文风险 </li>
</ul>
<p>几经周折，最终还是选择了自己搭建写作环境：<code>sumblime配置markdown写作环境 + evernote笔记检索+hexo博客框架 + github.io发布</code>；<br>以sublimeText编辑器作为写作环境（markdown语法高亮/预览），以sublime-evernote发布到evernote，hexo搭建博客框架定期发布到github.io，<br>谨记编辑器够用就好，内容应始终放在第一位。</p>
<hr>
<a id="more"></a>
<h1 id="安装Package-Control"><a href="#安装Package-Control" class="headerlink" title="安装Package Control"></a>安装Package Control</h1><p>使用Ctrl+`快捷键或者通过View-&gt;Show Console菜单打开命令行，粘贴如下代码：</p>
<p><code>import urllib.request,os; pf = &#39;Package Control.sublime-package&#39;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &#39;wb&#39;).write(urllib.request.urlopen( &#39;http://sublime.wbond.net/&#39; + pf.replace(&#39; &#39;,&#39;%20&#39;)).read())</code></p>
<h1 id="SublimeText快捷键"><a href="#SublimeText快捷键" class="headerlink" title="SublimeText快捷键"></a>SublimeText快捷键</h1><ul>
<li>命令面板：Ctrl+Shift+P’</li>
<li>列选择：Shirft+右键</li>
<li>行选择：Ctrl+L</li>
<li>全屏书写：Shirft + F11</li>
</ul>
<h1 id="SublimeText-用户配置"><a href="#SublimeText-用户配置" class="headerlink" title="SublimeText 用户配置"></a>SublimeText 用户配置</h1><p>主题：Material-Theme</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"color_scheme"</span>: <span class="string">"Packages/Monokai Extended/Monokai Extended Bright.tmTheme"</span>,</span><br><span class="line">    <span class="attr">"draw_centered"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"font_face"</span>: <span class="string">"Consolas"</span>,</span><br><span class="line">    <span class="attr">"font_size"</span>: <span class="number">9</span>,</span><br><span class="line">    <span class="attr">"gutter"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"ignored_packages"</span>:</span><br><span class="line">    [</span><br><span class="line">        <span class="string">"Markdown"</span>,</span><br><span class="line">        <span class="string">"Vintage"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"index_exclude_patterns"</span>:</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"*.log"</span>,</span><br><span class="line">      <span class="string">"*.gitignore"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"line_numbers"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"line_padding_bottom"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"line_padding_top"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"scroll_past_end"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"tab_size"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"theme"</span>: <span class="string">"Material-Theme.sublime-theme"</span>,  </span><br><span class="line">    <span class="attr">"translate_tabs_to_spaces"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"word_wrap"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Markdown插件"><a href="#Markdown插件" class="headerlink" title="Markdown插件"></a>Markdown插件</h1><h2 id="Markdown语法高亮：Monokai"><a href="#Markdown语法高亮：Monokai" class="headerlink" title="Markdown语法高亮：Monokai"></a>Markdown语法高亮：Monokai</h2><p>语法高亮：Monokai Extended<br><a href="https://github.com/jonschlinkert/sublime-monokai-extended">Github地址</a> <img src="sublimetext.png" alt="效果图"></p>
<h2 id="Markdown编辑：MarkdownEditing"><a href="#Markdown编辑：MarkdownEditing" class="headerlink" title="Markdown编辑：MarkdownEditing"></a>Markdown编辑：MarkdownEditing</h2><p>设置为MarkdownEditing&gt;MultiMarkDown<br><a href="https://github.com/SublimeText-Markdown/MarkdownEditing#key-bindings">官方文档</a></p>
<ul>
<li>选择内容设为链接：Ctrl + Win + V  </li>
<li>粘贴板内容设为链接：Ctrl + Win + R</li>
<li>插入链接：Ctrl + Win + K</li>
<li>插入图片：Shift + Win + K</li>
<li>加粗：Ctrl + Shift + B</li>
<li>斜体：Ctrl + Shift + I</li>
<li>标题：Ctrl + 1/2/3/4/5/6</li>
<li>显示Markdown文件标题：Ctrl + Shift + R</li>
</ul>
<h2 id="Markdown预览：OmniMarkupPreviewer"><a href="#Markdown预览：OmniMarkupPreviewer" class="headerlink" title="Markdown预览：OmniMarkupPreviewer"></a>Markdown预览：OmniMarkupPreviewer</h2><ul>
<li>Ctrl + Alt + O: 在浏览器中预览(实时无需刷新的哦)</li>
<li>Ctrl + Alt + X: 导出HTML</li>
<li>Ctrl + Alt + C: HTML标记拷贝至剪贴板</li>
</ul>
<h2 id="markdown样式"><a href="#markdown样式" class="headerlink" title="markdown样式"></a>markdown样式</h2><p>next主题修改：<code>/next/source/css/_variables/base.styl</code>文件中的<code>$font-family-chinese</code>、<code>$font-size-base</code>等属性定制</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#333</span>;</span><br><span class="line">  <span class="attribute">background</span>: <span class="number">#fff</span>;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">14.5px</span>;</span><br><span class="line">  <span class="attribute">line-height</span>: <span class="number">1.8</span>;</span><br><span class="line">  <span class="attribute">font-family</span>: Consolas, monaco, <span class="string">"Helvetica Neue"</span>, Helvetica, Arial, <span class="string">"Hiragino Sans GB"</span>, <span class="string">"Microsoft YaHei"</span>, STHeiti, <span class="string">"WenQuanYi Micro Hei"</span>, sans-serif;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="sublime配置笔记同步到evernote"><a href="#sublime配置笔记同步到evernote" class="headerlink" title="sublime配置笔记同步到evernote"></a>sublime配置笔记同步到evernote</h1><p><a href="http://www.jianshu.com/p/f5118d466f81/comments/2422205">参考配置sublime-evernote</a></p>
<p>Evernote 的快捷键在 Key Bindings——User配置</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"super+e"</span>], <span class="attr">"command"</span>: <span class="string">"show_overlay"</span>, <span class="attr">"args"</span>: &#123;<span class="attr">"overlay"</span>: <span class="string">"command_palette"</span>, <span class="attr">"text"</span>: <span class="string">"Evernote: "</span>&#125; &#125;,</span><br><span class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+s"</span>], <span class="attr">"command"</span>: <span class="string">"send_to_evernote"</span> &#125;,</span><br><span class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+o"</span>], <span class="attr">"command"</span>: <span class="string">"open_evernote_note"</span> &#125;,</span><br><span class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+u"</span>], <span class="attr">"command"</span>: <span class="string">"save_evernote_note"</span> &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>如新增笔记：[“ctrl+e”, “ctrl+s”] 就是先按完ctrl + e 后再按 ctrl + s ；</p>
<p>sublime-evernote配置</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"> &#123;</span><br><span class="line">  <span class="attr">"code_friendly"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"code_highlighting_style"</span>: <span class="string">"github"</span>,</span><br><span class="line">  <span class="attr">"extensions"</span>:</span><br><span class="line">  [</span><br><span class="line">    <span class="string">"md"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"noteStoreUrl"</span>: <span class="string">"https://www.evernote.com/shard/s56/notestore"</span>,</span><br><span class="line">  <span class="attr">"show_stacks"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"token"</span>: <span class="string">"S=s56:U=63871d:E=15c7d92376e:C=15525e109a8:P=1cd:A=en-devtoken:V=2:H=b30896c360f9be6886b610bbb7dc7df3"</span>,</span><br><span class="line">  <span class="attr">"update_on_save"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h2 id="markdown笔记与evernote保留字冲突问题"><a href="#markdown笔记与evernote保留字冲突问题" class="headerlink" title="markdown笔记与evernote保留字冲突问题"></a>markdown笔记与evernote保留字冲突问题</h2><ul>
<li>问题描述：Evernote complained:The contents of the note are not valid. The inline HTML tag ‘String’ is not allowed in Evernote notes.Retry?    </li>
<li>问题解决：List<String>改为List&lt; String&gt;接警</li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>TextEditor</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库使用笔记</title>
    <url>/2015/09/21/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>记录一些常用的MysQL运维脚本和常见问题</p>
<hr>
<a id="more"></a>
<p><a href="http://dev.mysql.com/doc/refman/5.7/en/string-functions.html">MySQL函数文档</a></p>
<h1 id="linux重置mysql-root密码"><a href="#linux重置mysql-root密码" class="headerlink" title="linux重置mysql root密码"></a>linux重置mysql root密码</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 新建文件</span></span><br><span class="line">touch /mnt/script/mysql-init</span><br><span class="line"><span class="comment"># 文件内容为</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">PASSWORD</span> <span class="keyword">FOR</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> = <span class="keyword">PASSWORD</span>(<span class="string">'MyNewPass'</span>);</span><br><span class="line"><span class="comment"># 查看mysqld进程ID并杀掉</span></span><br><span class="line">service mysqld status</span><br><span class="line"><span class="keyword">kill</span> $&#123;pid&#125;</span><br><span class="line"><span class="comment"># 重启mysql服务并重置root密码</span></span><br><span class="line">mysqld_safe <span class="comment">--init-file=/mnt/script/mysql-init &amp;</span></span><br></pre></td></tr></table></figure>
<h1 id="重启mysql服务"><a href="#重启mysql服务" class="headerlink" title="重启mysql服务"></a>重启mysql服务</h1><p>service mysqld restart</p>
<h1 id="MySQL开启远程连接"><a href="#MySQL开启远程连接" class="headerlink" title="MySQL开启远程连接"></a>MySQL开启远程连接</h1><p>问题：Access denied for user ‘root’@’192.168.1.172’ (using password: YES)<br>解决：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql -uroot -proot</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">grants</span>;</span><br><span class="line"><span class="keyword">use</span> mysql</span><br><span class="line"><span class="keyword">select</span> host,<span class="keyword">user</span>,<span class="keyword">password</span> <span class="keyword">from</span> <span class="keyword">user</span>;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host=<span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">"root"</span> <span class="keyword">and</span> host;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure>
<h1 id="mysql-新建用户，设置权限"><a href="#mysql-新建用户，设置权限" class="headerlink" title="mysql 新建用户，设置权限"></a>mysql 新建用户，设置权限</h1><p>DROP USER ‘ugc’@’%’;<br>CREATE USER ‘ugc’@’%’ IDENTIFIED BY ‘ugc’;<br>GRANT ALL PRIVILEGES ON <em> . </em> TO ‘ugc’@’%’  Identified by ‘ugc’;<br>GRANT ALL PRIVILEGES ON <em> . </em> TO ‘ugc’@’localhost’  Identified by ‘ugc’;<br>FLUSH PRIVILEGES;</p>
<h1 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h1><p>mysql -uugc -pugc</p>
<h1 id="建库"><a href="#建库" class="headerlink" title="建库"></a>建库</h1><p>CREATE DATABASE  ugc;</p>
<h1 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h1><p>单个导入：<code>source  data.sql</code><br>如：<code>cd /tmp/ugc-data/ &amp;&amp; find . -name &#39;echzutravel.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u ugc -p ugc</code></p>
<p>批量导入：<code>find . -name &#39;*.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u root -p db_name</code><br>如导入/tmp/ugc-data/目录的所有sql文件到ugc库：<code>cd /tmp/ugc-data/ &amp;&amp; find . -name &#39;*.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u ugc -p ugc</code></p>
<h1 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h1><ol>
<li>导出整个数据库<br>mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名<br>mysqldump -u wcnc -p smgp_apps_wcnc &gt; wcnc.sql</li>
<li>导出一个表<br>mysqldump -u 用户名 -p 数据库名表名&gt; 导出的文件名<br>mysqldump -u wcnc -p smgp_apps_wcnc users&gt; wcnc_users.sql</li>
<li>导出一个数据库结构<br>mysqldump -u wcnc -p -d —add-drop-table smgp_apps_wcnc &gt;d:wcnc_db.sql<br>-d 没有数据 —add-drop-table 在每个create语句之前增加一个drop table</li>
</ol>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据库备份</span></span><br><span class="line">`mysqldump geocodingdb  -ugeocodingdb -pgeocodingdb   <span class="comment">--routines --comments &gt; /uadb/geocodingdb.sql`</span></span><br><span class="line"><span class="comment"># 压缩备份</span></span><br><span class="line">`mysqldump standarddb  -ustandarddb -pstandarddb  <span class="comment">--routines   --comments   | gzip -v &gt; /uadb/standarddb.gz`</span></span><br><span class="line"><span class="comment"># 压缩已有备份sql</span></span><br><span class="line">`zip -r   /uadb/uadb.bakcup.suzhou.0512.zip  /uadb/uadb.bakcup.suzhou.0512`</span><br><span class="line"><span class="comment"># 数据库还原</span></span><br><span class="line">`mysql   -ugeocodingdb -pgeocodingdb geocodingdb   <span class="comment">--comments  &lt; /uadb/geocodingdb.sql`</span></span><br></pre></td></tr></table></figure>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="Too-many-connections"><a href="#Too-many-connections" class="headerlink" title="Too many connections"></a>Too many connections</h2><p>查看最大连接数：show variables like ‘max_connections’;<br>查询一下服务器响应的最大连接数： show global status like ‘Max_used_connections’;<br>show status like ‘%connection%’;<br>显示当前运行的Query： show processlist;<br>设置新的最大连接数为5000：<br>1）shell临时修改： set GLOBAL max_connections=5000;<br>2）在/etc/my.cnf 中修改连接max_connections = 5000</p>
<h1 id="Packet-for-query-is-too-large"><a href="#Packet-for-query-is-too-large" class="headerlink" title="Packet for query is too large"></a>Packet for query is too large</h1><ul>
<li>关于max_allowed_packet参数<br>MySQL根据配置文件会限制Server接受的数据包大小。有时候大的插入和更新会受 max_allowed_packet 参数限制，导致写入或者更新失败。</li>
<li>查询：show VARIABLES like ‘%max_allowed_packet%’;</li>
<li>命令行中修改：set global max_allowed_packet = 2<em>1024</em>1024*10;</li>
<li>在windows（my.ini），Linux（/etc/my.cnf）中 修改：max_allowed_packet = 20M</li>
</ul>
<h1 id="Host-is-blocked-because-of-many-connection-errors"><a href="#Host-is-blocked-because-of-many-connection-errors" class="headerlink" title="Host is blocked because of many connection errors"></a>Host is blocked because of many connection errors</h1><ul>
<li>错误描述：An error occurred while establishing the connection: message from server: “Host ‘192.168.1.174’ is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’”</li>
<li>查询：show VARIABLES like ‘%max_connect_errors%’;</li>
<li>命令行中修改：set global max_connect_errors =1000;</li>
<li>在windows（my.ini），Linux（/etc/my.cnf）中 修改：max_connect_errors= 1000</li>
</ul>
<h1 id="No-buffer-space-available-maximum-connections-reached"><a href="#No-buffer-space-available-maximum-connections-reached" class="headerlink" title="No buffer space available (maximum connections reached?)"></a>No buffer space available (maximum connections reached?)</h1><ul>
<li>错误描述：大量数据库连接运行sql，抛出异常java.net.SocketException: No buffer space available (maximum connections reached?): JVM_Bind,在运行 Windows Server 2008 R2 或 Windows 7 的多处理器计算机上的内核套接字泄漏</li>
<li>解决：winServer2008多处理器计算机上的内核套接字泄漏bug，下载补丁修复<br>The reason we got this error is a bug in Windows Server 2008 R2 / Windows 7. The kernel leaks loopback sockets due to a race condition on machines with more than one core,<br><a href="http://support.microsoft.com/kb/2577795">patch 2577795</a> fixes the issue:</li>
</ul>
<h2 id="You-can’t-specify-target-table-‘Place’-for-update-in-FROM-clause"><a href="#You-can’t-specify-target-table-‘Place’-for-update-in-FROM-clause" class="headerlink" title="You can’t specify target table ‘Place’ for update in FROM clause"></a>You can’t specify target table ‘Place’ for update in FROM clause</h2><p>执行错误：DELETE   FROM  Place where guid in (select guid  from  Place  where address like ‘%市%区’ and address   not  like ‘%南海区%’) ;<br>修改为：DELETE   FROM  Place whereguid in (select  * from (select guid  from  Place  where address like ‘%市%区’ and address   not  like ‘%南海区%’)  as t);</p>
<h2 id="mysql表名区分大小写"><a href="#mysql表名区分大小写" class="headerlink" title="mysql表名区分大小写"></a>mysql表名区分大小写</h2><p>MySQL在Windows下数据库名、表名、列名、别名都不区分大小写。<br>如果想大小写区分，在my.ini 里面的mysqld部分，加入 lower_case_table_names=0</p>
<h2 id="查询表的字段名称"><a href="#查询表的字段名称" class="headerlink" title="查询表的字段名称"></a>查询表的字段名称</h2><p>select column_name from information_schema.columns where table_name = ‘ExtractedAddress’ and column_name like ‘地名%’ and  column_name &lt;&gt; ‘地名’</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker学习笔记</title>
    <url>/2015/10/03/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>dockerfile就像人体的DNA，提供自动构建一切的元数据。</p>
<hr>
<a id="more"></a>
<h1 id="Docker基本概念"><a href="#Docker基本概念" class="headerlink" title="Docker基本概念"></a>Docker基本概念</h1><h2 id="镜像（Image）"><a href="#镜像（Image）" class="headerlink" title="镜像（Image）"></a>镜像（Image）</h2><p>Docker 镜像就是一个只读的模板。镜像可以用来创建 Docker 容器。</p>
<h2 id="容器（Container）"><a href="#容器（Container）" class="headerlink" title="容器（Container）"></a>容器（Container）</h2><p>Docker 利用容器来运行应用。<br>容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。<br>可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。<br>*注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。</p>
<h2 id="仓库（Repository）"><a href="#仓库（Repository）" class="headerlink" title="仓库（Repository）"></a>仓库（Repository）</h2><p>仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。<br>仓库分为公开仓库（Public）和私有仓库（Private）两种形式。<br>*注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。</p>
<p>理解了这三个概念，就理解了 Docker 的整个生命周期。</p>
<h1 id="Docker相关术语"><a href="#Docker相关术语" class="headerlink" title="Docker相关术语"></a>Docker相关术语</h1><h2 id="LXC"><a href="#LXC" class="headerlink" title="LXC"></a>LXC</h2><p>LXC（Linux Container）Linux Container容器是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。相当于C++中的NameSpace。容器有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。与传统虚拟化技术相比，它的优势在于：<br>（1）与宿主机使用同一个内核，性能损耗小；<br>（2）不需要指令级模拟；<br>（3）不需要即时(Just-in-time)编译；<br>（4）容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制；<br>（5）避免了准虚拟化和系统调用替换中的复杂性；<br>（6）轻量级隔离，在隔离的同时还提供共享机制，以实现容器与宿主机的资源共享。<br>总结：Linux Container是一种轻量级的虚拟化的手段。<br>Linux Container提供了在单一可控主机节点上支持多个相互隔离的server container同时执行的机制。Linux Container有点像chroot，提供了一个拥有自己进程和网络空间的虚拟环境，但又有别于虚拟机，因为lxc是一种操作系统层次上的资源的虚拟化。</p>
<h2 id="Hypervisor"><a href="#Hypervisor" class="headerlink" title="Hypervisor"></a>Hypervisor</h2><p>Hypervisor是一种运行在物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）。Hypervisor是所有虚拟化技术的核心。非中断地支持多工作负载迁移的能力是Hypervisor的基本功能。当服务器启动并执行Hypervisor时，它会给每一台虚拟机分配适量的内存、CPU、网络和磁盘，并加载所有虚拟机的客户操作系统。</p>
<h1 id="容器VS-虚拟机"><a href="#容器VS-虚拟机" class="headerlink" title="容器VS 虚拟机"></a>容器VS 虚拟机</h1><p>容器会比虚拟机更高效，因为它们能够分享一个内核和分享应用程序库。相比虚拟机系统，这也将使得 Docker使用的内存更小，即便虚拟机利用了内存超量使用的技术。部署容器时共享底层的镜像层也可以减少存储占用。IBM 的 Boden Russel 已经做了一些基准测试来说明两者之间的不同。</p>
<p>相比虚拟机系统，容器具有较低系统开销的优势，所以在容器中，应用程序的运行效率将会等效于在同样的应用程序在虚拟机中运行，甚至效果更佳。</p>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul>
<li>查看所有镜像：docker images：</li>
<li>删除所有镜像：docker rmi $(docker images | grep none | awk ‘{print $3}’ | sort -r)</li>
<li>删除所有容器：docker rm $(docker ps -a -q)</li>
<li>停止/启动/杀死一个容器：stop/start/kill &lt;容器名orID&gt; </li>
</ul>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><ol>
<li><p>docker: relocation error: docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference<br>解决方案：<br>You may have to enable the public_ol6_latest repo in order to get this package.<br><code>sudo yum-config-manager --enable public_ol6_latest</code><br>And then install the package:<br><code>sudo yum install device-mapper-event-libs</code></p>
</li>
<li><p>Error response from daemon: EOF</p>
</li>
</ol>
<h1 id="Docker方案"><a href="#Docker方案" class="headerlink" title="Docker方案"></a>Docker方案</h1><h2 id="Kitematic"><a href="#Kitematic" class="headerlink" title="Kitematic"></a>Kitematic</h2><blockquote>
<p><a href="https://github.com/kitematic/kitematic">Kitematic</a> 是一个具有现代化的界面设计的自由开源软件，它可以让我们在 Docker 中交互式执行任务。Kitematic 设计的非常漂亮、界面美观。使用它，我们可以简单快速地开箱搭建我们的容器而不需要输入命令，可以在图形用户界面中通过简单的点击从而在容器上部署我们的应用。<br>Kitematic 集成了 Docker Hub，允许我们搜索、拉取任何需要的镜像，并在上面部署应用。它同时也能很好地切换到命令行用户接口模式。目前，它包括了自动映射端口、可视化更改环境变量、配置卷、流式日志以及其它功能。</p>
</blockquote>
<p><a href="http://www.linuxidc.com/Linux/2015-09/122601.htm">参考教程</a><br>安装问题</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Error creating machine: exit status 1</span><br><span class="line">You will want to check the provider to make sure the machine and associated resources were properly removed.</span><br></pre></td></tr></table></figure>
<p>待解决：<a href="https://github.com/docker/toolbox/issues/245">github issue</a></p>
<h1 id="待解决问题"><a href="#待解决问题" class="headerlink" title="待解决问题"></a>待解决问题</h1><h2 id="如何自动部署Github程序到Docker镜像"><a href="#如何自动部署Github程序到Docker镜像" class="headerlink" title="如何自动部署Github程序到Docker镜像"></a>如何自动部署Github程序到Docker镜像</h2><h2 id="构建搭载Tomcat环境的镜像"><a href="#构建搭载Tomcat环境的镜像" class="headerlink" title="构建搭载Tomcat环境的镜像"></a>构建搭载Tomcat环境的镜像</h2><h2 id="部署前端web应用"><a href="#部署前端web应用" class="headerlink" title="部署前端web应用"></a>部署前端web应用</h2><h2 id="部署后端Java服务"><a href="#部署后端Java服务" class="headerlink" title="部署后端Java服务"></a>部署后端Java服务</h2>]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群离线部署</title>
    <url>/2015/10/20/Hadoop%E9%9B%86%E7%BE%A4%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>GFW墙的没人性，只能费时费力搞个离线安装教程，一路遇到很多问题，稍微深入了解了一些ClouderaManager的内部实现，步骤概要：<br>IP配置&gt;Host配置&gt;关闭iptables防火墙&gt;关闭SELinux&gt;配置NTP时钟服务&gt;SSH无密码登陆&gt;安装JDK&gt;<br>配置CM安装包&gt;配置Parcel&gt;配置MySQL&gt;初始化SCM数据库&gt;复制到Agent机器&gt;<br>启动CM Server&gt;配置Service&gt;设置Server/Agent开机启动</p>
<hr>
<a id="more"></a>
<h1 id="部署文档参考"><a href="#部署文档参考" class="headerlink" title="部署文档参考"></a>部署文档参考</h1><p><a href="http://blog.csdn.net/scgaliguodong123_/article/details/46661881">离线安装Cloudera Manager5.3.4与CDH5.3.4</a><br><a href="http://www.tuicool.com/articles/ENjmeaY">离线安装Cloudera Manager 5和CDH5(最新版5.1.3) 完全教程</a><br><a href="http://www.cnblogs.com/modestmt/p/4540818.html">离线安装 Cloudera ( CDH 5.x )</a><br><a href="http://www.aboutyun.com/thread-8921-1-1.html">离线安装 Cloudera</a><br><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_install_path_b.html#cmig_topic_6_6">官方教程</a><br><a href="http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cdh_vd_cdh5_maven_repo.html#concept_emz_fg3_kq_unique_2">cdh对应hadoop版本</a></p>
<h1 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h1><p><a href="http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cm_vd.html">官方资源地址</a></p>
<ul>
<li>JDK7最低版本：1.7.0_67</li>
<li>cloudera-manager-installer：<a href="http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin">下载地址</a></li>
<li>cloudera-manager-bin:<a href="https://archive.cloudera.com/cm5/cm/5/">下载地址</a></li>
<li>CDH Parcel：<a href="http://archive.cloudera.com/cdh5/parcels/latest/">下载地址</a></li>
</ul>
<h1 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h1><p>Cloudera Manager+MySQL</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Cloudera Manager</span><br><span class="line">HostMonitor</span><br><span class="line">Event Server</span><br><span class="line">Activity Monitor</span><br><span class="line">Service Monitor</span><br><span class="line">Alert Publisher </span><br><span class="line">MySQL</span><br></pre></td></tr></table></figure>
<p>Master</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：Active NameNode</span><br><span class="line">Hbase：Active Master</span><br><span class="line">YARN：Active ResourceManager,JobHistory Server</span><br></pre></td></tr></table></figure>
<p>Standby Master </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：Standby NameNode、DataNode</span><br><span class="line">Hbase：Standby Master、RegionServer</span><br><span class="line">YARN：Standby ResourceManager,Node Manager</span><br><span class="line">HUE：Hue Server</span><br></pre></td></tr></table></figure>
<p>Slave1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：DataNode、FailoverController、JournalNode</span><br><span class="line">Hbase：RegionServer</span><br><span class="line">YARN：Node Manager</span><br><span class="line">Impala：Impala CatalogServer,Impala StateStore,Impala lama ApplicationMaster</span><br><span class="line">Oozie：Oozie Server</span><br><span class="line">Hive：Hive Server</span><br><span class="line">Sor：Solr Server</span><br><span class="line">ZoomKeeper：zoomKeeper Server</span><br></pre></td></tr></table></figure>
<p>Slave2</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：DataNode、FailoverController、JournalNode</span><br><span class="line">Hbase：RegionServer</span><br><span class="line">YARN：Node Manager</span><br><span class="line">Impala：Impala Daemon</span><br><span class="line">Hive：Hive Metastore Server</span><br><span class="line">Sor：Solr Server</span><br><span class="line">ZoomKeeper：zoomKeeper Server</span><br></pre></td></tr></table></figure>
<p>Slave3</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：DataNode、FailoverController、JournalNode</span><br><span class="line">Hbase：RegionServer</span><br><span class="line">YARN：Node Manager</span><br><span class="line">Impala：Impala Daemon</span><br><span class="line">Spark：Spark History Server</span><br><span class="line">Hive：Hive Metastore Server</span><br><span class="line">Sor：Solr Server</span><br><span class="line">ZoomKeeper：zoomKeeper Server</span><br></pre></td></tr></table></figure>
<p>Slave4</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS：DataNode</span><br><span class="line">Hbase：RegionServer</span><br><span class="line">YARN：Node Manager</span><br><span class="line">Impala：Impala Daemon</span><br></pre></td></tr></table></figure>
<h1 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h1><p>将 JDK 提取至 /usr/java/jdk-version；例如：/usr/java/jdk1.7.0_80<br>将装有 JDK 的目录通过符号链接至 /usr/java/default；例如：<br>ln -s /usr/java/jdk.1.7.0_80 /usr/java/default </p>
<h1 id="MySQL数据库配置"><a href="#MySQL数据库配置" class="headerlink" title="MySQL数据库配置"></a>MySQL数据库配置</h1><h2 id="安装配置MySQL"><a href="#安装配置MySQL" class="headerlink" title="安装配置MySQL"></a>安装配置MySQL</h2><h2 id="配置SCM数据库"><a href="#配置SCM数据库" class="headerlink" title="配置SCM数据库"></a>配置SCM数据库</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--hive数据库</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="comment">--集群监控数据库</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> amon <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="comment">--hue数据库</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hue <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="comment">--oozie数据库</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"></span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'master'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'192.168.1.100'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'192.168.1.183'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure>
<h1 id="安装cloudera-manager"><a href="#安装cloudera-manager" class="headerlink" title="安装cloudera-manager"></a>安装cloudera-manager</h1><p>主节点解压安装<br>cloudera manager的目录默认位置在/opt下，<br>解压：<code>cd /opt &amp;&amp; tar xzvf cloudera-manager*.tar.gz</code></p>
<h1 id="添加cloudera-scm用户："><a href="#添加cloudera-scm用户：" class="headerlink" title="添加cloudera-scm用户："></a>添加cloudera-scm用户：</h1><p>Agent节点执行：useradd —system —home=/opt/cm/run/cloudera-scm-server/ —no-create-home —shell=/bin/false —comment  “Cloudera SCM User” cloudera-scm</p>
<h1 id="更改cloudera-scm用户目录"><a href="#更改cloudera-scm用户目录" class="headerlink" title="更改cloudera-scm用户目录"></a>更改cloudera-scm用户目录</h1><ul>
<li>查看用户ID:id cloudera-scm</li>
<li>查看用户home：echo ~cloudera-scm</li>
<li>修改用户home：usermod -d /opt/cm/run/cloudera-scm-server/ -u ${用户ID} cloudera-scm<br>如：usermod -d /opt/cm/run/cloudera-scm-server/ -u 493 cloudera-scm</li>
</ul>
<h1 id="安装-mysql-connector："><a href="#安装-mysql-connector：" class="headerlink" title="安装 mysql connector："></a>安装 mysql connector：</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_mysql.html?scroll=cmig_topic_5_5">外部MySQL数据库配置</a><br><a href="http://www.cnblogs.com/peijie-tech/articles/4446011.html">mysql-connector-java与mysql的版本对应关系</a></p>
<ul>
<li>下载<a href="http://ftp.ntu.edu.tw/MySQL/Downloads/Connector-J/">mysql-connector-java-5.1.36.tar.gz</a>文件中提取 JDBC 驱动程序 JAR 文件。</li>
<li>解压：<code>tar zxvf mysql-connector-java-5.1.36.tar.gz</code>，</li>
<li>解压后找到mysql-connector-java-5.1.33-bin.jar，放到/opt/cm/share/cmf/lib/中。</li>
</ul>
<h1 id="初始化CM5的数据库："><a href="#初始化CM5的数据库：" class="headerlink" title="初始化CM5的数据库："></a>初始化CM5的数据库：</h1><p>在SCM主节点初始化SCM数据库<br>格式:scm_prepare_database.sh 数据库类型 数据库 服务器IP 用户名 密码 –scm-host Cloudera_Manager_Server机器IP scm scm scm<br>如：<code>/opt/cm/share/cmf/schema/scm_prepare_database.sh  mysql -h 192.168.1.161 -uroot -proot --scm-host 192.168.1.100 scm scm scm</code><br>重新执行的话，需要在mysql服务器执行  <code>drop database scm;</code></p>
<h1 id="Agent配置"><a href="#Agent配置" class="headerlink" title="Agent配置"></a>Agent配置</h1><ul>
<li>修改配置文件<br><code>/opt/cm/etc/cloudera-scm-agent/config.ini</code>中的server_host为主节点的主机名。</li>
<li>务必解压后不能启动server和agent，纯净版本同步Agent到其他节点<br><code>scp -r /opt/cm root@192.168.1.91:/opt/</code>  </li>
</ul>
<p>复制运行中的agent需执行以下脚本后复制</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service cloudera-scm-agent stop </span><br><span class="line">chkconfig cloudera-scm-agent off  </span><br><span class="line">poweroff</span><br></pre></td></tr></table></figure>
<ul>
<li>修改hostname、hosts</li>
</ul>
<h1 id="准备Parcels，用以安装CDH5"><a href="#准备Parcels，用以安装CDH5" class="headerlink" title="准备Parcels，用以安装CDH5"></a>准备Parcels，用以安装CDH5</h1><p>将CHD5相关的Parcel包放到主节点的/opt/cloudera/parcel-repo/目录中（parcel-repo需要手动创建）。<br>相关的文件如下：</p>
<blockquote>
<p>CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel<br>CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha1<br>manifest.json</p>
</blockquote>
<p>将CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha1，重命名为CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha，这点必须注意，否则，系统会重新下载CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel文件。</p>
<h1 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h1><ul>
<li>启动cloudera manager server服务：<code>/opt/cm/etc/init.d/cloudera-scm-server start</code></li>
<li>启动cloudera manager agent服务：<code>/opt/cm/etc/init.d/cloudera-scm-agent start</code></li>
</ul>
<h1 id="设置为-开机自动启动"><a href="#设置为-开机自动启动" class="headerlink" title="设置为 开机自动启动"></a>设置为 开机自动启动</h1><ul>
<li>server端</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo "/opt/cm/etc/init.d/cloudera-scm-server start" &gt;&gt; /etc/rc.local </span><br><span class="line">echo "/opt/cm/etc/init.d/cloudera-scm-agent start" &gt;&gt; /etc/rc.local</span><br><span class="line">cat  /etc/rc.local</span><br></pre></td></tr></table></figure>
<ul>
<li>agent端</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动cloudera manager agent服务</span></span><br><span class="line">echo "/opt/cm/etc/init.d/cloudera-scm-agent start" &gt;&gt; /etc/rc.local</span><br><span class="line">cat  /etc/rc.local</span><br></pre></td></tr></table></figure>
<ul>
<li>chkconfig服务方式更优，但目前无效，待完善TODO</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动cloudera manager server服务 </span></span><br><span class="line">cp /opt/cm/etc/init.d/cloudera-scm-server /etc/init.d/cloudera-scm-server</span><br><span class="line">chkconfig cloudera-scm-server on</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动cloudera manager agent服务</span></span><br><span class="line">cp /opt/cm/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent</span><br><span class="line">chkconfig cloudera-scm-agent on</span><br></pre></td></tr></table></figure>
<h1 id="CDH5的安装配置"><a href="#CDH5的安装配置" class="headerlink" title="CDH5的安装配置"></a>CDH5的安装配置</h1><p>进入cm网站：192.168.1.100:7180</p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CDH</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat服务器运维</title>
    <url>/2015/10/03/Tomcat%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/</url>
    <content><![CDATA[<p>记录Tomcat服务器的配置安装脚本</p>
<hr>
<a id="more"></a>
<h1 id="Tomcat安装"><a href="#Tomcat安装" class="headerlink" title="Tomcat安装"></a>Tomcat安装</h1><h2 id="配置系统环境变量"><a href="#配置系统环境变量" class="headerlink" title="配置系统环境变量"></a>配置系统环境变量</h2><ul>
<li>JAVA_HOME=D:\java\JDK1.6</li>
<li>PATH环境变量加入：%JAVA_HOME%\bin</li>
</ul>
<h2 id="安装Tomcat"><a href="#安装Tomcat" class="headerlink" title="安装Tomcat"></a>安装Tomcat</h2><ul>
<li>开始-运行-cmd</li>
<li>输入：cd D:\tomcat\bin进入tomcat安装目录</li>
<li>输入：service install tomcat7进行安装（xx为tomcat服务名称，可随意给，也可不设置）</li>
</ul>
<h2 id="设置为开机启动"><a href="#设置为开机启动" class="headerlink" title="设置为开机启动"></a>设置为开机启动</h2><p>开始-运行-services.msc进入服务管理器，将刚才安装的tomcat服务设置为自动，并启动，此时tomcat已成功安装并成功注册为自动启动的系统服务。</p>
<h2 id="卸载Tomcat"><a href="#卸载Tomcat" class="headerlink" title="卸载Tomcat"></a>卸载Tomcat</h2><ul>
<li>输入：cd D:\tomcat\bin进入tomcat安装目录</li>
<li>输入：service remove tomcat7进行卸载（xx为已安装tomcat服务的名称，以前没设置就不用写）</li>
</ul>
<h1 id="tomcat内存配置"><a href="#tomcat内存配置" class="headerlink" title="tomcat内存配置"></a>tomcat内存配置</h1><h2 id="windows服务内存配置"><a href="#windows服务内存配置" class="headerlink" title="windows服务内存配置"></a>windows服务内存配置</h2><p>编辑tomcat\bin\service.bat<br>找到<code>&quot;%EXECUTABLE%&quot; //US//%SERVICE_NAME% --JvmOptions</code><br>新增<code>-Xms1024M;-Xmx2048M;-XX:PermSize=512M;-XX:MaxPermSize=1024M</code>;<br>然后卸载掉服务—&gt;安装服务—&gt;启动服务，生效。<br>在localhost:8080/manager/status 查看修改后的可用内存大小</p>
<h2 id="console控制台内存配置"><a href="#console控制台内存配置" class="headerlink" title="console控制台内存配置"></a>console控制台内存配置</h2><p>编辑catalina.bat，找到下面行修改</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rem</span> <span class="string">-----</span> <span class="string">Execute</span> <span class="string">The</span> <span class="string">Requested</span> <span class="string">Command</span> <span class="string">---------------------------------------</span></span><br><span class="line"><span class="string">set</span> <span class="string">JAVA_OPTS=%JAVA_OPTS%</span> <span class="string">-server</span>  <span class="string">-Xms6400m</span> <span class="string">-Xmx6400m</span>  <span class="string">-XX:MaxNewSize=2048m</span> <span class="string">-XX:PermSize=512M</span> <span class="string">-XX:MaxPermSize=1024m</span></span><br></pre></td></tr></table></figure>
<h2 id="Tomcat与Jetty"><a href="#Tomcat与Jetty" class="headerlink" title="Tomcat与Jetty"></a>Tomcat与Jetty</h2><ul>
<li>单纯比较 Tomcat与Jetty的性能意义不是很大，只能说在某种使用场景下，它表现的各有差异。因为它们面向的使用场景不尽相同。</li>
<li>从架构上来看 Tomcat 在处理少数非常繁忙的连接上更有优势，也就是说连接的生命周期如果短的话，Tomcat 的总体性能更高。而 Jetty 刚好相反，Jetty可以同时处理大量连接而且可以长时间保持这些连接。例如像一些 web 聊天应用非常适合用 Jetty 做服务器，像淘宝的 web 旺旺就是用 Jetty 作为 Servlet 引擎。由于 Jetty 的架构非常简单，作为服务器它可以按需加载组件，这样不需要的组件可以去掉，这样无形可以减少服务器本身的内存开销，处理一次请求也是可以减少产生的临时对象，这样性能也会提高。另外 Jetty 默认使用的是 NIO 技术在处理 I/O 请求上更占优势，Tomcat 默认使用的是 BIO，在处理静态资源时，Tomcat 的性能不如 Jetty。</li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式学习笔记</title>
    <url>/2015/10/03/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>记录常用正则以及相关测试工具</p>
<h1 id="关于正则表达式"><a href="#关于正则表达式" class="headerlink" title="关于正则表达式"></a>关于正则表达式</h1><p>正则表达式（Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列符合某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。<br>许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成“regex”，单数有regexp、regex，复数有regexps、regexes、regexen。</p>
<hr>
<a id="more"></a>
<h1 id="常用正则"><a href="#常用正则" class="headerlink" title="常用正则"></a>常用正则</h1><p>在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。</p>
<h2 id="元字符"><a href="#元字符" class="headerlink" title="元字符"></a>元字符</h2><div class="table-container">
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>匹配除换行符以外的任意字符</td>
</tr>
<tr>
<td>\w</td>
<td>匹配字母或数字或下划线或汉字</td>
</tr>
<tr>
<td>\s</td>
<td>匹配任意的空白符</td>
</tr>
<tr>
<td>\d</td>
<td>匹配数字</td>
</tr>
<tr>
<td>\b</td>
<td>匹配单词的开始或结束</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串的开始</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串的结束</td>
</tr>
</tbody>
</table>
</div>
<p>示例</p>
<ul>
<li>1号10号：<code>^[0-9]+号[0-9]+号?$</code></li>
<li>TAB+TAB关键词+TAB与TAA分隔符+TAA+TAA关键词，除TAB其余都可为空,如1号-10号：<br><code>^[0-9０-９零一二三四五六七八九十壹贰叁肆伍陆柒捌玖拾]+[号]?([-])?([0-9０-９零一二三四五六七八九十壹贰叁肆伍陆柒捌玖拾]+)?[号]?$</code></li>
</ul>
<h2 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a>转义字符</h2><p>如果你想查找元字符本身的话，比如你查找.或\，就出现了问题：你没办法指定它们，因为它们会被解释成别的意思。这时你就得使用\来取消这些字符的特殊意义。因此，你应该使用\.和\*，要查找\本身，你也得用\.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>\.</td>
</tr>
<tr>
<td>*</td>
<td>\*</td>
</tr>
<tr>
<td>\</td>
<td>\\</td>
</tr>
</tbody>
</table>
</div>
<h2 id="重复"><a href="#重复" class="headerlink" title="重复"></a>重复</h2><div class="table-container">
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>重复零次或更多次</td>
</tr>
<tr>
<td>+</td>
<td>重复一次或更多次</td>
</tr>
<tr>
<td>?</td>
<td>重复零次或一次</td>
</tr>
<tr>
<td>{n}</td>
<td>重复n次</td>
</tr>
<tr>
<td>{n,}</td>
<td>重复n次或更多次</td>
</tr>
<tr>
<td>{n,m}</td>
<td>重复n到m次</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h2><p>要想查找数字，字母或数字，空白是很简单的，因为已经有了对应这些字符集合的元字符，但是如果你想匹配没有预定义元字符的字符集合(比如元音字母a,e,i,o,u),应该怎么办？<br>指定一个字符范围，像[0-9]代表的含意与\d就是完全一致的：一位数字；同理[a-z0-9A-Z_]也完全等同于\w（如果只考虑英文的话）。</p>
<h2 id="分支条件"><a href="#分支条件" class="headerlink" title="分支条件"></a>分支条件</h2><p>正则表达式里的分枝条件指的是有几种规则，如果满足其中任意一种规则都应该当成匹配，具体方法是用 | 把不同的规则分隔开。</p>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><p>可以用小括号来指定子表达式(也叫做分组)<br>如IP格式：：<code>(\d{1,3}\.){3}\d{1,3}</code>是一个简单的IP地址匹配表达式：\d{1,3}匹配1到3位的数字，(\d{1,3}.){3}匹配三位数字加上一个英文句号(这个整体也就是这个分组)重复3次，最后再加上一个一到三位的数字(\d{1,3})。</p>
<p>IP地址中每个数字都不能大于255.但是正则表达式中并不提供关于数学的任何功能，所以只能使用冗长的分组，选择，字符类来描述一个正确的IP地址：<code>((2[0-4]\d|25[0-5]|[01]?\d\d?)\.){3}(2[0-4]\d|25[0-5]|[01]?\d\d?)</code></p>
<h2 id="反义"><a href="#反义" class="headerlink" title="反义"></a>反义</h2><p>有时需要查找不属于某个能简单定义的字符类的字符。比如想查找除了数字以外，其它任意字符都行的情况，这时需要用到反义,<br>常用的反义代码  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>\w</td>
<td>匹配任意不是字母，数字，下划线，汉字的字符</td>
</tr>
<tr>
<td>\S</td>
<td>匹配任意不是空白符的字符</td>
</tr>
<tr>
<td>\D</td>
<td>匹配任意非数字的字符</td>
</tr>
<tr>
<td>\B</td>
<td>匹配不是单词开头或结束的位置</td>
</tr>
<tr>
<td><sup><a href="#fn_x" id="reffn_x">x</a></sup></td>
<td>匹配除了x以外的任意字符</td>
</tr>
<tr>
<td><sup><a href="#fn_aeiou" id="reffn_aeiou">aeiou</a></sup></td>
<td>匹配除了aeiou这几个字母以外的任意字符</td>
</tr>
</tbody>
</table>
</div>
<p>例子：<code>\S+</code>匹配不包含空白符的字符串；<code>&lt;a[^&gt;]+&gt;</code>匹配用尖括号括起来的以a开头的字符串。</p>
<h2 id="后向引用"><a href="#后向引用" class="headerlink" title="后向引用"></a>后向引用</h2><h2 id="零宽断言"><a href="#零宽断言" class="headerlink" title="零宽断言"></a>零宽断言</h2><h2 id="负向零宽断言"><a href="#负向零宽断言" class="headerlink" title="负向零宽断言"></a>负向零宽断言</h2><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><h2 id="贪婪与懒惰"><a href="#贪婪与懒惰" class="headerlink" title="贪婪与懒惰"></a>贪婪与懒惰</h2><h2 id="处理选项"><a href="#处理选项" class="headerlink" title="处理选项"></a>处理选项</h2><h2 id="平衡组-递归匹配"><a href="#平衡组-递归匹配" class="headerlink" title="平衡组/递归匹配"></a>平衡组/递归匹配</h2><h1 id="测试工具"><a href="#测试工具" class="headerlink" title="测试工具"></a>测试工具</h1><p><a href="http://www.regexr.com/">regex在线测试</a> 这个专业！<br><a href="http://tool.oschina.net/regex//">oschina regex在线测试</a> 国内的还是不太靠谱！</p>
<h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><p>本文笔记内容参考<a href="http://deerchao.net/tutorials/regex/regex.htm">正则表达式30分钟入门教程</a></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>RegEx</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse安装MapReduceTools插件</title>
    <url>/2015/11/20/MyEclipse%E5%AE%89%E8%A3%85MapReduceTools%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>Windwos10开发环境测试MapReduce程序，需自行编译hadoop2x-eclipse-plugin，生成MyEclipse2014的MapReduceTolls插件，可结合MRUnit进行单元测试。</p>
<hr>
<a id="more"></a>
<p><a href="http://my.oschina.net/muou/blog/408543">参考中文教程</a><br>具体配置步骤如下：</p>
<h2 id="安装MyEclipse2014"><a href="#安装MyEclipse2014" class="headerlink" title="安装MyEclipse2014"></a>安装MyEclipse2014</h2><p>Myeclipse安装位置：C:\Dev\myeclipse（路径无中文字段/空格）</p>
<h2 id="下载Hadoop-lib"><a href="#下载Hadoop-lib" class="headerlink" title="下载Hadoop lib"></a>下载Hadoop lib</h2><p>下载hadoop-2.6.0.tar.gz并解压到目录（路径无中文字段/空格）<br><a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz">hadoop-2.6.0.tar.gz下载地址</a><br>解压后置于F:\Dev\hadoop\hadoop-2.6.0</p>
<h2 id="配置Ant"><a href="#配置Ant" class="headerlink" title="配置Ant"></a>配置Ant</h2><p><a href="http://archive.apache.org/dist/ant/binaries/apache-ant-1.9.0-bin.zip">ant-1.9.0下载地址</a><br>配置环境变量</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ANT_HOME=F:\Dev\apache-ant-1.9.0</span></span><br><span class="line"><span class="string">PATH</span> <span class="string">后追加</span> <span class="string">;%ANT_HOME%\bin</span></span><br></pre></td></tr></table></figure>
<p>检验Ant配置：<code>ant -version</code></p>
<h2 id="编译hadoop-eclipse-plugin插件"><a href="#编译hadoop-eclipse-plugin插件" class="headerlink" title="编译hadoop-eclipse-plugin插件"></a>编译hadoop-eclipse-plugin插件</h2><p><a href="https://github.com/winghc/hadoop2x-eclipse-plugin">hadoop-eclipse-plugin下载地址</a><br>解压后置于F:\Dev\hadoop\hadoop2x-eclipse-plugin-master<br>打开cmd执行以下脚本编译hadoop-eclipse-plugin插件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">F:\Dev\hadoop\hadoop2x-eclipse-plugin-master\src\contrib\eclipse-plugin</span></span><br><span class="line"><span class="string">ant</span> <span class="string">jar</span> <span class="string">-Dversion=2.6.0</span> <span class="string">-Declipse.home=C:\Dev\myeclipse</span> <span class="string">-Dhadoop.home=F:\Dev\hadoop\hadoop-2.6.0</span></span><br></pre></td></tr></table></figure>
<p>执行成功后生成的jar位置：<br><code>F:\Dev\hadoop\hadoop2x-eclipse-plugin-master\build\contrib\eclipse-plugin\hadoop-eclipse-plugin-2.6.0.jar</code></p>
<h2 id="配置hadoop-eclipse-plugin-2-6-0-jar"><a href="#配置hadoop-eclipse-plugin-2-6-0-jar" class="headerlink" title="配置hadoop-eclipse-plugin-2.6.0.jar"></a>配置hadoop-eclipse-plugin-2.6.0.jar</h2><ol>
<li>将<code>hadoop-eclipse-plugin-2.6.0.jar</code>剪切到<code>C:\Dev\myeclipse\dropins</code>目录；</li>
<li>重启Myeclipse即完成MyEclipse2014的MapReduceTolls插件；</li>
<li>可在Window&gt;Show View&gt;MapReduce Tools打开插件视图。</li>
</ol>
<h2 id="配置hadoop-location"><a href="#配置hadoop-location" class="headerlink" title="配置hadoop location"></a>配置hadoop location</h2><p>Location name ：随便取个名字 比如 hadoop2.6.0<br>Map/Reduce（V2） Master ：根据hdfs-site.xml中配置dfs.datanode.ipc.address的值填写，50020<br>DFS Master： Name Node的IP和端口，根据core-site.xml中配置fs.defaultFS的值填写，8020</p>
<p>CDH配置文件位置：/etc/hadoop/conf.cloudera.yarn</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Hadoop</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS配置本地Yum源</title>
    <url>/2015/12/07/CentOS%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0Yum%E6%BA%90/</url>
    <content><![CDATA[<p>现场环境没有网络，有些软件安装简直太痛苦，和maven的依赖链一样，最终耗时耗力不一定能安装好，此时制作本地yum只读光盘就是一个好主意，此文主要介绍如何配置本地yum。</p>
<hr>
<a id="more"></a>
<h1 id="建立本地源目录"><a href="#建立本地源目录" class="headerlink" title="建立本地源目录"></a>建立本地源目录</h1><p><code>mkdir   /mnt/cdrom</code></p>
<h1 id="挂载CentOS光盘"><a href="#挂载CentOS光盘" class="headerlink" title="挂载CentOS光盘"></a>挂载CentOS光盘</h1><p><code>mount   /dev/cdrom    /mnt/cdrom</code></p>
<h1 id="备份repo"><a href="#备份repo" class="headerlink" title="备份repo"></a>备份repo</h1><p>进入/etc/yum.repos.d目录，可以看到四个文件分别为CentOS-Base.repo、 CentOS-Media.repo 、CentOS-Vault.repo、CentOS-Vault.repo.repo,将其中三个改名或者移走留下CentOS-Media.repo<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d</span><br><span class="line">mv  CentOS-Base.repo     CentOS-Base.repo.bak</span><br><span class="line">mv  CentOS-Vault.repo     CentOS-Vault.repo.bak</span><br><span class="line">mv  CentOS-Vault.repo     CentOS-Vault.repo.bak</span><br><span class="line">cp  CentOS-Media.repo     CentOS-Vault.Media.bak</span><br></pre></td></tr></table></figure></p>
<h1 id="编辑CentOS-Media-repo"><a href="#编辑CentOS-Media-repo" class="headerlink" title="编辑CentOS-Media.repo"></a>编辑CentOS-Media.repo</h1><p>编辑CentOS-Media.repo：<code>vi  CentOS-Media.repo</code><br>将以下内容<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[c6-media]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Media</span><br><span class="line">baseurl=file:///media/CentOS/</span><br><span class="line">        file:///media/cdrom/</span><br><span class="line">        file:///media/cdrecorder/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</span><br></pre></td></tr></table></figure><br>修改为<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[c6-media]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Media</span><br><span class="line">baseurl=file:///mnt/cdrom/  <span class="comment">#这里为本地源路径</span></span><br><span class="line">        file:///media/cdrom/</span><br><span class="line">        file:///media/cdrecorder/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1    <span class="comment">##开启本地源</span></span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</span><br></pre></td></tr></table></figure><br>修改好保存并退出</p>
<h1 id="清yum缓存"><a href="#清yum缓存" class="headerlink" title="清yum缓存"></a>清yum缓存</h1><p><code>yum   clean</code>   </p>
<h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>如需要将yum源改为网络，还原<code>/etc/yum.repos.d</code>目录下的四个文件即可！</p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive学习笔记</title>
    <url>/2015/12/06/Hive%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>最近处理一个ETL的项目，技术选型是CDH的Hadoop方案，理所当然离不了Hive数据仓库，记录下Hive学习路上的点滴。<br><a id="more"></a></p>
<h1 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h1><p>Apache Hive是一个建立在Hadoop架构之上的数据仓库。它能够提供数据的精炼，查询和分析。<br>Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL）。<br>Hive定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。</p>
<h1 id="Hive-Maven库"><a href="#Hive-Maven库" class="headerlink" title="Hive Maven库"></a>Hive Maven库</h1><p><a href="http://maven.outofmemory.cn/org.apache.hive/hive-exec/1.1.0/">Hive1.1.0离线包</a></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive 官方Wiki</a></p>
<h1 id="hive-Maven库"><a href="#hive-Maven库" class="headerlink" title="hive Maven库"></a>hive Maven库</h1><p>有时候中央库的没法下载，但是spring.io提供的CDH的可以。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- cdh  repository--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>cdh-5.3.0<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo.spring.io/libs-release-remote/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- hive jdbc --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Hive-With-Hbase"><a href="#Hive-With-Hbase" class="headerlink" title="Hive With Hbase"></a>Hive With Hbase</h1><h1 id="Hive存储Hbase数据-测试语句"><a href="#Hive存储Hbase数据-测试语句" class="headerlink" title="Hive存储Hbase数据 测试语句"></a>Hive存储Hbase数据 测试语句</h1><h2 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://zh.hortonworks.com/blog/hbase-via-hive-part-1/">hbase-via-hive1</a><br><a href="http://www.n10k.com/blog/hbase-via-hive-pt2/">hbase-via-hive2</a></p>
<h2 id="示例SQL"><a href="#示例SQL" class="headerlink" title="示例SQL"></a>示例SQL</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span>  <span class="keyword">User</span> (userId <span class="keyword">STRING</span>, address <span class="keyword">STRING</span>,<span class="keyword">name</span> <span class="keyword">STRING</span> ,photo <span class="keyword">STRING</span> ,psd <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span></span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">'hbase.columns.mapping'</span> = <span class="string">':key,f:data'</span>)</span><br><span class="line">TBLPROPERTIES (<span class="string">'hbase.table.name'</span> = <span class="string">'User'</span>);</span><br></pre></td></tr></table></figure>
<h1 id="hive-新建表"><a href="#hive-新建表" class="headerlink" title="hive 新建表"></a>hive 新建表</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> Geocoding_Address (</span><br><span class="line"><span class="keyword">SID</span> <span class="keyword">String</span>,SAddress <span class="keyword">String</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br><span class="line"><span class="comment">--PARTITIONED BY(STR STRING)</span></span><br></pre></td></tr></table></figure>
<h2 id="hive新增partion"><a href="#hive新增partion" class="headerlink" title="hive新增partion"></a>hive新增partion</h2><p>alter table alter2 add partition (insertdate=’2008-01-01’) location ‘2008/01/01’;</p>
<h1 id="Hive数据导入"><a href="#Hive数据导入" class="headerlink" title="Hive数据导入"></a>Hive数据导入</h1><h2 id="导入hdfs数据到hive表"><a href="#导入hdfs数据到hive表" class="headerlink" title="导入hdfs数据到hive表"></a>导入hdfs数据到hive表</h2><p><code>load data inpath &#39;/user/uadb/test.txt&#39; into table test ;</code></p>
<h2 id="导入本地文件到hive表"><a href="#导入本地文件到hive表" class="headerlink" title="导入本地文件到hive表"></a>导入本地文件到hive表</h2><p><code>load data local inpath &#39;/home/uadb/test.txt&#39; into table test ;</code></p>
<h1 id="Hive自定义函数"><a href="#Hive自定义函数" class="headerlink" title="Hive自定义函数"></a>Hive自定义函数</h1><ul>
<li><p>UDF:一进一出（ 输入一行输出一行 On-to-one maping ）</p>
<blockquote>
<p>transformation of one row value into another one, which can be added with UDFs (User Defined Function);</p>
</blockquote>
</li>
<li><p>UDAF:多进一出（ 输入多行输出一行 Many-to-one maping ）</p>
<blockquote>
<p>transformation of multiple row values into one, which can be added with UDAFs (User Defined Aggregate Functions);</p>
</blockquote>
</li>
<li><p>UDTF:一进多出（ 输入一行输出多行 On-to-many maping ）</p>
<blockquote>
<p>transformation of one row value into many, which can be added with UDTFs (User Defined Table Functions).</p>
</blockquote>
</li>
</ul>
<h2 id="查看UDF依赖的jar包"><a href="#查看UDF依赖的jar包" class="headerlink" title="查看UDF依赖的jar包"></a>查看UDF依赖的jar包</h2><p>查看自定义函数依赖的jar包：<code>list jars</code>;</p>
<h2 id="hue导入-删除jar"><a href="#hue导入-删除jar" class="headerlink" title="hue导入/删除jar"></a>hue导入/删除jar</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">add  jar /user/hive/test/test.jar;</span><br><span class="line"><span class="keyword">delete</span> jar /<span class="keyword">user</span>/hive/<span class="keyword">test</span>/test.jar;</span><br></pre></td></tr></table></figure>
<h2 id="新建临时UDF函数"><a href="#新建临时UDF函数" class="headerlink" title="新建临时UDF函数"></a>新建临时UDF函数</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">temporary</span> <span class="keyword">function</span>  testUDF  <span class="keyword">as</span> <span class="string">"com.lt.uadb.match.udf.SkeletonAddressNodeMapUDF"</span>;</span><br><span class="line"><span class="keyword">select</span> a.skeleton_addressnode,testUDF(a.skeleton_addressnode,<span class="string">'一'</span>)   <span class="keyword">from</span> matchingAddress <span class="keyword">as</span> a</span><br></pre></td></tr></table></figure>
<h2 id="Hive-UUID"><a href="#Hive-UUID" class="headerlink" title="Hive  UUID"></a>Hive  UUID</h2><p>select reflect(“java.util.UUID”, “randomUUID”) from table</p>
<h2 id="UDF程序打包"><a href="#UDF程序打包" class="headerlink" title="UDF程序打包"></a>UDF程序打包</h2><p>UDF程序打包有两张方式：</p>
<ol>
<li>以类fatjar工具将UDF和依赖打成一个jar包，但是打包部署耗时；</li>
<li>将jar包分为稳定和经常更新的两类；通过执行add和delete动态添加依赖</li>
</ol>
<h2 id="CM中设置Hive自动加载UDTF依赖JAR"><a href="#CM中设置Hive自动加载UDTF依赖JAR" class="headerlink" title="CM中设置Hive自动加载UDTF依赖JAR"></a>CM中设置Hive自动加载UDTF依赖JAR</h2><p><a href="http://blog.csdn.net/xiao_jun_0820/article/details/38302451">参考cloudera mamager中配置hive加载自定义的jar包</a></p>
<ol>
<li>进入Hive配置页</li>
<li>在高级选型中设置<code>Hive 辅助 JAR 目录</code>：<code>/etc/hive/udtflib</code></li>
<li>设置Gateway Default Group（hive-env.sh 的 Gateway 客户端环境高级配置代码段（安全阀））：<code>HIVE_AUX_JARS_PATH=/etc/hive/udtflib</code></li>
<li>重启集群，CM会自动将Hive辅助JAR目录中的jar包分发到Hive客户端</li>
</ol>
<h2 id="UDF日志查看"><a href="#UDF日志查看" class="headerlink" title="UDF日志查看"></a>UDF日志查看</h2><p>除了开发环境的Junit单元测试外，生产环境的日志查看非常重要，</p>
<ol>
<li>通过在hue -jobbrowser中查看syslog；</li>
<li>通过在YARN的ResourceManager UI中查看Mapreduce打印的详细日志，日志会打印syso的内容；</li>
</ol>
<h1 id="Hive-JDBC"><a href="#Hive-JDBC" class="headerlink" title="Hive JDBC"></a>Hive JDBC</h1><p>HiveServer和HiveServer2都有两种模式，分别为嵌入式和单机服务器模式，</p>
<ol>
<li>嵌入式URI为”jdbc:hive://“或者”jdbc:hive2://“；</li>
<li>单机服务器模式的URI为”jdbc:hive://host:port/dbname”或者”jdbc:hive2://host:port/dbname”；</li>
<li>HiveServer使用的JDBC驱动类为org.apache.hadoop.hive.jdbc.HiveDriver，HiveServer2使用的驱动类为org.apache.hive.jdbc.HiveDriver；</li>
</ol>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="tmp-hive-on-HDFS-should-be-writable"><a href="#tmp-hive-on-HDFS-should-be-writable" class="headerlink" title="/tmp/hive on HDFS should be writable"></a>/tmp/hive on HDFS should be writable</h2><p>问题日志：Exception in thread “main” java.lang.RuntimeException: java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable. Current permissions are: rwx-wx—x<br>解决方法：</p>
<ol>
<li>更新权限hdfs目录权限：<code>hadoop fs -chmod 777 /tmp/hive</code></li>
<li>hdfs执行：<code>hadoop fs -rm -r /tmp/hive;</code></li>
<li>local执行：<code>rm -rf /tmp/hive</code></li>
</ol>
<h2 id="hive-query-can’t-generate-result-set-via-jdbc"><a href="#hive-query-can’t-generate-result-set-via-jdbc" class="headerlink" title="hive query can’t generate result set via jdbc"></a>hive query can’t generate result set via jdbc</h2><p>解决：Use stmt.execute() for a query that makes a new table. of executeQuery. The executeQuery() is now only for select queries (DML) while execute is probably for DDL (data definition).</p>
<ul>
<li>DDL（Data Definition Language 数据定义语言）用于操作对象和对象的属性，这种对象包括数据库本身，以及数据库对象，像：表、视图等等，DDL对这些对象和属性的管理和定义具体表现在Create、Drop和Alter上；  </li>
<li>DML（Data Manipulation Language 数据操控语言）用于操作数据库对象中包含的数据，也就是说操作的单位是记录；  </li>
</ul>
<h2 id="Hive-Jdbc调用UDTF问题"><a href="#Hive-Jdbc调用UDTF问题" class="headerlink" title="Hive Jdbc调用UDTF问题"></a>Hive Jdbc调用UDTF问题</h2><ul>
<li>问题描述：在Java中以Hive的JDBC接口调用UDTF语句，逐行执行到create temporary function就会报错，但在Hue中（客户端连接）能正常执行</li>
<li>问题日志<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.hive.service.cli.HiveSQLException: Error <span class="keyword">while</span> processing statement: FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> from org.apache.hadoop.hive.ql.exec.FunctionTask</span><br><span class="line">    at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:<span class="number">315</span>)</span><br></pre></td></tr></table></figure></li>
<li>解决方案：</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB常用脚本</title>
    <url>/2015/12/28/MongoDB%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p>记录一些工作过程中常用的MongoDB脚本。</p>
<hr>
<a id="more"></a>
<h1 id="数据库连接与关闭"><a href="#数据库连接与关闭" class="headerlink" title="数据库连接与关闭"></a>数据库连接与关闭</h1><h2 id="数据库连接"><a href="#数据库连接" class="headerlink" title="数据库连接"></a>数据库连接</h2><p>mongo uadb</p>
<h2 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h2><p>use uadb</p>
<h2 id="强制关闭mongodb进程"><a href="#强制关闭mongodb进程" class="headerlink" title="强制关闭mongodb进程"></a>强制关闭mongodb进程</h2><p>pkill mongod</p>
<h1 id="查询语句"><a href="#查询语句" class="headerlink" title="查询语句"></a>查询语句</h1><p>模糊查询<br>查询条件中包含like时，格式为：<code>{&quot;地址节全称&quot;:new RegExp(&quot;.*花园&quot;)}</code></p>
<h1 id="操作关键词"><a href="#操作关键词" class="headerlink" title="操作关键词"></a>操作关键词</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;,</span> <span class="string">&gt;=,</span> <span class="string">&lt;,</span> <span class="string">&lt;=,</span> <span class="string">!=,</span> <span class="string">=</span></span><br><span class="line"><span class="string">$gt,</span> <span class="string">$gte,</span> <span class="string">$lt,</span> <span class="string">$lte,$ne,</span></span><br><span class="line"><span class="string">And，OR，In，NotIn</span></span><br><span class="line"><span class="string">无关键字,</span> <span class="string">$or,</span> <span class="string">$in，$nin</span></span><br></pre></td></tr></table></figure>
<h1 id="更新语句"><a href="#更新语句" class="headerlink" title="更新语句"></a>更新语句</h1><p>MongoDB更新字段名，如将AddressNode的adalias字段改为adtext：<code>db.AddressNode.update({}, {$rename:{&quot;adalias&quot;:&quot;adtext&quot;}}, false, true);</code></p>
<h1 id="数据备份恢复"><a href="#数据备份恢复" class="headerlink" title="数据备份恢复"></a>数据备份恢复</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据备份</span></span><br><span class="line"><span class="string">mongodump</span> <span class="string">-d</span> <span class="string">uadb</span>  <span class="string">-u</span> <span class="string">uadb</span> <span class="string">-p</span> <span class="string">psd</span>  <span class="string">-o</span>  <span class="string">/usr/local/mongodb/dump</span></span><br><span class="line"><span class="comment">#数据还原</span></span><br><span class="line"><span class="string">mongorestore</span> <span class="string">-drop</span>  <span class="string">-d</span> <span class="string">uadb</span>   <span class="string">-u</span> <span class="string">uadb</span> <span class="string">-p</span> <span class="string">psd</span>  <span class="string">/usr/local/mongodb/dump/uadb</span></span><br><span class="line"><span class="string">```</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除数据库</span></span><br><span class="line"><span class="string">db.dropDatabase();</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># maxConns并发连接数设置</span></span><br><span class="line"><span class="string">备注：V3.0版本以上参数为maxIncomingConnections，默认65536，详见</span></span><br><span class="line"><span class="string">[V3.2官方configuration-options文档](https://docs.mongodb.org/v3.2/reference/configuration-options/)</span></span><br><span class="line"><span class="comment">## 查询并发数</span></span><br><span class="line"><span class="string">db.serverStatus().connections</span></span><br><span class="line"><span class="comment">## ulimit 设置可以打开最大文件描述符的数量。</span></span><br><span class="line"><span class="string">查看最大文件打开数：ulimite</span> <span class="string">-n</span></span><br><span class="line"><span class="string">临时生效：`ulimit</span> <span class="string">-n</span> <span class="number">32768</span><span class="string">`</span></span><br><span class="line"><span class="string">永久生效：`vim</span> <span class="string">/etc/rc.local`</span> <span class="string">新增`ulimit</span> <span class="string">-n</span> <span class="number">32768</span><span class="string">`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 重启mongodb服务，带上--maxConns参数</span></span><br><span class="line"><span class="string">`/usr/local/mongodb/bin/mongod</span> <span class="string">--dbpath</span> <span class="string">/usr/local/mongodb/data</span> <span class="string">--logpath</span> <span class="string">/usr/local/mongodb/log/mongodb.log</span> <span class="string">--maxConns=20000</span>  <span class="string">--fork</span> <span class="string">--smallfiles`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MongoDB全局变量设置</span></span><br><span class="line"><span class="string">```yaml</span></span><br><span class="line"><span class="comment"># vim /etc/profile</span></span><br><span class="line"><span class="string">export</span> <span class="string">MONGODB_HOME=/usr/local/mongodb</span></span><br><span class="line"><span class="string">export</span> <span class="string">PATH=$MONGODB_HOME/bin:$PATH</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB权限配置</title>
    <url>/2015/12/28/MongoDB%E6%9D%83%E9%99%90%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<hr>
<a id="more"></a>
<h1 id="在未开启auth模式下新建sa用户"><a href="#在未开启auth模式下新建sa用户" class="headerlink" title="在未开启auth模式下新建sa用户"></a>在未开启auth模式下新建sa用户</h1><p>//进入admin数据库<br>mongo admin<br>//新建sa超级用户<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">db.createUser(</span><br><span class="line">   &#123;</span><br><span class="line">     user: <span class="string">"sa"</span>,</span><br><span class="line">     pwd: <span class="string">"1qaz2wsx"</span>,</span><br><span class="line">     roles:</span><br><span class="line">       [</span><br><span class="line">         &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,    </span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,     </span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,</span><br><span class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"root"</span> &#125;</span><br><span class="line">       ]</span><br><span class="line">   &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>//sa用户授权测试<br>db.auth(“sa”,”1qaz2wsx”)</p>
<h1 id="启用MongoDB权限控制"><a href="#启用MongoDB权限控制" class="headerlink" title="启用MongoDB权限控制"></a>启用MongoDB权限控制</h1><p>Windows<br>卸载现有MongoDB服务<br>C:\WINDOWS\system32&gt;sc delete “MongoDB”</p>
<p>启动服务<br>按照MongoDB服务（设置权限控制）：E:\mongodb\bin\mongod —logpath “E:\mongodb\log\mongo.log” —logappend —dbpath “E:\mongodb\data” —directoryperdb   —auth  —serviceName “MongoDB” —serviceDisplayName “MongoDB” —install</p>
<p>Linux<br>启动服务<br>/mnt/data/mongodb/bin/mongod —dbpath /mnt/data/mongodb/data —logpath /mnt/data/mongodb/log/mongodb.log  —auth</p>
<h1 id="开启auth后新建用户"><a href="#开启auth后新建用户" class="headerlink" title="开启auth后新建用户"></a>开启auth后新建用户</h1><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//以admin登陆获取权限</span></span><br><span class="line">use admin</span><br><span class="line"><span class="comment">//sa用户授权</span></span><br><span class="line">db.auth(<span class="string">"sa"</span>,<span class="string">"1qaz2wsx"</span>)</span><br><span class="line"><span class="comment">//切换到uadb库新建用户uadb</span></span><br><span class="line">use uadb</span><br><span class="line">db.auth(<span class="string">"uadb"</span>,<span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>)</span><br><span class="line">db.dropUser(<span class="string">"uadb"</span>);</span><br><span class="line">db.createUser( &#123;<span class="attr">user</span>: <span class="string">"uadb"</span>, <span class="attr">pwd</span>: <span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>, <span class="attr">roles</span>: [   <span class="string">"readWrite"</span> , <span class="string">"dbAdmin"</span> ] &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">//切换到uadb库新建用户uadb_attachment</span></span><br><span class="line">use uadb_attachment</span><br><span class="line">db.dropUser(<span class="string">"uadb_attachment"</span>);</span><br><span class="line">db.createUser( &#123;<span class="attr">user</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">pwd</span>: <span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>, <span class="attr">roles</span>: [   <span class="string">"readWrite"</span> , <span class="string">"dbAdmin"</span> ] &#125;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB空间分析</title>
    <url>/2015/12/28/MongoDB%E7%A9%BA%E9%97%B4%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>用MongoDB与其他NoSQL数据库之间一个大的差别就是她的空间数据存储，2dsphere空间索引（WGS84），用于通用的空间分析（如缓冲区）会很方便。</p>
<hr>
<a id="more"></a>  
<h1 id="新建空间索引"><a href="#新建空间索引" class="headerlink" title="新建空间索引"></a>新建空间索引</h1><p>连接到数据库：<code>/mnt/data/mongodb/bin/mongo uadb</code><br>新建空间索引：<code>db.AddressNode.ensureIndex( { 空间位置 : &quot;2dsphere&quot; });</code><br>新建空间联合索引：<code>db.AddressNode.ensureIndex( { 空间位置 : &quot;2dsphere&quot;, 规范地址节简称: 1  });</code></p>
<h1 id="几何查询"><a href="#几何查询" class="headerlink" title="几何查询"></a>几何查询</h1><p>MongoDB查询关键词：<a href="http://docs.mongodb.org/manual/reference/operator/query-geospatial/">http://docs.mongodb.org/manual/reference/operator/query-geospatial/</a></p>
<h2 id="geoWithin多边形范围查询"><a href="#geoWithin多边形范围查询" class="headerlink" title="geoWithin多边形范围查询"></a>geoWithin多边形范围查询</h2><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">空间位置: &#123;</span><br><span class="line">        $geoWithin: &#123;</span><br><span class="line">            $geometry: &#123;</span><br><span class="line">                 <span class="string">"type"</span>:<span class="string">"Polygon"</span>,</span><br><span class="line">                 <span class="string">"coordinates"</span>:[[</span><br><span class="line">                    [<span class="number">110</span>,<span class="number">30</span>],</span><br><span class="line">                    [<span class="number">110</span>, <span class="number">60</span>],</span><br><span class="line">                    [<span class="number">120</span>, <span class="number">60</span>],</span><br><span class="line">                    [<span class="number">120</span>, <span class="number">30</span>],</span><br><span class="line">                    [<span class="number">110</span>,<span class="number">30</span>]</span><br><span class="line">                    ]]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">空间位置:&#123;</span><br><span class="line">  $geoWithin:&#123;</span><br><span class="line">  $geometry: &#123;<span class="attr">type</span>:<span class="string">'Polygon'</span>,<span class="attr">coordinates</span>:[[[<span class="number">110</span>,<span class="number">30</span>],[<span class="number">110</span>, <span class="number">60</span>],[<span class="number">120</span>, <span class="number">60</span>],[<span class="number">120</span>, <span class="number">30</span>],[<span class="number">110</span>,<span class="number">30</span>]]]&#125;&#125;&#125;,</span><br><span class="line">  规范地址节简称:&#123;<span class="attr">$in</span>:[<span class="string">"DIS"</span>,<span class="string">"POI"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="geoWithin圆范围查询（距离单位：弧度）"><a href="#geoWithin圆范围查询（距离单位：弧度）" class="headerlink" title="geoWithin圆范围查询（距离单位：弧度）"></a>geoWithin圆范围查询（距离单位：弧度）</h2><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">空间位置:&#123;</span><br><span class="line">        $geoWithin: &#123;</span><br><span class="line">            $centerSphere: [[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>],<span class="number">0.0025</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">联合索引查询</span><br><span class="line">&#123;</span><br><span class="line">空间位置:&#123;</span><br><span class="line">        $geoWithin: &#123;</span><br><span class="line">            $centerSphere: [[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>],<span class="number">0.0025</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">     <span class="string">"规范地址节简称"</span>:<span class="string">"POI"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="矩形范围查询"><a href="#矩形范围查询" class="headerlink" title="矩形范围查询"></a>矩形范围查询</h2><p>$box，针对2d索引，不能针对GeoJson数据进行查询</p>
<h2 id="nearSphere缓冲区范围查询（距离单位：米）"><a href="#nearSphere缓冲区范围查询（距离单位：米）" class="headerlink" title="nearSphere缓冲区范围查询（距离单位：米）"></a>nearSphere缓冲区范围查询（距离单位：米）</h2><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">空间位置: &#123;</span><br><span class="line">        $nearSphere: &#123;</span><br><span class="line">            $geometry: &#123;</span><br><span class="line">                 <span class="string">"type"</span>:<span class="string">"Point"</span>,</span><br><span class="line">                 <span class="string">"coordinates"</span>:[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>]</span><br><span class="line">            &#125;,</span><br><span class="line">          $maxDistance : <span class="number">5000</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="intersect相交查询"><a href="#intersect相交查询" class="headerlink" title="intersect相交查询"></a>intersect相交查询</h2><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">空间位置: &#123;</span><br><span class="line">        $geoIntersects: &#123;</span><br><span class="line">            $geometry: &#123;</span><br><span class="line">                 <span class="string">"type"</span>:<span class="string">"Polygon"</span>,</span><br><span class="line">                 <span class="string">"coordinates"</span>:[[</span><br><span class="line">                    [<span class="number">110</span>,<span class="number">30</span>],</span><br><span class="line">                    [<span class="number">110</span>, <span class="number">60</span>],</span><br><span class="line">                    [<span class="number">120</span>, <span class="number">60</span>],</span><br><span class="line">                    [<span class="number">120</span>, <span class="number">30</span>],</span><br><span class="line">                    [<span class="number">110</span>,<span class="number">30</span>]</span><br><span class="line">                    ]]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>图解 MongoDB 地理位置索引的实现原理： <a href="http://blog.nosqlfan.com/html/1811.html">http://blog.nosqlfan.com/html/1811.html</a><br>结合MongoDB开发LBS应用：<a href="http://www.infoq.com/cn/articles/depth-study-of-Symfony2">http://www.infoq.com/cn/articles/depth-study-of-Symfony2</a><br><a href="http://docs.mongodb.org/manual/applications/geospatial-indexes/">http://docs.mongodb.org/manual/applications/geospatial-indexes/</a></p>
<h2 id="MongoDB地理位置索引"><a href="#MongoDB地理位置索引" class="headerlink" title="MongoDB地理位置索引"></a>MongoDB地理位置索引</h2><p>MongoDB地理位置索引常用的有两种</p>
<pre><code>* 2d 平面坐标索引，适用于基于平面的坐标计算。也支持球面距离计算，不过官方推荐使用2dsphere索引。
* 2dsphere 几何球体索引，适用于球面几何运算
* 2d空间索引也支持Polygon+属性查询，但在组合索引/查询中为串行过程（低效），而2dsphere空间索引支持高效的组合索引/查询（即真正的GIS查询）
</code></pre><p>查询方式分三种情况：</p>
<pre><code>1. Inclusion。范围查询，如百度地图“视野内搜索”。
2. Inetersection。交集查询。不常用。
3. Proximity。周边查询，如“附近500内的餐厅”。
</code></pre><p>MongoDB查询地理位置默认有3种距离单位：</p>
<pre><code>* 米(meters)
* 平面单位(flat units，可以理解为经纬度的“一度”)
* 弧度(radians)。
</code></pre><p>通过GeoJSON格式查询，单位默认是米，通过其它方式则比较混乱<br>geoWithin的查询范围：经/纬度范围之和不能大于180<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"> double[][] geometry = GeoUtil. createRectangle(<span class="number">-20</span>, <span class="number">90</span>, <span class="number">160</span>, <span class="number">-90</span>);</span><br><span class="line">&#123;空间位置: &#123;<span class="attr">$geoWithin</span>: &#123;<span class="attr">$geometry</span>: &#123;<span class="attr">type</span>:<span class="string">'Polygon'</span>,<span class="attr">coordinates</span>:[[[<span class="number">-20.0</span>,<span class="number">90.0</span>],[<span class="number">-20.0</span>,<span class="number">-90.0</span>],[<span class="number">160.0</span>,<span class="number">-90.0</span>],[<span class="number">160.0</span>,<span class="number">90.0</span>],[<span class="number">-20.0</span>,<span class="number">90.0</span>]]]&#125;&#125;&#125;,规范地址节简称:<span class="string">'POI'</span>,空间优先级:<span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB集群学习笔记</title>
    <url>/2015/12/29/MongoDB%E9%9B%86%E7%BE%A4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>考虑部署实施的复杂度，一直没上MongoDB集群，但现在海量数据一来，单机性能就扛不住了，本文记录MongoDB集群的基础知识。</p>
<hr>
<a id="more"></a>
<p>Mongodb 有三种集群方式的搭建： Replica Set ，Sharding 和 Master-Slaver</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ol>
<li>Chunck（块）：一个区间的数据称为一个数据块,是一个逻辑概念，物理存储并不连续，默认64M,可通过启动时附加’—chunkSize N’参数设置块大小</li>
<li>Vertical Scaling（垂直扩展）：CPU/RAM/IO等硬件层扩展，有云端部署和硬件扩展的瓶颈</li>
<li>Sharding（水平分片）：逻辑上是一个数据库，但物理存储上分开独立存储</li>
<li>Balancing（平衡）：当存在多个可用的分片，且块的数量足够多，mongodb的balancer（平衡器）会把数据迁移到其他分片上</li>
<li>mongos：mongos是用户和群集间的交互点，其职责是隐藏分片内部的复杂性并向用户提供一个简洁的单服务器接口，mongos会将所有用户请求转发到恰当的分片上。</li>
<li>config server（配置服务器）：配置服务器包含了有关集群的最完整可靠的信息以供所有人（分片、mongos进程和系统管理员）访问。</li>
</ol>
<h1 id="集群的构造"><a href="#集群的构造" class="headerlink" title="集群的构造"></a>集群的构造</h1><p>一个MongoDB集群基本由3类进程组成： shards（存储数据）, mongos(路由器）、 config servers（配置服务器）</p>
<h2 id="Shard-Server"><a href="#Shard-Server" class="headerlink" title="Shard Server"></a>Shard Server</h2><p>即存储实际数据的分片每个Shard 可以是一个mongod实例也可以是一组mongod实例构成的Replica Set。为了实现每个Shard内部的auto-failover，MongoDB官方建议每个Shard为一组Replica Set。</p>
<h2 id="Config-Server"><a href="#Config-Server" class="headerlink" title="Config Server"></a>Config Server</h2><p>为了将一个特定的collection 存储在多个shard 中需要为该collection指定一个shard key例如{age: 1} shard key 可以决定该条记录属于哪个chunk。Config Servers 就是用来存储所有shard 节点的配置信息、每个chunk 的shard key 范围、chunk 在各shard 的分布情况、该集群中所有DB 和collection 的sharding 配置信息。</p>
<h2 id="Route-Process"><a href="#Route-Process" class="headerlink" title="Route Process"></a>Route Process</h2><p>路由客户端由此接入，然后询问Config Servers 需要到哪个Shard 上查询或保存记录再连接相应的Shard 进行操作，最后将结果返回给客户端。客户端只需要将原本发给mongod的查询或更新请求原封不动地发给Routing Process而不必关心所操作的记录存储在哪个Shard 上。</p>
<h1 id="Replica-Set（复制）"><a href="#Replica-Set（复制）" class="headerlink" title="Replica Set（复制）"></a>Replica Set（复制）</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>复制是在多台服务器之间同步数据的过程。</p>
<h2 id="容灾性"><a href="#容灾性" class="headerlink" title="容灾性"></a>容灾性</h2><p>由于在不同的数据库服务器上拥有多个数据镜像，复制可以有效的防止由于单台服务器故障而导致的数据丢失。复制还能够帮助我们从硬件故障或是服务中断中恢复数据。我们也可以通过增加复制节点来将其用于灾难恢复、报表或是备份。</p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>在某些情况中，我们可以通过复制的方式来提高读的性能。客户端可以将读与写请求分别发送到不同的服务器上。我们还能够通过在其他数据中心建立分布式复制节点的方式来做异地冗灾，以进一步提高可用性。</p>
<h1 id="Sharding（分片）"><a href="#Sharding（分片）" class="headerlink" title="Sharding（分片）"></a>Sharding（分片）</h1><p><a href="https://docs.mongodb.org/manual/faq/sharding/">shard官方QA</a></p>
<h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>sharding（分片）是使用多个机器存储数据的方法,MongoDB使用分片以支持巨大的数据存储量与对数据操作.<br>为了解决这些问题,有两个基本的方法: 纵向扩展 和 分片 .<br>分片的目的：高数据量和吞吐量的数据库应用会对单机的性能造成较大压力,大的查询量会将单机的CPU耗尽,大的数据量对单机的存储压力较大,最终会耗尽系统的内存而将压力转移到磁盘IO上.</p>
<p>一个分片可由多台服务器组成（每台服务器都有一份分片数据的Replica set副本）<br>根据片键（key）分片[a,b)，MongoDB会在不同分片区间移动数据子集<br><a href="http://www.server110.com/mongodb/201403/7201.html">MongoDB集群（分片）安装与配置方法图解</a></p>
<h2 id="shard-key-片键"><a href="#shard-key-片键" class="headerlink" title="shard key(片键)"></a>shard key(片键)</h2><p>shard key大小不能超过512 bytes.<br>分片后shard key不可改变，除非重建collection</p>
<h3 id="小基数片键"><a href="#小基数片键" class="headerlink" title="小基数片键"></a>小基数片键</h3><p>小基数片键：片键值数量有限<br>适用的键：应使用组合片键(一个片键包含2个字段），请确保第二个字段有足够的值供MongoDB用来进行分割</p>
<h3 id="升序片键"><a href="#升序片键" class="headerlink" title="升序片键"></a>升序片键</h3><p>适用于任何升序排列的键值，而并不必须是时间戳，包括日期、自增主键。<br>只要键值趋于无穷大，就会面临单一且不可分散的热点问题</p>
<h3 id="随机片键"><a href="#随机片键" class="headerlink" title="随机片键"></a>随机片键</h3><p>初衷是为了避免热点，会选择一个随机值的字段来分片。<br>数据量变大后会给RAM增加压力，且会引发大量的磁盘IO</p>
<h3 id="好片键"><a href="#好片键" class="headerlink" title="好片键"></a>好片键</h3><p>具有良好的数据局部性（data locality）特征，但又不会太局部而导致热点出现。<br>准升序键+搜索键<code>｛coarselyAscending:1，search:1｝</code>，coarselyAscending用来控制数据局部化，search字段则是数据上常用的一个检索字段。<br>coarselyAscending键的每个值最好能对应几十到几百个数据块，如月份（2015-12）<br>search键则应当是应用程序通常都会依据其进行查询的字段，如用户信息、文件名称、或GUID等</p>
<h1 id="Master-Slaver（主从）"><a href="#Master-Slaver（主从）" class="headerlink" title="Master-Slaver（主从）"></a>Master-Slaver（主从）</h1><p>对于Mongodb来说，并不推荐使用Master-Slave架构，因为Master-Slave其中Master宕机后不能自动恢复，推荐使用Replica Set，除非Replica的节点数超过50，才需要使用Master-Slave架构，正常情况是不可能用那么多节点的。<br>主从架构一般用于备份或者做读写分离。由两种角色构成：</p>
<h2 id="主-Master"><a href="#主-Master" class="headerlink" title="主(Master)"></a>主(Master)</h2><p>可读可写，当数据有修改的时候，会将oplog同步到所有连接的salve上去。</p>
<h2 id="从-Slave"><a href="#从-Slave" class="headerlink" title="从(Slave)"></a>从(Slave)</h2><p>只读不可写，自动从Master同步数据。</p>
<h1 id="mongodb集群监控"><a href="#mongodb集群监控" class="headerlink" title="mongodb集群监控"></a>mongodb集群监控</h1><p>在线：Mongodb Cloud Manager<br>离线：MongoDB Management Service(MMS)<br><img src="automation.png" alt="how automation agent work"><br><img src="monitoring.png" alt="how monitoring agent work"><br><img src="backup.png" alt="how bakcup agent work"></p>
<h1 id="mongodb-gui-tools"><a href="#mongodb-gui-tools" class="headerlink" title="mongodb gui tools"></a>mongodb gui tools</h1><p><code>MongoVUE1.6.9</code> 在<code>Mongodb3.2.0</code>版本不可用了，不得不寻找替代品<br><a href="https://docs.mongodb.org/ecosystem/tools/administration-interfaces">官方推荐工具列表</a></p>
<p>亲测觉得不错的GUI工具</p>
<ul>
<li><a href="http://3t.io/mongochef/">3T MongoChef</a> 提供64位</li>
<li><a href="http://mongobooster.com/">mongobooster</a></li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Samba安装配置笔记</title>
    <url>/2015/12/07/Samba%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>一个局域网的项目，需要在Linux上进行文件共享，最终选型samba，即通过jcifs实现java读写共享文件。</p>
<hr>
<a id="more"></a>
<h1 id="关于SMB"><a href="#关于SMB" class="headerlink" title="关于SMB"></a>关于SMB</h1><p>SMB（Server Message Block）:通信协议是微软（Microsoft）和英特尔(Intel)在1987年制定的协议，主要是作为Microsoft网络的通讯协议。SMB 是在会话层（session layer）和表示层（presentation layer）以及小部分应用层（application layer）的协议。SMB使用了NetBIOS的应用程序接口 （Application Program Interface，简称API）。另外，它是一个开放性的协议，允许了协议扩展——使得它变得更大而且复杂；大约有65个最上层的作业，而每个作业都超过120个函数，甚至Windows NT也没有全部支持到，最近微软又把 SMB 改名为 CIFS（Common Internet ile System），并且加入了许多新的特色。　　<br>SMB协议是基于TCP－NETBIOS下的，一般端口使用为139，445</p>
<h1 id="关于CIFS"><a href="#关于CIFS" class="headerlink" title="关于CIFS"></a>关于CIFS</h1><p>CIFS(Common Internet File System)：通用Internet文件系统在windows主机之间进行网络文件共享是通过使用微软公司自己的CIFS服务实现的。CIFS 是一个新提出的协议，它使程序可以访问远程Internet计算机上的文件并要求此计算机的服务。CIFS 使用客户/服务器模式。客户程序请求远在服务器上的服务器程序为它提供服务。服务器获得请求并返回响应。<br>CIFS是公共的或开放的SMB协议版本，并由Microsoft使用。SMB协议现在是局域网上用于服务器文件访问和打印的协议。<br>象SMB协议一样，CIFS在高层运行，而不象TCP/IP协议那样运行在底层。CIFS可以看做是应用程序协议如文件传输协议和超文本传输协议的一个实现。</p>
<h1 id="关于JCIFS"><a href="#关于JCIFS" class="headerlink" title="关于JCIFS"></a>关于JCIFS</h1><p>JCIFS是CIFS 在JAVA中的一个实现，是samba组织负责维护开发的一个开源项目，专注于使用java语言对cifs协议的设计和实现。他们将jcifs设计成为一个完整的，丰富的，具有可扩展能力且线程安全的客户端库。这一库可以应用于各种java虚拟机访问遵循CIFS/SMB网络传输协议的网络资源。类似于java.io.File的接口形式，在多线程的工作方式下被证明是有效而容易使用的。</p>
<h1 id="关于Samba"><a href="#关于Samba" class="headerlink" title="关于Samba"></a>关于Samba</h1><p>Samba，是种用来让UNIX系列的操作系统与微软Windows操作系统的SMB/CIFS（Server Message Block/Common Internet File System）网络协议做链接的自由软件。第三版不仅可访问及分享SMB的文件夹及打印机，本身还可以集成入Windows Server的域，扮演为域控制站（Domain Controller）以及加入Active Directory成员。简而言之，此软件在Windows与UNIX系列OS之间搭起一座桥梁，让两者的资源可互通有无。</p>
<h1 id="CentOS下yum安装配置Samba"><a href="#CentOS下yum安装配置Samba" class="headerlink" title="CentOS下yum安装配置Samba"></a>CentOS下yum安装配置Samba</h1><h2 id="新建用户samba"><a href="#新建用户samba" class="headerlink" title="新建用户samba"></a>新建用户samba</h2><p>useradd  samba</p>
<h2 id="设置samba用户密码"><a href="#设置samba用户密码" class="headerlink" title="设置samba用户密码"></a>设置samba用户密码</h2><p>passwd samba</p>
<h2 id="将samba加入到Samba用户数据库"><a href="#将samba加入到Samba用户数据库" class="headerlink" title="将samba加入到Samba用户数据库"></a>将samba加入到Samba用户数据库</h2><p><code>smbpasswd -a samba</code> windows访问samba共享目录时需要输入此用户名和密码</p>
<h2 id="设置目录访问权限"><a href="#设置目录访问权限" class="headerlink" title="设置目录访问权限"></a>设置目录访问权限</h2><p>chown -R   samba:samba /uadb/exchange/import<br>chown -R   samba:samba /uadb/exchange/export<br>chown -R  samba:samba /uadb/exchange/export_backup</p>
<h2 id="编辑smb-conf配置文件"><a href="#编辑smb-conf配置文件" class="headerlink" title="编辑smb.conf配置文件"></a>编辑smb.conf配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim/etc/samba/smb.conf</span></span><br><span class="line">[global]</span><br><span class="line"></span><br><span class="line">workgroup = WORKGROUP</span><br><span class="line">netbios name = sambaServer</span><br><span class="line">server string = Linux Samba Server TestServer</span><br><span class="line">security = user</span><br><span class="line"></span><br><span class="line">[import]</span><br><span class="line">path = /uadb/exchange/import</span><br><span class="line">writeable = yes</span><br><span class="line">browseable = yes</span><br><span class="line">guest ok = yes</span><br><span class="line"></span><br><span class="line">[<span class="built_in">export</span>]</span><br><span class="line">path = /uadb/exchange/<span class="built_in">export</span></span><br><span class="line">writeable = yes</span><br><span class="line">browseable = yes</span><br><span class="line">guest ok = yes</span><br></pre></td></tr></table></figure>
<h2 id="设置samba服务开机启动"><a href="#设置samba服务开机启动" class="headerlink" title="设置samba服务开机启动"></a>设置samba服务开机启动</h2><p><code>chkconfig smb on</code></p>
<h2 id="重启服samba服务"><a href="#重启服samba服务" class="headerlink" title="重启服samba服务"></a>重启服samba服务</h2><p><code>service smb  restart</code></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="连接路径问题"><a href="#连接路径问题" class="headerlink" title="连接路径问题"></a>连接路径问题</h2><ul>
<li>问题描述：cifs.smb.SmbException: The network name cannot be found.</li>
<li>问题定位：不能用绝对路径来访问，需要用samba的配置的共享文件夹名称来访问</li>
<li>解决方案：正确：<code>smb://samba:samba@192.168.1.80/import</code>；错误：<code>smb://samba:samba@192.168.1.80/uadb/exchange/import</code>  </li>
</ul>
<h1 id="Samba读写示例"><a href="#Samba读写示例" class="headerlink" title="Samba读写示例"></a>Samba读写示例</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">/</span><br><span class="line"> * jcifs的开发方法类似java的文件操作功能，它的资源url定位：smb:<span class="comment">//&#123;user&#125;:&#123;password&#125;@&#123;host&#125;/&#123;path&#125;，</span></span><br><span class="line"> * smb为协议名，user和password分别为共享文件机子的登陆名和密码，@后面是要访问的资源的主机名或IP地址。最后是资源的共享文件夹名称和共享资源名。</span><br><span class="line"> * 例如smb:<span class="comment">//administrator:122122@192.168.0.22/test/response.txt。</span></span><br><span class="line"> *  </span><br><span class="line"> * SmbFile file = newSmbFile(<span class="string">"smb://guest:1234@192.168.3.56/share/a.txt"</span>);</span><br><span class="line"> *</span><br><span class="line">/</span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line">true<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">truetrue<span class="keyword">try</span> &#123;</span><br><span class="line">truetruetrue<span class="comment">// 局域网共享文件，读文件</span></span><br><span class="line">truetruetrueSmbFile smbFile = <span class="keyword">new</span> SmbFile(<span class="string">"smb://samba:samba@192.168.1.80/import/test.db"</span>);</span><br><span class="line">truetruetrue<span class="comment">// 通过 smbFile.isDirectory();isFile()可以判断smbFile是文件还是文件夹</span></span><br><span class="line">truetruetrue<span class="keyword">int</span> length = smbFile.getContentLength();</span><br><span class="line">truetruetrue<span class="keyword">byte</span> buffer[] = <span class="keyword">new</span> <span class="keyword">byte</span>[length];</span><br><span class="line">truetruetrueSmbFileInputStream in = <span class="keyword">new</span> SmbFileInputStream(smbFile);</span><br><span class="line">truetruetrue<span class="keyword">while</span> ((in.read(buffer)) != -<span class="number">1</span>) &#123;</span><br><span class="line">truetruetruetrueSystem.out.write(buffer);</span><br><span class="line">truetruetruetrueSystem.out.println(<span class="string">"\n"</span> + buffer.length);</span><br><span class="line">truetruetrue&#125;</span><br><span class="line">truetruetruein.close();</span><br><span class="line">truetruetruesmbFile.delete();</span><br><span class="line"></span><br><span class="line">truetrue&#125; <span class="keyword">catch</span> (SmbAuthException e) &#123;</span><br><span class="line">truetruetruee.printStackTrace();</span><br><span class="line">truetrue&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">truetruetruee.printStackTrace();</span><br><span class="line">truetrue&#125;</span><br><span class="line">true&#125;</span><br><span class="line"></span><br><span class="line">true<span class="meta">@Test</span></span><br><span class="line">true<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wariteFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">truetrue<span class="keyword">try</span> &#123;</span><br><span class="line">truetruetrueSmbFile smbFileOut = <span class="keyword">new</span> SmbFile(<span class="string">"smb://samba:samba@192.168.1.80/import/test2.db"</span>);</span><br><span class="line">truetruetrue<span class="keyword">if</span> (!smbFileOut.exists())</span><br><span class="line">truetruetruetruesmbFileOut.createNewFile();</span><br><span class="line">truetruetrueSmbFileOutputStream out = <span class="keyword">new</span> SmbFileOutputStream(smbFileOut);</span><br><span class="line">truetruetrueout.write(<span class="string">"abcdefw"</span>.getBytes());</span><br><span class="line">truetruetrueout.close();</span><br><span class="line">truetruetruesmbFileOut.delete();</span><br><span class="line">truetrue&#125; <span class="keyword">catch</span> (SmbAuthException e) &#123;</span><br><span class="line">truetruetruee.printStackTrace();</span><br><span class="line">truetrue&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">truetruetruee.printStackTrace();</span><br><span class="line">truetrue&#125;</span><br><span class="line">true&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse常用插件</title>
    <url>/2016/01/27/MyEclipse%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>记录以J2EE开发采用MyEclipse IDE的常用插件</p>
<hr>
<a id="more"></a>
<p><img src="Eclipse版本.png" alt="Eclipse内核版本"></p>
<h1 id="SVN"><a href="#SVN" class="headerlink" title="SVN"></a>SVN</h1><p><a href="http://subclipse.tigris.org/update_1.12.x/">svn update site URL</a><br><a href="http://subclipse.tigris.org/servlets/ProjectDocumentList?folderID=2240">svn offline package</a></p>
<h1 id="FatJar"><a href="#FatJar" class="headerlink" title="FatJar"></a>FatJar</h1><p><a href="http://kurucz-grafika.de/fatjar">FatJar update site URL</a></p>
<h1 id="Freemarker-Editor"><a href="#Freemarker-Editor" class="headerlink" title="Freemarker Editor"></a>Freemarker Editor</h1><p><a href="http://download.jboss.org/jbosstools/updates/development/kepler/">Freemarker Editor update site URL</a><br>安装时选择Jboss IDE即可</p>
<h1 id="Drools插件"><a href="#Drools插件" class="headerlink" title="Drools插件"></a>Drools插件</h1><p><a href="http://download.jboss.org/drools/release/5.5.0.Final/org.drools.updatesite/">drools 5.5.0 update site URL</a></p>
<h1 id="OneJar"><a href="#OneJar" class="headerlink" title="OneJar"></a>OneJar</h1><p><a href="http://one-jar.sourceforge.net/">OneJar官网</a></p>
<h2 id="maven配置onejar打包"><a href="#maven配置onejar打包" class="headerlink" title="maven配置onejar打包"></a>maven配置onejar打包</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Make this jar executable --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">plugin</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span> &gt;</span>org.apache.maven.plugins <span class="tag">&lt;/<span class="name">groupId</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span> &gt;</span>maven-jar-plugin <span class="tag">&lt;/<span class="name">artifactId</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">archive</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">manifest</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mainClass</span> &gt;</span>gto.amo.mapper.app.form.Main <span class="tag">&lt;/<span class="name">mainClass</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">manifest</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">archive</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">plugin</span> &gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Includes the runtime dependencies --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">plugin</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span> &gt;</span>com.jolira <span class="tag">&lt;/<span class="name">groupId</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span> &gt;</span>onejar-maven-plugin <span class="tag">&lt;/<span class="name">artifactId</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span> &gt;</span>1.4.4 <span class="tag">&lt;/<span class="name">version</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">executions</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">execution</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">attachToBuild</span> &gt;</span>true <span class="tag">&lt;/<span class="name">attachToBuild</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">classifier</span> &gt;</span>onejar <span class="tag">&lt;/<span class="name">classifier</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">goals</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">goal</span> &gt;</span>one-jar <span class="tag">&lt;/<span class="name">goal</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">goals</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">execution</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">executions</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">plugin</span> &gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>J2EE</tag>
        <tag>Eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>Ne04j单机版和集群版部署</title>
    <url>/2016/01/25/Ne04j%E5%8D%95%E6%9C%BA%E7%89%88%E5%92%8C%E9%9B%86%E7%BE%A4%E7%89%88%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>Neo4j HA(Neo4j High Availability)，高可用性主要指其包含容错机制和可进行水平扩展，即Neo4j Cluster</p>
<hr>
<a id="more"></a>
<h1 id="部署Ne04j单机版-windows"><a href="#部署Ne04j单机版-windows" class="headerlink" title="部署Ne04j单机版(windows)"></a>部署Ne04j单机版(windows)</h1><h2 id="java-se-8安装"><a href="#java-se-8安装" class="headerlink" title="java se 8安装"></a>java se 8安装</h2><p><a href="http://download.oracle.com/otn-pub/java/jdk/8u71-b15/jdk-8u71-windows-x64.exe?AuthParam=1453700621_44741e28a0fd105dbfea10bad65c95b3">java8下载</a><br>安装java se8后，并临时设置环境变量：<code>set JAVA_HOME=E:\Software\jdk8x64\jre1.8</code>（避免与本机java7冲突）</p>
<h2 id="下载Neo4j-3-0-0"><a href="#下载Neo4j-3-0-0" class="headerlink" title="下载Neo4j-3.0.0"></a>下载Neo4j-3.0.0</h2><p><a href="http://neo4j.com/artifact.php?name=neo4j-enterprise-3.0.0-M02-windows.zip">neo4j-enterprise-3.0.0-M02-windows</a></p>
<h2 id="下载Neo4j-2-3-2"><a href="#下载Neo4j-2-3-2" class="headerlink" title="下载Neo4j-2.3.2"></a>下载Neo4j-2.3.2</h2><p><a href="http://neo4j.com/artifact.php?name=neo4j-community-2.3.2-windows.zip">neo4j-enterprise-2.3.2-windows</a><br>设置NEO4J_HOME，</p>
<h2 id="Neo4j-Browser"><a href="#Neo4j-Browser" class="headerlink" title="Neo4j Browser"></a>Neo4j Browser</h2><ul>
<li>运行bin\Neo4j.bat，如<code>cd F:\Dev\neo4j-enterprise-3.0.0-M02\bin &amp;&amp; Neo4j.bat</code></li>
<li>在浏览器打开Neo4j的在线REPL，即<a href="http://localhost:7474/">Neo4j Browser</a>,在命令行输入Cypher query语句进行查询</li>
<li>在浏览器打开<a href="http://localhost:7474/webadmin/#/info/">Neo4j Guide</a>了解Neo4j</li>
<li>老版本的在线入口：<a href="http://localhost:7474/webadmin/#/index/">neo4j webAdmin</a></li>
</ul>
<h2 id="在Windows-PowerShell运行Neo4j"><a href="#在Windows-PowerShell运行Neo4j" class="headerlink" title="在Windows PowerShell运行Neo4j"></a>在Windows PowerShell运行Neo4j</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 权限配置</span></span><br><span class="line"><span class="string">Set-ExecutionPolicy</span> <span class="string">-ExecutionPolicy</span> <span class="string">RemoteSigned</span></span><br><span class="line"><span class="comment"># 导入Neo4j模块</span></span><br><span class="line"><span class="string">Import-Module</span> <span class="string">C:\Neo4j\bin\Neo4j-Management.psd1</span></span><br><span class="line"><span class="comment"># 查询Neo4j命令</span></span><br><span class="line"><span class="string">Get-Command</span> <span class="string">-Module</span> <span class="string">Neo4j-Management</span></span><br><span class="line"><span class="comment"># 安装Neo4j服务</span></span><br><span class="line"><span class="string">Install-Neo4jServer</span></span><br><span class="line"><span class="comment"># 查询NEO4J_HOME路径</span></span><br><span class="line"><span class="string">Get-Neo4jServer</span> <span class="string">C:\Neo4j</span></span><br><span class="line"><span class="comment"># 启动Neo4j服务</span></span><br><span class="line"><span class="string">Start-Neo4jServer</span></span><br><span class="line"><span class="comment"># 关闭Neo4j服务</span></span><br><span class="line"><span class="string">Stop-Neo4jServer</span></span><br><span class="line"><span class="comment"># 重启Neo4j服务</span></span><br><span class="line"><span class="string">Restart-Neo4jServer</span></span><br></pre></td></tr></table></figure>
<h2 id="Neo4j-Browser常用脚本"><a href="#Neo4j-Browser常用脚本" class="headerlink" title="Neo4j Browser常用脚本"></a>Neo4j Browser常用脚本</h2><p>:help 帮助<br>shift+enter 多行书写<br>ctrl+enter 执行<br>:clear 清空执行结果<br>:play 打开入门教程</p>
<h1 id="部署Neo4j集群-Linux"><a href="#部署Neo4j集群-Linux" class="headerlink" title="部署Neo4j集群(Linux)"></a>部署Neo4j集群(Linux)</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/">neo4j manual doc</a></p>
<ul>
<li>TODO<br>Neo4j HA has been designed to make the transition from single machine to multi machine operation simple, by not having to change the already existing application.<br>Consider an existing application with Neo4j embedded and running on a single machine. To deploy such an application in a multi machine setup the only required change is to switch the creation of the GraphDatabaseService from GraphDatabaseFactory to HighlyAvailableGraphDatabaseFactory. Since both implement the same interface, no additional changes are required.</li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title>Python并行编程笔记</title>
    <url>/2016/01/23/Python%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>大数据时代，并发/并行是不变的话题，以并行计算来提高程序运行效率，可充分利用硬件资源（CPU，内存，磁盘/网络IO）。Python作为脚本语言，解释器简洁轻量，软件研发后无需编译且更新部署方便，对于实现一些类似爬取的工具十分友好。</p>
<hr>
<a id="more"></a>
<h1 id="关于多进程问题"><a href="#关于多进程问题" class="headerlink" title="关于多进程问题"></a>关于多进程问题</h1><p><a href="http://blog.tankywoo.com/2015/09/06/cant-pickle-instancemethod.html">http://blog.tankywoo.com/2015/09/06/cant-pickle-instancemethod.html</a><br>如果你的代码是CPU密集型，多个线程的代码很有可能是线性执行的。所以这种情况下多线程是鸡肋，效率可能还不如单线程因为有context switch,<br>如果你的代码是IO密集型，多线程可以明显提高效率。例如制作爬虫（我就不明白为什么Python总和爬虫联系在一起…不过也只想起来这个例子…），绝大多数时间爬虫是在等待socket返回数据。这个时候C代码里是有release GIL的，最终结果是某个线程等待IO的时候其他线程可以继续执行。</p>
<h1 id="python线程"><a href="#python线程" class="headerlink" title="python线程"></a>python线程</h1><h2 id="python协程"><a href="#python协程" class="headerlink" title="python协程"></a>python协程</h2><p>协程，又称微线程，纤程。英文名Coroutine。<br>最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。<br>第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。<br>因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。<br>Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。</p>
<h2 id="threading"><a href="#threading" class="headerlink" title="threading"></a>threading</h2><h2 id="生产者-消费者模型"><a href="#生产者-消费者模型" class="headerlink" title="生产者-消费者模型"></a>生产者-消费者模型</h2><h1 id="python多线程"><a href="#python多线程" class="headerlink" title="python多线程"></a>python多线程</h1><h2 id="monkey-patch"><a href="#monkey-patch" class="headerlink" title="monkey.patch"></a>monkey.patch</h2><p>monkey patch指的是在运行时动态替换,一般是在startup的时候.<br>用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了.<br>之前做的一个游戏服务器,很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗?<br>其实只需要在进程startup的地方monkey patch就行了.是影响整个进程空间的.<br>同一进程空间中一个module只会被运行一次.</p>
<h2 id="gevent"><a href="#gevent" class="headerlink" title="gevent"></a>gevent</h2><p>gevent 并发实现：<br>from gevent import monkey; monkey.patch_socket()</p>
<h1 id="python多进程"><a href="#python多进程" class="headerlink" title="python多进程"></a>python多进程</h1><h2 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h2><p>One can create a pool of processes which will carry out tasks submitted to it with the Pool class.<br>参考：<a href="http://www.davidmoodie.com/python-multiprocessing-fbalbumdownloader/">http://www.davidmoodie.com/python-multiprocessing-fbalbumdownloader/</a></p>
<p>注意：multiprocessing与gevent同时使用时，如果运行了gevent.monkey.patch_thread()或patch_all(),pool进程池将无效</p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>并行</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建Python工程化开发框架</title>
    <url>/2016/01/20/%E6%90%AD%E5%BB%BAPython%E5%B7%A5%E7%A8%8B%E5%8C%96%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<p>2016的元月以python作为开端。<br>采用python进行网络数据聚合抽取，需调研并搭建python工程化开发框架，几番迭代，一个适用于数据采集的开发环境搭建完成：</p>
<ul>
<li>开发环境：python2.7.10 32位/pycharm5</li>
<li>项目构建：virtualenv/virtualenvWrapper 虚拟运行环境；pip 依赖项管理；pyBuilder项目构建，其中pyBuilder以disutils用于项目打包</li>
<li>项目文档：mkdocs/sphinx；参考<a href="http://docs.python-guide.org/en/latest/writing/documentation/">python-guide-writing</a></li>
<li>Web框架：Tornado/web,py（非阻塞式web服务器，精简）；django（文档功能齐全，但生态封闭）</li>
<li>单元测试：unittest/coverage(测试覆盖率统计)</li>
<li>并行框架：gevent(多线程)+monkey patch(运行时动态替换模块)，multiprocessing(多进程)</li>
<li>爬虫框架：scrapy/selenium</li>
<li>接口设计： zope.interface</li>
<li>编码风格：<a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/contents/">google-python-styleguide</a></li>
</ul>
<hr>
<a id="more"></a>
<p>pip install -i  <a href="http://pypi.douban.com/simple">http://pypi.douban.com/simple</a>  Shapely —trusted-host pypi.douban.com</p>
<h1 id="pip源配置"><a href="#pip源配置" class="headerlink" title="pip源配置"></a>pip源配置</h1><h2 id="临时换源"><a href="#临时换源" class="headerlink" title="临时换源"></a>临时换源</h2><p>临时换源只在某一条命令中生效，只要在命令中加上”-i“，指定使用的源即可<code>pip install scrapy -i url</code>，<br>如安装pandas：<code>pip install -i  http://pypi.douban.com/simple  pandas --trusted-host pypi.douban.com</code></p>
<h2 id="永久换源"><a href="#永久换源" class="headerlink" title="永久换源"></a>永久换源</h2><p>要是想永久更改pip源，在pip的配置文件（~/.pip/pip.conf）中增加<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url=http://pypi.douban.com/simple</span><br></pre></td></tr></table></figure></p>
<h2 id="一些国内的pip源"><a href="#一些国内的pip源" class="headerlink" title="一些国内的pip源"></a>一些国内的pip源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://mirrors.aliyun.com/pypi/simple/ # 阿里云</span><br><span class="line">http://pypi.douban.com/simple  #豆瓣</span><br><span class="line">http://pypi.hustunique.com/simple  #华中理工大学</span><br><span class="line">http://pypi.sdutlinux.org/simple  #山东理工大学</span><br><span class="line">http://pypi.mirrors.ustc.edu.cn/simple  #中国科学技术大学</span><br></pre></td></tr></table></figure>
<h1 id="打包部署问题"><a href="#打包部署问题" class="headerlink" title="打包部署问题"></a>打包部署问题</h1><p><a href="http://zengrong.net/post/2169.htm">python打包部署历史</a><br>distutils&gt;setuptools/easyinstall(<em>.egg)&gt;pip/wheel(</em>.whl)</p>
<h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><p>导出dependency:<code>pip freeze &gt; requirements.txt</code><br>安装dependency:<code>pip install -r requirements.txt</code></p>
<h2 id="whl"><a href="#whl" class="headerlink" title="whl"></a>whl</h2><p>二进制文件whl</p>
<h2 id="如何cmd中运行开发的-py程序模块"><a href="#如何cmd中运行开发的-py程序模块" class="headerlink" title="如何cmd中运行开发的*.py程序模块"></a>如何cmd中运行开发的*.py程序模块</h2><p>新增workspace.path文件到virtualenv目录（如<code>E:\PythonWorkspace\ugc\ugc_venv\Lib\site-packages</code>）<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">E:\PythonWorkspace\ugc\ugc.aggregator</span><br><span class="line">E:\PythonWorkspace\ugc\ugc.aggregator\src\main\python</span><br></pre></td></tr></table></figure><br>注意path文件中的模块目录必须有<strong>init</strong>.py文件</p>
<h1 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h1><p>习惯了J2EE下的maven开发，对于python默认的module都安装到site-packages下的混乱不能理解，好在原来有virtualenv，它比maven本地repositoy库更具有独立性，当然冗余module是代价,好在python intepreter足够小巧。<br>virtualenv可以用来创建隔离的python环境 ，但新建出来的virtualenv都依赖本机安装的python底层dll等库。</p>
<ul>
<li>安装：<code>pip install virtualenv</code></li>
<li>新建virtualEnv：<code>virtualenv --no-site-packages venv</code></li>
<li>进入venvShel：<code>E:\PythonWorkspace\ugc\ugc_venv\Scripts\activate</code></li>
</ul>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li>问题描述：执行<code>pip install MySQL-python</code>报错： <code>fatal error C1083: Cannot open include file: &#39;config-win.h&#39;: No such file or directory</code>或者报错<code>No module named MySQLdb</code><br>解决方案：从<code>C:\Python27\Lib\site-packages</code>复制mysql相关的文件到虚拟环境的site-packages目录</li>
</ul>
<h1 id="virtualenvwrapper"><a href="#virtualenvwrapper" class="headerlink" title="virtualenvwrapper"></a>virtualenvwrapper</h1><p>virtualenv创建的环境都是零散的，而且还要执行cd，执行source 来激活环境。 如此繁琐十分影响工作效率，于是有了virtualenvwrapper。vw可以进行环境的管理，把创建的环境记录下来，并进行管理。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li>linux：<code>pip install  virtualenvwrapper</code>  </li>
<li>windows：<code>pip install virtualenvwrapper-win</code>  </li>
</ul>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul>
<li>安装完毕过后在环境变量里面新建一个WORKON_HOME字段存储虚拟python环境,WORKON_HOME：<code>E:\PythonWorkspace\venv</code></li>
<li>环境变量立即生效：cmd中运行<code>set WORKON_HOME=E:\PythonWorkspace\venv</code></li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>virtualenvwrapper运行bat默认安装在<code>C:\Python27\Scripts\*.bat</code></p>
<ul>
<li>创建虚拟环境:<code>mkvirtualenv VirtualenvName</code></li>
<li>列出所有虚拟环境:<code>Lsvirtualenv</code></li>
<li>移除虚拟环境:<code>rmvirtualenv VirtualenvName</code></li>
<li>切换到VirtualenvName环境:<code>workon VirtualenvName</code></li>
<li>退出当前虚拟环境:<code>deactivate</code></li>
</ul>
<h2 id="问题记录-1"><a href="#问题记录-1" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li><p>问题描述：执行virtualenv报错：<code>SyntaxError: Non-ASCII character &#39;\x90&#39; in file C:\Python27\Scripts\virtualenv.exe on line 1, but no encoding declared;</code><br>解决方案：卸载virtualenv<code>pip uninstall virtualenv</code>；卸载virtualenvwarpper<code>pip uninstall virtualenvwarpper-win</code>；重新安装virtualenvwarpper<code>pip install virtualenvwarpper-win</code>,要是还不行那就重装python！</p>
</li>
<li><p>问题描述：  File “E:\PythonWorkspace\venv\ugc.venv\Scripts\pip.exe”, line 1 SyntaxError: Non-ASCII character ‘\x90’ in file E:\PythonWorkspace\venv\ugc.venv\Scripts\pip.exe on line 1, but no encoding declared;<br>解决方案：原因是pip安装python包会加载我的用户目录，我的用户目录恰好是中文的，ascii不能编码。解决办法是：<br>python目录 Python27\Lib\site-packages 建一个文件sitecustomize.py,python会自动运行这个文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.setdefaultencoding(<span class="string">'gb2312'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="pybuilder"><a href="#pybuilder" class="headerlink" title="pybuilder"></a>pybuilder</h1><p><a href="http://pybuilder.github.io/">pybuilder官网</a><br>经常在java/c#/javascript之间切着敲代码，今年又多了python这个数据分析神器，习惯了Maven约定俗成的构建环境，为了实现单元测试打包一体化的高效，于是决定采用pybuidler进行工程构建</p>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p>在venv环境安装：<code>pip install pybuilder</code></p>
<h2 id="pybuilder项目目录结构"><a href="#pybuilder项目目录结构" class="headerlink" title="pybuilder项目目录结构"></a>pybuilder项目目录结构</h2><p><code>src/main/python</code>：源码<br><code>src/main/scripts</code>：可执行脚本<br><code>src/main/unittest</code>：单元测试</p>
<h2 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li>进入venvShell：<code>workon ugc.venv</code></li>
<li>执行默认build文件：<code>pyb_.exe</code> (参考官方文档执行pyb报错，暂未找到办法)</li>
<li>执行默认build文件，并打印unittest错误详情：<code>pyb_.exe -v</code></li>
<li>新增测试项目：<code>pyb_.exe  --start-project</code></li>
<li>发布：<code>pyb_.exe install_dependencies publish</code></li>
</ul>
<h2 id="问题记录-2"><a href="#问题记录-2" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li>单元测试执行错误：<code>BUILD FAILED - &#39;module&#39; object has no attribute &#39;FileUtil_test</code></li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python开发常见问题</title>
    <url>/2016/02/24/Python%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>记录Python开发过程中的遇到的问题</p>
<hr>
<a id="more"></a>
<h1 id="ImportError-No-module-named-MySQLdb"><a href="#ImportError-No-module-named-MySQLdb" class="headerlink" title="ImportError: No module named MySQLdb"></a>ImportError: No module named MySQLdb</h1><p>You can find binary installers here (Python 2.6-3.2), here (2.7) or here (2.6). Note that you don’t have to use 64bit Python on Windows x64. You can just as well use a 32bit build of Python, for which there are more pre-built 3rd party packages around.</p>
<h1 id="TypeError-‘-Callable’-object-is-not-callable"><a href="#TypeError-‘-Callable’-object-is-not-callable" class="headerlink" title="TypeError: ‘_Callable’ object is not callable"></a>TypeError: ‘_Callable’ object is not callable</h1><p>That error occurs when you try to call, with (), an object that is not callable.<br>A callable object can be a function or a class (that implements <strong>call</strong> method). According toPython Docs:<br>解决：在init构造函数删除初始化对象的代码</p>
<h1 id="TypeError-getPointByBounds-takes-exactly-4-arguments-5-given"><a href="#TypeError-getPointByBounds-takes-exactly-4-arguments-5-given" class="headerlink" title="TypeError: getPointByBounds() takes exactly 4 arguments (5 given)"></a>TypeError: getPointByBounds() takes exactly 4 arguments (5 given)</h1><p><code>def getPointByBounds(lng0, lat0, lng1, lat1, step=0.001) :</code>应该为<br><code>def getPointByBounds(self,lng0, lat0, lng1, lat1, step=0.001) :</code>第一个参数为self</p>
<h2 id="apply-async最后一个process调用的函数被中止"><a href="#apply-async最后一个process调用的函数被中止" class="headerlink" title="apply_async最后一个process调用的函数被中止"></a>apply_async最后一个process调用的函数被中止</h2><p>暂未发现原因</p>
<h2 id="hangs-on-‘scanning-files-to-index’-background-task"><a href="#hangs-on-‘scanning-files-to-index’-background-task" class="headerlink" title="hangs on ‘scanning files to index’ background task"></a>hangs on ‘scanning files to index’ background task</h2><p>go to the “File” on the left top, then select “invalidate caches/restart…”, and press “invalidate and restart”.</p>
<h2 id="pycharm添加已有virtualEnv"><a href="#pycharm添加已有virtualEnv" class="headerlink" title="pycharm添加已有virtualEnv"></a>pycharm添加已有virtualEnv</h2><p>如通过virtualEnvWarpper创建的env，默认在pycharm中无法选择已有virtualEnv，只能新建，可通过add local手动完成虚拟环境导入<br><code>File&gt;setting&gt;Project Interpreter&gt;add local&gt;选择virtualEnv\Scripts\python.exe</code></p>
<h2 id="pycharm5源代码管理之svn配置"><a href="#pycharm5源代码管理之svn配置" class="headerlink" title="pycharm5源代码管理之svn配置"></a>pycharm5源代码管理之svn配置</h2><p><a href="http://netcologne.dl.sourceforge.net/project/win32svn/1.8.14/Setup-Subversion-1.8.14.msi">svn1.8下载地址</a></p>
<ul>
<li>svn安装：注意安装路径不能带空格：</li>
<li>pycharm配置svn：在version contro&gt;svn&gt;command line client设置为C:\Dev\SVN\bin\svn.exe</li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>《深入理解Java虚拟机》读书笔记</title>
    <url>/2016/02/22/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>2016上半年花点时间深入了解JVM，读《《深入理解Java虚拟机 JVM高级特性与最佳实践》，整理遇到过的内存泄漏，性能优化问题</p>
<hr>
<a id="more"></a>
<h1 id="第一章-走近Java"><a href="#第一章-走近Java" class="headerlink" title="第一章 走近Java"></a>第一章 走近Java</h1><h2 id="Java技术体系"><a href="#Java技术体系" class="headerlink" title="Java技术体系"></a>Java技术体系</h2><p><img src="JDK技术组成.png" alt="JDK"></p>
<ul>
<li>Java程序设计语言、Java虚拟机、Java API类库三部分统称为JDK(Java Development Kit) ,JDK是Java程序开发的最小环境</li>
<li>Java API类库中的Java SE API子集和Java虚拟机两部分统称为JRE(Java Runtime Environment)，JRE是支持Java程序运行的标准环境</li>
<li>按照Java技术关注的重点业务领域来划分，Java技术体系可分为4个平台<ul>
<li>Java Card：支持Applets(Java小程序)运行在小内存设备（如智能卡）上的平台；</li>
<li>Java ME(Micro Edition)：支持Java运行在移动终端上的平台；（今有Android SDK）</li>
<li>Java SE(Standard Edition)：支持面向桌面级应用的Java平台；</li>
<li>Java EE(Enterprise Edition)：支持使用多层架构的企业级应用(如ERP、CRM应用)的Java平台；</li>
</ul>
</li>
</ul>
<h2 id="Java发展史"><a href="#Java发展史" class="headerlink" title="Java发展史"></a>Java发展史</h2><h2 id="Java虚拟机发展史"><a href="#Java虚拟机发展史" class="headerlink" title="Java虚拟机发展史"></a>Java虚拟机发展史</h2><ul>
<li>Sun Classic/Extract VM</li>
<li>Sun HotSpot VM</li>
<li>Sun Mobile-Embedded VM/Meta-Circular VM</li>
<li>Bea Jrockit/IDM J9 VM</li>
<li>Azul VM/BEA Liquid VM</li>
<li>Apache Harmony/Google Android Dalvik VM</li>
<li>Microsoft JVM…</li>
</ul>
<h2 id="Java技术的未来展望"><a href="#Java技术的未来展望" class="headerlink" title="Java技术的未来展望"></a>Java技术的未来展望</h2><ul>
<li>模块化（Jigsaw）</li>
<li>混合语言：多语言混合编程，通过特定领域发语言去解决特定领域的问题</li>
<li>多核并行（concurrent.forkjoin；Lambada；函数式编程）</li>
<li>丰富语法（Coin子项目）</li>
<li>64位虚拟机（计算机终究完全过渡到64位的时代）</li>
</ul>
<h2 id="JDK编译实战"><a href="#JDK编译实战" class="headerlink" title="JDK编译实战"></a>JDK编译实战</h2><p><a href="https://jdk7.java.net/source.html">OpenJDK7下载</a><br>Building the source code for the OpenJDK requires a certain degree of technical expertise.</p>
<h1 id="第二章-Java内存区域与内存溢出异常"><a href="#第二章-Java内存区域与内存溢出异常" class="headerlink" title="第二章 Java内存区域与内存溢出异常"></a>第二章 Java内存区域与内存溢出异常</h1><h2 id="运行时的数据区域"><a href="#运行时的数据区域" class="headerlink" title="运行时的数据区域"></a>运行时的数据区域</h2><p><img src="Java虚拟机运行时数据区.jpg" alt="Java虚拟机运行时数据区"></p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><ul>
<li>程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器；</li>
<li>PCR为线程私有内存；</li>
<li>是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域；</li>
</ul>
<h3 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h3><p><img src="JavaStacks.jpg" alt="Java虚拟机栈"></p>
<ul>
<li>Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在在执行的同时都会创建一个栈帧（Stack Frame）用于存储 局部变量表、操作数栈、动态链接、方法接口 等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈出栈的过程。</li>
<li>Java虚拟机栈也是线程私有，它的生命周期与线程相同。</li>
<li>Java内存区常分为 堆内存（Heap）和栈内存（Stack）；</li>
<li>OOM情况：（1）线程请求的栈深度&gt;虚拟机所运行的最大深度；（2）虚拟机动态扩展时无法申请到足够的内存</li>
</ul>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p><img src="Java本地方法栈.png" alt="Java本地方法栈"><br>本地方法栈（Native Method Stack）与虚拟机所发挥的作用非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机所使用的Native方法服务。</p>
<ul>
<li>HotSpot虚拟机把本地方法栈和虚拟机栈合二为一；</li>
<li>此区域会抛StackOverflowError 和 OutofMemoryError异常</li>
</ul>
<h3 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h3><p><img src="JavaHeap.gif" alt="Java堆"><br>Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块，Java Heap是所有线程共享的一块内存区域，在VM启动时创建。</p>
<ul>
<li>所有的对象实例以及数组都要在堆上分配（不绝对：栈上分配、标量替换优化技术）；</li>
<li>Java堆是垃圾收集器管理的主要区域，也可称做GC堆（Garbage Collected Heap）</li>
<li>从内存回收的角度，现代收集器基本都采用分代收集算法，Java Heap可细分为新生代和老年代，再细致可氛围Eden空间、From Survivor空间、To Survivor空间等—&gt;更好回收内存。</li>
<li>从内存分配的角度，线程共享的Java堆中可能分出多个线程私有的分配缓存区（TLAB：Thread Local Allocation Buffer）—&gt;更快分配内存。</li>
<li>Java堆出于逻辑连续的内存空间中，物理上可不连续，如磁盘空间一样；</li>
<li>Java堆在实现上可时，可以实现成固定大小的，也可以按照可扩展实现（-Xmx和-Xms控制）；</li>
<li>OOM情况：堆中没有内存完成实例分配，堆也无法再扩展时</li>
</ul>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><ul>
<li>Non-Heap：在Java虚拟机规范中，将方法区作为堆的一个逻辑部分来对待，但事实上，方法区并不是堆（Non-Heap）；</li>
<li>永久代：JavaGC的分代收集机制分为3个代：年青代，老年代，永久代，将方法区定义为“永久代”，这是因为，对于之前的HotSpot Java虚拟机的实现方式中，将分代收集的思想扩展到了方法区，并将方法区设计成了永久代。不过，除HotSpot之外的多数虚拟机，并不将方法区当做永久代，随着Java8的到来，已放弃永久代改为采用Native Memory来实现方法区的规划。</li>
<li>线程共享区域：方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，</li>
<li>方法区用于存储已经被虚拟机加载的类信息（即加载类时需要加载的信息，包括版本、field、方法、接口等信息）、final常量、静态变量、编译器即时编译后的代码等数据。</li>
<li>方法区在物理上也不需要是连续的，可以选择固定大小或可扩展大小，并且方法区比堆还多了一个限制：可以选择是否执行垃圾收集。</li>
<li>一般的，方法区上执行的垃圾收集是很少的，这也是方法区被称为永久代的原因之一（HotSpot），但这也不代表着在方法区上完全没有垃圾收集，<code>此区域回收目标主要是针对常量池的回收和对类型的卸载</code>。 </li>
</ul>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p><img src="Java虚拟机运行时数据区拓扑关系.png" alt="Java虚拟机运行时数据区拓扑关系"><br>运行时常量池（Runtime Constants Pool）是方法区的一部分</p>
<ul>
<li>Class文件中除了有类的版本、字段、方法、接口等描述的信息外，还有一项信息是常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。</li>
</ul>
<h3 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h3><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。</p>
<ul>
<li>能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</li>
<li>直接内存的分配不会受到Java堆大小的限制，但会收到本机总内存（RAM以及SWAP/分页文件）大小以及处理器寻址空间的限制。</li>
<li>设置Xmx等参数信息时注意不能忽略直接内存，不然会引起OOM。</li>
</ul>
<h2 id="HotSpot虚拟机"><a href="#HotSpot虚拟机" class="headerlink" title="HotSpot虚拟机"></a>HotSpot虚拟机</h2>]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS使用笔记</title>
    <url>/2016/03/03/HDFS%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Hadoop框架中最核心的设计就是：MapReduce和HDFS。MapReduce的思想是分而治之（任务的分解与结果的汇总）。HDFS是Hadoop分布式文件系统（Hadoop Distributed File System）的缩写，为分布式计算存储提供了底层支持。</p>
<hr>
<a id="more"></a>
<p><img src="https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" alt="HDFS架构图"></p>
<h1 id="HDFS的基本概念"><a href="#HDFS的基本概念" class="headerlink" title="HDFS的基本概念"></a>HDFS的基本概念</h1><h2 id="数据块-block"><a href="#数据块-block" class="headerlink" title="数据块(block)"></a>数据块(block)</h2><p>HDFS默认的最基本的存储单位是64M的数据块。和普通文件系统相同的是，HDFS中的文件是被分成64M一块的数据块存储的。不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间。</p>
<h2 id="元数据节点-Namenode"><a href="#元数据节点-Namenode" class="headerlink" title="元数据节点(Namenode)"></a>元数据节点(Namenode)</h2><p>元数据节点用来管理文件系统的命名空间。其将所有的文件和文件夹的元数据保存在一个文件系统树中。这些信息也会在硬盘上保存成以下文件：命名空间镜像(namespace image)及修改日志(edit log)其还保存了一个文件包括哪些数据块，分布在哪些数据节点上。然而这些信息并不存储在硬盘上，而是在系统启动的时候从数据节点收集而成的。</p>
<h2 id="数据节点-datanode"><a href="#数据节点-datanode" class="headerlink" title="数据节点(datanode)"></a>数据节点(datanode)</h2><p>数据节点是文件系统中真正存储数据的地方。客户端(client)或者元数据信息(namenode)可以向数据节点请求写入或者读出数据块。其周期性的向元数据节点回报其存储的数据块信息。</p>
<h2 id="从元数据节点-secondary-namenode"><a href="#从元数据节点-secondary-namenode" class="headerlink" title="从元数据节点(secondary namenode)"></a>从元数据节点(secondary namenode)</h2><p>从元数据节点并不是元数据节点出现问题时候的备用节点，它和元数据节点负责不同的事情。其主要功能就是周期性将元数据节点的命名空间镜像文件和修改日志合并，以防日志文件过大。合并过后的命名空间镜像文件也在从元数据节点保存了一份，以防元数据节点失败的时候，可以恢复。</p>
<h1 id="HDFS读文件原理"><a href="#HDFS读文件原理" class="headerlink" title="HDFS读文件原理"></a>HDFS读文件原理</h1><p>//TODO</p>
<h1 id="HDFS写文件原理"><a href="#HDFS写文件原理" class="headerlink" title="HDFS写文件原理"></a>HDFS写文件原理</h1><p>//TODO</p>
<h1 id="HDFS文件操作"><a href="#HDFS文件操作" class="headerlink" title="HDFS文件操作"></a>HDFS文件操作</h1><h2 id="上传本地文件到hdfs"><a href="#上传本地文件到hdfs" class="headerlink" title="上传本地文件到hdfs"></a>上传本地文件到hdfs</h2><p><a href="http://www.linuxidc.com/Linux/2013-05/83867.htm">使用Java实现在HDFS中创建文件夹</a><br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="string">-rm</span>  <span class="string">/user/uadb/etl/geocoding</span></span><br><span class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="string">-rm</span>  <span class="string">/user/uadb/etl/geocoding</span></span><br><span class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="string">-put</span>  <span class="string">/user/uadb/etl/geocoding</span>  <span class="string">/user/uadb/etl/</span></span><br></pre></td></tr></table></figure></p>
<h2 id="删除hdfs文件"><a href="#删除hdfs文件" class="headerlink" title="删除hdfs文件"></a>删除hdfs文件</h2><ul>
<li>rm命令：<code>-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</code><br>删除hdfs文件夹内所有文件：<code>hdfs dfs  -rm -R  /user/hive/warehouse/geocodingdb.db/addressnodesgroupbyskeleton/*</code></li>
</ul>
<h2 id="删除hdfs文件夹"><a href="#删除hdfs文件夹" class="headerlink" title="删除hdfs文件夹"></a>删除hdfs文件夹</h2><ul>
<li>rmdir命令：<code>[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</code>，不能删除非空文件夹<br>hdfs dfs  -rmdir   /user/hive/warehouse/geocodingdb.db/addressnodesgroupbyskeleton</li>
</ul>
<h1 id="HDFS相关"><a href="#HDFS相关" class="headerlink" title="HDFS相关"></a>HDFS相关</h1><h2 id="为什么HDFS不适合大量小文件"><a href="#为什么HDFS不适合大量小文件" class="headerlink" title="为什么HDFS不适合大量小文件"></a>为什么HDFS不适合大量小文件</h2><p>1）在HDFS中，namenode将文件系统中的元数据存储在内存中，因此，HDFS所能存储的文件数量会受到namenode内存的限制。一般来说，每个文件、目录、数据块的存储信息大约占150个字节，根据当前namenode的内存空间的配置，就可以计算出大约能容纳多少个文件了。<br>2）有一种误解就是，之所以HDFS不适合大量小文件，是因为即使很小的文件也会占用一个块的存储空间。这是错误的，HDFS与其它文件系统不同，小于一个块大小的文件，不会占用一个块的空间。</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM学习笔记（一）走近Java</title>
    <url>/2016/02/22/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E8%B5%B0%E8%BF%91Java/</url>
    <content><![CDATA[<p>2016上半年花点时间深入了解JVM，读《《深入理解Java虚拟机 JVM高级特性与最佳实践》，整理遇到过的内存泄漏，性能优化问题</p>
<hr>
<a id="more"></a>
<h1 id="第一章-走近Java"><a href="#第一章-走近Java" class="headerlink" title="第一章 走近Java"></a>第一章 走近Java</h1><h2 id="Java技术体系"><a href="#Java技术体系" class="headerlink" title="Java技术体系"></a>Java技术体系</h2><p><img src="JDK技术组成.png" alt="JDK"></p>
<ul>
<li>Java程序设计语言、Java虚拟机、Java API类库三部分统称为JDK(Java Development Kit) ,JDK是Java程序开发的最小环境</li>
<li>Java API类库中的Java SE API子集和Java虚拟机两部分统称为JRE(Java Runtime Environment)，JRE是支持Java程序运行的标准环境</li>
<li><p>按照Java技术关注的重点业务领域来划分，Java技术体系可分为4个平台</p>
<ul>
<li>Java Card：支持Applets(Java小程序)运行在小内存设备（如智能卡）上的平台；</li>
<li>Java ME(Micro Edition)：支持Java运行在移动终端上的平台；（今有Android SDK）</li>
<li>Java SE(Standard Edition)：支持面向桌面级应用的Java平台；</li>
<li>Java EE(Enterprise Edition)：支持使用多层架构的企业级应用(如ERP、CRM应用)的Java平台；</li>
</ul>
</li>
</ul>
<h2 id="Java发展史"><a href="#Java发展史" class="headerlink" title="Java发展史"></a>Java发展史</h2><h2 id="Java虚拟机发展史"><a href="#Java虚拟机发展史" class="headerlink" title="Java虚拟机发展史"></a>Java虚拟机发展史</h2><ul>
<li>Sun Classic/Extract VM</li>
<li>Sun HotSpot VM</li>
<li>Sun Mobile-Embedded VM/Meta-Circular VM</li>
<li>Bea Jrockit/IDM J9 VM</li>
<li>Azul VM/BEA Liquid VM</li>
<li>Apache Harmony/Google Android Dalvik VM</li>
<li>Microsoft JVM…</li>
</ul>
<h2 id="Java技术的未来展望"><a href="#Java技术的未来展望" class="headerlink" title="Java技术的未来展望"></a>Java技术的未来展望</h2><ul>
<li>模块化（Jigsaw）</li>
<li>混合语言：多语言混合编程，通过特定领域发语言去解决特定领域的问题</li>
<li>多核并行（concurrent.forkjoin；Lambada；函数式编程）</li>
<li>丰富语法（Coin子项目）</li>
<li>64位虚拟机（计算机终究完全过渡到64位的时代）</li>
</ul>
<h2 id="JDK编译实战"><a href="#JDK编译实战" class="headerlink" title="JDK编译实战"></a>JDK编译实战</h2><p><a href="https://jdk7.java.net/source.html">OpenJDK7下载</a> Building the source code for the OpenJDK requires a certain degree of technical expertise.</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB与Neo4j数据同步</title>
    <url>/2016/03/23/MongoDB%E4%B8%8ENeo4j%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<p>采用mongo-connector及Neo4j Doc Manager将MongoDB中数据导入Neo4j（嵌套结构形成关系）</p>
<hr>
<a id="more"></a>
<p><a href="http://neo4j.com/developer/mongodb/#_neo4j_doc_manager">参考文档</a><br><a href="https://github.com/neo4j-contrib/neo4j_doc_manager">neo4j_doc_manager项目地址</a></p>
<h1 id="MongoDB启用副本"><a href="#MongoDB启用副本" class="headerlink" title="MongoDB启用副本"></a>MongoDB启用副本</h1><h2 id="Windows安装MongoDB服务-bat脚本"><a href="#Windows安装MongoDB服务-bat脚本" class="headerlink" title="Windows安装MongoDB服务 bat脚本"></a>Windows安装MongoDB服务 bat脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line">title  卸载MongoDB</span><br><span class="line">sc delete MongoDB</span><br><span class="line">cmd /k</span><br></pre></td></tr></table></figure>
<h2 id="Windows卸载MongoDB服务-bat脚本"><a href="#Windows卸载MongoDB服务-bat脚本" class="headerlink" title="Windows卸载MongoDB服务 bat脚本"></a>Windows卸载MongoDB服务 bat脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line">title 安装MongoDB</span><br><span class="line">D:\mongodb\bin\mongod --logpath <span class="string">"D:\mongodb\log\mongo.log"</span> --logappend --dbpath <span class="string">"D:\mongodb\data"</span> --directoryperdb --replSet myDevReplSet --serviceName <span class="string">"MongoDB"</span> --serviceDisplayName <span class="string">"MongoDB"</span>  --install</span><br><span class="line">cmd /k</span><br></pre></td></tr></table></figure>
<h2 id="初始化MongoDB-Replica-set"><a href="#初始化MongoDB-Replica-set" class="headerlink" title="初始化MongoDB Replica set"></a>初始化MongoDB Replica set</h2><p>进入mongo shell执行<code>rs.initiate()</code></p>
<h1 id="安装Neo4j-Doc-Manager"><a href="#安装Neo4j-Doc-Manager" class="headerlink" title="安装Neo4j Doc Manager"></a>安装Neo4j Doc Manager</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 新增python环境neo4j.venv</span></span><br><span class="line">virtualenv  --no-site-packages neo4j.venv</span><br><span class="line"><span class="comment">#  进入neo4j.venv</span></span><br><span class="line">workon neo4j.venv</span><br><span class="line"><span class="comment">#  安装neo4j-doc-manager   --pre</span></span><br><span class="line">pip install -i  http://pypi.douban.com/simple  neo4j-doc-manager --trusted-host pypi.douban.com</span><br></pre></td></tr></table></figure>
<h1 id="启动mongo-connector"><a href="#启动mongo-connector" class="headerlink" title="启动mongo-connector"></a>启动mongo-connector</h1><p>进入Python环境：<code>workon neo4j.venv</code><br>运行neo4j_doc_manager：<code>mongo-connector -m 192.168.1.188:27017 -t http://127.0.0.1:7474/db/data -d neo4j_doc_manager</code><br>同步指定Databse.Collection：<code>mongo-connector -m 127.0.0.1:27017 -n uadb_suzhou_gyyq.AddressNode -t http://127.0.0.1:7474/db/data -d neo4j_doc_manager</code><br>neo4j_doc_manager运行后，当MongoDB插入数据时，mongodb Document将会实时转换为图结构存储到Neo4j，文档Key会转换为Node,值对象作为Node的属性值。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="No-handlers-could-be-found-for-logger-“mongo-connector-util”"><a href="#No-handlers-could-be-found-for-logger-“mongo-connector-util”" class="headerlink" title="No handlers could be found for logger “mongo_connector.util”"></a>No handlers could be found for logger “mongo_connector.util”</h2><p>实际错误：py2neo.database.status.Unauthorized: <a href="http://127.0.0.1:7474/db/manage/server/jmx/domain/org.neo4j">http://127.0.0.1:7474/db/manage/server/jmx/domain/org.neo4j</a><br>解决方案：</p>
<ol>
<li>停用 authorization<br>考虑到性能和测试便捷可停用Neo4j安全授权机制。<br>在<code>neo4j-server.properties</code>中设置<code>dbms.security.auth_enabled=false</code></li>
<li>设置NEO4J_AUTH环境变量<br>若生产环境已启用授权，设置NEO4J_AUTH环境变量<code>export NEO4J_AUTH=user:password</code></li>
</ol>
<h2 id="AttributeError-‘Graph’-object-has-no-attribute-‘cypher’"><a href="#AttributeError-‘Graph’-object-has-no-attribute-‘cypher’" class="headerlink" title="AttributeError: ‘Graph’ object has no attribute ‘cypher’"></a>AttributeError: ‘Graph’ object has no attribute ‘cypher’</h2><p>解决方案：<a href="https://github.com/neo4j-contrib/neo4j_doc_manager/issues/59">neo4j_doc_manager github issue</a><br>参考官网文档，安装时附加—pre参数，然而运行dev版有问题，老实安装stable版本即可</p>
<h2 id="OplogThread-Last-entry-no-longer-in-oplog-cannot-recove"><a href="#OplogThread-Last-entry-no-longer-in-oplog-cannot-recove" class="headerlink" title="OplogThread: Last entry no longer in oplog cannot recove"></a>OplogThread: Last entry no longer in oplog cannot recove</h2><p>修改mongo-connector配置参数后报错<br>解决：删除日志文件（mongo-connector.log）所在根目录的<code>oplog.timestamp</code>文件，上次异常终止mongo-connector写入了xxx，导致无法正常运行</p>
<h2 id="如何提高同步速度"><a href="#如何提高同步速度" class="headerlink" title="如何提高同步速度"></a>如何提高同步速度</h2><p><a href="https://github.com/mongodb-labs/mongo-connector/wiki/FAQ#how-do-i-increase-the-speed-of-mongo-connector">how-do-i-increase-the-speed-of-mongo-connector</a><br><a href="https://github.com/mongodb-labs/mongo-connector/wiki/Configuration-Options">mongo-connector Configuration-Options</a></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL存储过程学习笔记</title>
    <url>/2016/03/08/MySQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>团队一直有小伙伴顶着数据库相关的工作，ETL数据整合分析事情多了，研发开发工作相应减少，终于有机会也来写写存储过程了。<br>以SP进行SQL业务逻辑封装，执行性能能大大提高，在注意合理拆分SP、SQL书写简洁规范和注释到位的情况下，也能做到易于维护。<br>特别是对于海量数据分析追求时效性的业务，效率第一，就算逻辑复杂不易维护也得认。如Hibernate VS Mybatis，产品 VS 项目，现实世界丰富多彩，存在即合理。</p>
<hr>
<a id="more"></a>
<p>MySQL从V5.0开始支持存储过程，V5.0~V5.7版本之间自带的function有所差别，查资料的时候注意过滤，本文以<code>MySQL5.5.4</code>作为测试环境。</p>
<h1 id="关于MySQL存储过程"><a href="#关于MySQL存储过程" class="headerlink" title="关于MySQL存储过程"></a>关于MySQL存储过程</h1><p>MySQL 存储过程(Stored Procedure) 是通过给定的语法格式编写自定义的数据库API, 包含一系列sql语句的集合, 完成一个复杂的功能.</p>
<ul>
<li><a href="http://dev.mysql.com/doc/refman/5.5/en/stored-programs-views.html">MySQL5.5官方文档 存储过程</a></li>
<li>调试工具：dbForge Studio for MySQL Professional Edition<br><img src="DbForgeStudio调试MySQL存储过程.png" alt="DbForgeStudio调试MySQL存储过程"></li>
</ul>
<h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><p>mysql存储过程中，定义变量有两种方式：</p>
<h2 id="会话变量"><a href="#会话变量" class="headerlink" title="会话变量"></a>会话变量</h2><p>使用set或select直接赋值，变量名以 @ 开头，可以在一个会话的任何地方声明，作用域是整个会话，称为会话变量。<br>如:<code>set @var=1;</code></p>
<h2 id="存储过程变量"><a href="#存储过程变量" class="headerlink" title="存储过程变量"></a>存储过程变量</h2><p>以 DECLARE 关键字声明的变量，只能在存储过程中使用，称为存储过程变量，主要用在存储过程中，或者是给存储传参数中。<br>如：<code>DECLARE var1  INT DEFAULT 0;</code></p>
<h2 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h2><ul>
<li>在调用存储过程时，以DECLARE声明的变量都会被初始化为 NULL。</li>
<li>会话变量（即@开头的变量）则不会被再初始化，在一个会话内，只须初始化一次，之后在会话内都是对上一次计算的结果，就相当于在是这个会话内的全局变量。</li>
<li>在存储过程中，使用动态语句，预处理时，动态内容必须赋给一个会话变量。</li>
</ul>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul>
<li>变量命名需与表字段不一致；</li>
</ul>
<h1 id="输出日志信息"><a href="#输出日志信息" class="headerlink" title="输出日志信息"></a>输出日志信息</h1><p>SELECT concat(‘Comment:’,’—-Comment—-‘);</p>
<h1 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h1><p><a href="http://www.nowamagic.net/librarys/veda/detail/1317">参考-MySQL临时表的简单用法</a><br><a href="http://dev.mysql.com/doc/refman/5.5/en/internal-temporary-tables.html">参考-internal-temporary-tables</a><br>临时表将在你连接MySQL期间存在。当连接断开时，MySQL将自动删除表并释放所用的空间。当然也可以在仍然连接的时候删除表并释放空间。<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 新建</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TEMPORARY</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> sp_output_tmp <span class="keyword">ENGINE</span> = <span class="keyword">MEMORY</span> SELECT... from... where... ;</span><br><span class="line"><span class="comment">-- 删除</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TEMPORARY</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> sp_output_tmp;</span><br></pre></td></tr></table></figure></p>
<h1 id="游标嵌套循环（nested-cursor-loop）"><a href="#游标嵌套循环（nested-cursor-loop）" class="headerlink" title="游标嵌套循环（nested cursor loop）"></a>游标嵌套循环（nested cursor loop）</h1><p><a href="http://stackoverflow.com/questions/6099500/multiple-cursors-in-nested-loops-in-mysql/6099837#6099837">参考/multiple-cursors-in-nested-loops-in-mysql</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">  <span class="keyword">DECLARE</span> done1 <span class="built_in">int</span> <span class="keyword">default</span> <span class="literal">false</span>;  </span><br><span class="line">  <span class="comment">-- 批量更新计数器</span></span><br><span class="line">  <span class="keyword">DECLARE</span> cachSize_matchedAddress <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- 定义Cursor1</span></span><br><span class="line">  <span class="keyword">DECLARE</span> cursor_bizId <span class="keyword">CURSOR</span> <span class="keyword">FOR</span> <span class="keyword">select</span> *  <span class="keyword">from</span> table1;</span><br><span class="line">  <span class="keyword">DECLARE</span> CONTINUE <span class="keyword">HANDLER</span> <span class="keyword">FOR</span> <span class="keyword">NOT</span> <span class="keyword">FOUND</span> <span class="keyword">SET</span> done1 = <span class="literal">TRUE</span>;  </span><br><span class="line"></span><br><span class="line">  <span class="comment">-- 打开Cursor1</span></span><br><span class="line">  OPEN cursor_bizId;</span><br><span class="line">  <span class="comment">-- 循环获取业务ID  </span></span><br><span class="line">  loop_getBizId:LOOP</span><br><span class="line">     FETCH cursor_bizId INTO bizId;</span><br><span class="line">      IF done1 THEN</span><br><span class="line">        LEAVE loop_getBizId;</span><br><span class="line">        <span class="comment"># 关闭Cursor1</span></span><br><span class="line">        CLOSE cursor_bizId;</span><br><span class="line">      <span class="keyword">END</span> <span class="keyword">IF</span>;</span><br><span class="line">    <span class="comment">-- TODO Cursor1相关业务逻辑</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">-- 根据业务ID获取业务数据</span></span><br><span class="line">    block_matchedAddress:<span class="keyword">BEGIN</span></span><br><span class="line">        <span class="keyword">DECLARE</span> done2 <span class="built_in">int</span> <span class="keyword">default</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">-- 定义Cursor2</span></span><br><span class="line">        <span class="keyword">DECLARE</span> cursor_matchedAddress <span class="keyword">CURSOR</span> <span class="keyword">FOR</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> temp_matchedAddress;</span><br><span class="line">        <span class="keyword">DECLARE</span> continue <span class="keyword">handler</span> <span class="keyword">for</span> <span class="keyword">not</span> <span class="keyword">found</span> <span class="keyword">set</span> done2 = <span class="literal">true</span>;  </span><br><span class="line"></span><br><span class="line">        OPEN cursor_matchedAddress;  </span><br><span class="line">        <span class="comment">-- 循环获取业务数据</span></span><br><span class="line">        loop_getMatchedAddress:LOOP   </span><br><span class="line">            FETCH cursor_matchedAddress INTO _rownum, _matchID, _matchedType, _matchedAddress, _x, _y;</span><br><span class="line">            IF done2 THEN</span><br><span class="line">               LEAVE loop_getMatchedAddress;</span><br><span class="line">               <span class="comment">-- 关闭Cursor2</span></span><br><span class="line">               CLOSE cursor_matchedAddress;</span><br><span class="line">            <span class="keyword">END</span> <span class="keyword">IF</span>;</span><br><span class="line">            <span class="comment">-- TODO Cursor2相关业务逻辑</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">END</span> <span class="keyword">LOOP</span> loop_getMatchedAddress;</span><br><span class="line">      <span class="keyword">END</span> block_matchedAddress;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">END</span> <span class="keyword">LOOP</span> loop_getBizId;</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure>
<h1 id="动态sql"><a href="#动态sql" class="headerlink" title="动态sql"></a>动态sql</h1><p>PREPARE命令：<code>PREPARE stmt_name FROM preparable_stmt</code><br>The PREPARE statement prepares a SQL statement and assigns it a name, stmt_name, by which to refer to the statement later. The prepared statement is executed with EXECUTE and released with DEALLOCATE PREPARE. For examples, see Section 13.5, “SQL Syntax for Prepared Statements”.  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> @<span class="keyword">sql</span> = <span class="string">"select *  from table"</span>;</span><br><span class="line"><span class="keyword">PREPARE</span> stmt <span class="keyword">from</span> @<span class="keyword">sql</span> ;</span><br><span class="line"><span class="keyword">EXECUTE</span> stmt;</span><br><span class="line"><span class="keyword">DEALLOCATE</span> <span class="keyword">PREPARE</span> stmt;</span><br></pre></td></tr></table></figure>
<p>注意：<strong>The text must represent a single statement, not multiple statements.</strong></p>
<h1 id="批量更新"><a href="#批量更新" class="headerlink" title="批量更新"></a>批量更新</h1><p>在sp中类似<code>insert into (column1) values (value1)</code>这样循环单条insert执行速度太慢，<br>可采用<code>temporary table</code>将数据先插入临时表；设置一个计数器，当临时表达到limit记录数时，关联更新目标表并重置临时表以释放资源。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="Json序列化函数JSON-Array不存在问题"><a href="#Json序列化函数JSON-Array不存在问题" class="headerlink" title="Json序列化函数JSON_Array不存在问题"></a>Json序列化函数JSON_Array不存在问题</h2><p>问题描述：JSON_Array does not existed<br>解决：我用的V5.5，不支持,V5.7.8才支持;</p>
<blockquote>
<p>As of MySQL 5.7.8, MySQL supports a native JSON data type that enables efficient access to data in JSON (JavaScript Object Notation) documents. The JSON data type provides these advantages over storing JSON-format strings in a string column:</p>
</blockquote>
<h2 id="嵌套Cusor问题"><a href="#嵌套Cusor问题" class="headerlink" title="嵌套Cusor问题"></a>嵌套Cusor问题</h2><p>问题描述：子Cursor fetch的values总是父Cursor的第一个值，见<a href="https://gist.github.com/geosmart/c3d7f4eb0d9ad53751d7">gist存储过程记录</a><br>解决：View的问题，换成temporary table解决，见<a href="https://gist.github.com/geosmart/9020fdc1cad9fb0ab36e">gist-batchUpdateMatchedAddress.sql</a></p>
<h2 id="游标动态sql问题"><a href="#游标动态sql问题" class="headerlink" title="游标动态sql问题"></a>游标动态sql问题</h2><p>问题描述：动态设置的条件与静态条件相比，少返回1条记录<br>原因：游标中查询条件不支持动态条件。<br><a href="http://dev.mysql.com/doc/refman/5.6/en/sql-syntax-prepared-statements.html">参考sql-syntax-prepared-statements</a></p>
<blockquote>
<p>SQL syntax for prepared statements can be used within stored procedures, but not in stored functions or triggers. However, a cursor cannot be used for a dynamic statement that is prepared and executed with PREPARE and EXECUTE. The statement for a cursor is checked at cursor creation time, so the statement cannot be dynamic.</p>
</blockquote>
<p>解决：<a href="http://stackoverflow.com/questions/7685588/dynamic-cursor-in-stored-procedure">参考dynamic-cursor-in-stored-procedure</a></p>
<ul>
<li>A cursor will only accept a select statement, so if the SQL really needs to be dynamic make the declare cursor part of the statement you are executing.</li>
<li>以View视图或Temporary Table临时表形式间接实现</li>
</ul>
<h2 id="新建视图时select中不能带有动态参数"><a href="#新建视图时select中不能带有动态参数" class="headerlink" title="新建视图时select中不能带有动态参数"></a>新建视图时select中不能带有动态参数</h2><p>原因： Within a stored program, the SELECT statement cannot refer to program parameters or local variables.<br>解决：View嵌套子查询，参考<a href="http://stackoverflow.com/questions/8428641/views-select-contains-a-subquery-in-the-from-clause">View’s SELECT contains a subquery in the FROM clause</a><br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> view_clients_credit_usage <span class="keyword">as</span></span><br><span class="line">    <span class="keyword">select</span> client_id, <span class="keyword">sum</span>(credits_used) <span class="keyword">as</span> credits_used</span><br><span class="line">    <span class="keyword">from</span> credit_usage</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> client_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> view_credit_status <span class="keyword">as</span></span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        credit_orders.client_id,</span><br><span class="line">        <span class="keyword">sum</span>(credit_orders.number_of_credits) <span class="keyword">as</span> purchased,</span><br><span class="line">        <span class="keyword">ifnull</span>(t1.credits_used,<span class="number">0</span>) <span class="keyword">as</span> used</span><br><span class="line">    <span class="keyword">from</span> credit_orders</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> view_clients_credit_usage <span class="keyword">as</span> t1 <span class="keyword">on</span> t1.client_id = credit_orders.client_id</span><br><span class="line">    <span class="keyword">where</span> credit_orders.payment_status=<span class="string">'Paid'</span></span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> credit_orders.client_id);</span><br></pre></td></tr></table></figure>
　</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Stored Procedure</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL常用函数（UDF）</title>
    <url>/2016/03/18/MySQL%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%EF%BC%88UDF%EF%BC%89/</url>
    <content><![CDATA[<p>数据分析/特定业务逻辑MySQL内置的Function无法满足需求，只能祭出UDF。</p>
<hr>
<a id="more"></a>
<h1 id="字符串分割-split-string"><a href="#字符串分割-split-string" class="headerlink" title="字符串分割(split_string)"></a>字符串分割(split_string)</h1><ul>
<li>函数定义</li>
<li>CREATE DEFINER = ‘ugcdb’@’%’<br>FUNCTION ugcdb.split_string(<br>x VARCHAR(255),<br>delim VARCHAR(12),<br>pos INT<br>)<br>RETURNS varchar(255) CHARSET utf8<br>RETURN REPLACE(SUBSTRING(SUBSTRING_INDEX(x, delim, pos),<br>   LENGTH(SUBSTRING_INDEX(x, delim, pos -1)) + 1),<br>   delim, ‘’)</li>
<li>函数调用</li>
<li><code>update tableName set 门牌号= SPLIT_STR(门牌号,&#39;号&#39;,1) ;</code></li>
</ul>
<h1 id="获取行号-get-rownum"><a href="#获取行号-get-rownum" class="headerlink" title="获取行号(get_rownum)"></a>获取行号(get_rownum)</h1><p><a href="http://stackoverflow.com/questions/15891993/create-a-view-with-column-num-rows-mysql">参考create-a-view-with-column-num-rows-mysql</a></p>
<ul>
<li>函数定义</li>
<li>CREATE DEFINER=<code>geocodingdb</code>@<code>%</code> FUNCTION <code>geocodingdb</code>.<code>get_rownum</code>() RETURNS int(11)<br>BEGIN<br>  SET @temp_rowNumber := IFNULL(@temp_rowNumber,0)+1;<br>  return @temp_rowNumber;<br>END</li>
<li>函数调用</li>
<li>SET @temp_rowNumber=0;<br>select fieldA , get_rownum() AS rownum from tableName;</li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Neo4j常用CypherQL语句</title>
    <url>/2016/03/30/Neo4j%E5%B8%B8%E7%94%A8CypherQL%E8%AF%AD%E5%8F%A5/</url>
    <content><![CDATA[<p>记录常用Cypher语句</p>
<hr>
<a id="more"></a>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="http://neo4j.com/docs/stable/cypher-query-lang.html">cypher-query-lang</a><br><a href="http://neo4j.com/docs/stable/cypher-refcard/">cypher-refcard </a></p>
<h1 id="create-Node"><a href="#create-Node" class="headerlink" title="create Node"></a>create Node</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> (root:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'admin'</span>, <span class="keyword">name</span>: <span class="string">'root'</span>&#125;)</span><br><span class="line"><span class="keyword">CREATE</span> (u1:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span> : <span class="string">'user1'</span>&#125;)</span><br><span class="line"><span class="keyword">CREATE</span> (u2:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user2'</span>&#125;)</span><br><span class="line"><span class="keyword">CREATE</span> (u3:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user3'</span>&#125;)</span><br><span class="line"><span class="keyword">CREATE</span> (u4:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user4'</span>&#125;)</span><br></pre></td></tr></table></figure>
<h1 id="Create-RelationShip"><a href="#Create-RelationShip" class="headerlink" title="Create RelationShip"></a>Create RelationShip</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (root&#123;type:'admin' &#125;),(guest&#123;type:'guest'&#125;)</span><br><span class="line"><span class="keyword">CREATE</span>  (root)-[r:knows]-&gt;(guest)</span><br><span class="line"><span class="keyword">RETURN</span> r</span><br></pre></td></tr></table></figure>
<h1 id="Create-Unique-RelationShip"><a href="#Create-Unique-RelationShip" class="headerlink" title="Create  Unique RelationShip"></a>Create  Unique RelationShip</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (root&#123;type:'admin' &#125;)</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">UNIQUE</span> (root)-[r:knows]-(u5:<span class="keyword">User</span>&#123;<span class="keyword">name</span>:<span class="string">'user5'</span>&#125;)</span><br><span class="line"><span class="keyword">RETURN</span>  u5</span><br></pre></td></tr></table></figure>
<h1 id="match-Node"><a href="#match-Node" class="headerlink" title="match Node"></a>match Node</h1><ul>
<li>match by property<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (root &#123; name : 'root' &#125;)</span><br><span class="line">return root</span><br></pre></td></tr></table></figure></li>
<li>match by ID identifier<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (s)</span><br><span class="line">WHERE ID(s) = 65110</span><br><span class="line">RETURN s</span><br></pre></td></tr></table></figure></li>
<li>complex query<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (d:District &#123;state: &#123;state&#125;, district: &#123;district&#125;&#125;)</span><br><span class="line">MATCH (d)&lt;-[:REPRESENTS]-(l:Legislator)</span><br><span class="line">MATCH (l)-[:SERVES_ON]-&gt;(c:Committee)</span><br><span class="line">MATCH (c)&lt;-[:REFERRED_TO]-(b:Bill)</span><br><span class="line">MATCH (b)-[:DEALS_WITH]-&gt;(s:Subject)</span><br><span class="line"><span class="keyword">WITH</span> l.govtrackID <span class="keyword">AS</span> govtrackID, l.lastName <span class="keyword">AS</span> lastName, l.firstName <span class="keyword">AS</span> firstName, l.currentParty <span class="keyword">AS</span> party, s.title <span class="keyword">AS</span> subject, <span class="keyword">count</span>(*) <span class="keyword">AS</span> strength, <span class="keyword">collect</span>(<span class="keyword">DISTINCT</span> c.name) <span class="keyword">AS</span> committees <span class="keyword">ORDER</span> <span class="keyword">BY</span> strength <span class="keyword">DESC</span> <span class="keyword">LIMIT</span> <span class="number">10</span></span><br><span class="line"><span class="keyword">WITH</span> &#123;lastName: lastName, firstName: firstName, govtrackID: govtrackID, party: party, committees: committees&#125; <span class="keyword">AS</span> legislator, <span class="keyword">collect</span>(&#123;subject: subject, strength: strength&#125;) <span class="keyword">AS</span> subjects</span><br><span class="line"><span class="keyword">RETURN</span> &#123;legislator: legislator, subjects: subjects&#125; <span class="keyword">AS</span> r</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="match-relationNode"><a href="#match-relationNode" class="headerlink" title="match relationNode"></a>match relationNode</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (root&#123; type:'admin' &#125;)--&gt;(user)</span><br><span class="line">RETURN user</span><br></pre></td></tr></table></figure>
<h1 id="match-Node-and-relationNode"><a href="#match-Node-and-relationNode" class="headerlink" title="match Node and relationNode"></a>match Node and relationNode</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (root &#123; type:'admin' &#125;)-[r]-(user)</span><br><span class="line">RETURN r</span><br></pre></td></tr></table></figure>
<h1 id="match-collection"><a href="#match-collection" class="headerlink" title="match collection"></a>match collection</h1><h2 id="collection-contain-string"><a href="#collection-contain-string" class="headerlink" title="collection contain string"></a>collection contain string</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">match (an)</span><br><span class="line">where all (x IN ['709908DCF9D24734BA8FEF8A831F1BA4'] where x in an.preAddressNodeGUIDs)</span><br><span class="line">return count(an)</span><br></pre></td></tr></table></figure>
<h2 id="collection-equal"><a href="#collection-equal" class="headerlink" title="collection equal"></a>collection equal</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">match (an&#123;preAddressNodeGUIDs:['709908DCF9D24734BA8FEF8A831F1BA4 ']&#125;)</span><br><span class="line">return count(an)</span><br></pre></td></tr></table></figure>
<h1 id="delete-relationship"><a href="#delete-relationship" class="headerlink" title="delete relationship"></a>delete relationship</h1><h2 id="delete-a-node-with-its-relationships"><a href="#delete-a-node-with-its-relationships" class="headerlink" title="delete a node with its relationships"></a>delete a node with its relationships</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line">MATCH (n &#123; name:'Andres' &#125;)DETACH DELETE n</span><br></pre></td></tr></table></figure>
<h2 id="delete-all-relationships"><a href="#delete-all-relationships" class="headerlink" title="delete all relationships"></a>delete all relationships</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Match (:AddressNode)-[r:parent]-&gt;(:AddressNode)</span><br><span class="line"><span class="keyword">delete</span> r</span><br></pre></td></tr></table></figure>
<h1 id="start"><a href="#start" class="headerlink" title="start"></a>start</h1><p>The START clause should only be used when accessing legacy indexes <a href="http://neo4j.com/docs/stable/indexing.html">Legacy Indexing</a>.<br>In all other cases, use MATCH instead (see Section 11.1, “Match”).<br>In Cypher, every query describes a pattern, and in that pattern one can have multiple starting points.<br>A starting point is a relationship or a node where a pattern is anchored. Using START you can only introduce starting points by legacy index seeks.<br>Note that trying to use a legacy index that doesn’t exist will generate an error.</p>
<h1 id="index"><a href="#index" class="headerlink" title="index"></a>index</h1><h2 id="create-index"><a href="#create-index" class="headerlink" title="create index"></a>create index</h2><p>CREATE INDEX ON :PRO( preAddressNodeGUIDs)</p>
<h2 id="drop-index"><a href="#drop-index" class="headerlink" title="drop index"></a>drop index</h2><p>DROP INDEX ON :PRO( preAddressNodeGUIDs)</p>
<h2 id="Neo4j联合索引"><a href="#Neo4j联合索引" class="headerlink" title="Neo4j联合索引"></a>Neo4j联合索引</h2><p>Neo4j2.3.x不支持联合索引，可采用拼接字段实现，<a href="https://dzone.com/articles/indexing-neo4j-overview">参考indexing-neo4j-overview</a>；<br>Neo4j 3.0开始支持联合索引，但需要升级至JDK8，<a href="https://github.com/neo4j/neo4j/issues/6841">参考github neo4j Issue</a><br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile</span><br><span class="line">MATCH (p:AddressNode &#123;text:"拙政别墅"&#125;)</span><br><span class="line"><span class="keyword">WITH</span> p</span><br><span class="line"><span class="keyword">MATCH</span> (o:AddressNode&#123; ruleabbr:<span class="string">"POI"</span>&#125;)</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span>(p) = <span class="keyword">id</span>(o)</span><br><span class="line"><span class="keyword">RETURN</span> p</span><br></pre></td></tr></table></figure><br><img src="Neo4j联合索引测试1.png" alt="Neo4j联合索引测试1"></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile</span><br><span class="line">MATCH (p:AddressNode &#123;ruleabbr:"POI",text:"拙政别墅"&#125;)</span><br><span class="line">RETURN p</span><br></pre></td></tr></table></figure>
<p><img src="Neo4j联合索引测试2.png" alt="Neo4j联合索引测试2"><br>暂测试，疑neo4j由于采用lucene全文索引的缘故，在2个字段各有索引，但无联合索引的情况下，索引倒排会提高检索命中率。</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title>Neo4j中实现自定义中文全文索引</title>
    <url>/2016/04/21/Neo4j%E4%B8%AD%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%AD%E6%96%87%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<p>数据库检索效率时，一般首要优化途径是从索引入手，然后根据需求再考虑更复杂的负载均衡、读写分离和分布式水平/垂直分库/表等手段；<br>索引通过信息冗余来提高检索效率，其以空间换时间并会降低数据写入的效率；因此对索引字段的选择非常重要。</p>
<ul>
<li>Neo4j可对指定Label的Node Create Index，当新增/更新符合条件的Node属性时，Index会自动更新。Neo4j Index默认采用Lucene实现（可定制，如Spatial Index自定义实现的RTree索引），但默认新建的索引只支持精确匹配（get），模糊查询（query）的话需要以全文索引，控制Lucene后台的分词行为。  </li>
<li>Neo4j全文索引默认的分词器是针对西方语种的，如默认的exact查询采用的是lucene KeywordAnalyzer（关键词分词器）,fulltext查询采用的是 white-space tokenizer（空格分词器），大小写什么的对中文没啥意义；所以针对中文分词需要挂一个中文分词器，如IK Analyzer,Ansj，至于类似梁厂长家的基于深度学习的分词系统pullword，那就更厉害啦。   </li>
</ul>
<p>本文以常用的IK Analyzer分词器为例，介绍如何在Neo4j中对字段新建全文索引实现模糊查询。</p>
<hr>
<a id="more"></a>
<h1 id="IKAnalyzer分词器"><a href="#IKAnalyzer分词器" class="headerlink" title="IKAnalyzer分词器"></a>IKAnalyzer分词器</h1><p><a href="https://github.com/wks/ik-analyzer">IKAnalyzer</a>是一个开源的，基于java语言开发的轻量级的中文分词工具包。<br>IKAnalyzer3.0特性:</p>
<ul>
<li>采用了特有的“正向迭代最细粒度切分算法“，支持细粒度和最大词长两种切分模式；具有83万字/秒（1600KB/S）的高速处理能力。</li>
<li>采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符优化的词典存储，更小的内存占用。支持用户词典扩展定义</li>
<li>针对Lucene全文检索优化的查询分析器IKQueryParser(作者吐血推荐)；引入简单搜索表达式，采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。<br>IK Analyser目前还没有maven库，还得自己手动下载install到本地库，下次空了自己在github做一个maven私有库，上传这些maven central库里面没有的工具包。</li>
</ul>
<h1 id="IKAnalyzer自定义用户词典"><a href="#IKAnalyzer自定义用户词典" class="headerlink" title="IKAnalyzer自定义用户词典"></a>IKAnalyzer自定义用户词典</h1><ul>
<li>词典文件<br>自定义词典后缀名为.dic的词典文件，必须使用无BOM的UTF-8编码保存的文件。  </li>
<li>词典配置<br>词典和IKAnalyzer.cfg.xml配置文件的路径问题，IKAnalyzer.cfg.xml必须在src根目录下。词典可以任意放，但是在IKAnalyzer.cfg.xml里要配置对。如下这种配置，ext.dic和stopword.dic应当在同一目录下。<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">properties</span> <span class="meta-keyword">SYSTEM</span> <span class="meta-string">"http://java.sun.com/dtd/properties.dtd"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">comment</span>&gt;</span>IK Analyzer 扩展配置<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_dict"</span>&gt;</span>/ext.dic;<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_stopwords"</span>&gt;</span>/stopword.dic<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Neo4j全文索引构建"><a href="#Neo4j全文索引构建" class="headerlink" title="Neo4j全文索引构建"></a>Neo4j全文索引构建</h1><p>指定IKAnalyzer作为luncene分词的analyzer，并对所有Node的指定属性新建全文索引<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createAddressNodeFullTextIndex</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (Transaction tx = graphDBService.beginTx()) &#123;</span><br><span class="line">      IndexManager index = graphDBService.index();</span><br><span class="line">      Index&lt;Node&gt; addressNodeFullTextIndex =</span><br><span class="line">            index.forNodes( <span class="string">"addressNodeFullTextIndex"</span>, MapUtil.stringMap(IndexManager.PROVIDER, <span class="string">"lucene"</span>, <span class="string">"analyzer"</span>, IKAnalyzer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()))</span>;</span><br><span class="line"></span><br><span class="line">      ResourceIterator&lt;Node&gt; nodes = graphDBService.findNodes(DynamicLabel.label( <span class="string">"AddressNode"</span>));</span><br><span class="line">      <span class="keyword">while</span> (nodes.hasNext()) &#123;</span><br><span class="line">          Node node = nodes.next();</span><br><span class="line">          <span class="comment">//对text字段新建全文索引</span></span><br><span class="line">          Object text = node.getProperty( <span class="string">"text"</span>, <span class="keyword">null</span>);</span><br><span class="line">          addressNodeFullTextIndex.add(node, <span class="string">"text"</span>, text);</span><br><span class="line">      &#125;</span><br><span class="line">      tx.success();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Neo4j全文索引测试"><a href="#Neo4j全文索引测试" class="headerlink" title="Neo4j全文索引测试"></a>Neo4j全文索引测试</h1><p>对关键词（如’有限公司’），多关键词模糊查询（如’苏州 教育 公司’）默认都能检索，且检索结果按关联度已排好序。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> uadb.tr.neodao.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.GraphDatabaseService;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.Node;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.Transaction;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.Index;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.IndexHits;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.IndexManager;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.helpers.collection.MapUtil;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.ContextConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringJUnit4ClassRunner;</span><br><span class="line"><span class="keyword">import</span> org.wltea.analyzer.lucene.IKAnalyzer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lt.uadb.tr.entity.adtree.AddressNode;</span><br><span class="line"><span class="keyword">import</span> com.lt.util.serialize.JsonUtil;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * AddressNodeNeoDaoTest</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> geosmart</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringJUnit4ClassRunner. <span class="class"><span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">@<span class="title">ContextConfiguration</span>(<span class="title">locations</span> </span>= &#123; <span class="string">"classpath:app.neo4j.cfg.xml"</span> &#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AddressNodeNeoDaoTest</span> </span>&#123;</span><br><span class="line">      <span class="meta">@Autowired</span></span><br><span class="line">      GraphDatabaseService graphDBService;</span><br><span class="line"></span><br><span class="line">      <span class="meta">@Test</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test_selectAddressNodeByFullTextIndex</span><span class="params">()</span> </span>&#123;</span><br><span class="line">             <span class="keyword">try</span> (Transaction tx = graphDBService.beginTx()) &#123;</span><br><span class="line">                  IndexManager index = graphDBService.index();</span><br><span class="line">                  Index&lt;Node&gt; addressNodeFullTextIndex = index.forNodes(<span class="string">"addressNodeFullTextIndex"</span> ,</span><br><span class="line">                              MapUtil. stringMap(IndexManager.PROVIDER, <span class="string">"lucene"</span>, <span class="string">"analyzer"</span> , IKAnalyzer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()))</span>;</span><br><span class="line">                  IndexHits&lt;Node&gt; foundNodes = addressNodeFullTextIndex.query(<span class="string">"text"</span> , <span class="string">"苏州 教育 公司"</span> );</span><br><span class="line">                   <span class="keyword">for</span> (Node node : foundNodes) &#123;</span><br><span class="line">                        AddressNode entity = JsonUtil.ConvertMap2POJO(node.getAllProperties(), AddressNode. <span class="class"><span class="keyword">class</span>, <span class="title">false</span>, <span class="title">true</span>)</span>;</span><br><span class="line">                        System. out.println(entity.getAll地址实全称());</span><br><span class="line">                  &#125;</span><br><span class="line">                  tx.success();</span><br><span class="line">            &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="CyperQL中使用自定义全文索引查询"><a href="#CyperQL中使用自定义全文索引查询" class="headerlink" title="CyperQL中使用自定义全文索引查询"></a>CyperQL中使用自定义全文索引查询</h1><h2 id="正则查询"><a href="#正则查询" class="headerlink" title="正则查询"></a>正则查询</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile  </span><br><span class="line">match (a:AddressNode&#123;ruleabbr:'TOW',text:'唯亭镇'&#125;)&lt;-[r:BELONGTO]-(b:AddressNode&#123;ruleabbr:'STR'&#125;)</span><br><span class="line">where b.text=~ '金陵.*'</span><br><span class="line">return a,b</span><br></pre></td></tr></table></figure>
<h2 id="全文索引查询"><a href="#全文索引查询" class="headerlink" title="全文索引查询"></a>全文索引查询</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile</span><br><span class="line"><span class="keyword">START</span> b=node:addressNodeFullTextIndex(<span class="string">"text:金陵*"</span>)</span><br><span class="line"><span class="keyword">match</span> (a:AddressNode&#123;ruleabbr:<span class="string">'TOW'</span>,<span class="built_in">text</span>:<span class="string">'唯亭镇'</span>&#125;)&lt;-[r:BELONGTO]-(b:AddressNode)</span><br><span class="line"><span class="keyword">where</span> b.ruleabbr=<span class="string">'STR'</span></span><br><span class="line"><span class="keyword">return</span> a,b</span><br></pre></td></tr></table></figure>
<h1 id="LegacyIndex中建立联合exact和fulltext索引"><a href="#LegacyIndex中建立联合exact和fulltext索引" class="headerlink" title="LegacyIndex中建立联合exact和fulltext索引"></a>LegacyIndex中建立联合exact和fulltext索引</h1><p>对label为AddressNode的节点，根据节点属性ruleabbr的分类addressnode_fulltext_index（省-&gt;市-&gt;区县-&gt;乡镇街道-&gt;街路巷/物业小区）/addressnode_exact_index(门牌号-&gt;楼幢号-&gt;单元号-&gt;层号-&gt;户室号)，对属性text分别建不同类型的索引<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile</span><br><span class="line"><span class="keyword">START</span> a=node:addressnode_fulltext_index(<span class="string">"text:商业街"</span>),b=node:addressnode_exact_index(<span class="string">"text:二期19"</span>)</span><br><span class="line"><span class="keyword">match</span> (a:AddressNode&#123;ruleabbr:<span class="string">'STR'</span>&#125;)-[r:BELONGTO]-(b:AddressNode&#123;ruleabbr:<span class="string">'TAB'</span>&#125;)</span><br><span class="line"><span class="keyword">return</span> a,b <span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title>前端工程化开发环境</title>
    <url>/2016/04/19/%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%8C%96%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE en-note SYSTEM "http://xml.evernote.com/pub/enml2.dtd">

<en-note><div><span style="font-weight: bold;"># IDE</span></div><div>Hbuild apiclound：<a href="http://www.dcloud.io/">http://www.dcloud.io/</a></div><div> </div><div><span style="font-weight: bold;"># node.js</span></div><div><a href="http://nodejs.org/">Node.js</a>是一个事件驱动I/O伺服端JavaScript环境，基于Google的V8引擎。目的是为了提供撰写可扩充网络程序，如Web服务。Node.js并不是在Web浏览器上执行，而是一种在服务器上执行的Javascript伺服端JavaScript。Node.js实作了部份CommonJS规格（Spec）。Node.js包含了一个互动测试REPL环境。[<a href="http://zh.wikipedia.org/wiki/Node.js">wiki</a>]</div><div> </div><div><span style="font-weight: bold;"># npm</span></div><div>npm 是 node.js 用来下载及安装套件的工具</div><div> </div><div><span style="font-weight: bold;"># bower</span><span style="font-weight: bold;">（弃用）</span></div><div>bower 由 Twitter  团队研发，能自动下载安装 CSS 及 JavaScript 套件，并可自动处理相依性，角色与 NuGet 相当</div><div> </div><div><span style="font-weight: bold;"># grunt</span></div><div><a href="http://gruntjs.com/getting-started">Grunt</a> 是一个 Task Runner，常用来执行 JS/CSS 打包压缩、SASS/LESS/CoffeeScript 编译、单元测试… 等工作，常被拿来当成前端开发自动化的引擎。</div><div> </div><div><span style="font-weight: bold;"># Gulp</span></div><div>用来简化 Grunt 设定，透过 gulpfile.js 按排作业流程：task, run, watch, src, dest</div><div>npm -g install gulp</div><div>npm install --save-dev gulp （安装到项目目录，限定开发才用到）</div><div>npm install gulp-compass --save-dev （gulp-compass 是常用 Gulp 外挂，内含大量 Mixin 定义）</div><div>一种常见应用是让 Gulp 透过 watch 目录，一旦档案发生异动，就立即启动编译、打包等动作，实现连续整合的目标。</div><div><br/></div><div><br/></div><div> </div></en-note>]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
  </entry>
  <entry>
    <title>Neo4j索引笔记之SchemaIndex和LegacyIndex</title>
    <url>/2016/05/01/Neo4j%E7%B4%A2%E5%BC%95%E7%AC%94%E8%AE%B0%E4%B9%8BSchemaIndex%E5%92%8CLegacyIndex/</url>
    <content><![CDATA[<p>neo4j包含schema indexes 和 legacy indexes两种类型，两者理念不同且不可互换或兼容，实际应用中应明确检索需求后采用合适的索引。<br><a id="more"></a></p>
<h1 id="schema-index-vs-legacy-index"><a href="#schema-index-vs-legacy-index" class="headerlink" title="schema index vs legacy index"></a>schema index vs legacy index</h1><p>参考<a href="http://nigelsmall.com/neo4j/index-confusion">neo4j index-confusion</a></p>
<ul>
<li>schema index和legacy index 都是基于lucene实现；</li>
<li>如果你正在使用Neo4j 2.0或者更高版本并且不需要支持2.0版本之前legacy index的代码，那么请只使用schema index同时避免legacy index；</li>
<li>如果你不得不使用Neo4j的早期版本，并且无法升级，无论如何你都只有一种索引可以选择（legacy index）；</li>
<li>如果你需要全文检索的索引，不管是什么版本，都将使用legacy index。</li>
</ul>
<h1 id="schema-index（schema-based-indexes）"><a href="#schema-index（schema-based-indexes）" class="headerlink" title="schema index（schema based indexes）"></a>schema index（schema based indexes）</h1><p><code>Neo4j is a schema-optional graph database. You can use Neo4j without any schema. Optionally you can introduce it in order to gain performance or modeling benefits.    This allows a way of working where the schema does not get in your way until you are at a stage where you want to reap the benefits of having one.</code></p>
<ul>
<li>在Neo4j 2.0版本之前，Legacy index被称作indexes。这个索引是在graph外部通过Lucene实现，允许“节点”和“关系”以键值对的形式被检索。从Neo4j 提供的REST接口来看，被称作<code>index</code>的变量通常是指Legacy indexes；</li>
<li>Legacy index能够提供全文本检索的能力。这个功能并没有在schema index中被提供，这也是Neo4j 2.0* 版本保留legacy indexes的原因之一。</li>
</ul>
<h2 id="新建索引"><a href="#新建索引" class="headerlink" title="新建索引"></a>新建索引</h2><p>create index on  :Node(property)，会对指定label property的所有node新建index ，index新建成功后，当graph更新时index会自动更新，index默认存储在根目录的/schema/index/lucene目录；<br>如：<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 新建索引</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="keyword">ON</span> :AddressNode( preAddressNodeGUIDs)</span><br><span class="line"><span class="comment"># 删除索引</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">INDEX</span> <span class="keyword">ON</span> :AddressNode(_id)</span><br></pre></td></tr></table></figure></p>
<h2 id="存储方式"><a href="#存储方式" class="headerlink" title="存储方式"></a>存储方式</h2><p>schema index存储方式为复合索引（Compound Index），除了段信息文件，锁文件，以及删除的文件外，其他的一系列索引文件压缩一个后缀名为cfs的文件，即所有的索引文件会被存储成一个单例的Directory，<br>此方式有助于减少索引文件数量，减少同时打开的文件数量，从而获取更高的效率。比如说，查询频繁，而不经常更新的需求，就很适合这种索引格式。</p>
<h1 id="legacy-index"><a href="#legacy-index" class="headerlink" title="legacy index"></a>legacy index</h1><p><a href="http://neo4j.com/docs/stable/indexing-create-advanced.html">Neo4j Legacy Index配置参数</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">值</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">type</td>
<td style="text-align:left">exact, fulltext</td>
<td style="text-align:center">exact采用Lucene keyword analyzer是默认配置. fulltext采用white-space tokenizer in its analyzer.</td>
</tr>
<tr>
<td style="text-align:left">to_lower_case</td>
<td style="text-align:left">true, false</td>
<td style="text-align:center">type=fulltext时生效，在新建索引和查询时会自动进行字母的大小写转换，默认为小写</td>
</tr>
<tr>
<td style="text-align:left">analyzer</td>
<td style="text-align:left">Analyzer类全名</td>
<td style="text-align:center">自定义Lucene Analyzer，注意：to_lower_case配置会默认将查询参数转换为小写.如果自定义analyzer索引写入的字母为大写，查询结果将会不匹配</td>
</tr>
</tbody>
</table>
</div>
<h2 id="新建索引-1"><a href="#新建索引-1" class="headerlink" title="新建索引"></a>新建索引</h2><p>分exact和fulltext两类，两者可结合使用，可新建relationship索引，默认存储在根目录的index/lucene目录；<br>fulltext索引新建方式参考笔记<a href="http://geosmart.github.io/2016/04/21/Neo4j中实现自定义中文全文索引">Neo4j中实现自定义中文全文索引</a></p>
<ul>
<li>注意：使用legacy index查询往往需要一个start node；</li>
</ul>
<h2 id="存储方式-1"><a href="#存储方式-1" class="headerlink" title="存储方式"></a>存储方式</h2><p>legacy index采用非复合索引，更灵活，可以单独的访问某几个索引文件</p>
<h1 id="Neo4j联合索引"><a href="#Neo4j联合索引" class="headerlink" title="Neo4j联合索引"></a>Neo4j联合索引</h1><p>参考：<a href="https://dzone.com/articles/indexing-neo4j-overview">https://dzone.com/articles/indexing-neo4j-overview</a><br>Neo4j不支持联合索引，可采用拼接字段实现</p>
<p>Neo4j 3.0开始支持联合索引，但需要升级至JDK8<br><a href="https://github.com/neo4j/neo4j/issues/6841">https://github.com/neo4j/neo4j/issues/6841</a></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch常用API</title>
    <url>/2016/07/30/Elasticsearch%E5%B8%B8%E7%94%A8API/</url>
    <content><![CDATA[<hr>
<a id="more"></a> 
<p>/_nodes/ 下有一个监控接口：<br>curl -XGET ‘<a href="http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s">http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s</a>‘<br>该接口会返回在 interval 时长内，该节点消耗资源最多的前三个线程的堆栈情况。这对于性能调优初期，采集现状数据，极为有用。<br>默认的，资源消耗是按照 CPU 来衡量，还可以用 ?type=wait 或者 ?type=block 来查看在等待和堵塞状态的当前线程排名。</p>
<p>curl -XGET ‘<a href="http://v3es1:9200/_nodes/v3es1/stats/jvm">http://v3es1:9200/_nodes/v3es1/stats/jvm</a>‘<br>查看：JVM stats, memory pool information, garbage collection, buffer pools, number of loaded/unloaded classes<br>你看看目前jvm状态如何</p>
<p>如果你的 ES 集群监控里发现经常有很耗时的 GC，说明集群负载很重，内存不足。<br>严重情况下，这些 GC 导致节点无法正确响应集群之间的 ping ，可能就直接从集群里退出了。<br>然后数据分片也随之在集群中重新迁移，引发更大的网络和磁盘 IO，正常的写入和搜索也会受到影响。</p>
<h1 id="动态修改Replica"><a href="#动态修改Replica" class="headerlink" title="动态修改Replica"></a>动态修改Replica</h1><p>curl -XPUT ‘localhost:9200/my_index/_settings’ -d ‘<br>{<br>    “index” : {<br>        “number_of_replicas” : 1<br>    }<br>}’</p>
<h1 id="修改-queue-size"><a href="#修改-queue-size" class="headerlink" title="修改 queue_size"></a>修改 queue_size</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html</a><br>curl -XPUT  _cluster/settings -d ‘{<br>    “persistent” : {<br>        “threadpool.bulk.queue_size” : 1000<br>    }<br>}’</p>
<p>参考：<a href="http://jfzhang.blog.51cto.com/1934093/1685530">http://jfzhang.blog.51cto.com/1934093/1685530</a></p>
<h1 id="ES高频写优化配置"><a href="#ES高频写优化配置" class="headerlink" title="ES高频写优化配置"></a>ES高频写优化配置</h1><pre><code>http://edgeofsanity.net/article/2012/12/26/elasticsearch-for-logging.html
</code></pre>]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch批量插入测试</title>
    <url>/2016/07/25/Elasticsearch%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>Elasticsearch批量插入测试<br>数据：10万结构化document（json），每个1.3k；<br>测试结果：bulkProcess性能最优(4s)，bulkRequest次之（1m）；indexAPI适用于单条插入。<br>测试项目源码见<a href="https://github.com/geosmart/me.demo.elasticsearch">me.demo.elasticsearch</a> </p>
<hr>
<a id="more"></a> 
<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>两个Node(8G/4核)</p>
<h1 id="JMeter测试框架"><a href="#JMeter测试框架" class="headerlink" title="JMeter测试框架"></a>JMeter测试框架</h1><p>TODO：模拟http测试rest</p>
<h1 id="单条插入测试"><a href="#单条插入测试" class="headerlink" title="单条插入测试"></a>单条插入测试</h1><p>以IndicesAdminClient新建Index,Type；以IndexAPI插入document(fields);</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-admin-indices.html">IndicesAdminClient </a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-index.html">Index API</a></li>
</ul>
<h1 id="批量插入性能测试"><a href="#批量插入性能测试" class="headerlink" title="批量插入性能测试"></a>批量插入性能测试</h1><p>以Bulk API进行手动批量插入，或采用BulkProcessor 进行自动分段插入；</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-bulk.html">bulk-api</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-bulk-processor.html">bulk-processor</a></li>
<li><a href="http://www.programcreek.com/java-api-examples/index.php?api=org.elasticsearch.action.bulk.BulkRequestBuilder">bulk-api-examples</a></li>
</ul>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="EsRejectedExecutionException"><a href="#EsRejectedExecutionException" class="headerlink" title="EsRejectedExecutionException"></a>EsRejectedExecutionException</h2><p>bulkProcess执行成功，但设置.setConcurrentRequests(4)后，断开线程连接时会抛出如下错误<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">transport: [Orchid] failed to notify response handler on rejection</span><br></pre></td></tr></table></figure><br>解决：todo</p>
<h2 id="ProcessClusterEventTimeoutException"><a href="#ProcessClusterEventTimeoutException" class="headerlink" title="ProcessClusterEventTimeoutException"></a>ProcessClusterEventTimeoutException</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#################################################################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> /etc/elasticsearch/elasticsearch.yml</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Base configuration <span class="keyword">for</span> a write heavy cluster</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Force all memory to be locked, forcing the JVM to never swap</span></span><br><span class="line">bootstrap.mlockall: true</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Threadpool Settings ##</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Search pool</span></span><br><span class="line">threadpool.search.type: fixed</span><br><span class="line">threadpool.search.size: 20</span><br><span class="line">threadpool.search.queue_size: 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bulk pool</span></span><br><span class="line">threadpool.bulk.type: fixed</span><br><span class="line">threadpool.bulk.size: 60</span><br><span class="line">threadpool.bulk.queue_size: 300</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Index pool</span></span><br><span class="line">threadpool.index.type: fixed</span><br><span class="line">threadpool.index.size: 20</span><br><span class="line">threadpool.index.queue_size: 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Indices settings</span></span><br><span class="line">indices.memory.index_buffer_size: 30%</span><br><span class="line">indices.memory.min_shard_index_buffer_size: 12mb</span><br><span class="line">indices.memory.min_index_buffer_size: 96mb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Cache Sizes</span></span><br><span class="line">indices.fielddata.cache.size: 15%</span><br><span class="line">indices.fielddata.cache.expire: 6h</span><br><span class="line">indices.cache.filter.size: 15%</span><br><span class="line">indices.cache.filter.expire: 6h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Indexing Settings <span class="keyword">for</span> Writes</span></span><br><span class="line">index.refresh_interval: 30s</span><br><span class="line">index.translog.flush_threshold_ops: 50000</span><br></pre></td></tr></table></figure>
<p>请教个es插入速度优化的问题，刚开始很快，但是现在目前每秒只能平均处理2个doc，<br>bulkProcess批量插入document，每个doc 25个字段，每个doc大小4k左右，3个Node(6个share,1个replica)；node配置（8G,4核）<br>配置了ES_HEAP_SIZE=3G</p>
<p>ElasticSearch索引优化<br><a href="http://m635674608.iteye.com/blog/2289439">http://m635674608.iteye.com/blog/2289439</a></p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>日志分析ELK</title>
    <url>/2016/07/21/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90ELK/</url>
    <content><![CDATA[<p><a href="http://jolestar.com/elasticsearch-architecture/">Elasticsearch 架构以及源码概览</a></p>
<p>开源实时日志分析 ELK 平台由 <code>ElasticSearch 、Logstash 和 Kiabana</code> 三个开源工具组成。<br><a href="https://www.elastic.co/products">官方网站</a></p>
<ul>
<li>Elasticsearch 是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制， restful 风格接口，多数据源，自动搜索负载等。</li>
<li>Logstash 是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索）。</li>
<li>kibana 也是一个开源和免费的工具，他 Kibana 可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。</li>
</ul>
<h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><p>Docker…</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos7安装MySQL5.6</title>
    <url>/2016/09/10/Centos7%E5%AE%89%E8%A3%85MySQL5-6/</url>
    <content><![CDATA[<p>Centos7系统，以rpm方式安装MySQL5.6</p>
<hr>
<a id="more"></a>
<p><a href="http://blog.csdn.net/liumm0000/article/details/18841197/">参考教程</a></p>
<h1 id="卸载MySQL"><a href="#卸载MySQL" class="headerlink" title="卸载MySQL"></a>卸载MySQL</h1><p>rpm -qa | grep MySQL<br>rpm -e —nodeps mysql MySQL-server-5<br>rpm -e —allmatches MySQL-client-5.6.33-1.el7.x86_64<br>rpm -e —allmatches MySQL-devel-5.6.33-1.el7.x86_64<br>rpm -e —allmatches MySQL-server-5.6.33-1.el7.x86_64<br>chkconfig —del mysql<br>rm -rf /user/local/mysql<br>rm -rf /etc/my.cnf<br>rm -rf /var/lib/mysql</p>
<h1 id="准备mysql安装文件"><a href="#准备mysql安装文件" class="headerlink" title="准备mysql安装文件"></a>准备mysql安装文件</h1><p>下载 mysql包：<code>wget http://cdn.mysql.com//Downloads/MySQL-5.6/mysql-5.6.33-winx64.zip</code><br>解压缩：<code>tar -xvf mysql-5.6.33-winx64.zip</code></p>
<h1 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su mysql</span><br><span class="line">rpm -ivh MySQL-server-5.6.33-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh MySQL-devel-5.6.33-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh MySQL-client-5.6.33-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<h1 id="修改配置文件位置"><a href="#修改配置文件位置" class="headerlink" title="修改配置文件位置"></a>修改配置文件位置</h1><p><code>cp /usr/share/mysql/my-default.cnf /etc/my.cnf</code></p>
<h1 id="初始化MySQL及设置密码"><a href="#初始化MySQL及设置密码" class="headerlink" title="初始化MySQL及设置密码"></a>初始化MySQL及设置密码</h1><p>安装server会自动执行数据库初始化（perl）：/usr/bin/mysql_install_db<br>启动服务：service mysql start<br>查看默认密码：<code>cat /root/.mysql_secret</code><br>修改root密码：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -uroot -pFiXBgAhVDgythr6B</span><br><span class="line">SET PASSWORD = PASSWORD(<span class="string">'root'</span>);   </span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure></p>
<h1 id="允许远程登陆"><a href="#允许远程登陆" class="headerlink" title="允许远程登陆"></a>允许远程登陆</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql -uroot -proot</span><br><span class="line"><span class="keyword">use</span> mysql;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host=<span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">'root'</span> <span class="keyword">and</span> host=<span class="string">'localhost'</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>
<h1 id="设置开机自启动"><a href="#设置开机自启动" class="headerlink" title="设置开机自启动"></a>设置开机自启动</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chkconfig mysql on</span><br><span class="line">chkconfig --list | grep mysql</span><br></pre></td></tr></table></figure>
<h1 id="配置-etc-my-cnf"><a href="#配置-etc-my-cnf" class="headerlink" title="配置/etc/my.cnf"></a>配置/etc/my.cnf</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  whereis my.ini</span></span><br><span class="line">[server]</span><br><span class="line"><span class="built_in">bind</span>-address           = 0.0.0.0</span><br><span class="line">character-set-server   = utf8</span><br><span class="line">collation-server       = utf8_unicode_ci</span><br><span class="line">init_connect           = <span class="string">'SET NAMES utf8'</span></span><br><span class="line">max_connections = 5000</span><br><span class="line">max_allowed_packet = 20M</span><br><span class="line">max_connect_errors= 1000</span><br><span class="line">lower_case_table_names=2</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">data=/usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line">socket=/var/lib/mysql/mysql.sock </span><br><span class="line"></span><br><span class="line">innodb_file_per_table = 1</span><br><span class="line">innodb_flush_method=O_DIRECT</span><br><span class="line">innodb_log_file_size=1G</span><br><span class="line">innodb_buffer_pool_size=4G</span><br><span class="line"></span><br><span class="line">[mysqld_safe]</span><br><span class="line"><span class="built_in">log</span>-error=/var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">long_query_time =1</span><br><span class="line"><span class="built_in">log</span>-slow-queries=slowqueris.log</span><br><span class="line"><span class="built_in">log</span>-queries-not-using-indexes = nouseindex.log</span><br><span class="line"><span class="built_in">log</span>=mylog.log</span><br></pre></td></tr></table></figure>
<h1 id="mysql数据目录设置权限"><a href="#mysql数据目录设置权限" class="headerlink" title="mysql数据目录设置权限"></a>mysql数据目录设置权限</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su root</span><br><span class="line">chown -R root:root /usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line">chown -R root:root /var/lib/mysql</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning课程笔记Week1-基础概念</title>
    <url>/2017/07/03/MachineLeaning%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0Week1-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p><a href="https://www.coursera.org/learn/machine-learning/home/week/1">Coursera斯坦福大学机器学习（Machine Leaning）课程第一周</a>课程笔记</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
</blockquote>
<p>“对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E学习。”</p>
<hr>
<a id="more"></a> 
<h1 id="机器学习定义"><a href="#机器学习定义" class="headerlink" title="机器学习定义"></a>机器学习定义</h1><p>机器学习有下面几种定义：</p>
<ul>
<li>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。</li>
<li>机器学习是对能通过经验自动改进的计算机算法的研究。</li>
<li>机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。<blockquote>
<p>What is Machine Learning?<br>Two definitions of Machine Learning are offered. Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition.<br>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”<br>Example: playing checkers.<br>E = the experience of playing many games of checkers<br>T = the task of playing checkers.<br>P = the probability that the program will win the next game.<br>In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and Unsupervised learning.</p>
</blockquote>
</li>
</ul>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p>监督学习从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。<br>监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。  </p>
<p>常见的监督学习算法包括回归分析和统计分类。</p>
<h2 id="回归分析（连续）"><a href="#回归分析（连续）" class="headerlink" title="回归分析（连续）"></a>回归分析（连续）</h2><p>房价预测</p>
<h2 id="统计分类（离散）"><a href="#统计分类（离散）" class="headerlink" title="统计分类（离散）"></a>统计分类（离散）</h2><p>癌症良恶性判断</p>
<blockquote>
<p>分类（Classification）和回归（Regression）的区别在于输出变量的类型。<br>定量输出称为回归，或者说是连续变量（continous）预测；<br>定性输出称为分类，或者说是离散变量（discrete）预测。</p>
</blockquote>
<h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><p>We can derive this structure by clustering the data based on relationships among<br>the variables in the data.</p>
<p>应用场景：</p>
<ul>
<li>市场细分</li>
<li>组织计算集群</li>
<li>社交网络分析</li>
<li>天文数据分析</li>
</ul>
<p>无监督学习与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有聚类。</p>
<h2 id="聚类问题"><a href="#聚类问题" class="headerlink" title="聚类问题"></a>聚类问题</h2><p>基因数据分组</p>
<h2 id="非聚类问题"><a href="#非聚类问题" class="headerlink" title="非聚类问题"></a>非聚类问题</h2><p>鸡尾酒会问题（音频分离）</p>
<h1 id="原型工具"><a href="#原型工具" class="headerlink" title="原型工具"></a>原型工具</h1><h2 id="matlab"><a href="#matlab" class="headerlink" title="matlab"></a>matlab</h2><h2 id="octave"><a href="#octave" class="headerlink" title="octave"></a><a href="https://www.gnu.org/software/octave/doc/interpreter/">octave</a></h2>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础概念</title>
    <url>/2017/07/11/MachineLearning%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>监督学习、非监督学习、神经网络……<br><a id="more"></a> </p>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><h2 id="分类问题和回归问题"><a href="#分类问题和回归问题" class="headerlink" title="分类问题和回归问题"></a>分类问题和回归问题</h2><p>分类问题希望解决的是将不同的样本分到事先定义好的类别中；</p>
<ul>
<li>分类（Classification）和回归（Regression）的区别在于输出变量的类型。</li>
<li>定量输出称为回归，或者说是连续变量（continous）预测；</li>
<li>定性输出称为分类，或者说是离散变量（discrete）预测。</li>
</ul>
<blockquote>
<p>对Regression回归一词的理解<br>出自高尔顿种豆子的实验，通过大量数据统计，他发现个体小的豆子往往倾向于产生比其更大的子代，而个体大的豆子则倾向于产生比其小的子代，然后高尔顿认为这是由于新个体在向这种豆子的平均尺寸“回归”，大概的意思就是事物总是倾向于朝着某种“平均”发展，也可以说是回归于事物本来的面目。<br>C.R.Rao等在Linear Models and Generalizations: Least Squares and Alternatives中解释道：the literature meaning of REGRESSION is “ to move in the backward direction”，<br>看以下两个陈述：<br>S1: model generates data or<br>S2: data generates model.<br>Rao认为很明显陈述S1才是对的，因为模型实际上本来就是存在的，<br>只不过我们不知道(model exists in nature but is unknown to the experimenter)，先有模型所以我们知道X就能得到Y：<br>先有模型 —&gt; 有了X就有Y（S1），而“回归”的意思就是我们通过收集X与Y来确定实际上存在的关系模型：<br>收集X与Y —&gt; 确定模型（S2），与S1相比，S2就是一个“回到”模型的过程，所以就叫做“regression”。</p>
</blockquote>
<h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><p>We can derive this structure by clustering the data based on relationships among the variables in the data.<br>Clustering：基因分组<br>Non-clustering: The “Cocktail Party Algorithm”,音频分离</p>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="RNN梯度消散问题"><a href="#RNN梯度消散问题" class="headerlink" title="RNN梯度消散问题"></a>RNN梯度消散问题</h2><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><h1 id="MLP（Multi-Layer-Perceptron-）"><a href="#MLP（Multi-Layer-Perceptron-）" class="headerlink" title="MLP（Multi Layer Perceptron ）"></a>MLP（Multi Layer Perceptron ）</h1><p>多层感知器，是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP可以被看做是一个有向图，由多个节点层组成，每一层全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为反向传播算法的监督学习方法常被用来训练MLP。MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。</p>
<h1 id="CUDA-Compute-Unified-Device-Architecture"><a href="#CUDA-Compute-Unified-Device-Architecture" class="headerlink" title="CUDA(Compute Unified Device Architecture)"></a>CUDA(Compute Unified Device Architecture)</h1><p>CUDA是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。<br> 开发人员现在可以使用C语言来为CUDA™架构编写程序，C语言是应用最广泛的一种高级编程语言。所编写出的程序于是就可以在支持CUDA™的处理器上以超高性能运行。CUDA3.0已经开始支持C++和FORTRAN。</p>
<h1 id="State-of-the-art"><a href="#State-of-the-art" class="headerlink" title="State of the art"></a>State of the art</h1><p>对应国内文献里的“研究现状”,当前的最高研究水平。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>MachineLearning课程笔记Week1-损失函数</title>
    <url>/2017/07/08/MachineLearning%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0Week1-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p><a href="https://www.coursera.org/learn/machine-learning/supplement/cRa2m/model-representation">Coursera斯坦福大学机器学习（Machine Leaning）课程第一周</a>课程笔记</p>
<blockquote>
<p>given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. </p>
</blockquote>
<hr>
<a id="more"></a> 
<h1 id="监督学习模型"><a href="#监督学习模型" class="headerlink" title="监督学习模型"></a>监督学习模型</h1><p><img src="监督学习模型.jpg" alt="supervised learning problem"></p>
<blockquote>
<p>When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem.</p>
</blockquote>
<h1 id="损失函数（Cost-Function）"><a href="#损失函数（Cost-Function）" class="headerlink" title="损失函数（Cost Function）"></a>损失函数（Cost Function）</h1><p><img src="损失函数公式.jpg" alt="损失函数公式"></p>
<script type="math/tex; mode=display">J(\theta|_0,\theta|_1)</script><p><img src="损失函数推演过程.jpg" alt="损失函数推演过程"></p>
<p>示例：线性回归-单变量</p>
<h1 id="梯度下降法（Gradiant-Discent）"><a href="#梯度下降法（Gradiant-Discent）" class="headerlink" title="梯度下降法（Gradiant Discent）"></a>梯度下降法（Gradiant Discent）</h1><p>梯度下降法求解线性回归问题，即求解最小化损失函数J</p>
<p><img src="线性回归问题求解.jpg" alt="线性回归问题求解"></p>
<p><img src="梯度下降法求解线性回归问题.jpg" alt="梯度下降法求解线性回归问题"></p>
<p><img src="梯度下降法可视化.jpg" alt="梯度下降法-轮廓图"></p>
<blockquote>
<p>θ0 on the x axis and θ1 on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters.</p>
</blockquote>
<p><img src="梯度下降法公式.jpg" alt="梯度下降法公式"></p>
<ul>
<li>learning rate：The size of each step is determined by the parameter α,</li>
<li>j=0,1 represents the feature index number.</li>
<li>At each iteration j, one should <strong>simultaneously</strong> update the parameters θ1,θ2,…,θn. Updating a specific parameter prior to calculating another one on the j(th) iteration would yield to a wrong implementation.</li>
</ul>
<h2 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h2><blockquote>
<p>Debugging gradient descent. Make a plot with number of iterations on the x-axis. Now plot the cost function, J(θ) over the number of iterations of gradient descent. If J(θ) ever increases, then you probably need to decrease α.</p>
<p>Automatic convergence test. Declare convergence if J(θ) decreases by less than E in one iteration, where E is some small value such as 10−3. However in practice it’s difficult to choose this threshold value.</p>
</blockquote>
<p>To summarize:</p>
<ul>
<li>If α is too small: slow convergence.</li>
<li>If α is too large: ￼may not decrease on every iteration and thus may not converge.</li>
</ul>
<h2 id="批量梯度下降（batch-gradient-descent）"><a href="#批量梯度下降（batch-gradient-descent）" class="headerlink" title="批量梯度下降（batch gradient descent）"></a>批量梯度下降（batch gradient descent）</h2><p><a href="https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression">https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression</a></p>
<p>凸二次函数（convex quadratic function）</p>
<h2 id="特征选择和多项式回归"><a href="#特征选择和多项式回归" class="headerlink" title="特征选择和多项式回归"></a>特征选择和多项式回归</h2><p>Features and Polynomial Regression</p>
<ul>
<li>多个特征可合并为一个新特征</li>
<li>线性假设函数效果不好时，可以用平方，立方，平方根或其他形式来改变函数曲线</li>
</ul>
<blockquote>
<p>One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important.<br>eg. if x1 has range 1 - 1000 then range of x21 becomes 1 - 1000000 and that of x31 becomes 1 - 1000000000</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>R学习笔记</title>
    <url>/2017/07/04/R%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>R is a tool for statistics and data modeling. The R programming language is elegant, versatile, and has a highly expressive syntax designed around working with data. R is more than that, though — it also includes extremely powerful graphics capabilities.</p>
</blockquote>
<hr>
<a id="more"></a> 
<p><a href="http://tryr.codeschool.com/">Try R</a></p>
<h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><p>定义： x&lt;-42，x赋值为42</p>
<h1 id="向量（Vectors）"><a href="#向量（Vectors）" class="headerlink" title="向量（Vectors）"></a>向量（Vectors）</h1><p>定义： c(1,T,”three”)</p>
<h2 id="Sequence-Vectors"><a href="#Sequence-Vectors" class="headerlink" title="Sequence Vectors"></a>Sequence Vectors</h2><p>输入：seq(5,9)或5:9<br>输出：[1] 5 6 7 8 9</p>
<h2 id="设置步长-increments"><a href="#设置步长-increments" class="headerlink" title="设置步长-increments"></a>设置步长-increments</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt;seq(<span class="number">5</span>,<span class="number">9</span>,<span class="number">0.5</span>)</span><br><span class="line">[<span class="number">1</span>] <span class="number">5.0</span> <span class="number">5.5</span> <span class="number">6.0</span> <span class="number">6.5</span> <span class="number">7.0</span> <span class="number">7.5</span> <span class="number">8.0</span> <span class="number">8.5</span> <span class="number">9.0</span></span><br></pre></td></tr></table></figure>
<h2 id="向量访问"><a href="#向量访问" class="headerlink" title="向量访问"></a>向量访问</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence &lt;- c(<span class="string">'walk'</span>, <span class="string">'the'</span>, <span class="string">'plank'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>索引访问:R索引从1开始 </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence[<span class="number">3</span>]</span><br><span class="line">[<span class="number">1</span>] <span class="string">"plank"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>定义向量访问： </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence[c(<span class="number">1</span>,<span class="number">3</span>)]</span><br><span class="line">[<span class="number">1</span>] <span class="string">"walk"</span> <span class="string">"dog"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>范围访问： </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence[<span class="number">2</span>:<span class="number">4</span>]  </span><br><span class="line">[<span class="number">1</span>] <span class="string">"the"</span> <span class="string">"dog"</span> <span class="string">"to"</span></span><br></pre></td></tr></table></figure>
<h2 id="修改向量值"><a href="#修改向量值" class="headerlink" title="修改向量值"></a>修改向量值</h2></li>
<li>单个修改<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence[<span class="number">3</span>]&lt;-<span class="string">"dog"</span></span><br></pre></td></tr></table></figure></li>
<li>批量修改<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; sentence[<span class="number">5</span>:<span class="number">7</span>]&lt;-c(<span class="string">'the'</span>,<span class="string">'poop'</span>,<span class="string">'deck'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>新增向量<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">sentence[<span class="number">4</span>]&lt;-<span class="string">"to"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h1><p>barplot直方图<br><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; vesselsSunk &lt;- c(<span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">&gt; barplot(vesselsSunk)</span><br></pre></td></tr></table></figure></p>
<p>scatter plots散点图<br><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; values &lt;- -<span class="number">10</span>:<span class="number">10</span></span><br><span class="line">&gt; absolutes &lt;- abs(values)</span><br><span class="line">&gt; plot(values, absolutes)</span><br></pre></td></tr></table></figure></p>
<h1 id="NA"><a href="#NA" class="headerlink" title="NA"></a>NA</h1><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; a &lt;- c(<span class="number">1</span>, <span class="number">3</span>, <span class="literal">NA</span>, <span class="number">7</span>, <span class="number">9</span>)</span><br><span class="line">&gt; sum(a)</span><br><span class="line">[<span class="number">1</span>] <span class="literal">NA</span></span><br><span class="line">&gt; sum(a,na.rm=<span class="literal">T</span>)</span><br><span class="line">[<span class="number">1</span>] <span class="number">20</span></span><br></pre></td></tr></table></figure>
<h1 id="matrix"><a href="#matrix" class="headerlink" title="matrix"></a>matrix</h1><p>定义：3行4列，值都为0<br>matrix(0,3,4)</p>
<p>升维：dim设置matrix维度<br><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; plank  &lt;- <span class="number">1</span>:<span class="number">8</span></span><br><span class="line">&gt; dim(plank) &lt;- c(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">&gt; print(plank)</span><br><span class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>] [,<span class="number">4</span>]</span><br><span class="line">[<span class="number">1</span>,]    <span class="number">1</span>    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></span><br><span class="line">[<span class="number">2</span>,]    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></span><br></pre></td></tr></table></figure></p>
<p>赋值：&gt; plank[1,4] &lt;- 0</p>
<h2 id="matrix访问"><a href="#matrix访问" class="headerlink" title="matrix访问"></a>matrix访问</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; print(plank)</span><br><span class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>] [,<span class="number">4</span>]</span><br><span class="line">[<span class="number">1</span>,]    <span class="number">1</span>    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></span><br><span class="line">[<span class="number">2</span>,]    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></span><br></pre></td></tr></table></figure>
<ul>
<li>单个元素<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; plank[<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">[<span class="number">1</span>] <span class="number">6</span></span><br></pre></td></tr></table></figure></li>
<li><p>列</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; plank[,<span class="number">4</span>]</span><br><span class="line">[<span class="number">1</span>] <span class="number">7</span> <span class="number">8</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>指定范围</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; plank[,<span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>]</span><br><span class="line">[<span class="number">1</span>,]    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></span><br><span class="line">[<span class="number">2</span>,]    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="绘图-1"><a href="#绘图-1" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; elevation &lt;- matrix(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">&gt; elevation[<span class="number">4</span>, <span class="number">6</span>] &lt;- <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>轮廓图</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; contour(elevation)</span><br></pre></td></tr></table></figure>
</li>
<li><p>三维轮廓图</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; persp(elevation)</span><br><span class="line">&gt; persp(elevation, expand=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="统计函数"><a href="#统计函数" class="headerlink" title="统计函数"></a>统计函数</h1><h2 id="Mean-平均值"><a href="#Mean-平均值" class="headerlink" title="Mean 平均值"></a>Mean 平均值</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">limbs &lt;- c(<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">names(limbs) &lt;- c(<span class="string">'One-Eye'</span>, <span class="string">'Peg-Leg'</span>, <span class="string">'Smitty'</span>, <span class="string">'Hook'</span>, <span class="string">'Scooter'</span>, <span class="string">'Dan'</span>, <span class="string">'Mikey'</span>, <span class="string">'Blackbeard'</span>)</span><br><span class="line">&gt; mean(limbs)</span><br><span class="line"><span class="comment"># 平均值柱状图</span></span><br><span class="line">&gt; barplot(limbs)</span><br><span class="line"><span class="comment"># 平均值柱状图 + 平均值水平线</span></span><br><span class="line">&gt; abline(h=mean(limbs)</span><br></pre></td></tr></table></figure>
<h2 id="Median-中位数"><a href="#Median-中位数" class="headerlink" title="Median 中位数"></a>Median 中位数</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; limbs &lt;- c(<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">14</span>)</span><br><span class="line">&gt; names(limbs) &lt;- c(<span class="string">'One-Eye'</span>, <span class="string">'Peg-Leg'</span>, <span class="string">'Smitty'</span>, <span class="string">'Hook'</span>, <span class="string">'Scooter'</span>, <span class="string">'Dan'</span>, <span class="string">'Mikey'</span>, <span class="string">'Davy Jones'</span>)</span><br><span class="line">&gt; mean(limbs)</span><br><span class="line">[<span class="number">1</span>] <span class="number">4.75</span></span><br><span class="line">&gt; barplot(limbs)</span><br><span class="line">&gt; abline(h = mean(limbs))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>It may be factually accurate to say that our crew has an average of 4.75 limbs, but it’s probably also misleading.<br>For situations like this, it’s probably more useful to talk about the “median” value.<br>The median is calculated by sorting the values and choosing the middle one (for sets with an even number of values, the middle two values are averaged).</p>
</blockquote>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; median(limbs)</span><br><span class="line">[<span class="number">1</span>] <span class="number">4</span></span><br></pre></td></tr></table></figure>
<h2 id="Standard-Deviation-标准偏差"><a href="#Standard-Deviation-标准偏差" class="headerlink" title="Standard Deviation 标准偏差"></a>Standard Deviation 标准偏差</h2><blockquote>
<p>Statisticians use the concept of “standard deviation” from the mean to describe the range of typical values for a data set. For a group of numbers, it shows how much they typically vary from the average value. To calculate the standard deviation, you calculate the mean of the values, then subtract the mean from each number and square the result, then average those squares, and take the square root of that average.</p>
</blockquote>
<h1 id="Data-Frames"><a href="#Data-Frames" class="headerlink" title="Data Frames"></a>Data Frames</h1><blockquote>
<p>R has a structure for just this purpose: the data frame. You can think of a data frame as something akin to a database table or an Excel spreadsheet. It has a specific number of columns, each of which is expected to contain values of a particular type. It also has an indeterminate number of rows - sets of related values for each column.</p>
</blockquote>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; treasure &lt;- data.frame(weights, prices, types)</span><br><span class="line">&gt; print(treasure)</span><br><span class="line">  weights prices  types</span><br><span class="line"><span class="number">1</span>     <span class="number">300</span>   <span class="number">9000</span>   gold</span><br><span class="line"><span class="number">2</span>     <span class="number">200</span>   <span class="number">5000</span> silver</span><br><span class="line"><span class="number">3</span>     <span class="number">100</span>  <span class="number">12000</span>   gems</span><br><span class="line"><span class="number">4</span>     <span class="number">250</span>   <span class="number">7500</span>   gold</span><br><span class="line"><span class="number">5</span>     <span class="number">150</span>  <span class="number">18000</span>   gems</span><br></pre></td></tr></table></figure>
<h2 id="数据访问"><a href="#数据访问" class="headerlink" title="数据访问"></a>数据访问</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; treasure[[<span class="number">2</span>]]</span><br><span class="line">[<span class="number">1</span>]  <span class="number">9000</span>  <span class="number">5000</span> <span class="number">12000</span>  <span class="number">7500</span> <span class="number">18000</span></span><br><span class="line"></span><br><span class="line">&gt; treasure[[<span class="string">"weights"</span>]]</span><br><span class="line">[<span class="number">1</span>] <span class="number">300</span> <span class="number">200</span> <span class="number">100</span> <span class="number">250</span> <span class="number">150</span></span><br><span class="line"></span><br><span class="line">&gt; treasure$prices</span><br><span class="line">[<span class="number">1</span>]  <span class="number">9000</span>  <span class="number">5000</span> <span class="number">12000</span>  <span class="number">7500</span> <span class="number">18000</span></span><br></pre></td></tr></table></figure>
<h1 id="文件IO"><a href="#文件IO" class="headerlink" title="文件IO"></a>文件IO</h1><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; piracy &lt;- read.csv(<span class="string">"piracy.csv"</span>)</span><br><span class="line">&gt; gdp &lt;- read.table(<span class="string">"gdp.txt"</span>, sep=<span class="string">"  "</span>, header=<span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>
<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="cor-test"><a href="#cor-test" class="headerlink" title="cor.test"></a>cor.test</h2><p>R can test for correlation between two vectors with the cor.test function.<br><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; cor.test(countries$GDP, countries$Piracy)</span><br></pre></td></tr></table></figure></p>
<h2 id="lm"><a href="#lm" class="headerlink" title="lm"></a>lm</h2><p>if we calculate the linear model that best represents all our data points (with a certain degree of error).<br>The lm function takes a model formula, which is represented by a response variable (piracy rate), a tilde character (~), and a predictor variable (GDP). (Note that the response variable comes first.)</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; line &lt;- lm(countries$Piracy ~ countries$GDP)</span><br><span class="line">&gt; abline(line)</span><br></pre></td></tr></table></figure>
<h1 id="扩展安装"><a href="#扩展安装" class="headerlink" title="扩展安装"></a>扩展安装</h1><p>install.packages(“ggplot2”)</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow实现神经网络</title>
    <url>/2017/07/03/TensorFlow%E5%AE%9E%E7%8E%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p><a href="http://playground.tensorflow.org/">神经网络可视化示例-TensorFlow游乐场</a><br>一个最简单的神经元的结构的输出就是所有输入的<strong>加权和</strong>，而不同输入的权重就是神经元的参数。神经网络的优化过程就是优化神经元中参数的取值过程。</p>
<hr>
<a id="more"></a> 
<h1 id="神经网络数据结构"><a href="#神经网络数据结构" class="headerlink" title="神经网络数据结构"></a>神经网络数据结构</h1><p>第一层是输入层，代表特征向量中每一个特征的取值；<br>在输入层和输出层之间的神经网络叫隐藏层；<br>一般一个神经网络的隐藏层越多，这个神经网络就越’深’；</p>
<p><img src="三层神经网络结构图.jpg" alt="判断零件是否合格的三层神经网络结构图"></p>
<h1 id="神经网络解决分类问题的步骤："><a href="#神经网络解决分类问题的步骤：" class="headerlink" title="神经网络解决分类问题的步骤："></a>神经网络解决分类问题的步骤：</h1><p>神经网络解决分类问题主要分为以下4个步骤：</p>
<ol>
<li>提取问题中实体的特征向量作为神经网络的输入。</li>
<li>定义神经网络的结构，并定义如何从神经网络的输入得到输出；</li>
<li>通过训练数据来调整神经网络中参数的取值，这就是训练神经网络的过程。</li>
<li>使用训练好的神经网络来预测未知数据；</li>
</ol>
<h1 id="前向传播算法"><a href="#前向传播算法" class="headerlink" title="前向传播算法"></a>前向传播算法</h1><h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><p>神经元是构成一个神经网络的最小单元。</p>
<ul>
<li>一个神经元有多个输入和一个输出；</li>
<li>每个神经元的输入既可以是其他神经元的输出，也可以是整个个神经网络的输入；</li>
<li>神经网络的结构即不同神经元之间的连接结构；<br>一个最简单的神经元的结构的输出就是所有输入的<strong>加权和</strong>，而不同输入的权重就是神经元的参数。神经网络的优化过程就是优化神经元中参数的取值过程。</li>
</ul>
<h2 id="前向传播算法（forward-propagation）"><a href="#前向传播算法（forward-propagation）" class="headerlink" title="前向传播算法（forward-propagation）"></a>前向传播算法（forward-propagation）</h2><p>计算神经网络的前向传播算法需3部分信息：</p>
<ol>
<li>神经网络的输入，即从实体中提取的特征向量；</li>
<li>神经网络的连接结构</li>
<li>神经元中的参数；</li>
</ol>
<p>给定神经网络的输入，神经网络的结构以及边上权重，就可以通过前向传播算法来计算神经网络的输出。<br><img src="神经网络前向传播算法示意图.jpg" alt="神经网络前向传播算法示意图"><br>在TensorFlow中实现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># matmul为矩阵乘法函数</span></span><br><span class="line">a= tf.matmul(x1 , w1)</span><br><span class="line">y= tf.matmul(a , w2)</span><br></pre></td></tr></table></figure><br>前向传播算法可以表示为矩阵乘法，将输入x1,x2组织成一个1x2的矩阵x=[x1,x2]，而W(1)组织成一个2x3的矩阵：<br><img src="前向传播算法计算公式.jpg" alt="前向传播算法计算公式"></p>
<h1 id="神经网络参数与TensorFlow变量"><a href="#神经网络参数与TensorFlow变量" class="headerlink" title="神经网络参数与TensorFlow变量"></a>神经网络参数与TensorFlow变量</h1><h1 id="通过TensorFlow训练神经网络模型"><a href="#通过TensorFlow训练神经网络模型" class="headerlink" title="通过TensorFlow训练神经网络模型"></a>通过TensorFlow训练神经网络模型</h1><h1 id="完整神经网络示例程序"><a href="#完整神经网络示例程序" class="headerlink" title="完整神经网络示例程序"></a>完整神经网络示例程序</h1>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow基础概念</title>
    <url>/2017/07/03/TensorFlow%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>TensorFlow最重要的两个概念-Tensor和Flow；<br>Tensor就是张量，可简单理解为多维数组；<br>Flow直观表达Tensor之间通过计算相互转换的过程；<br>TensorFlow是一个通过计算图的形式来表述计算的编程系统。TensorFlow中的每个计算都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系。</p>
<hr>
<a id="more"></a> 
<h1 id="TensorFlow的计算模型-计算图"><a href="#TensorFlow的计算模型-计算图" class="headerlink" title="TensorFlow的计算模型-计算图"></a>TensorFlow的计算模型-计算图</h1><h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><ul>
<li>tf.get_default_grapph()：获取当前默认计算图；</li>
<li>tf.Graph()：生成新的计算图；</li>
<li>tf.Graph.device(‘device’)：指定运行计算的设备；</li>
</ul>
<h1 id="TensorFlow的数据模型-张量"><a href="#TensorFlow的数据模型-张量" class="headerlink" title="TensorFlow的数据模型-张量"></a>TensorFlow的数据模型-张量</h1><p>TensorFlow中所有运算的输入、输出都是张量（Tensor）。张量本身并不存储任何数据，它是对运算结果的引用。Tensor可简单理解为多维数组； </p>
<ul>
<li>零阶张量-标量（scalar）</li>
<li>第一阶张量-向量（vector）</li>
<li>第n阶张量（n维数组）</li>
</ul>
<p>TensorFlow中的每一个计算是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系；<br>不同计算图中的张量和运算都不会共享；</p>
<h2 id="张量的数据结构"><a href="#张量的数据结构" class="headerlink" title="张量的数据结构"></a>张量的数据结构</h2><p>示例：Tensor( “add:0” , shape=(2,) , dtype=float32 )</p>
<h3 id="名字（name）"><a href="#名字（name）" class="headerlink" title="名字（name）"></a>名字（name）</h3><p>node:src_output</p>
<h3 id="维度（shape）"><a href="#维度（shape）" class="headerlink" title="维度（shape）"></a>维度（shape）</h3><h3 id="类型（type）"><a href="#类型（type）" class="headerlink" title="类型（type）"></a>类型（type）</h3><ul>
<li>实数（tf.float32、tf.float64）</li>
<li>整数（tf.int8、tf.int16、tf.int32、tf.int64、tf.uint8）</li>
<li>布尔型（tf.bool）</li>
<li>复数（tf.complex64、tf.complex128） </li>
</ul>
<h2 id="张量的使用"><a href="#张量的使用" class="headerlink" title="张量的使用"></a>张量的使用</h2><p>通过Tensor可更好的组织TensorFlow程序</p>
<ul>
<li>对中间结果的引用，提供代码可读性</li>
<li>当计算图构造完成后，通过张量获取计算结果</li>
</ul>
<h1 id="TensorFlow的运算模型-会话（session）"><a href="#TensorFlow的运算模型-会话（session）" class="headerlink" title="TensorFlow的运算模型-会话（session）"></a>TensorFlow的运算模型-会话（session）</h1><h2 id="session的使用模式"><a href="#session的使用模式" class="headerlink" title="session的使用模式"></a>session的使用模式</h2><h3 id="明确调用会话生成函数和关闭会话函数"><a href="#明确调用会话生成函数和关闭会话函数" class="headerlink" title="明确调用会话生成函数和关闭会话函数"></a>明确调用会话生成函数和关闭会话函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">session=tf.Session()</span><br><span class="line">sess.run(...)</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<h3 id="Python上下文管理器管理会话"><a href="#Python上下文管理器管理会话" class="headerlink" title="Python上下文管理器管理会话"></a>Python上下文管理器管理会话</h3><p>将所有计算放在with内部<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess</span><br><span class="line">    sess.run(...)</span><br></pre></td></tr></table></figure><br>优点：  </p>
<ul>
<li>解决异常退出时资源释放问题，</li>
<li>解决忘记调用Session.close函数而产生的资源泄露问题；</li>
</ul>
<h3 id="默认会话"><a href="#默认会话" class="headerlink" title="默认会话"></a>默认会话</h3><ul>
<li>手动指定session为默认会话</li>
<li>交互式环境以tf.InteractiveSession配置会话</li>
</ul>
<h2 id="ConfigProto配置会话"><a href="#ConfigProto配置会话" class="headerlink" title="ConfigProto配置会话"></a>ConfigProto配置会话</h2><h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><ul>
<li>allow_soft_placement（bool）：当运算无法被当前GPU支持时，可以自动切换到CPU上；</li>
<li>log_device_placemnet（bool）：日志中将会记录每个节点被安排在那个设备上以方便调试。</li>
</ul>
<h3 id="ConfigProto可配参数"><a href="#ConfigProto可配参数" class="headerlink" title="ConfigProto可配参数"></a>ConfigProto可配参数</h3><ul>
<li>并行线程数</li>
<li>GPU分配策略</li>
<li>运算超时时间</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow环境搭建</title>
    <url>/2017/07/01/TensorFlow%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>将近一年未更新博客，期间专注做互联网金融领域的身份识别类产品（身份证OCR、活体检测、人脸比对），现在产品线趋于成熟，可以静下心来研究神往已久的深度学习了。</p>
<hr>
<a id="more"></a>
<h1 id="Anaconda安装"><a href="#Anaconda安装" class="headerlink" title="Anaconda安装"></a>Anaconda安装</h1><p>Anaconda是一个和Canopy类似的Python科学计算环境，但用起来更加方便。</p>
<ul>
<li>下载：<code>wget https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh</code></li>
<li>安装：<code>bash Anaconda3-4.4.0-Linux-x86_64.sh</code></li>
<li>配置：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将anaconda的bin目录加入PATH</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH="~/anaconda3/bin:$PATH"'</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="comment"># 更新bashrc以立即生效</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">配置好PATH后，可以通过 <span class="built_in">which</span> conda 或 conda --version 命令检查是否正确；</span><br><span class="line"><span class="comment"># 配置镜像</span></span><br><span class="line">安装完以后，打开Anaconda Prompt，输入清华的仓库镜像，更新包更快；</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="TensorFlow安装"><a href="#TensorFlow安装" class="headerlink" title="TensorFlow安装"></a>TensorFlow安装</h1><ul>
<li>打开Anaconda Prompt，输入：<code>conda create -n tensorflow python=3.6</code></li>
<li>查看已安装环境列表: <code>conda env list</code>；</li>
<li>激活环境：<ul>
<li>linux：<code>source activate tensorflow</code>；</li>
<li>windows：<code>activate tensorflow</code>；</li>
</ul>
</li>
<li>安装tensorflow的CPU版本，<ul>
<li>linux安装：<code>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp36-cp36m-linux_x86_64.whl</code></li>
<li>windows安装：<code>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp36-cp36m-win_amd64.whl</code></li>
</ul>
</li>
</ul>
<h1 id="HelloWorld示例"><a href="#HelloWorld示例" class="headerlink" title="HelloWorld示例"></a>HelloWorld示例</h1><p>一个TensorFlow示例实现两个向量求和<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a=tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>],name=<span class="string">"a"</span>)</span><br><span class="line">b=tf.constant([<span class="number">2.0</span>,<span class="number">3.0</span>],name=<span class="string">"b"</span>)</span><br><span class="line">result=a+b</span><br><span class="line">sess=tf.Session() </span><br><span class="line">sess.run(result)</span><br></pre></td></tr></table></figure></p>
<h1 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h1><p>IDE：pycharm 2017<br>注册服务器：<a href="http://idea.iteblog.com/key.php">http://idea.iteblog.com/key.php</a>  </p>
<h2 id="pycharm远程调试"><a href="#pycharm远程调试" class="headerlink" title="pycharm远程调试"></a>pycharm远程调试</h2><p>以pycharm配置remote interpreter远程开发调试，并以ssh自动上传本地程序到测试/生产环境；<br>配置参考<a href="https://blog.jetbrains.com/pycharm/2015/03/feature-spotlight-python-remote-development-with-pycharm/">feature-spotlight-python-remote-development-with-pycharm</a></p>
<h1 id="归档环境"><a href="#归档环境" class="headerlink" title="归档环境"></a>归档环境</h1><p><a href="http://jupyter.org/">Jupyter Notebook</a><br><a href="http://nbviewer.jupyter.org/github/masinoa/machine_learning/tree/master/">Jupyter Notebook-machine_learning</a></p>
<ol>
<li>一次运行, 多次阅读,保存运行结果</li>
<li>交互式编程, 边看边写</li>
<li>可以添加各种元素,比如图片,视频, 链接, 文档(比代码注释要好看), 相当于PPT<br><a href="http://python.jobbole.com/87527/?repeat=w3tc">ref</a><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>深层神经网络</title>
    <url>/2017/07/20/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<a id="more"></a> 
<h1 id="深度学习与深层神经网络"><a href="#深度学习与深层神经网络" class="headerlink" title="深度学习与深层神经网络"></a>深度学习与深层神经网络</h1><h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><h2 id="经典损失函数"><a href="#经典损失函数" class="headerlink" title="经典损失函数"></a>经典损失函数</h2><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><blockquote>
<p>如何判断输出向量和期望向量之间的接近程度？<br>交叉熵是常用的评判方法，其刻画了两个概率分布之间的距离，它是分类问题中使用较广的一种损失函数；</p>
<h3 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h3><p>如何将神经网络前向传播得到的结果也变成概率分布？<br>Softmax回归是一个非常常用的方法<br>公式：</p>
</blockquote>
<p>tensorflow 实现交叉熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,<span class="number">1e-10</span>,<span class="number">1.0</span>)))</span><br><span class="line"><span class="comment"># y_：正确结果</span></span><br><span class="line"><span class="comment"># y:预测结果</span></span><br><span class="line"><span class="comment"># tf.clip_by_value：将一个张量的数值限制在一个范围内，避免一些运算错误，如log0</span></span><br><span class="line"><span class="comment"># tf.log：对张量中的数据依次就对数</span></span><br><span class="line"><span class="comment"># * ：乘法，每个位置上对应元素的乘积，不是矩阵乘法</span></span><br></pre></td></tr></table></figure>
<p>因为交叉熵一般会与softmax回归一起使用，所以tensorflow对这两个功能进行了统一封装，并提供了<code>tf.nn.softmax_cross_entropy_with_logists(y,y_)</code></p>
<p>对于回归问题，最常用的损失函数是均方差（MSE,mean squared error）；</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang学习笔记</title>
    <url>/2017/10/22/Golang%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Go is not meant to innovate <code>programming theory</code>. It’s<br>meant to innovate <code>programming practice</code>.  — Samuel Tesla</p>
<hr>
<a id="more"></a> 
<h2 id="Golang学习笔记"><a href="#Golang学习笔记" class="headerlink" title="Golang学习笔记"></a>Golang学习笔记</h2><h1 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h1><p><img src="常见微服务架构.png" alt="常见微服务架构"></p>
<h1 id="微服务架构的核心"><a href="#微服务架构的核心" class="headerlink" title="微服务架构的核心"></a>微服务架构的核心</h1><ul>
<li>负载均衡：seasaw，caddy</li>
<li>服务网关：tyk，fabio，vulcand</li>
<li>进程间通信：restful，rpc，自定义</li>
<li>服务注册与发现：etcd，consul，serf</li>
<li>分布式调度：k8s，swarm</li>
<li>分布式配置：etcd，consul，mgmt</li>
<li>异步消息队列：NSQ， Nats</li>
<li>日志分析：Beats，Heka</li>
<li>服务监控/告警：open-falcon，prometheus</li>
<li>APM（应用性能监控）：appdash，Cloudinsight，opentracing</li>
<li>CI/CD：Drone</li>
<li>熔断器：gateway，Hystrix-go</li>
</ul>
<h1 id="Go的框架"><a href="#Go的框架" class="headerlink" title="Go的框架"></a>Go的框架</h1><ul>
<li>REST框架：beego，gin，Iris，micro，go-kit，goa</li>
<li>RPC框架：grpc，thrift，hprose</li>
</ul>
<h1 id="Go的应用场景"><a href="#Go的应用场景" class="headerlink" title="Go的应用场景"></a>Go的应用场景</h1><p>GO适用于高并发低延迟</p>
<ol>
<li>中间件系统</li>
<li>服务器编程</li>
<li>分布式系统</li>
<li>网络编程</li>
<li>云平台应用</li>
<li>数据库系统</li>
<li>运维系统</li>
<li>云存储系统</li>
<li>容器类系统</li>
</ol>
<h1 id="Go优点"><a href="#Go优点" class="headerlink" title="Go优点"></a>Go优点</h1><ol>
<li>出身名门，血统纯正：Google开发，2009发布，系统语言</li>
<li>开发效率，运行效率</li>
<li>类C语法，内置GC，编译快速，调试方便</li>
<li>多核支持，轻量并发，简易同步</li>
<li>组合无对象，无侵入接口</li>
<li>网络编程必备库，系统编程必备库</li>
<li>交叉编译，无依赖部署</li>
<li>编译检查，编码规范，工程工具</li>
</ol>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库优化</title>
    <url>/2017/10/02/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>MySQL优化技术：负载均衡，读写分类，分库分表，索引优化…</p>
<hr>
<a id="more"></a> 
<h2 id="MySQL数据库优化"><a href="#MySQL数据库优化" class="headerlink" title="MySQL数据库优化"></a>MySQL数据库优化</h2><h1 id="负载均衡技术"><a href="#负载均衡技术" class="headerlink" title="负载均衡技术"></a>负载均衡技术</h1><p>多数据库同步</p>
<h1 id="数据库的读写分离"><a href="#数据库的读写分离" class="headerlink" title="数据库的读写分离"></a>数据库的读写分离</h1><p>数据库复制</p>
<h1 id="数据库拆分（分布式）"><a href="#数据库拆分（分布式）" class="headerlink" title="数据库拆分（分布式）"></a>数据库拆分（分布式）</h1><p>CAP法则</p>
<h2 id="垂直（纵向）拆分"><a href="#垂直（纵向）拆分" class="headerlink" title="垂直（纵向）拆分"></a>垂直（纵向）拆分</h2><p>按功能模块拆分</p>
<h2 id="水平（横向）拆分"><a href="#水平（横向）拆分" class="headerlink" title="水平（横向）拆分"></a>水平（横向）拆分</h2><p>将同一张表的数据分块存储到不同的数据库</p>
<h1 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h1><h2 id="索引选择性"><a href="#索引选择性" class="headerlink" title="索引选择性"></a>索引选择性</h2><p>索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？<br>答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。</p>
<ol>
<li>表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。</li>
<li>索引的选择性较低。所谓<code>索引的选择性</code>（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：<code>Index Selectivity = Cardinality / #T</code><br>显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。</li>
</ol>
<blockquote>
<p>有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。</p>
</blockquote>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Nodejs入门笔记</title>
    <url>/2017/10/02/Nodejs%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p> Everything runs in parallel except your code!</p>
<hr>
<a id="more"></a> 
<h2 id="Nodejs入门笔记"><a href="#Nodejs入门笔记" class="headerlink" title="Nodejs入门笔记"></a>Nodejs入门笔记</h2><h1 id="诞生背景"><a href="#诞生背景" class="headerlink" title="诞生背景"></a>诞生背景</h1><p>Node.js，或者 Node，是一个可以让 JavaScript 运行在服务器端的平台。它可以让 JavaScript 脱离浏览器的束缚运行在一般的服务器环境下，就像运行 Python、Perl、PHP、Ruby 程序一样。你可以用 Node.js 轻松地进行服务器端应用开发，Python、Perl、PHP、Ruby 能做的事情 Node.js 几乎都能做。</p>
<p>Node.js 是一个为实时Web（Real-time Web）应用开发而诞生的平台，它从诞生之初就充分考虑了在<code>实时响应、超大规模数据</code>要求下架构的可扩展性。这使得它摒弃了传统平台依靠多线程来实现高并发的设计思路，而采用了<code>单线程、异步式I/O、事件驱动式</code>的程序设计模型。这些特性不仅带来了巨大的性能提升，还减少了多线程程序设计的复杂性，进而提高了开发效率。</p>
<h1 id="Node-js定义"><a href="#Node-js定义" class="headerlink" title="Node.js定义"></a>Node.js定义</h1><p>一个搭建在Chrome JavaScript运行时 上的平台，用于构建高速、可伸缩的网络程序。<br>Node.js采用的事件驱动、非阻塞I/O模型，使它 既轻量又高效，并成为构建运行在分布式设备上的数据密集型实时程序的完美选择。</p>
<h1 id="Node-js模块构成"><a href="#Node-js模块构成" class="headerlink" title="Node.js模块构成"></a>Node.js模块构成</h1><p><img src="Alt text.png" alt="Alt text"></p>
<ul>
<li>core javascript API 实现高层级别的 Node.js API。</li>
<li>bindings用于包装并暴露底层libuv和其他底层接口</li>
<li>v8 是google开源javascript解释引擎。</li>
<li>libuv 是 Node.js 非阻塞引擎。</li>
</ul>
<p>Node.js是首个将异步作为主要编程方式和设计理念的平台，伴随着异步I/O的还有<code>事件驱动</code>和<code>单线程</code>，它们构成Node的基调。</p>
<h1 id="异步I-O与事件驱动"><a href="#异步I-O与事件驱动" class="headerlink" title="异步I/O与事件驱动"></a>异步I/O与事件驱动</h1><p>Node.js 最大的特点就是采用异步式 I/O 与事件驱动的架构设计。<br>对于高并发的解决方案，传统的架构是多线程模型，也就是为每个业务逻辑提供一个系统线程，通过系统线程切换来弥补同步式 I/O 调用时的时间开销。<br>Node.js 使用的是单线程模型，对于所有 I/O 都采用异步式的请求方式，<code>避免了频繁的上下文切换</code>。<br>Node.js 在执行的过程中会维护一个事件队列，程序在执行时进入事件循环等待下一个事件到来，每个异步式 I/O 请求完成后会被推送到事件队列，等待程序进程进行处理。</p>
<blockquote>
<p>同步和异步是指工作过程，阻塞和非阻塞是指表现形式；<br>同步导致阻塞线程，异步是非阻塞线程；</p>
</blockquote>
<h2 id="异步过程"><a href="#异步过程" class="headerlink" title="异步过程"></a>异步过程</h2><p>主线程发起一个异步请求，相应的工作线程接收请求并告知主线程已收到(异步函数返回)；<br>主线程可以继续执行后面的代码，同时工作线程执行异步任务；<br>工作线程完成工作后，利用消息队列和事件循环通知主线程；<br>主线程收到通知后，执行一定的动作(调用回调函数)。</p>
<h2 id="消息队列和事件循环"><a href="#消息队列和事件循环" class="headerlink" title="消息队列和事件循环"></a>消息队列和事件循环</h2><p>工作线程将消息放到消息队列，主线程通过事件循环过程去取消息。<br>消息队列：消息队列是一个先进先出的队列，它里面存放着各种消息。<br>事件循环：事件循环是指主线程重复从消息队列中取消息、执行的过程。</p>
<blockquote>
<p>消息队列中的每条消息实际上都对应着一个事件。</p>
</blockquote>
<h2 id="生产者与消费者"><a href="#生产者与消费者" class="headerlink" title="生产者与消费者"></a>生产者与消费者</h2><p><img src="javascript消息队列和事件循环.png" alt="javascript消息队列和事件循环"><br>从生产者与消费者的角度看，异步过程是这样的：<br>工作线程是生产者，主线程是消费者(只有一个消费者)。<br>工作线程执行异步任务，执行完成后把对应的回调函数封装成一条消息放到消息队列中；<br>主线程不断地从消息队列中取消息并执行，当消息队列空时主线程阻塞，直到消息队列再次非空。</p>
<h2 id="同步和异步的示例"><a href="#同步和异步的示例" class="headerlink" title="同步和异步的示例"></a>同步和异步的示例</h2><p>用一个生活中的例子总结一下同步和异步：<br>同步：在公路上，汽车一辆接一辆，有条不紊的运行。这时，有一辆车坏掉了。假如它停在原地进行修理，那么后面的车就会被堵住没法行驶，交通就乱套了。<br>异步：幸好旁边有应急车道，可以把故障车辆推到应急车道修理，而正常的车流不会受到任何影响。等车修好了，再从应急车道回到正常车道即可。唯一的影响就是，应急车道用多了，原来的车辆之间的顺序会有点乱。</p>
<p>这就是同步和异步的区别。<code>同步可以保证顺序一致，但是容易导致阻塞</code>；<code>异步可以解决阻塞问题，但是会改变顺序性</code>。改变顺序性其实也没有什么大不了的，只不过让程序变得稍微难理解了一些 :)</p>
<h2 id="并行编程"><a href="#并行编程" class="headerlink" title="并行编程"></a>并行编程</h2><ol>
<li><a href="http://eventproxy.html5ify.com/">EventProxy</a><br>EventProxy 仅仅是一个很轻量的工具，但是能够带来一种<code>事件式编程</code>的思维变化。有几个特点：</li>
</ol>
<ul>
<li>利用事件机制解耦复杂业务逻辑</li>
<li>移除被广为诟病的深度callback嵌套问题</li>
<li>将串行等待变成并行等待，提升多异步协作场景下的执行效率</li>
<li>友好的Error handling</li>
<li>无平台依赖，适合前后端，能用于浏览器和Node.js</li>
<li>兼容CMD，AMD以及CommonJS模块环境</li>
</ul>
<ol>
<li>Async<blockquote>
<p>Async is a utility module which provides straight-forward, powerful functions for working with asynchronous JavaScript. Although originally designed for use with Node.js and installable via npm install —save async, it can also be used directly in the browser.</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>当你需要去多个源(一般是小于 10 个)汇总数据的时候，用 eventproxy 方便；<br>当你需要用到队列，需要控制并发数，或者你喜欢函数式编程思维时，使用 async；<br>大部分场景是前者。</p>
</blockquote>
<h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><ul>
<li>测试框架 mocha : <a href="http://mochajs.org/">http://mochajs.org/</a></li>
<li>断言库 should : <a href="https://github.com/tj/should.js">https://github.com/tj/should.js</a></li>
<li>测试率覆盖工具 istanbul : <a href="https://github.com/gotwarlost/istanbul">https://github.com/gotwarlost/istanbul</a></li>
<li>Makefile 的编写 : <a href="http://blog.csdn.net/haoel/article/details/2886">http://blog.csdn.net/haoel/article/details/2886</a></li>
</ul>
<h3 id="浏览器测试"><a href="#浏览器测试" class="headerlink" title="浏览器测试"></a>浏览器测试</h3><ul>
<li>mocha 进行前端测试 : <a href="http://mochajs.org/">http://mochajs.org/</a></li>
<li>断言库 chai: <a href="http://chaijs.com/">http://chaijs.com/</a></li>
<li>配合express集成测试 supertest（superagent 的孪生库）：<a href="https://github.com/tj/supertest">https://github.com/tj/supertest</a></li>
<li>headless 浏览器 phantomjs: <a href="http://phantomjs.org/">http://phantomjs.org/</a></li>
</ul>
<h1 id="其他库"><a href="#其他库" class="headerlink" title="其他库"></a>其他库</h1><ul>
<li>web框架：express</li>
<li>html解析（类jquery）：cheerio </li>
<li>爬虫：superagent</li>
<li>辅助工具：utility</li>
<li>热部署工具：nodemon </li>
<li>ORM：Sequelize</li>
<li></li>
</ul>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="Node-js-为何单线程却能并发"><a href="#Node-js-为何单线程却能并发" class="headerlink" title="Node.js 为何单线程却能并发"></a>Node.js 为何单线程却能并发</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.infoq.com/cn/articles/nodejs-asynchronous-io">初探Node.js的异步I/O实现</a><br><a href="https://cnodejs.org/getstart">Node.js入门</a><br><a href="http://nqdeng.github.io/7-days-nodejs/#1">七天学会NodeJS</a></p>
]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title>python高级特性</title>
    <url>/2017/10/04/python%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url>
    <content><![CDATA[<p>python高级特性之GIL全局解释锁，concurrent多线程</p>
<hr>
<a id="more"></a> 
<h2 id="python高级特性"><a href="#python高级特性" class="headerlink" title="python高级特性"></a>python高级特性</h2><h1 id="concurrent任务并发"><a href="#concurrent任务并发" class="headerlink" title="concurrent任务并发"></a>concurrent任务并发</h1><blockquote>
<p>The concurrent.futures module provides a high-level interface for asynchronously executing callables.<br>The asynchronous execution can be performed with threads, using <code>ThreadPoolExecutor</code>, or separate processes, using <code>ProcessPoolExecutor</code>. Both implement the same interface, which is defined by the abstract Executor class.</p>
</blockquote>
<h1 id="GIL-全局解释器锁"><a href="#GIL-全局解释器锁" class="headerlink" title="GIL 全局解释器锁"></a>GIL 全局解释器锁</h1><h2 id="什么是全局解释器锁GIL"><a href="#什么是全局解释器锁GIL" class="headerlink" title="什么是全局解释器锁GIL"></a>什么是全局解释器锁GIL</h2><p>Python代码的执行由Python 虚拟机(也叫解释器主循环，CPython版本)来控制，Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证<code>同一时刻只有一个线程在运行</code>。<br>在多线程环境中，Python 虚拟机按以下方式执行：</p>
<ol>
<li>设置GIL</li>
<li>切换到一个线程去运行</li>
<li>运行：<ul>
<li>指定数量的字节码指令，或者</li>
<li>线程主动让出控制（可以调用time.sleep(0)）</li>
</ul>
</li>
<li>把线程设置为睡眠状态</li>
<li>解锁GIL</li>
<li>再次重复以上所有步骤 </li>
</ol>
<p>在调用外部代码（如C/C++扩展函数）的时候，GIL 将会被锁定，直到这个函数结束为止（由于在这期间没有Python 的字节码被运行，所以不会做线程切换）。</p>
<h2 id="全局解释器锁GIL设计理念与限制"><a href="#全局解释器锁GIL设计理念与限制" class="headerlink" title="全局解释器锁GIL设计理念与限制"></a>全局解释器锁GIL设计理念与限制</h2><p>GIL的设计简化了CPython的实现，使得对象模型，包括关键的内建类型如字典，都是隐含可以并发访问的。锁住全局解释器使得比较容易的实现对多线程的支持，但也损失了多处理器主机的并行计算能力。<br>但是，不论标准的，还是第三方的扩展模块，都被设计成在进行密集计算任务是，释放GIL。<br>还有，就是在做I/O操作时，GIL总是会被释放。对所有面向I/O 的(会调用内建的操作系统C 代码的)程序来说，GIL 会在这个I/O 调用之前被释放，以允许其它的线程在这个线程等待I/O 的时候运行。如果是纯计算的程序，没有 I/O 操作，解释器会每隔 100 次操作就释放这把锁，让别的线程有机会执行（这个次数可以通过 sys.setcheckinterval 来调整）如果某线程并未使用很多I/O 操作，它会在自己的时间片内一直占用处理器（和GIL）。也就是说，I/O 密集型的Python 程序比计算密集型的程序更能充分利用多线程环境的好处。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://zhuoqiang.me/python-thread-gil-and-ctypes.html">python 线程，GIL 和 ctypes</a><br><a href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures — Launching parallel tasksï¿½</a></p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>前端工程化工具</title>
    <url>/2017/10/04/%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%8C%96%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>前端工程化框架/工具</p>
<hr>
<a id="more"></a> 
<h2 id="前端工程化工具"><a href="#前端工程化工具" class="headerlink" title="前端工程化工具"></a>前端工程化工具</h2><h1 id="node-js"><a href="#node-js" class="headerlink" title="node.js"></a>node.js</h1><p>Node.js是一个事件驱动I/O伺服端JavaScript环境，基于Google的V8引擎。目的是为了提供撰写可扩充网络程序，如Web服务。Node.js并不是在Web浏览器上执行，而是一种在服务器上执行的Javascript伺服端JavaScript。Node.js实作了部份CommonJS规格（Spec）。Node.js包含了一个互动测试REPL环境。[wiki]</p>
<h1 id="npm"><a href="#npm" class="headerlink" title="npm"></a>npm</h1><p>npm 是 node.js 用来下载及安装套件的工具</p>
<h1 id="bower（弃用）"><a href="#bower（弃用）" class="headerlink" title="bower（弃用）"></a>bower（弃用）</h1><p>bower 由 Twitter  团队研发，能自动下载安装 CSS 及 JavaScript 套件，并可自动处理相依性，角色与 NuGet 相当</p>
<h1 id="grunt"><a href="#grunt" class="headerlink" title="grunt"></a>grunt</h1><p>Grunt 是一个 Task Runner，常用来执行 JS/CSS 打包压缩、SASS/LESS/CoffeeScript 编译、单元测试… 等工作，常被拿来当成前端开发自动化的引擎。</p>
<h1 id="gulp"><a href="#gulp" class="headerlink" title="gulp"></a>gulp</h1><p>用来简化 Grunt 设定，透过 gulpfile.js 按排作业流程：task, run, watch, src, dest</p>
<ul>
<li>npm -g install gulp</li>
<li>npm install —save-dev gulp （安装到项目目录，限定开发才用到）</li>
<li>npm install gulp-compass —save-dev （gulp-compass 是常用 Gulp 外挂，内含大量 Mixin 定义）</li>
</ul>
<p>一种常见应用是让 Gulp 透过 watch 目录，一旦档案发生异动，就立即启动编译、打包等动作，实现连续整合的目标。</p>
<h1 id="webpack"><a href="#webpack" class="headerlink" title="webpack"></a>webpack</h1><p>Webpack 是一个模块打包器。它将根据模块的依赖关系进行静态分析，然后将这些模块按照指定的规则生成对应的静态资源。</p>
<h1 id="IDE"><a href="#IDE" class="headerlink" title="IDE"></a>IDE</h1><ul>
<li>Hbuild apiclound：<a href="http://www.dcloud.io/">http://www.dcloud.io/</a></li>
<li>VSCode</li>
<li>WebStorm</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://zhaoda.net/webpack-handbook/index.html">webpack</a><br><a href="http://zhaoda.net/webpack-handbook/module-system.html">前端模块系统的演进</a></p>
]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
  </entry>
  <entry>
    <title>数据库特性总结-关系数据库</title>
    <url>/2017/10/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E6%80%BB%E7%BB%93-%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<p>列举关系型数据库MySQL的InnoDB和MyISAM索引的实现和</p>
<hr>
<a id="more"></a> 
<h2 id="数据库特性总结-关系数据库"><a href="#数据库特性总结-关系数据库" class="headerlink" title="数据库特性总结-关系数据库"></a>数据库特性总结-关系数据库</h2><h1 id="关系型数据库（MySQL）"><a href="#关系型数据库（MySQL）" class="headerlink" title="关系型数据库（MySQL）"></a>关系型数据库（MySQL）</h1><h2 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h2><p><img src="InnoDb内存使用机制.png" alt="InnoDb内存使用机制"><br>Mysql的缓冲池机制是能充分利用内存且有预加载机制，在某些条件下目标数据完全在内存中，也能够具备非常好的查询性能。</p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>示例数据的B树索引示意图<br><img src="B树索引.png" alt="B树索引"></p>
<h3 id="MyISAM索引实现"><a href="#MyISAM索引实现" class="headerlink" title="MyISAM索引实现"></a>MyISAM索引实现</h3><p>MyISAM引擎使用B+Tree作为索引结构，索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。叶节点的data域存放的是数据记录的地址。<br>MyISAM的索引方式也叫做<code>非聚集索引</code>，之所以这么称呼是为了与InnoDB的聚集索引区分。</p>
<ul>
<li><p>主索引（Primary key）<br><img src="MyISAM表的主索引示意.png" alt="MyISAM表的主索引示意"><br>MyISAM的索引文件仅仅保存数据记录的地址。</p>
</li>
<li><p>辅助索引（Secondary key）<br><img src="MyISAM表的辅助索引示意图.png" alt="MyISAM表的辅助索引示意图"><br>在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。<br>同样辅助索引也是一颗B+Tree，data域保存数据记录的地址。</p>
</li>
</ul>
<blockquote>
<p>MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p>
</blockquote>
<h3 id="InnoDB索引实现"><a href="#InnoDB索引实现" class="headerlink" title="InnoDB索引实现"></a>InnoDB索引实现</h3><p>在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此<code>InnoDB表数据文件本身就是主索引</code>。</p>
<ul>
<li><p>主索引（Primary key）<br><img src="InnoDB主索引示意图.png" alt="InnoDB主索引示意图"><br>由InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做<code>聚集索引</code>。<br>因为InnoDB的数据文件本身要<code>按主键聚集</code>，所以InnoDB要求表必须有主键（MyISAM可以没有）； 如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键；如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p>
</li>
<li><p>辅助索引（Secondary key）<br><img src="InnoDB辅助索引示意图.png" alt="InnoDB辅助索引示意图"><br>InnoDB的辅助索引data域存储相应记录<code>主键的值</code>而不是地址，即InnoDB的所有辅助索引都<code>引用主键作为data域</code>。</p>
<blockquote>
<p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助：</p>
<ol>
<li>eg 知道了InnoDB的索引实现后，就很容易明白为什么<code>不建议使用过长的字段作为主键</code>，因为所有辅助索引都引用主索引，<code>过长的主索引会令辅助索引变得过大</code>。</li>
<li>eg 用<code>非单调的字段作为主键在InnoDB中不是个好主意</code>，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在<code>插入新记录时</code>数据文件为了维持B+Tree的特性而频繁的<code>分裂调整</code>，十分低效，而使用<code>自增字段</code>作为主键则是一个很好的选择。</li>
</ol>
</blockquote>
</li>
</ul>
<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p><img src="innodb query.png" alt="innodb query"></p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>关系型数据库适合存储结构化数据，如用户的帐号、地址：</p>
<ul>
<li>这些数据通常需要做<code>结构化查询</code>，比如join，这时候，关系型数据库就要胜出一筹</li>
<li>可以预期的数据增长规模和增长速度</li>
<li>事务性、一致性</li>
</ul>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="由于传统机械磁盘有局部性原理和磁盘预读，数据库索引采用BTree，现在SSD已经普及，Btree数据结构的优势还在不在？"><a href="#由于传统机械磁盘有局部性原理和磁盘预读，数据库索引采用BTree，现在SSD已经普及，Btree数据结构的优势还在不在？" class="headerlink" title="由于传统机械磁盘有局部性原理和磁盘预读，数据库索引采用BTree，现在SSD已经普及，Btree数据结构的优势还在不在？"></a>由于传统机械磁盘有局部性原理和磁盘预读，数据库索引采用BTree，现在SSD已经普及，Btree数据结构的优势还在不在？</h2><p>参考<a href="https://www.zhihu.com/question/65628840">在 SSD 相对在服务器端普及的今天，为什么大部分数据库还是用 B/B+ 树实现的？</a></p>
<h2 id="MySQL数据写入流程是什么？"><a href="#MySQL数据写入流程是什么？" class="headerlink" title="MySQL数据写入流程是什么？"></a>MySQL数据写入流程是什么？</h2><h2 id="MySQL数据查询的流程是什么？索引如何生效的？"><a href="#MySQL数据查询的流程是什么？索引如何生效的？" class="headerlink" title="MySQL数据查询的流程是什么？索引如何生效的？"></a>MySQL数据查询的流程是什么？索引如何生效的？</h2><h2 id="MySQL的存储引擎InnoDB和MyISAM有什么区别，各自的存储结构是什么样的？"><a href="#MySQL的存储引擎InnoDB和MyISAM有什么区别，各自的存储结构是什么样的？" class="headerlink" title="MySQL的存储引擎InnoDB和MyISAM有什么区别，各自的存储结构是什么样的？"></a>MySQL的存储引擎InnoDB和MyISAM有什么区别，各自的存储结构是什么样的？</h2><ol>
<li>本质上都是B+Tree索引结构，但是InnoDB是<code>聚集索引</code>（树的叶节点data域保存了完整的数据记录。索引的key是数据表的主键），MyISAM是<code>非聚集索引</code>（引文件和数据文件是分离的，索引文件仅保存数据记录的地址。叶节点的data域存放的是数据记录的地址）；</li>
<li>MyISAM不支持<code>事务</code>，<code>表级锁</code>，适合查询以及插入为主的应用；InnoDB支持事务，<code>行级锁</code>，适合频繁修改以及涉及到安全性较高的应用；（在where条件没有使用主键时，照样会锁全表，如 <code>update table set a=1 where user like &#39;%lee%&#39;</code>）；</li>
<li>InnoDB支持<code>外键</code>，MyISAM不支持；</li>
<li>InnoDB不支持<code>FULLTEXT</code>类型的索引，MyISAM支持；</li>
<li>InnoDB中不保存表的行数，如<code>select count(*) from table</code>时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(*)语句包含where条件时MyISAM也需要扫描整个表；</li>
<li>truncate表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表；</li>
</ol>
<blockquote>
<p>常规说法：现在一般都是选用innodb了，主要是myisam的全表锁，读写串行问题，并发效率锁表，效率低myisam对于<code>读写密集型</code>应用一般是不会去选用的。</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://blog.csdn.net/voidccc/article/details/40077329">剖析Mysql的InnoDB索引</a></li>
<li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html">MySQL索引背后的数据结构及算法原理</a><br><a href="http://www.ywnds.com/?p=8282">MySQL读写IO的操作过程解析</a></li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>数据预处理方法论</title>
    <url>/2017/10/07/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/</url>
    <content><![CDATA[<p>记录数据预处理，特征向量化的一些常见方法</p>
<a id="more"></a> 
<h1 id="预处理流程"><a href="#预处理流程" class="headerlink" title="预处理流程"></a>预处理流程</h1><h2 id="浏览数据"><a href="#浏览数据" class="headerlink" title="浏览数据"></a>浏览数据</h2><ul>
<li>了解业务流程：数据是如何产生；</li>
<li>看元数据：数据字典整理分类；</li>
<li>看数据内容：抽样浏览数据内容，初步了解数据，如对前100行数据内容进行统计；</li>
</ul>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><ul>
<li>确定缺失范围：根据缺失比例和缺失字段重要性2个维度分别制定处理策略。<ul>
<li>重要性高 &amp; 缺失率高：其他渠道获取；其他字段计算获取；删除并备注；</li>
<li>重要性高 &amp; 缺失率低：其他字段计算获取；提供业务知识/经验估计；</li>
<li>重要性低 &amp; 缺失率高：删除字段；</li>
<li>重要性低 &amp; 缺失率低：不做处理；简单填充</li>
</ul>
</li>
<li>删除不需要的字段：注意数据备份</li>
<li>填充缺失内容<ul>
<li>以业务知识或经验推测填充缺失值</li>
<li>以同一指标的计算结果（均值、中位数、众数等）填充缺失值</li>
<li>以不同指标的计算结果填充缺失值，如年龄字段缺失，但是有屏蔽后六位的身份证号可以计算得出年龄 </li>
<li>机器学习模型预测，如随机森林预测字段值</li>
</ul>
</li>
<li>重新获取数据<h2 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h2></li>
<li>格式异常：时间、日期、数值、全半角等显示格式不一致</li>
<li>语义异常：数据中的空格问题，数值问题，如年龄&lt;0</li>
<li>业务异常：系统bug导致的数据异常，或者人工输入数据导致的自相矛盾的数据，如订单状态不正确，年龄与身份证号不匹配<h2 id="重复值处理"><a href="#重复值处理" class="headerlink" title="重复值处理"></a>重复值处理</h2></li>
<li>去重</li>
</ul>
<blockquote>
<p>PS 如果数据量没有大到不删字段就没办法处理的程度，那么能不删的字段尽量不删；<br>进行阶段性数据备份，并注意命名规则统一；</p>
</blockquote>
<h2 id="多源数据的关联验证"><a href="#多源数据的关联验证" class="headerlink" title="多源数据的关联验证"></a>多源数据的关联验证</h2><p>自相矛盾数据的确认</p>
<h1 id="特征向量化"><a href="#特征向量化" class="headerlink" title="特征向量化"></a>特征向量化</h1><h2 id="离散特征"><a href="#离散特征" class="headerlink" title="离散特征"></a>离散特征</h2><p>分类编码后onehot编码</p>
<h2 id="连续特征"><a href="#连续特征" class="headerlink" title="连续特征"></a>连续特征</h2><p>归一化处理</p>
<ul>
<li>Standard标准化</li>
<li>Min-Max归一化</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>ETL</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数学基础</title>
    <url>/2017/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>记录机器学习数学概念/公式</p>
<hr>
<a id="more"></a> 
<h2 id="机器学习数学基础"><a href="#机器学习数学基础" class="headerlink" title="机器学习数学基础"></a>机器学习数学基础</h2><h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><h2 id="Variance-方差"><a href="#Variance-方差" class="headerlink" title="Variance(方差)"></a>Variance(方差)</h2><blockquote>
<p>方差（Variance），应用数学里的专有名词。<br>在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。方差越大，数据的分布越分散。<br>一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量。<br>说白了，就是将各个误差将之平方（而非取绝对值），使之肯定为正数，相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。<br>继续延伸的话，方差的算术平方根称为该随机变量的标准差（此为相对各个数据点间）。</p>
</blockquote>
<p>总体方差计算公式：  </p>
<h2 id="Bias-偏差"><a href="#Bias-偏差" class="headerlink" title="Bias(偏差)"></a>Bias(偏差)</h2><p>偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，<br>方差，是形容数据分散程度的，算是“无监督的”，客观的指标，<br>偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。</p>
<h2 id="Standard-Deviation-标准差"><a href="#Standard-Deviation-标准差" class="headerlink" title="Standard Deviation(标准差)"></a>Standard Deviation(标准差)</h2><blockquote>
<p>标准差（Standard Deviation，SD）又常称均方差，数学符号 σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。<br>标准差定义：标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。  </p>
</blockquote>
<p>标准差也被称为标准偏差，或者实验标准差，公式为<br><img src="标准差公式.png" alt="标准差公式"></p>
<h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><h3 id="矩阵的性质"><a href="#矩阵的性质" class="headerlink" title="矩阵的性质"></a>矩阵的性质</h3><ul>
<li>不满足交换律</li>
<li>方阵：行列相等</li>
<li>单位矩阵：xx对角线都为1</li>
<li>逆矩阵：I<em>A=A</em>I=A</li>
<li>奇异矩阵/退化矩阵（singular/degenerate）：没有逆矩阵，如零矩阵（矩阵元素都为0）<h3 id="矩阵的乘法"><a href="#矩阵的乘法" class="headerlink" title="矩阵的乘法"></a>矩阵的乘法</h3><h3 id="矩阵的转置（transpose）"><a href="#矩阵的转置（transpose）" class="headerlink" title="矩阵的转置（transpose）"></a>矩阵的转置（transpose）</h3></li>
</ul>
<h1 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h1><h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><h2 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h2><h2 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h2><h2 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h2><h1 id="常用公式"><a href="#常用公式" class="headerlink" title="常用公式"></a>常用公式</h1><ul>
<li><p>假定函數（Hypothesis）：<script type="math/tex">h_    heta(x)=    heta_0+    heta_1x</script><br>参数：$    heta_0{,}    heta_1$</p>
</li>
<li><p>损失函数（Cost Function）：<script type="math/tex">J(    heta_0,    heta_1) = rac{1}{2m} \sum_{i=1}^m (h_    heta(x^{(i)})-y^{(i)})^2</script><br>目标：$ argmin $ $ J(    heta_0,    heta_1) $ </p>
</li>
<li><p>多元梯度下降算法</p>
<ul>
<li>假设函数：<script type="math/tex">h_    heta(x)=    heta^Tx=     heta_0x_0+    heta_1x_1+    heta_2x_2 +...+    heta_0x_n</script></li>
<li>参数：<script type="math/tex">heta_0{,}    heta_1,...,    heta_n</script></li>
<li>代价函数：<script type="math/tex">J_(    heta)=J(    heta_0,    heta_1,...,    heta_n)=rac{1}{2m} \sum_{i=1}^m (h_    heta(x^{(i)})-y^{(i)})^2</script>，<br>一元时，$x_j^{(i)}=x_0^{(1)}=1$</li>
<li>梯度下降：Repeat { <script type="math/tex">heta_j :=    heta_j - lpha rac{\partial}{\partial    heta_j}J(    heta) =
lpha  rac{1}{m} \sum_{i=1}^m (h_    heta(x^{(i)})-y^{(i)})⋅x_j^{(i)}</script> } ，同步更新每个$j=0,…m$<br>$lpha$为学习率，定义了每次参数更新的幅度；</li>
</ul>
</li>
</ul>
<blockquote>
<p>Learning Rate:<br>If α is too small: slow convergence.<br>If α is too large: ￼may not decrease on every iteration and thus may not converge.</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习方法论</title>
    <url>/2017/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA/</url>
    <content><![CDATA[<p>机器学习中监督学习（分类/回归）/非监督学习（聚类/降维）的常算法</p>
<hr>
<a id="more"></a> 
<h2 id="机器学习方法论"><a href="#机器学习方法论" class="headerlink" title="机器学习方法论"></a>机器学习方法论</h2><p><img src="ML Algorithms.png" alt="ML Algorithms"></p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><ul>
<li>训练数据（Test Data）：用于模型构建</li>
<li>验证数据（Validation Data）：可选，用于辅助模型构建，可以重复使用。</li>
<li>测试数据（Test Data）：用于检测模型构建，此数据只在模型检验时使用，用于评估模型的准确率。绝对不允许用于模型构建过程，否则会导致过渡拟合。</li>
</ul>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><h3 id="Naive-Bayes（朴素贝叶斯）"><a href="#Naive-Bayes（朴素贝叶斯）" class="headerlink" title="Naive Bayes（朴素贝叶斯）"></a>Naive Bayes（朴素贝叶斯）</h3><h3 id="SVM（支持向量机）"><a href="#SVM（支持向量机）" class="headerlink" title="SVM（支持向量机）"></a>SVM（支持向量机）</h3><h3 id="Random-Forests（随机森林）"><a href="#Random-Forests（随机森林）" class="headerlink" title="Random Forests（随机森林）"></a>Random Forests（随机森林）</h3><h3 id="GBM"><a href="#GBM" class="headerlink" title="GBM"></a>GBM</h3><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><h3 id="Ridge"><a href="#Ridge" class="headerlink" title="Ridge"></a>Ridge</h3><h3 id="Lasso"><a href="#Lasso" class="headerlink" title="Lasso"></a>Lasso</h3><h3 id="SVR"><a href="#SVR" class="headerlink" title="SVR"></a>SVR</h3><h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><h2 id="聚类问题"><a href="#聚类问题" class="headerlink" title="聚类问题"></a>聚类问题</h2><h3 id="K最近邻法"><a href="#K最近邻法" class="headerlink" title="K最近邻法"></a>K最近邻法</h3><h2 id="降维问题"><a href="#降维问题" class="headerlink" title="降维问题"></a>降维问题</h2><h3 id="PCA（主成分分析）"><a href="#PCA（主成分分析）" class="headerlink" title="PCA（主成分分析）"></a>PCA（主成分分析）</h3><h3 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h3><h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><h2 id="ROC"><a href="#ROC" class="headerlink" title="ROC"></a>ROC</h2><p>ROC曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，<br>ROC曲线称为受试者工作特征曲线 （receiver operating characteristic curve，简称ROC曲线），又称为感受性曲线（sensitivity curve），</p>
<p>在计算ROC曲线之前，首先要了解一些基本概念。<br>在二元分类模型的预测结果有四种，以判断人是否有病为例：<br>真阳性（TP）：诊断为有，实际上也有病。<br>伪阳性（FP）：诊断为有，实际却没有病。<br>真阴性（TN）：诊断为没有，实际上也没有病。<br>伪阴性（FN）：诊断为没有，实际却有病。</p>
<p>ROC空间将伪阳性率（FPR）定义为X轴，真阳性率（TPR）定义为Y轴。<br>TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率，TPR=TPTP+FN 。<br>FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率，FPR=FPFP+TN。</p>
<h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><p>AUC（Area Under Curve）是ROC曲线下的面积。</p>
<h2 id="Precision"><a href="#Precision" class="headerlink" title="Precision"></a>Precision</h2><h2 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h2><h2 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h2><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="如何将数据集划分为测试数据集和训练数据集？"><a href="#如何将数据集划分为测试数据集和训练数据集？" class="headerlink" title="如何将数据集划分为测试数据集和训练数据集？"></a>如何将数据集划分为测试数据集和训练数据集？</h2><ol>
<li>像sklearn一样，提供一个将数据集切分成训练集和测试集的函数： 默认是把数据集的75%作为训练集，把数据集的25%作为测试集。</li>
<li><code>交叉验证</code>（一般取十折交叉验证：10-fold cross validation） k个子集，每个子集均做一次测试集，其余的作为训练集。 交叉验证重复k次，每次选择一个子集作为测试集，并将k次的平均交叉验证识别正确率作为结果。</li>
<li>训练数据，验证数据（注意区别交叉验证数据集），测试数据（在Coursera上提到） 一般做预测分析时，会将数据分为两大部分。一部分是训练数据，用于构建模型，一部分是测试数据，用于检验模型。<br>但是，有时候模型的构建过程中也需要检验模型，辅助模型构建，所以会将训练数据在分为两个部分：</li>
</ol>
<ul>
<li>训练数据；</li>
<li>验证数据（Validation Data）。验证数据用于负责模型的构建。典型的例子是用K-Fold Cross Validation裁剪决策树，求出最优叶节点数，防止过渡拟合（Overfitting）。<br>所以：</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/Nbwii7Di_h5Ewy5p5xzBdQ">机器学习问题有通法</a><br><a href="http://blog.csdn.net/quincuntial/article/details/69596456">ROC、AUC、Precision、Recall、F1</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>系统设计问题记录</title>
    <url>/2017/10/02/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>记录遇到的系统设计问题，如内部支撑系统、2B的数据服务系统以及通用的系统设计问题</p>
<a id="more"></a> 
<h1 id="系统设计问题记录"><a href="#系统设计问题记录" class="headerlink" title="系统设计问题记录"></a>系统设计问题记录</h1><h1 id="常规敏捷开发流程"><a href="#常规敏捷开发流程" class="headerlink" title="常规敏捷开发流程"></a>常规敏捷开发流程</h1><ol>
<li>产品Story需求确认，制定Epic里程碑</li>
<li>产品交互原型设计</li>
<li>后端API接口设计确认/后端数据模型设计</li>
<li>Story任务分解</li>
<li>前后端各自编码实现</li>
</ol>
<p>迭代上述过程</p>
<h1 id="衡量项目质量的指标"><a href="#衡量项目质量的指标" class="headerlink" title="衡量项目质量的指标"></a>衡量项目质量的指标</h1><ol>
<li><code>功能</code>：功能目标是应用的基本要求，如果不能实现既定的功能逻辑，应用就失去了存在的意义，因此<code>实现产品需求</code>是应用的基本的目标。</li>
<li><code>性能</code>：在基本的功能之上，会有一些性能的要求，但是很少有产品经理或者用户能提前提出这样的要求，因此架构师要有丰富的经验去发现和解决(或者<code>为未来提升性能做准备</code>)性能问题。<br>性能的主要衡量有：单次请求的相应时间，单实例请求并发数，服务最大并发量等。</li>
<li><code>扩展性</code>：目前互联网应用的开发模式：提出需求，快速响应，迭代开发，尽快上线</li>
</ol>
<h1 id="架构设计的主要过程"><a href="#架构设计的主要过程" class="headerlink" title="架构设计的主要过程"></a>架构设计的主要过程</h1><ol>
<li>确定问题域：根据需求定位关键问题，需根据性能和扩展性定义问题域；如何<code>平衡性能和扩展的关系</code>，是架构师设计的关键。扩展把握关键问题，优先满足关键问题的性能，确定<code>最小功能集</code>；确定最小功能集的优势可以快速实现，快速验证需求的准确性，每次需求开发都完成最小和最<code>关键的需求</code>。</li>
<li>数据建模：StarUML，ER</li>
<li>模块划分：单实例结构（应用&gt;DB）；集群结构；分布式结构（显示层&gt;服务n&gt;DB） ；混合结构；</li>
<li>关键流程描述：检查系统架构是否满足需求和指导开发的必要条件。使用<code>流程图</code>解决关键问题</li>
<li>技术选型</li>
<li>代码实现</li>
<li>验收测试</li>
</ol>
<h1 id="内部系统类"><a href="#内部系统类" class="headerlink" title="内部系统类"></a>内部系统类</h1><h2 id="B2B的支付机制"><a href="#B2B的支付机制" class="headerlink" title="B2B的支付机制"></a>B2B的支付机制</h2><ul>
<li>流程：记账-&gt;账单-&gt;扣款；</li>
<li>记账：业务系统异步写入操作记录；</li>
<li>账单：根据计费逻辑（折扣/套餐/阶梯）以存储过程生成账单；</li>
<li>扣款：运营月结/日结+法务催收；</li>
</ul>
<h2 id="系统耦合问题"><a href="#系统耦合问题" class="headerlink" title="系统耦合问题"></a>系统耦合问题</h2><p>问题：业务系统与基础设施系统（Boss）强耦合，Boss缓存问题影响业务系统鉴权；<br>方案：Boss数据库单点，缓存多点实时同步；业务系统读取本地缓存进行鉴权；</p>
<h1 id="数据服务类"><a href="#数据服务类" class="headerlink" title="数据服务类"></a>数据服务类</h1><h2 id="渠道分流控制工具-自动分流工具"><a href="#渠道分流控制工具-自动分流工具" class="headerlink" title="渠道分流控制工具/自动分流工具"></a>渠道分流控制工具/自动分流工具</h2><p>需求：渠道调用超时自动切换，渠道恢复正常自动切换；<br>分析：1个服务对应多个提供者，多个提供者可配置权重，要求多个提供者之间可根据超时时间down或者on<br>技巧：超时时间=接口平均调用时间*2</p>
<h2 id="保证主流程用户体验，减少故障点"><a href="#保证主流程用户体验，减少故障点" class="headerlink" title="保证主流程用户体验，减少故障点"></a>保证主流程用户体验，减少故障点</h2><p>梳理主流程，区分立即一致和最终一致，最终一致的业务逻辑可以消息中间件异步执行，以减少主流程阻塞时间；</p>
<blockquote>
<p>eg  在实名验证+人脸比对前，异步调用防骇客接口；在认证结束时，从缓存获取防骇客接口调用结果，若检测到活体攻击，进入人审；若无攻击，正常返回；</p>
</blockquote>
<h2 id="认证结果通知机制"><a href="#认证结果通知机制" class="headerlink" title="认证结果通知机制"></a>认证结果通知机制</h2><p>认证结果通知：SDK端同步返回和服务端异步返回，SDK同步返回时需支持敏感字段掩码（开关）；<br>实时性要求不高，提供异步通知接口；实时性要求高，提供认证结果查询接口；<br>1）异步通知双层设计：<br>第一层：实时通知，设置正常超时时间（3S）且不重试，不论通知成功与否，都写表记录通知结果标识；<br>第二层：扫描异步通知表，对未成功通知的记录进行重试通知（3次，重试时间递增）<br>2）异步通知：商户异步通知地址不能保证Https，数据需加密传输<br>3）认证结果查询接口：独立查询库</p>
<h1 id="通用问题"><a href="#通用问题" class="headerlink" title="通用问题"></a>通用问题</h1><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>调用外部服务异常时打印所有日志；<br>自定义异常，在最外围捕捉抛出</p>
<h2 id="网络超时问题"><a href="#网络超时问题" class="headerlink" title="网络超时问题"></a>网络超时问题</h2><p>从三个关键点排查</p>
<ol>
<li>对端：TCP握手问题</li>
<li>数据传输：</li>
<li>读取结果：readTimeout的实际含义<br>the read timeout is that it corresponds to the timeout on a socket read.<br>So it’s not the time allowed for the full response to arrive, but rather the time given to a single socket read.<br>So if there are 4 socket reads, each taking 9 seconds, your total read time is 9 * 4 = 36 seconds.<br><a href="http://stackoverflow.com/questions/9873810/using-apache-httpclient-how-to-set-the-timeout-on-a-request-and-response">http://stackoverflow.com/questions/9873810/using-apache-httpclient-how-to-set-the-timeout-on-a-request-and-response</a></li>
</ol>
<h2 id="HttpClient超时类型"><a href="#HttpClient超时类型" class="headerlink" title="HttpClient超时类型"></a>HttpClient超时类型</h2><ol>
<li>connectionRequestTimeout:从连接池中获取连接的超时时间，超过该时间未拿到可用连接，会抛出org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool</li>
<li>connectTimeout:连接上服务器(握手成功)的时间，超出该时间抛出connect timeout</li>
<li>socketTimeout:服务器返回数据(response)的时间，超过该时间抛出read timeout</li>
</ol>
<h2 id="线程池使用场景"><a href="#线程池使用场景" class="headerlink" title="线程池使用场景"></a>线程池使用场景</h2><ol>
<li>节省时间，多个线程并行处理后返回，如双重比对</li>
<li>异步任务，不影响主流程</li>
</ol>
<h2 id="输入提示服务"><a href="#输入提示服务" class="headerlink" title="输入提示服务"></a>输入提示服务</h2><p>高并发系统的设计，关键在合理的数据结构的设计，而不在架构的套用</p>
<h3 id="缓存-哈希"><a href="#缓存-哈希" class="headerlink" title="缓存+哈希"></a>缓存+哈希</h3><p>把搜索的搜索提示词存在redis集群中，每次来了请求直接redis集群中查找key，然后返回相应的value值就行了，完美解决，虽然耗费点内存，但是空间换时间嘛；</p>
<h3 id="trie树"><a href="#trie树" class="headerlink" title="trie树"></a>trie树</h3><p>这种搜索提示的功能一般用trie树来做，耗费的内存不多，查找速度为O(k)，其中k为字符串的长度，虽然看上去没有哈希表的O(1)好，但是少了网络开销，节约了很多内存，并且实际查找时间还要不比缓存+哈希慢多少，<br>一种合适当前场景的核心数据结构才是高并发系统的关键，缓存+哈希如果也看成一种数据结构，但这种数据结构并不适用于所有的高并发场景。</p>
<h2 id="LRU缓存"><a href="#LRU缓存" class="headerlink" title="LRU缓存"></a>LRU缓存</h2><p>LRU是Least Recently Used 近期最少使用算法；<br>硬盘上有N条数据，并且有一个程序包，提供GET和SET方法，可以操作磁盘读写数据，但是速度太慢，请设计一个内存中的数据结构，也提供GET和SET方法，保存最近访问的前100条数据，这个数据结构就是一个LRU了，让面试者实现出来，如果觉得写代码麻烦，可以把数据结构设计出来描述一下就行了，就这样，还很多人不会，这怎么能说是对缓存技术有深入了解呢？就这样，怎么能说有过大型高并发系统的经验呢？这只是开源工具的使用经验罢了。</p>
<h2 id="常用容错机制"><a href="#常用容错机制" class="headerlink" title="常用容错机制"></a>常用容错机制</h2><p>常见容错机制：failover ，failsafe，failfase ，failback，forking，来源于阿里的定义</p>
<ul>
<li>Failover 失败自动切换<br>当出现失败，重试其它服务器，通常用于读操作（推荐使用）。 重试会带来更长延迟。</li>
<li>Failfast  快速失败<br>只发起一次调用，失败立即报错,通常用于非幂等性的写操作。 如果有机器正在重启，可能会出现调用失败 。</li>
<li>Failsafe 失败安全<br>出现异常时，直接忽略，通常用于写入审计日志等操作。 调用信息丢失 可用于生产环境 Monitor。</li>
<li>Failback  失败自动恢复<br>后台记录失败请求，定时重发。通常用于消息通知操作 不可靠，重启丢失。 可用于生产环境 Registry。</li>
<li>Forking  并行调用多个服务器<br>只要一个成功即返回，通常用于实时性要求较高的读操作。 需要浪费更多服务资源   。</li>
<li>Broadcast<br>广播调用，所有提供逐个调用，任意一台报错则报错。通常用于更新提供方本地状态 速度慢，任意一台报错则报错 。</li>
</ul>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow笔记</title>
    <url>/2018/01/11/TensorFlow%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>整理TensorFlow学习笔记</p>
<hr>
<a id="more"></a>
<h1 id="TensorFlow-安装"><a href="#TensorFlow-安装" class="headerlink" title="TensorFlow 安装"></a>TensorFlow 安装</h1><p>pip install tensorflow -i <a href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a> —trusted-host mirrors.aliyun.com</p>
<h1 id="TensorFlow-API"><a href="#TensorFlow-API" class="headerlink" title="TensorFlow API"></a>TensorFlow API</h1><p>TensorFlow provides multiple APIs.</p>
<ul>
<li>The lowest level API—TensorFlow Core— provides you with complete programming control.<br>We recommend TensorFlow Core for machine learning researchers and others who require fine levels of control over their models.</li>
<li>The higher level APIs are built on top of TensorFlow Core. A high-level API like tf.estimator helps you manage data sets, estimators, training and inference.</li>
</ul>
<h1 id="TensorBoard"><a href="#TensorBoard" class="headerlink" title="TensorBoard"></a>TensorBoard</h1><ul>
<li>SCALARS：记录单一变量的，使用 tf.summary.scalar() 收集构建。</li>
<li>IMAGES：收集的图片数据，当我们使用的数据为图片时（选用）。</li>
<li>AUDIO：收集的音频数据，当我们使用数据为音频时（选用）。</li>
<li>GRAPHS：构件图，效果图类似流程图一样，我们可以看到数据的流向，使用 tf.name_scope() 收集构建。</li>
<li>DISTRIBUTIONS：用于查看变量的分布值，比如 W（Weights）变化的过程中，主要是在 0.5 附近徘徊。</li>
<li>HISTOGRAMS：用于记录变量的历史值（比如 weights 值，平均值等），并使用折线图的方式展现，使用 tf.summary.histogram() 进行收集构建。</li>
</ul>
<h1 id="TensorFlow概念"><a href="#TensorFlow概念" class="headerlink" title="TensorFlow概念"></a>TensorFlow概念</h1><ul>
<li>batchsize：批大小。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练；</li>
<li>iteration：1个iteration等于使用batchsize个样本训练一次；</li>
<li>epoch：1个epoch等于使用训练集中的全部样本训练一次；<blockquote>
<p>eg：训练集有1000个样本，batchsize=10，那么训练完整个样本集需要100次iteration，1次epoch。</p>
</blockquote>
</li>
</ul>
<h1 id="Cross-Entropy（差熵损失函数）"><a href="#Cross-Entropy（差熵损失函数）" class="headerlink" title="Cross Entropy（差熵损失函数）"></a>Cross Entropy（差熵损失函数）</h1><ul>
<li><a href="http://m.blog.csdn.net/qian99/article/details/78046329">softmax交差熵损失函数推导</a></li>
<li><a href="http://colah.github.io/posts/2015-09-Visual-Information/">信息论概念可视化</a></li>
<li><a href="https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/information-entropy">信息熵</a></li>
<li><a href="http://randolph.pro/2017/09/25/ãTensorFlowãCross Entropy Function in TensorFlow /">TensorFlow中的交差熵</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Backprop/">反向传播算法</a></li>
</ul>
<h1 id="Perplexity（困惑度）"><a href="#Perplexity（困惑度）" class="headerlink" title="Perplexity（困惑度）"></a>Perplexity（困惑度）</h1><p>信息论中，困惑度是一种评判概率模型或概率分布预测的衡量指标，可用于评价模型好坏。<br>可分为三种：</p>
<pre><code>1. Perplexity of a probability distribution
2. Perplexity of a probability model
3. Perplexity per word
</code></pre><h1 id="Activation-激活函数"><a href="#Activation-激活函数" class="headerlink" title="Activation 激活函数"></a>Activation 激活函数</h1><p>激活函数其中一个重要的作用是加入非线性因素的，解决线性模型所不能解决的问题。</p>
<blockquote>
<p>在激活函数运算后，能够起到特征组合的作用。</p>
</blockquote>
<h2 id="激活函数通常有如下一些性质："><a href="#激活函数通常有如下一些性质：" class="headerlink" title="激活函数通常有如下一些性质："></a>激活函数通常有如下一些性质：</h2><ul>
<li>非线性： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。</li>
<li>可微性： 当优化方法是基于梯度的时候，这个性质是必须的。</li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。</li>
<li>f(x)≈x： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。</li>
<li>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate.</li>
</ul>
<p>这些性质，也正是我们使用激活函数的原因。</p>
<h2 id="激活函数比较"><a href="#激活函数比较" class="headerlink" title="激活函数比较"></a>激活函数比较</h2><p><img src="CNN卷积神经网络/激活函数比较.png" alt="激活函数比较"></p>
<ul>
<li>sigmoid 缺点<ul>
<li>两头过于平坦</li>
<li>输出值域不对称（非0均值）</li>
</ul>
</li>
<li>tanh 缺点:<ul>
<li>两头依旧过于平坦</li>
</ul>
</li>
<li>ReLU优缺点:<ul>
<li>收敛速度比 sigmoid/tanh 更快</li>
<li>计算高效简单</li>
<li>Dead Area 中权重不更新(leaky ReLU 不存在 dead area)</li>
</ul>
</li>
</ul>
<p>一般现在都直接取 ReLU，然而如果使用 ReLU，一定要小心设置 learning rate，要注意不要让你的网络出现很多 “dead” 神经元，<br>如果这个问题不好解决，那么可以试试 Leaky ReLU、PReLU、random ReLU 或者 Maxout。<br>另外，现在主流的做法，会多做一步batch normalization，尽可能保证每一层网络的输入具有相同的分布，见Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift。</p>
<h1 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h1><p>wiki百科对softmax函数的定义：</p>
<blockquote>
<p>softmax is a generalization of <code>logistic function</code> that “squashes”(maps) a K-dimensional vector z of arbitrary real values to a K-dimensional vector σ(z) of real values in the range (0, 1) that add up to 1.</p>
</blockquote>
<p>这句话既表明了softmax函数与logistic函数的关系，也同时阐述了softmax函数的本质就是将一个K维的任意实数向量压缩（映射）成另一个K维的实数向量，其中向量中的每个元素取值都介于（0，1）之间。</p>
<script type="math/tex; mode=display">egin{equation*} h(z) = rac{e^{z_j}}{\sum_{k=1}^K e^{z_k}}, j = 1, 2, ..., K \end{equation*}</script><p>它在多元分类（Multiclass Classification）和神经网络中也有很多应用。<br>Softmax 不用于普通的”max”函数，”max”函数只输出最大的那个值，而 Softmax 则确保较小的值也有较小的概率，不会被直接舍弃掉，是一个比较“Soft”的“max”。<br>　<br>更形象的如下图表示：<br><img src="softmax layer.png" alt="softmax layer"><br>softmax直白来说就是将原来输出是3,1,-3通过softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标！</p>
<blockquote>
<p>softmax 可以理解为归一化，<br>如目前图片分类有100种，那经过 softmax 层的输出就是一个100维的向量。<br>向量中的第1个值就是当前图片属于第1类的概率值，向量中的第2个值就是当前图片属于第2类的概率值…这100维的向量之和为1.</p>
</blockquote>
<p>softmax的输入层和输出层的维度是一样的，如果不一样，就在输入至 softmax 层之前通过一层全连接层。</p>
<h1 id="Dropout层"><a href="#Dropout层" class="headerlink" title="Dropout层"></a>Dropout层</h1><p>为输入数据施加Dropout。Dropout将在训练过程中每次更新参数时随机断开一定百分比（p）的输入神经元连接，<br>Dropout层用于防止过拟合。</p>
<h1 id="Flatten层"><a href="#Flatten层" class="headerlink" title="Flatten层"></a>Flatten层</h1><p>Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。</p>
<h1 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h1><p>输出全连接层神经元的数量</p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="GPU资源分配"><a href="#GPU资源分配" class="headerlink" title="GPU资源分配"></a>GPU资源分配</h2><p><a href="https://www.cnblogs.com/darkknightzh/p/6591923.html">enter link description here</a></p>
<h1 id="深度学习参考资料"><a href="#深度学习参考资料" class="headerlink" title="深度学习参考资料"></a>深度学习参考资料</h1><ul>
<li><a href="https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results">图片分类数据集-算法</a></li>
<li><a href="http://randolph.pro/2017/03/17/ãTensorFlowãUse WeChat to Monitor Your Network/">微信监控训练网络</a></li>
<li><a href="http://randolph.pro/categories/TensorFlow/">Tensorflow博客-randolph</a></li>
<li><a href="https://www.jianshu.com/p/95c79381ab4f">CNN详解</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbiMQ之AMQP协议</title>
    <url>/2019/11/06/RabbiMQ%E4%B9%8BAMQP%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>rabbitmq是基于amqp协议的一种实现，包含<code>amqp的三层协议</code></p>
<a id="more"></a> 
<p>//todo</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.xuejiayuan.net/blog/60a9cc9f53e6420fa4c48c99e8178cd2">ActiveMQ系列—消息协议（AMQP协议）</a> </li>
<li><a href="http://www.amqp.org/resources/download">amqp官方文档</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ延迟队列</title>
    <url>/2019/11/10/RabbitMQ%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<p>如何通过RabbitMQ的<code>延迟/死信队列</code>实现消息投递系统中的<code>异常重试机制</code>？<br><a id="more"></a> </p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>给用户发送消息时，如果出现目标方不可达（非200状态码）或发送时网络超时，需要重新投递n次，每次投递的重试间隔可定制；</p>
<h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><p>可以通过RabbitMQ的死信队列dlx（dead letter exchange）和ttl（time to live）机制实现延迟队列；<br><img src="rabbitmq_延迟队列.png" alt="rabbit延时队列"></p>
<h2 id="Dead-Letter-Exchanges"><a href="#Dead-Letter-Exchanges" class="headerlink" title="Dead Letter Exchanges"></a>Dead Letter Exchanges</h2><p>消息在队列满足达到一定的条件，会被认为是死信消息（dead-lettered），<br>这时候，RabbitMQ会重新把这类消息发到另外一个的<code>exchange</code>，这个exchange称为<code>Dead Letter Exchanges</code>.</p>
<p>以下任一条件满足，即可认为是死信：</p>
<ul>
<li><code>rejected</code>：消息被customer拒绝消费(basic.reject or basic.nack)并且设置了requeue=fasle（不重新入队列）；</li>
<li><code>expired</code>：消息的TTL(per-message ttl)到了（消息过期）；</li>
<li><code>maxlen</code>：达到了队列的长度限制(max-length-bytes)；</li>
</ul>
<blockquote>
<p>注意</p>
<ol>
<li>Dead letter exchanges (DLXs) 其实就是普通的exchange，可以和正常的exchange一样的声明或者使用。</li>
<li>如果dlx设置的exchange为当前exchange，这样的循环路由情况下，这条私信会被丢弃；</li>
<li>死信的路由是采用rabbitmq的消息确认机制实现（Publisher Confirms），如果在死信路由后但是未收到路由队列的消息回执时rabbitmq宕机，重启后会出现<code>消息重复</code>(同一条消息出现在2个队列)，消息会重新路由到死信队列，那么这时死信队列的消费者需要做好<code>幂等消费</code>处理；</li>
</ol>
</blockquote>
<h2 id="dlx的路由设置"><a href="#dlx的路由设置" class="headerlink" title="dlx的路由设置"></a>dlx的路由设置</h2><p>队列中可以设置两个属性：</p>
<ul>
<li>x-dead-letter-exchange</li>
<li>x-dead-letter-routing-key</li>
</ul>
<p>当这个队列里面的消息成为死信之后，就会投递到<code>x-dead-letter-exchange</code>指定的exchange中，其中带着的routing key就是中指定的值<code>x-dead-letter-routing-key</code>。</p>
<blockquote>
<p>异常情况<br>死信的路由是采用rabbitmq的消息确认机制实现（Publisher Confirms），死信路由后但是未收到路由队列的消息回执，在此时若rabbitmq发生宕机，rabbitmq重启后会出现<code>消息重复</code>(同一条消息出现在2个队列)，消息会重新路由到死信队列，那么这时死信队列的消费者需要做好<code>幂等消费</code>处理；</p>
</blockquote>
<h2 id="Time-To-Live（TTL）"><a href="#Time-To-Live（TTL）" class="headerlink" title="Time-To-Live（TTL）"></a>Time-To-Live（TTL）</h2><p>RabbitMQ针对TTL有三种场景：</p>
<ol>
<li>Per-Queue Message TTL：队列中每条消息都拥有相同的过期时间<ul>
<li>队列属性： <code>x-message-ttl</code></li>
</ul>
</li>
<li>Per-Message TTL：每个消息有不同的过期时间;<ul>
<li>消息属性：<code>expiration</code>，毫秒单位，设置为字符串</li>
</ul>
</li>
<li>Queue TTL：队列过期<ul>
<li>队列属性：<code>x-expires</code></li>
<li>队列以下情况会标记为过期：没有consumer，没有被重新declare，没有basic.get调用</li>
</ul>
</li>
</ol>
<blockquote>
<p>注意 </p>
<ol>
<li>当同时指定了queue和message的TTL，则两者中较小的那个才会起作用;</li>
</ol>
</blockquote>
<h2 id="RabbitMQ的ttl问题"><a href="#RabbitMQ的ttl问题" class="headerlink" title="RabbitMQ的ttl问题"></a>RabbitMQ的ttl问题</h2><blockquote>
<p>Queues that had a per-message TTL applied to them retroactively (when they already had messages) will discard the messages when specific events occur.<br>Only when expired messages <code>reach the head of a queue</code> will they actually be discarded (or dead-lettered) Consumers will not have expired messages delivered to them.<br>Keep in mind that there can be a natural <code>race condition</code> between <code>message expiration</code> and <code>consumer delivery</code>, e.g. a message can expire after it was written to the socket but before it has reached a consumer.  </p>
</blockquote>
<ul>
<li><code>Per-Queue Message TTL</code>设置队列TTL属性的方法，一旦消息过期，就会从队列中抹去， </li>
<li><code>Per-Message TTL</code>设置消息TTL属性的方法，即使消息过期，也不会马上从队列中抹去，因为每条消息是否过期是消息到达队列head，在即将投递时判定；</li>
</ul>
<h3 id="为什么Per-Message-TTL不能按设置的ttl进行投递"><a href="#为什么Per-Message-TTL不能按设置的ttl进行投递" class="headerlink" title="为什么Per-Message TTL不能按设置的ttl进行投递"></a>为什么<code>Per-Message TTL</code>不能按设置的ttl进行投递</h3><ol>
<li>按照队列的<code>FIFO原则</code>,<code>Per-Queue Message TTL</code>方法设置ttl，队列中先过期的消息肯定在队列head，RabbitMQ只要定期从队头开始扫描是否有过期消息即可，</li>
<li><code>Per-Message TTL</code>方法设置ttl，每条消息的过期时间不同，如果要准确的删除所有过期消息，势必要每次扫描整个队列，扫描时间可能比过期时间都长，所以只能折衷考虑在等到此<code>消息即将被消费时再判定是否过期</code>，如果过期，再进行删除。</li>
</ol>
<h2 id="采用RabbitMQ实现延迟队列的坑"><a href="#采用RabbitMQ实现延迟队列的坑" class="headerlink" title="采用RabbitMQ实现延迟队列的坑"></a>采用RabbitMQ实现延迟队列的坑</h2><p>由于rabbitmq的死信队列本身也是普通队列，其过期的顺序是按照队列头部顺序的过期的。<br>也就是说，如果消息A设置过期时间是10s，消息B的设置过期时间1s，那么后面的必须要等消息B过期了才会触发A过期，也就是说都要等10s，<br>这怎么搞，完全不能满足需求啊…</p>
<h3 id="解决方案-多级延迟队列"><a href="#解决方案-多级延迟队列" class="headerlink" title="解决方案-多级延迟队列"></a>解决方案-多级延迟队列</h3><ul>
<li>对于一个队列中每个消息有不同的延迟时间的，可以考虑设置<code>多级延迟队列</code>（Per-Queue Message TTL）。</li>
<li>例如按秒，分，时3个级别，各个级别设置几个队列，并使得延迟相近的尽量放到同一个队列中，尽量减少队列拥堵情况；  </li>
<li>如，<code>30s，1m，5m，30m，1h，3h，6h，12h，24h</code>；预置多个超时区间，<blockquote>
<ul>
<li>如果设置的过期时间不在预设队列，比如expire=15m，15在[5,30]区间内，因为放在比其小的会阻塞该队列的其他消息触发过期，所以必须取过期时间较大的队列进行投递，即将expire=15的投递到30m队列；</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="解决方案-多级延迟队列-延时队列（X）"><a href="#解决方案-多级延迟队列-延时队列（X）" class="headerlink" title="解决方案-多级延迟队列+延时队列（X）"></a>解决方案-多级延迟队列+延时队列（X）</h3><ul>
<li><p>上述的多级延时队列并结合<code>priority queue</code>实现；<br>如设置30m队列的最大优先级为1，在expire=15m时，由于15在[5,30]区间内，区间内默认优先级都为0,投递进来的确保是比队列ttl时间短的，这时设置(5,30)之间的优先级为1，那么能保证时间在30m之前的过期时间的消息能不被等于30m的阻塞；  </p>
</li>
<li><p>那么问题来了，如果投递到ttl=30队列中的消息大多是<code>priority=1</code>的怎么搞？<br>由于rabbitmq会优先处理priority大的消息，那么会导致<code>priority=</code>0但是expire时间已到的消息<code>被阻塞</code>没法消费；</p>
</li>
</ul>
<blockquote>
<p>Messages which should expire will still only expire from the<code>head</code> of the queue.<br>This means that unlike with normal queues, even <code>per-queue TTL</code> can lead to <code>expired lower-priority</code> messages getting stuck behind <code>non-expired higher priority ones</code>. These messages will never be delivered, but they will appear in queue statistics.<br>注意：priority优先级最大值为255，建议值是[1,10]范围内；</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><code>ttl</code>和<code>priority</code>是确定消息何时被消费的两个维度,ttl用于消息重试场景，priority用于类绿色通道场景；</li>
<li>在队列中消息堆积的情况下，ttl时间已到的消息会被<code>阻塞</code>，导致不能被即时消费；</li>
<li>如果一个队列中出现个别消息的<code>ttl和priority值同时很大</code>，而其他消息的ttl较小，这样会导致后面push的消息被队列头部这种ttl(皮厚)+心黑(priority)的个别消息搞爆掉! 这种消息得用1个单独的队列来特殊对待…</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.rabbitmq.com/dlx.html">rabbitmq-Dead Letter Exchanges</a></li>
<li><a href="https://www.rabbitmq.com/ttl.html">rabbitmq-Time To Live</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>如何模拟消息队列来并行处理任务</title>
    <url>/2019/12/12/%E5%A6%82%E4%BD%95%E6%A8%A1%E6%8B%9F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9D%A5%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<p>在某些场景，没有资源独立部署消息队列集群，但是有异步任务又需要快速处理完成，这时候就需要并行计算来解决了，</p>
<p>参考MQ的生产者消费者工作模式，将任务<code>生产者</code>与<code>消费者</code>通过<code>队列</code>的实现解耦；</p>
<p>1个生产者生成一批任务后，阻塞等待多个消费者并行执行完成，然后释放消费者线程和生产者线程；</p>
<a id="more"></a> 
<h1 id="broker-中间层"><a href="#broker-中间层" class="headerlink" title="broker-中间层"></a>broker-中间层</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ArrayBlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消息队列中间件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Broker</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> ArrayBlockingQueue&lt;JSONObject&gt; queue = <span class="keyword">new</span> ArrayBlockingQueue&lt;JSONObject&gt;(<span class="number">1000</span>);</span><br><span class="line">    <span class="keyword">public</span> Boolean continueProducing = Boolean.TRUE;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(JSONObject data)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.queue.put(data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> JSONObject <span class="title">get</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.queue.poll(<span class="number">1</span>, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="IProducer-生产者接口"><a href="#IProducer-生产者接口" class="headerlink" title="IProducer-生产者接口"></a>IProducer-生产者接口</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生产者</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wanggang</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/07/29</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 向队列提交1条消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 消息体</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">produceMessage</span><span class="params">(JSONObject message)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>生产者抽象类，<br>具体生产者继承后可不断produceMessage，<br>如：定时扫描数据库的待办任务并放入任务队列，或逐行读取1个csv后放入队列；</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">implements</span> <span class="title">IProducer</span>, <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(Producer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> Broker broker;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bindBroker</span><span class="params">(Broker broker)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.broker = broker;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">produceMessage</span><span class="params">(JSONObject message)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            broker.put(message);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            logger.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 将broker标记为不再生产新的消息，是用于终止消费者的信号</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">terminateProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.broker.continueProducing = Boolean.FALSE;</span><br><span class="line">        logger.info(<span class="string">"Producer[%s] terminating."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="IConsumer-消费者接口"><a href="#IConsumer-消费者接口" class="headerlink" title="IConsumer-消费者接口"></a>IConsumer-消费者接口</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 队列收到消息时调用本方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 消息体</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onConsumerMessage</span><span class="params">(JSONObject message)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>消费者抽象类，具体消费者通过继承Consumer，必须实现onConsumerMessage方法，可选择实现before和after方法；</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">implements</span> <span class="title">IConsumer</span>, <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(Consumer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> Broker broker;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> elapse = <span class="number">30</span> * <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bindBroker</span><span class="params">(Broker broker)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.broker = broker;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            JSONObject message = broker.get();</span><br><span class="line">            <span class="keyword">while</span> (broker.continueProducing) &#123;</span><br><span class="line">                <span class="keyword">if</span> (message == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        doBeforeConsumerMessage(message);</span><br><span class="line">                        onConsumerMessage(message);</span><br><span class="line">                        doAfterConsumerMessage(message, <span class="keyword">null</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                        logger.error(String.format(<span class="string">"messagge[%s]"</span>, message), e);</span><br><span class="line">                        doAfterConsumerMessage(message, e);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (System.currentTimeMillis() - start &gt; elapse) &#123;</span><br><span class="line">                        logger.warn(String.format(<span class="string">"处理超时,elapse[%s],msg[%s]"</span>, System.currentTimeMillis() - start, message.toString()));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                message = broker.get();</span><br><span class="line">            &#125;</span><br><span class="line">            logger.info(String.format(<span class="string">"Consumer[%s]已完成任务,terminating."</span>, Thread.currentThread().getName()));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            logger.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 消息前处理</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msg  消息体</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">doBeforeConsumerMessage</span><span class="params">(JSONObject msg)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 消息后处理</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msg 消息体</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> error 处理异常信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">doAfterConsumerMessage</span><span class="params">(JSONObject msg, Throwable error)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="消息队列使用辅助类"><a href="#消息队列使用辅助类" class="headerlink" title="消息队列使用辅助类"></a>消息队列使用辅助类</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * message queue service 消息队列中间件工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MqsClientHelper</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(MqsClientHelper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Producer producer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Consumer consumer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String consumerName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> consumerThreads;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MqsClientHelper</span><span class="params">(Producer producer, Consumer consumer, String consumerName, <span class="keyword">int</span> consumerThreads)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.producer = producer;</span><br><span class="line">        <span class="keyword">this</span>.consumer = consumer;</span><br><span class="line">        <span class="keyword">this</span>.consumerThreads = consumerThreads;</span><br><span class="line">        <span class="keyword">this</span>.consumerName = consumerName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">//线程池并行处理</span></span><br><span class="line">                ThreadFactory namedThreadFactory = <span class="keyword">new</span> ThreadFactoryBuilder().setNameFormat(consumerName + <span class="string">"-%d"</span>).build();</span><br><span class="line">                ThreadPoolExecutor threadPool = <span class="keyword">new</span> ThreadPoolExecutor(consumerThreads + <span class="number">1</span>, consumerThreads + <span class="number">1</span>,</span><br><span class="line">                        <span class="number">10</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(), namedThreadFactory, <span class="keyword">new</span> ThreadPoolExecutor.AbortPolicy());</span><br><span class="line">                <span class="comment">//生产者/消费者绑定队列</span></span><br><span class="line">                <span class="keyword">final</span> Broker broker = <span class="keyword">new</span> Broker();</span><br><span class="line">                producer.bindBroker(broker);</span><br><span class="line">                consumer.bindBroker(broker);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//消费者定义</span></span><br><span class="line">                IntStream.range(<span class="number">0</span>, consumerThreads).forEach(e -&gt; threadPool.execute(consumer));</span><br><span class="line">                <span class="comment">//生产者：生成message并提交给broker，consumer从broker中获取消息</span></span><br><span class="line">                Future producerStatus = threadPool.submit(producer);</span><br><span class="line"></span><br><span class="line">                logger.debug(String.format(<span class="string">"consumer[%s],等待数据导入消费者处理完成..."</span>, consumerThreads));</span><br><span class="line">                producerStatus.get();</span><br><span class="line"></span><br><span class="line">                producer.terminateProducer();</span><br><span class="line">                logger.info(<span class="string">"Producer[%s]已完成任务,terminating."</span>);</span><br><span class="line"></span><br><span class="line">                threadPool.shutdown();</span><br><span class="line">                <span class="keyword">while</span> (!threadPool.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES)) &#123;</span><br><span class="line">                    logger.info(String.format(<span class="string">"threadPool[%s],等待消费者处理完成[10m]..."</span>, threadPool));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                logger.error(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>如何用UML进行系统设计</title>
    <url>/2019/12/07/%E5%A6%82%E4%BD%95%E7%94%A8UML%E8%BF%9B%E8%A1%8C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<p>UML有3类模型，5类图形，是系统设计的有力建模工具，可在项目的<code>需求分析&gt;功能设计&gt;架构设计&gt;详细设计&gt;数据模型设计</code>等阶段进行<code>迭代更新</code>；<br>帮助团队成员从宏观到细节整体认识产品，有利于知识共享，便于团队协作并建立共识。</p>
<a id="more"></a> 
<h1 id="如何用UML进行系统设计"><a href="#如何用UML进行系统设计" class="headerlink" title="如何用UML进行系统设计"></a>如何用UML进行系统设计</h1><h2 id="UML"><a href="#UML" class="headerlink" title="UML"></a>UML</h2><p>UML(<code>Unified Model Language</code>)，统一建模语言，又称标准建模语言。是用来对软件密集系统进行可视化建模的一种语言。 </p>
<h3 id="3个主要的UML模型"><a href="#3个主要的UML模型" class="headerlink" title="3个主要的UML模型"></a>3个主要的UML模型</h3><ol>
<li><code>功能模型</code>: 从用户的角度展示系统的功能，包括<code>用例图</code>。 </li>
<li><code>对象模型</code>: 采用对象，属性，操作，关联等概念展示系统的基础结构，包括<code>类图、对象图、包图</code>。 </li>
<li><code>动态模型</code>: 展现系统的内部行为。 包括<code>时序图，活动图，状态图</code>。</li>
</ol>
<h3 id="5类UML图"><a href="#5类UML图" class="headerlink" title="5类UML图"></a>5类UML图</h3><p>UML可分为<code>用例图，静态图，行为图，交互图，实现图</code>5类</p>
<ol>
<li>用例图：从用户角度描述系统功能，并指各功能的操作者。</li>
<li>静态图：包括类图，包图，对象图。<ul>
<li>类图（Class Diagram）：描述系统中类的静态结构</li>
<li>包图（Package Diagram）：是包和类组成的，表示包与包之间的关系，包图描述系统的<code>分层结构</code></li>
<li>对象图（Object Diagram）：是类图的实例</li>
</ul>
</li>
<li>行为图：描述系统<code>动态模型</code>和<code>对象组成</code>的交换关系。包括状态图和活动图<ul>
<li>活动图（Activity Diagram）：描述了业务实现用例的工作流程，业务流程建模时梳理业务场景对应的业务逻辑</li>
<li>状态图（State Diagram）：是描述状态到状态控制流，常用于动态特性建模</li>
</ul>
</li>
<li>交互图：描述对象之间的<code>交互关系</code><ul>
<li>时序图（Sequence Diagram）：对象之间的动态合作关系，强调对象发送消息的顺序，同时显示对象之间的交互</li>
<li>通信图（Communication Diagram）：描述对象之间的消息流和协作关系</li>
</ul>
</li>
<li>实现图：<ul>
<li>部署图（Deploy Diagram）：定义系统中软硬件的物理体系结构</li>
<li>组件图（Composite Structure Diagram）：定义组件间的依赖关系</li>
</ul>
</li>
</ol>
<h3 id="其他UML图"><a href="#其他UML图" class="headerlink" title="其他UML图"></a>其他UML图</h3><ul>
<li>Profile Diagram：提供自定义stereotypes,tagged values,constrains来描述轻量级扩展机制的结构图，Profiles允许适应不同的UML元模型，如Java EE，.Net Framework，领域流程建模，面向服务的体系结构等等。 </li>
</ul>
<h3 id="UML组件参数"><a href="#UML组件参数" class="headerlink" title="UML组件参数"></a>UML组件参数</h3><h4 id="Interaction-Frames-Combined-Fragment"><a href="#Interaction-Frames-Combined-Fragment" class="headerlink" title="Interaction Frames (Combined Fragment)"></a>Interaction Frames (Combined Fragment)</h4><div class="table-container">
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>alt</td>
<td>Divides fragment into groups and defines condition for each group -  only the one whose condition is true will execute .</td>
</tr>
<tr>
<td>opt</td>
<td>Defines condition to a single call - the call will execute only if the supplied condition is true . Equivalent to an alt with only one trace.</td>
</tr>
<tr>
<td>par</td>
<td>Defines that the calls within the fragment run in parallel.</td>
</tr>
<tr>
<td>loop</td>
<td>Defines that the calls within the fragment run in a loop.</td>
</tr>
<tr>
<td>region</td>
<td>Defines that the calls within the fragment reside in a critical section, i.e. the fragment can have only one thread executing it at once.</td>
</tr>
</tbody>
</table>
</div>
<h2 id="StarUML流程图列表"><a href="#StarUML流程图列表" class="headerlink" title="StarUML流程图列表"></a>StarUML流程图列表</h2><p><img src="StarUML流程图列表.png" alt="StarUML流程图列表"></p>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>产品经理需根据用户故事梳理<code>Use Case Diagram</code>，系统&gt;功能模块；</p>
<h2 id="原型设计"><a href="#原型设计" class="headerlink" title="原型设计"></a>原型设计</h2><p>产品经理需根据需求文档，同步设计产品原型（<code>axure</code>），并根据需求确定不同保真层级，一般中保真即可；</p>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><p>架构师可根据需求文档，以<code>Package Diagram</code>设计模块间的关系，做模块分层设计；</p>
<blockquote>
<p>eg 基础设施(支撑层)&gt;计算框架&gt;模型与算法&gt;业务应用层</p>
</blockquote>
<h2 id="部署结构"><a href="#部署结构" class="headerlink" title="部署结构"></a>部署结构</h2><p>以始为终，同步设计最终交付时的线上部署方案，完成<code>Deployment Diagram</code>；</p>
<blockquote>
<p>eg 其中部署图包含负载均衡、应用层服务器、RPC服务器、MySQL数据库集群、Hive集群、Spark计算集群、ETCD配置应用服务集群、</p>
</blockquote>
<h2 id="接口文档"><a href="#接口文档" class="headerlink" title="接口文档"></a>接口文档</h2><p>同步根据<code>用例图</code>和<code>原型</code>设计为实现功能所需的API接口文档，确定每个功能模块的输入输出；</p>
<blockquote>
<p>可用如<code>APIDoc</code>这类工具编码编写API接口然后生成Html，接口代码后续可导入到<code>StarUML</code>中作为<code>Class Diagram</code>的一部分；</p>
</blockquote>
<h2 id="组件关系设计"><a href="#组件关系设计" class="headerlink" title="组件关系设计"></a>组件关系设计</h2><p>通过梳理接口文档，此时已对系统实现所需的基础技术支撑和应用组件都有所把握，此时可将思路整理为,<code>Composite Structure Diagram</code>，</p>
<blockquote>
<p>eg  前端-[接口]-&gt;后端-[接口]-&gt;RPC服务-[jdbc]-&gt;数据库</p>
</blockquote>
<h2 id="详细设计"><a href="#详细设计" class="headerlink" title="详细设计"></a>详细设计</h2><p>在完成产品原型设计，和系统总体架构设计后，此时可进行实现细节设计，<br>后端可根据需求/接口文档以<code>Package Diagram</code>,<code>Class Diagram</code>形式完善细节，并完成2类时序图<code>Sequence Diagram</code>：</p>
<ol>
<li>前后端交互时序图（设计原型时同步完成）；</li>
<li>具体功能对应的后端逻辑时序图（class调用）</li>
</ol>
<p>如果系统中涉及的对象非常复杂或要求精密，如汽车类工业设计，此时需提供每个组件对象的<code>Object Diagram</code>；</p>
<ol>
<li>如果系统存在复杂且要求精确的业务状态变更，如支付状态，需提供<code>StateChart Diagram</code>；</li>
<li>根据需要绘制数据流向图<code>FlowChart Diagram</code>，如涉及多源数据聚合，整合的ETL系统；</li>
</ol>
<h2 id="数据模型设计"><a href="#数据模型设计" class="headerlink" title="数据模型设计"></a>数据模型设计</h2><p>根据功能需求，设计数据模型：表结构/表关系，完成<code>ER Diagram</code>；</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.uml.org.cn/oobject/201211231.asp">类图</a><br><a href="http://www.cnblogs.com/Yogurshine/archive/2013/01/14/2859248.html">UML系列图—用例图</a></p>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title>如何设计一个好的数据处理工具</title>
    <url>/2019/12/03/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="好的工具应具备的特性"><a href="#好的工具应具备的特性" class="headerlink" title="好的工具应具备的特性"></a>好的工具应具备的特性</h1><ul>
<li>可配置：参数外部化</li>
<li>可中断：checkpoint打点</li>
<li>可容错：errorlist打点</li>
<li>高性能：可并行计算</li>
<li>易用性：使用简单，一键运行</li>
</ul>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>ETL</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次Locust分布式压测实践</title>
    <url>/2019/12/21/%E8%AE%B0%E4%B8%80%E6%AC%A1Locust%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%8B%E6%B5%8B%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>记录性能测试的相关知识与实践：测试指标，测试工具，性能调优点<br><a id="more"></a></p>
<h1 id="关于性能测试"><a href="#关于性能测试" class="headerlink" title="关于性能测试"></a>关于性能测试</h1><blockquote>
<p>性能测试是通过自动化的测试工具模拟多种<code>正常</code>、<code>峰值</code>以及<code>异常</code>负载条件来对系统的各项性能指标进行测试。<br>负载测试和压力测试都属于性能测试，两者可以结合进行。</p>
</blockquote>
<ul>
<li>通过<code>负载测试</code>，确定在各种工作负载下系统的性能，目标是测试当<code>负载逐渐增加</code>时，系统各项性能指标的变化情况。  </li>
<li><code>压力测试</code>是通过确定一个系统的<code>瓶颈</code>或者不能接受的<code>性能点</code>，来获得系统能提供的<code>最大服务级别</code>的测试。 </li>
</ul>
<h1 id="测试指标"><a href="#测试指标" class="headerlink" title="测试指标"></a>测试指标</h1><p>主要是从以下三个维度来衡量</p>
<ol>
<li>响应时间：从用户角度<ul>
<li>Average (ms)：服务平均响应时长</li>
<li>Min (ms)：服务最小响应时长</li>
<li>Max(ms)：服务最大响应时长</li>
</ul>
</li>
<li>服务器资源：从系统角度<ul>
<li>内存使用率：内存泄漏，内存溢出</li>
<li>CPU负载</li>
<li>磁盘IO</li>
<li>网络IO</li>
</ul>
</li>
<li>吞吐量：从业务角度<ul>
<li>Request：总请求数</li>
<li>RPS（并发数/平均响应时间）：服务每秒处理请求数</li>
</ul>
</li>
</ol>
<h1 id="测试准备工作"><a href="#测试准备工作" class="headerlink" title="测试准备工作"></a>测试准备工作</h1><blockquote>
<p>工欲善其事必先利其器</p>
</blockquote>
<h2 id="服务器监控工具"><a href="#服务器监控工具" class="headerlink" title="服务器监控工具"></a>服务器监控工具</h2><ul>
<li><code>prometheus</code>.node_exporter系统监控，或者<code>zabbix</code></li>
<li><code>grafana</code>可视化<h3 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h3></li>
<li>可用内存</li>
<li>可用磁盘</li>
<li>CPU负载</li>
<li>网络流量</li>
</ul>
<h3 id="JVM监控工具"><a href="#JVM监控工具" class="headerlink" title="JVM监控工具"></a>JVM监控工具</h3><h4 id="jps-lvm"><a href="#jps-lvm" class="headerlink" title="jps -lvm"></a>jps -lvm</h4><p>查看java进程情况</p>
<h4 id="Java-VisualVM"><a href="#Java-VisualVM" class="headerlink" title="Java VisualVM"></a>Java VisualVM</h4><p>在服务端启动j<code>statd</code>后，在本地用jdk自带的<code>jvisualvm</code>连接：</p>
<ul>
<li>监控Heap使用情况</li>
<li>监控线程情况</li>
</ul>
<h2 id="测试框架"><a href="#测试框架" class="headerlink" title="测试框架"></a>测试框架</h2><p><code>Locust</code>分布式性能测试框架</p>
<ul>
<li>master：1个</li>
<li>slave：4个</li>
</ul>
<h3 id="Locust的关键配置"><a href="#Locust的关键配置" class="headerlink" title="Locust的关键配置"></a>Locust的关键配置</h3><blockquote>
<p>压测Web界面配置</p>
</blockquote>
<ul>
<li>Number of users to simulate：模拟的用户数，即压测的用户总数</li>
<li>Hatch rate：压测时，每秒并发/启动的用户数</li>
</ul>
<blockquote>
<p>TaskSet脚本配置</p>
</blockquote>
<ul>
<li>min_wait：模拟用户在执行任务之间等待的最小时间，单位是毫秒；</li>
<li>max_wait：模拟用户在执行任务之间等待的最大时间，单位是毫秒；<br>默认1000，即locust在执行每个任务之间总是会等待1秒</li>
</ul>
<h1 id="测试环境搭建"><a href="#测试环境搭建" class="headerlink" title="测试环境搭建"></a>测试环境搭建</h1><h2 id="服务器准备"><a href="#服务器准备" class="headerlink" title="服务器准备"></a>服务器准备</h2><ul>
<li>API服务器</li>
<li>缓存服务器</li>
<li>数据库服务器</li>
<li>Web服务器</li>
</ul>
<h3 id="服务部署"><a href="#服务部署" class="headerlink" title="服务部署"></a>服务部署</h3><p>Jenkins编写服务部署脚本</p>
<h1 id="测试数据准备"><a href="#测试数据准备" class="headerlink" title="测试数据准备"></a>测试数据准备</h1><p>小样本数据采用Junit单元测试调用API接口生成，<br>大样本数据用locust脚本生成</p>
<ul>
<li>用户数据：100</li>
<li>人员数据：10000</li>
<li>设备数据：10000</li>
<li>设备人员关系数据：100000000</li>
</ul>
<h2 id="参数化"><a href="#参数化" class="headerlink" title="参数化"></a>参数化</h2><ul>
<li>为尽量模拟压测的真实性，测试数据应从测试数据源中随机抽样生成；<br>locust测试脚本中可采用python的random从list中抽样；<br>或者用pandas的sample生成采样数据；</li>
</ul>
<h1 id="测试脚本"><a href="#测试脚本" class="headerlink" title="测试脚本"></a>测试脚本</h1><h2 id="locust测试脚本示例"><a href="#locust测试脚本示例" class="headerlink" title="locust测试脚本示例"></a>locust测试脚本示例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> uuid</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> locust <span class="keyword">import</span> HttpLocust, TaskSet, task</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenPersonBackendApi</span><span class="params">(TaskSet)</span>:</span></span><br><span class="line">    __PERSON_LIBS = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># @task(1)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">person_query</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        人员列表查询</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ysk_id, person_lib_id = self._get_person_lib()</span><br><span class="line">        payload = &#123;</span><br><span class="line">            <span class="string">"ysk_id"</span>: ysk_id,</span><br><span class="line">            <span class="string">"person_lib_id"</span>: person_lib_id,</span><br><span class="line">            <span class="string">"limit"</span>: random.randint(<span class="number">10</span>, <span class="number">500</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        headers = &#123;<span class="string">'content-type'</span>: <span class="string">'application/json'</span>&#125;</span><br><span class="line">        r = self.client.post(<span class="string">"/person_create"</span>, data=json.dumps(payload), headers=headers, verify=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">assert</span> r.status_code == <span class="number">200</span></span><br><span class="line">        rData = json.loads(r.text, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        <span class="keyword">if</span> rData[<span class="string">"success"</span>]:</span><br><span class="line">            print(<span class="string">"person_lib_id &#123;&#125;,time &#123;&#125;,person_id:&#123;&#125;"</span>.format(person_lib_id, time, rData[<span class="string">"data"</span>][<span class="string">"person_id"</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(rData)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_person_lib</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.__PERSON_LIBS <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.__PERSON_LIBS = pd.read_csv(<span class="string">"data/person_libs.txt"</span>).values.tolist()</span><br><span class="line">        person_lib = random.choice(self.__PERSON_LIBS)</span><br><span class="line">        ysk_id = person_lib[<span class="number">0</span>]</span><br><span class="line">        person_lib_id = person_lib[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> ysk_id, person_lib_id</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenPersonLocust</span><span class="params">(HttpLocust)</span>:</span></span><br><span class="line">    task_set = OpenPersonBackendApi</span><br><span class="line">    host = <span class="string">"http://172.26.12.191:9881/open-person-backend/1.0"</span></span><br><span class="line">    min_wait = <span class="number">1000</span></span><br><span class="line">    max_wait = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    master启动脚本：export node=master &amp;&amp; python open_person_backend.py </span></span><br><span class="line"><span class="string">    slave启动脚本：export node=salve &amp;&amp; python open_person_backend.py</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ps -ef|grep locust |grep -v grep|awk '&#123;print $2&#125;'|xargs kill</span></span><br><span class="line">    node = os.environ.get(<span class="string">"node"</span>, <span class="string">"slave"</span>)</span><br><span class="line">    <span class="keyword">if</span> node == <span class="string">"master"</span>:</span><br><span class="line">        os.system(<span class="string">"nohup locust -f open_person_backend.py --master -P 9090 &gt;&gt;master.log &amp;"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.system(<span class="string">"nohup locust -f open_person_backend.py --slave --master-host=172.26.12.128 &gt;&gt;slave.log &amp;"</span>)</span><br><span class="line">        os.system(<span class="string">"nohup locust -f open_person_backend.py --slave --master-host=172.26.12.128 &gt;&gt;slave.log &amp;"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><h2 id="系统优化"><a href="#系统优化" class="headerlink" title="系统优化"></a>系统优化</h2><ul>
<li>连接数</li>
<li>TCP连接快速回收</li>
</ul>
<h2 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h2><ul>
<li>数据库连接</li>
<li>索引命中</li>
<li>字段类型</li>
<li>读写分离</li>
</ul>
<h2 id="应用程序优化"><a href="#应用程序优化" class="headerlink" title="应用程序优化"></a>应用程序优化</h2><ul>
<li>业务流程优化：异步处理</li>
<li>JVM优化：内存泄漏、内存溢出</li>
</ul>
]]></content>
      <categories>
        <category>系统测试</category>
      </categories>
      <tags>
        <tag>Locust</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次MySQL死锁问题排查</title>
    <url>/2019/12/11/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>记录一次线上MySQL数据库的死锁问题和相关知识：</p>
<ul>
<li>MySQL数据库事务的4要素，</li>
<li>事务隔离的4种级别，</li>
<li>事务隔离导致的3类问题，</li>
<li>死锁的4个必要条件，</li>
<li>死锁的解决方案…</li>
</ul>
<a id="more"></a>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 初始化</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span></span><br><span class="line">    test_deadlock</span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">id</span> <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">        <span class="keyword">name</span> <span class="built_in">VARCHAR</span>(<span class="number">36</span>),</span><br><span class="line">        code <span class="built_in">VARCHAR</span>(<span class="number">36</span>),</span><br><span class="line">        PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_deadlock(<span class="keyword">name</span>,code) <span class="keyword">values</span>(<span class="string">'device1'</span>,<span class="string">'d1'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_deadlock(<span class="keyword">name</span>,code) <span class="keyword">values</span>(<span class="string">'device2'</span>,<span class="string">'d1'</span>);</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span>,code <span class="keyword">from</span> test_deadlock;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 测试不按顺序加锁不同记录导致的死锁</span></span><br><span class="line"><span class="comment">-- txA</span></span><br><span class="line"><span class="comment">-- 1</span></span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">update</span> test_deadlock <span class="keyword">set</span> code=<span class="string">'tx1'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">1</span>;</span><br><span class="line"><span class="comment">-- 3</span></span><br><span class="line"><span class="keyword">update</span> test_deadlock <span class="keyword">set</span> code=<span class="string">'tx1'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">2</span>;</span><br><span class="line"><span class="keyword">commit</span> ;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- txB</span></span><br><span class="line"><span class="comment">--2 </span></span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">update</span> test_deadlock <span class="keyword">set</span> code=<span class="string">'tx2'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">update</span> test_deadlock <span class="keyword">set</span> code=<span class="string">'tx2'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">2</span>;</span><br><span class="line"><span class="comment">-- block atfer 3</span></span><br><span class="line"><span class="keyword">commit</span> ;</span><br></pre></td></tr></table></figure>
<h1 id="事务的ACID4要素"><a href="#事务的ACID4要素" class="headerlink" title="事务的ACID4要素"></a>事务的ACID4要素</h1><h2 id="原子性（atomicity）"><a href="#原子性（atomicity）" class="headerlink" title="原子性（atomicity）"></a>原子性（atomicity）</h2><p>一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性</p>
<h2 id="一致性（consistency）"><a href="#一致性（consistency）" class="headerlink" title="一致性（consistency）"></a>一致性（consistency）</h2><p> 数据库总是从一个一致性的状态转换到另一个一致性的状态。</p>
<h2 id="隔离性（isolation）"><a href="#隔离性（isolation）" class="headerlink" title="隔离性（isolation）"></a>隔离性（isolation）</h2><p>通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。</p>
<h2 id="持久性（durability）"><a href="#持久性（durability）" class="headerlink" title="持久性（durability）"></a>持久性（durability）</h2><p>一旦事务提交，则其所做的修改会永久保存到数据库。</p>
<blockquote>
<p>此时即使系统崩溃，修改的数据也不会丢失。持久性是个有占模糊的概念，因为实际上持久性也分很多不同的级别。有些持久性策略能够提供非常强的安全保障，而有些则未必，而且不可能有能做到100%的持久性保证的策略。</p>
</blockquote>
<h1 id="事务引发的3个问题"><a href="#事务引发的3个问题" class="headerlink" title="事务引发的3个问题"></a>事务引发的3个问题</h1><ul>
<li>脏读：uncommit导致</li>
<li>不可重复读:update,delete导致</li>
<li>幻读:insert导致</li>
</ul>
<h1 id="事务的4个隔离级别"><a href="#事务的4个隔离级别" class="headerlink" title="事务的4个隔离级别"></a>事务的4个隔离级别</h1><p>简写：<code>ru，rc，rr，se</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>读未提交（read-uncommitted）</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>读已提交（read-committed）</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>可重复读（repeatable-read）</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>串行化（serializable）</td>
<td>否</td>
<td>否</td>
<td>否</td>
</tr>
</tbody>
</table>
</div>
<h1 id="死锁的4个条件"><a href="#死锁的4个条件" class="headerlink" title="死锁的4个条件"></a>死锁的4个条件</h1><ol>
<li>互斥条件：一个资源每次只能被一个进程使用。</li>
<li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>
<li>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</li>
<li>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。<br>这四个条件是死锁的<code>必要条件</code>，只要系统发生死锁，这些条件必然成立，<br>而只要上述条件之一不满足，就不会发生死锁。</li>
</ol>
<h1 id="死锁的解决方案"><a href="#死锁的解决方案" class="headerlink" title="死锁的解决方案"></a>死锁的解决方案</h1><h2 id="顺序加锁"><a href="#顺序加锁" class="headerlink" title="顺序加锁"></a>顺序加锁</h2><p>对索引加锁顺序的不一致很可能会导致死锁，所以如果可以，尽量以相同的顺序来访问索引记录和表。<br>在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能；</p>
<blockquote>
<p>串行执行，不会死锁，先执行txA再执行txB</p>
</blockquote>
<h2 id="事务拆分"><a href="#事务拆分" class="headerlink" title="事务拆分"></a>事务拆分</h2><p>避免大事务，尽量将大事务拆成多个小事务来处理；<br>因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高；</p>
<h2 id="设置锁等待超时参数"><a href="#设置锁等待超时参数" class="headerlink" title="设置锁等待超时参数"></a>设置锁等待超时参数</h2><p>设置锁等待超时参数：innodb_lock_wait_timeout，</p>
<p>这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。</p>
<p>我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次不可回滚的数据迁移</title>
    <url>/2019/12/09/%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%B8%8D%E5%8F%AF%E5%9B%9E%E6%BB%9A%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
    <content><![CDATA[<p>记录一次系统重构升级时涉及数据迁移的注意事项；<br><a id="more"></a></p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>主要核心服务有用户、设备、机构、人员和人脸；</p>
<ol>
<li>系统分层问题，由于刚开始系统开发由业务驱动，机构、设备和人员服务是在业务平台中实现；</li>
<li>为满足市场变化，新产品不断推出时，技术架构也要做响应调整：提取公共业务组件作为基础服务，甚至将所有基础服务提取出来做成一个独立的系统（IOT开放平台);</li>
<li>由于初期需求局限，导致重构时动作特别大，业务流程，数据结构都发生了很大变动;</li>
</ol>
<p>问题来了，为了不影响已有客户，现在线上新老系统<code>双轨运行</code>，要废弃老系统前，必须得完成数据迁移工作。</p>
<h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ul>
<li>迁移前编写完整的数据迁移<code>实施流程</code>，并和相关业务负责人确认影响范围；</li>
<li>迁移工具的触发要<code>自动化</code>，做到用户无感知迁移：比如在App升级到特定版本时完成数据迁移；</li>
<li>迁移触发方式可以用<code>异步</code>任务的形式实现，收到迁移信号后push到mq，然后消费者pull迁移任务异步完成迁移；</li>
<li><p>迁移的系统架构可参考如下步骤：</p>
<ul>
<li>context（基础数据准备）</li>
<li>before（迁移前数据统计）</li>
<li>execute（执行迁移）</li>
<li>after（迁移后数据统计、释放资源）</li>
</ul>
</li>
<li><p>允许重复执行迁移：数据库<code>操作幂等</code>，可用<code>ON DUPLICATE KEY UPDATE</code>实现；</p>
</li>
<li>针对数据库的新字段要set default；</li>
<li>针对更新/删除的数据要delete缓存；</li>
<li>用户的部分设备数据迁移后，用户的报表服务需要从同时从新&amp;老系统中读取数据，合并后生成报表；</li>
<li>迁移结果要持久化存储，方便问题回溯；</li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Hash算法-两数之和O(n)</title>
    <url>/2019/05/31/2019-6-Hash%E7%AE%97%E6%B3%95-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8CO-n/</url>
    <content><![CDATA[<blockquote>
<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那两个整数，并返回他们的数组下标。<br>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。  </p>
</blockquote>
<p>示例:给定 nums = [2, 7, 11, 15], target = 9<br>因为 nums[0] + nums[1] = 2 + 7 = 9，所以返回 [0, 1]<br><a id="more"></a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***</span></span><br><span class="line"><span class="comment"> * 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。</span></span><br><span class="line"><span class="comment"> * 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 示例:</span></span><br><span class="line"><span class="comment"> * 给定 nums = [2, 7, 11, 15], target = 9</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 因为 nums[0] + nums[1] = 2 + 7 = 9</span></span><br><span class="line"><span class="comment"> * 所以返回 [0, 1]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Solution s = <span class="keyword">new</span> Solution();</span><br><span class="line">        <span class="keyword">int</span>[] nums = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">2</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>&#125;;</span><br><span class="line">        System.out.println(JSON.toJSONString(s.twoSum1(nums, <span class="number">9</span>)));</span><br><span class="line">        System.out.println(JSON.toJSONString(s.twoSum2(nums, <span class="number">9</span>)));</span><br><span class="line">        System.out.println(JSON.toJSONString(s.twoSum3(nums, <span class="number">9</span>)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 暴力法</span></span><br><span class="line"><span class="comment">     * 时间复杂度：O(n^2)</span></span><br><span class="line"><span class="comment">     * 空间复杂度：O(1)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum1(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; nums.length; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[i] + nums[j] == target) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;i, j&#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"can not calc twoSum of %s in %s"</span>, target, JSON.toJSONString(nums)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 两遍Hash表</span></span><br><span class="line"><span class="comment">     * 时间复杂度：O(n)</span></span><br><span class="line"><span class="comment">     * 空间复杂度：O(n)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum2(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; numsMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            numsMap.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nums.length; j++) &#123;</span><br><span class="line">            <span class="keyword">int</span> left = target - nums[j];</span><br><span class="line">            <span class="comment">//注意此处numsMap.get(left) != j避免target为偶数时，取到相同的</span></span><br><span class="line">            <span class="keyword">if</span> (numsMap.containsKey(left) &amp;&amp; numsMap.get(left) != j) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;numsMap.get(left), j&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"can not calc twoSum of %s in %s"</span>, target, JSON.toJSONString(nums)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 一遍Hash表</span></span><br><span class="line"><span class="comment">     * 时间复杂度：O(n)</span></span><br><span class="line"><span class="comment">     * 空间复杂度：O(n)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum3(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; numsMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> left = target - nums[i];</span><br><span class="line">            <span class="keyword">if</span> (numsMap.containsKey(left)) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;numsMap.get(left), i&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            numsMap.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"can not calc twoSum of %s in %s"</span>, target, JSON.toJSONString(nums)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树BFS-分层遍历</title>
    <url>/2019/05/31/2019-6-%E4%BA%8C%E5%8F%89%E6%A0%91-BFS-%E5%88%86%E5%B1%82%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<blockquote>
<p>二叉树分层遍历实现，<br>给定一个二叉树，返回其按层次遍历的节点值。 （即逐层地，从左到右访问所有节点）。<br><a id="more"></a></p>
</blockquote>
<p>例如:<br>给定二叉树: [3,9,20,null,null,15,7],<br>返回其层次遍历结果：[[3],[9,20],[15,7]]</p>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><h1 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h1><h2 id="利用外部队列遍历"><a href="#利用外部队列遍历" class="headerlink" title="利用外部队列遍历"></a>利用外部队列遍历</h2><p>算法思想：广度优先搜索BFS</p>
<ol>
<li>以一个FIFO的队列存储节点；</li>
<li>在遍历当前层时，把当前层的左右子节点入队;</li>
<li>当前层遍历完后再从队列获取节点，遍历下一层;</li>
<li>队列为空时完成树的遍历；</li>
</ol>
<h2 id="递归逐层遍历"><a href="#递归逐层遍历" class="headerlink" title="递归逐层遍历"></a>递归逐层遍历</h2><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Queue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 利用外部队列遍历</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;List&lt;Integer&gt;&gt; levelOrder_queue(TreeNode root) &#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> levels;</span><br><span class="line">        &#125;</span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.add(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> level = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (!queue.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">// start the current level</span></span><br><span class="line">            levels.add(<span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//当前层的元素大小=队列大小</span></span><br><span class="line">            <span class="keyword">int</span> level_length = queue.size();</span><br><span class="line">            <span class="comment">// 循环只处理当前层的元素</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; level_length; ++i) &#123;</span><br><span class="line">                TreeNode node = queue.remove();</span><br><span class="line"></span><br><span class="line">                <span class="comment">//元素加入当前层所在数组</span></span><br><span class="line">                levels.get(level).add(node.val);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//当前层级的子节点加入队列，下一层会处理</span></span><br><span class="line">                <span class="keyword">if</span> (node.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    queue.add(node.left);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    queue.add(node.right);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// go to next level</span></span><br><span class="line">            level++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> levels;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 递归逐层遍历</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;List&lt;Integer&gt;&gt; levelOrder_recurse(TreeNode root) &#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> levels;</span><br><span class="line">        &#125;</span><br><span class="line">        helper(root, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> levels;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">helper</span><span class="params">(TreeNode node, <span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (levels.size() == level) &#123;</span><br><span class="line">            <span class="comment">//当前层初始化</span></span><br><span class="line">            levels.add(<span class="keyword">new</span> ArrayList&lt;Integer&gt;());</span><br><span class="line">        &#125;</span><br><span class="line">        levels.get(level).add(node.val);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//递归左子树</span></span><br><span class="line">        <span class="keyword">if</span> (node.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">            helper(node.left, level + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//递归右子树</span></span><br><span class="line">        <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">            helper(node.right, level + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树BFS-锯齿遍历</title>
    <url>/2019/05/31/2019-6-%E4%BA%8C%E5%8F%89%E6%A0%91-BFS-%E9%94%AF%E9%BD%BF%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<blockquote>
<p>二叉树锯齿状遍历实现<br>给定一个二叉树，返回其节点值的锯齿形层次遍历。（即先从左往右，再从右往左进行下一层遍历，以此类推，层与层之间交替进行）。</p>
</blockquote>
<a id="more"></a>
<p>例如：<br>给定二叉树 [3,9,20,null,null,15,7],<br>返回锯齿形层次遍历如下：[[3], [20,9], [15,7]]</p>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><h1 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h1><h2 id="利用外部队列遍历"><a href="#利用外部队列遍历" class="headerlink" title="利用外部队列遍历"></a>利用外部队列遍历</h2><p>算法思想：广度优先搜索BFS+双端队列</p>
<ol>
<li>以一个双端队列存储节点，插入和删除仅限在两端操作；</li>
<li>层与层之间LIFO，FILO交叉，正好满足一层正序，一层反序；</li>
<li>当前层遍历完后再从队列获取节点，遍历下一层;</li>
<li>队列为空时完成树的遍历；</li>
</ol>
<h2 id="递归逐层遍历"><a href="#递归逐层遍历" class="headerlink" title="递归逐层遍历"></a>递归逐层遍历</h2><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Deque;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 层与层之间LIFO，FILO交叉，正好满足一层正序，一层反序；</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; levels = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> levels;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> BFS(root, levels);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> List&lt;List&lt;Integer&gt;&gt; BFS(TreeNode root, List&lt;List&lt;Integer&gt;&gt; levels) &#123;</span><br><span class="line">        Deque&lt;TreeNode&gt; deque = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        deque.addLast(root);</span><br><span class="line">        <span class="keyword">int</span> level = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历方向需隔层反转</span></span><br><span class="line">        <span class="keyword">boolean</span> reverse = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">while</span> (deque.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            levels.add(<span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line">            <span class="keyword">int</span> queueSize = deque.size();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; queueSize; i++) &#123;</span><br><span class="line">                TreeNode node;</span><br><span class="line">                <span class="keyword">if</span> (reverse) &#123;</span><br><span class="line">                    <span class="comment">//last in first out(先left再right)</span></span><br><span class="line">                    node = deque.removeFirst();</span><br><span class="line">                    <span class="keyword">if</span> (node.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        deque.addLast(node.left);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        deque.addLast(node.right);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//first in last out （先right再left）</span></span><br><span class="line">                    node = deque.removeLast();</span><br><span class="line">                    <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        deque.addFirst(node.right);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (node.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        deque.addFirst(node.left);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                levels.get(level).add(node.val);</span><br><span class="line">                System.out.println(level + <span class="string">",node-"</span> + node.val);</span><br><span class="line">            &#125;</span><br><span class="line">            reverse = !reverse;</span><br><span class="line">            level++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> levels;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树的中序遍历</title>
    <url>/2019/05/31/2019-6-%E4%BA%8C%E5%8F%89%E6%A0%91-%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<blockquote>
<p>二叉树的中序遍历的实现<br><a id="more"></a></p>
</blockquote>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>可以用来做表达式树 </p>
<h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><h3 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h3><ol>
<li>遇到一个结点，就把它压栈，并去遍历它的左子树；</li>
<li>当左子树遍历结束后，从栈顶弹出这个结点并访问它；</li>
<li>然后按其右指针再去中序遍历该结点的右子树；；<blockquote>
<p>时间复杂度：O(n)。<br>空间复杂度：O(n)</p>
</blockquote>
</li>
</ol>
<h3 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h3><ol>
<li>中序遍历访问左子树；</li>
<li>访问根节点；</li>
<li>中序遍历访问右子树；</li>
</ol>
<blockquote>
<p>时间复杂度：O(n)。递归函数 T(n) = 2 \cdot T(n/2)+1T(n)=2⋅T(n/2)+1。<br>空间复杂度：最坏情况下需要空间O(n)，平均情况为O(logn)。</p>
</blockquote>
<h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 中序遍历：左子树---&gt; 根结点 ---&gt; 右子树</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BTreeInorderTranversal94</span> </span>&#123;</span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 子树遍历-stack实现</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> root 根节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;Integer&gt; <span class="title">traversalTreeInOrder_stack</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; nodes = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Stack&lt;TreeNode&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        TreeNode curr = root;</span><br><span class="line">        <span class="comment">//遍历所有路径，直到某条路径没有叶子节点or栈已空时，结束遍历</span></span><br><span class="line">        <span class="keyword">while</span> (curr != <span class="keyword">null</span> || !stack.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">//树遍历左子树并入栈，到叶子节点停止</span></span><br><span class="line">            <span class="keyword">while</span> (curr != <span class="keyword">null</span>) &#123;</span><br><span class="line">                stack.push(curr);</span><br><span class="line">                curr = curr.left;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//叶子节点出栈</span></span><br><span class="line">            curr = stack.pop();</span><br><span class="line">            nodes.add(curr.val);</span><br><span class="line">            <span class="comment">//当前节点，从右子树遍历</span></span><br><span class="line">            curr = curr.right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nodes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 子树遍历-recurse实现</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> nodes 遍历结果数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> root 根节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">traversalTreeInOrder_recurse</span><span class="params">(List&lt;Integer&gt; nodes, TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (root.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//左子树遍历</span></span><br><span class="line">            traversalTreeInOrder_recurse(nodes, root.left);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//根节点</span></span><br><span class="line">        nodes.add(root.val);</span><br><span class="line">        <span class="keyword">if</span> (root.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//右子树遍历</span></span><br><span class="line">            traversalTreeInOrder_recurse(nodes, root.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 树节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> val;</span><br><span class="line">        TreeNode left;</span><br><span class="line">        TreeNode right;</span><br><span class="line"></span><br><span class="line">        TreeNode(<span class="keyword">int</span> val) &#123;</span><br><span class="line">            <span class="keyword">this</span>.val = val;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>单链表反转</title>
    <url>/2019/05/31/2019-6-%E5%8D%95%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/</url>
    <content><![CDATA[<p>反转一个单链表 </p>
<p>示例:</p>
<ul>
<li>输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL</li>
<li>输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</li>
</ul>
<a id="more"></a>
<h1 id="栈实现"><a href="#栈实现" class="headerlink" title="栈实现"></a>栈实现</h1><ul>
<li>时间复杂度：O(n*2)</li>
<li>空间复杂度：O(n)<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 栈实现</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 反转后链表头节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">reverseList3</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">    Stack&lt;ListNode&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">    <span class="keyword">while</span> (head != <span class="keyword">null</span>) &#123;</span><br><span class="line">        stack.push(head);</span><br><span class="line">        head = head.next;</span><br><span class="line">    &#125;</span><br><span class="line">    ListNode cur = stack.pop();</span><br><span class="line">    cur.next = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">//倒置后的链表</span></span><br><span class="line">    ListNode newHead = cur;</span><br><span class="line">    <span class="keyword">while</span> (!stack.isEmpty()) &#123;</span><br><span class="line">        ListNode tmp = stack.pop();</span><br><span class="line">        tmp.next = <span class="keyword">null</span>;</span><br><span class="line">        newHead.next = tmp;</span><br><span class="line">        newHead = newHead.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cur;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="迭代实现1"><a href="#迭代实现1" class="headerlink" title="迭代实现1"></a>迭代实现1</h1><ul>
<li>时间复杂度：O(n)</li>
<li>空间复杂度：O(1)<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除链表节点实现</span></span><br><span class="line"><span class="comment"> * 1.开始遍历：链表不为空或节点数大于1；</span></span><br><span class="line"><span class="comment"> * 2.每次删除next节点，并将删除节点插入到链表的头部</span></span><br><span class="line"><span class="comment"> * 3.将链表head节点指向执行剪切操作后的链表；</span></span><br><span class="line"><span class="comment"> * 3.结束遍历：到达链表尾部时；</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 反转后链表头节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">reverseList2</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//链表遍历指针</span></span><br><span class="line">    ListNode p = head;</span><br><span class="line">    ListNode tmp =<span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> (p != <span class="keyword">null</span> &amp;&amp; p.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//删除next，指向next.next</span></span><br><span class="line">        tmp = p.next;</span><br><span class="line">        p.next = p.next.next;</span><br><span class="line">        <span class="comment">//插入next，指向头</span></span><br><span class="line">        tmp.next = head;</span><br><span class="line">        <span class="comment">//链表head指向执行剪切操作后的链表</span></span><br><span class="line">        head = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="迭代实现2"><a href="#迭代实现2" class="headerlink" title="迭代实现2"></a>迭代实现2</h1><ul>
<li>时间复杂度：O(n)</li>
<li>空间复杂度：O(1)<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 迭代实现</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 反转后链表头节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">reverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//上一个节点</span></span><br><span class="line">    ListNode pre = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">//当前节点</span></span><br><span class="line">    ListNode cur = head;</span><br><span class="line">    <span class="comment">//临时节点</span></span><br><span class="line">    ListNode tmp = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> (cur != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//后续节点的指针</span></span><br><span class="line">        tmp = cur.next;</span><br><span class="line">        <span class="comment">//当前节点的next指向上一个节点-&gt;反转</span></span><br><span class="line">        cur.next = pre;</span><br><span class="line">        <span class="comment">//上一个节点=当前节点</span></span><br><span class="line">        pre = cur;</span><br><span class="line">        <span class="comment">//下一次从当前节点开始，新的链表引用</span></span><br><span class="line">        cur = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> pre;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="递归实现"><a href="#递归实现" class="headerlink" title="递归实现"></a>递归实现</h1><ul>
<li>时间复杂度：O(n)，假设 n 是列表的长度，那么时间复杂度为 O(n)。</li>
<li>空间复杂度：O(n)，由于使用递归，将会使用隐式栈空间。递归深度可能会达到 n 层。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 递归实现</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 反转后链表头节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">reverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//p为最后一个节点</span></span><br><span class="line">    ListNode p = reverseList(head.next);</span><br><span class="line">    <span class="comment">//反转</span></span><br><span class="line">    head.next.next = head;</span><br><span class="line">    <span class="comment">//当前next设为null，防止循环指针</span></span><br><span class="line">    head.next = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>单链表旋转</title>
    <url>/2019/05/31/2019-6-%E5%8D%95%E9%93%BE%E8%A1%A8%E6%97%8B%E8%BD%AC/</url>
    <content><![CDATA[<blockquote>
<p>给定一个链表，旋转链表，将链表每个节点向右移动 k 个位置，其中 k 是非负数。<br><a id="more"></a></p>
</blockquote>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h1><p>旋转链表</p>
<ol>
<li>求链表长度</li>
<li>计算实际需要移动的位置k</li>
<li>快慢指针法找到倒数第k个节点</li>
<li>链表旋转：k节点作为新的链表头，k-1节点作为链表尾，中间部分以循环链表方式连接</li>
</ol>
<h1 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h1><ul>
<li>空间复杂度：O(1)</li>
<li>时间复杂度：O(n)</li>
</ul>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>版本1<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">rotateRight</span><span class="params">(ListNode head, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        ListNode dummy = <span class="keyword">new</span> ListNode(-<span class="number">1</span>);</span><br><span class="line">        dummy.next = head;</span><br><span class="line">        ListNode tmp = dummy.next;</span><br><span class="line">        <span class="keyword">int</span> n = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//求链表长度</span></span><br><span class="line">        <span class="keyword">while</span> (tmp != <span class="keyword">null</span>) &#123;</span><br><span class="line">            tmp = tmp.next;</span><br><span class="line">            n++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (n == <span class="number">0</span> || k % n == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> dummy.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//当成循环链表，n次移动等于没移动，求余后的k为实际需移动的位置数</span></span><br><span class="line">        k = k % n;</span><br><span class="line">        <span class="comment">//快慢指针求倒数第k个节点</span></span><br><span class="line">        ListNode slow = dummy;</span><br><span class="line">        ListNode fast = dummy;</span><br><span class="line">        <span class="keyword">while</span> (k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            fast = fast.next;</span><br><span class="line">            k--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (fast.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">            slow = slow.next;</span><br><span class="line">            fast = fast.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//kNode为返回结果的head</span></span><br><span class="line">        ListNode kNode = slow.next;</span><br><span class="line">        <span class="comment">//原slow节点即为tail</span></span><br><span class="line">        slow.next = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//连接原链表的头部</span></span><br><span class="line">        fast.next = head;</span><br><span class="line">        <span class="keyword">return</span> kNode;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>版本2：快慢指针法，关键是k = k % n<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static ListNode rotateRight(ListNode head, int k) &#123;</span><br><span class="line">        ListNode dummy &#x3D; new ListNode(-1);</span><br><span class="line">        dummy.next &#x3D; head;</span><br><span class="line">        ListNode fast &#x3D; dummy.next;</span><br><span class="line">        int n &#x3D; 1;</span><br><span class="line">        &#x2F;&#x2F;快指针，求链表长度和tail节点</span><br><span class="line">        while (fast.next !&#x3D; null) &#123;</span><br><span class="line">            fast &#x3D; fast.next;</span><br><span class="line">            n++;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;n次移动等于没移动</span><br><span class="line">        if (k % n &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return dummy.next;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;当成循环链表，求余后的k为实际需移动的位置数</span><br><span class="line">        k &#x3D; k % n;</span><br><span class="line">        ListNode slow &#x3D; dummy.next;</span><br><span class="line">        &#x2F;&#x2F;求倒数第k个节点</span><br><span class="line">        for (int i &#x3D; 0; i &lt; n - k - 1; i++) &#123;</span><br><span class="line">            slow &#x3D; slow.next;</span><br><span class="line">        &#125;</span><br><span class="line">        ListNode newHead &#x3D; slow.next;</span><br><span class="line">        slow.next &#x3D; null;</span><br><span class="line">        &#x2F;&#x2F;连接原链表的头部</span><br><span class="line">        fast.next &#x3D; head;</span><br><span class="line">        return newHead;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>查找算法-BinarySearch二分查找</title>
    <url>/2019/05/31/2019-6-%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95-BinarySearch%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<p>二分查找利用已排好序的数组，每一次查找都可以将查找范围减半。查找范围内只剩一个数据时查找结束。<br><a id="more"></a></p>
<h1 id="二分查找算法简介"><a href="#二分查找算法简介" class="headerlink" title="二分查找算法简介"></a>二分查找算法简介</h1><ul>
<li>二分查找利用已排好序的数组，每一次查找都可以将查找范围减半。查找范围内只剩一个数据时查找结束。 </li>
<li>数据量为n 的数组，将其长度减半log2(n) 次后，其中便只剩一个数据了。</li>
<li>也就是说， 在二分查找中重复执行将<code>目标数据</code>和数组<code>中间的数据</code>进行比较后将查找<code>范围减半</code>的 操作log2(n)次后，就能找到目标数据（若没找到则可以得出数据不存在的结论），因此它 的时间复杂度为 O(logn)。</li>
</ul>
<h1 id="二分查找的复杂度"><a href="#二分查找的复杂度" class="headerlink" title="二分查找的复杂度"></a>二分查找的复杂度</h1><p> 二分查找的时间复杂度为<code>O(logn)</code>，与线性查找的O(n) 相比速度上得到了指数倍提高（x=log2(n)，则 n=2^x）。 </p>
<h1 id="二分查找算法的局限性"><a href="#二分查找算法的局限性" class="headerlink" title="二分查找算法的局限性"></a>二分查找算法的局限性</h1><p>二分查找必须建立在<code>数据已经排好序</code>的基础上才能使用，因此添加数据时必须加到合适的位置，这就需要额外耗费维护数组的时间。<br>而使用线性查找时，数组中的数据可以是无序的，因此添加数据时也无须顾虑位置，直接把它加在末尾即可，不需要耗费时间。</p>
<blockquote>
<p>具体使用哪种查找方法，可以根据<code>查找</code>和<code>添加</code>两个操作哪个更为频繁来决定。</p>
</blockquote>
<h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test_bsearch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> a[] = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>&#125;;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">int</span>[] search = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">11</span>&#125;;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> s : search) &#123;</span><br><span class="line">          System.out.println(String.format(<span class="string">"begin Rsearch[%s]"</span>, s));</span><br><span class="line">          <span class="keyword">int</span> idx = bsearch_recurse(a, <span class="number">0</span>, a.length - <span class="number">1</span>, s);</span><br><span class="line">          System.out.println(String.format(<span class="string">"end Rsearch[%s],index[%s]"</span>, s, idx));</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> s : search) &#123;</span><br><span class="line">          System.out.println(String.format(<span class="string">"begin Lsearch[%s]"</span>, s));</span><br><span class="line">          <span class="keyword">int</span> idx = bsearch_while(a, s);</span><br><span class="line">          System.out.println(String.format(<span class="string">"end Lsearch[%s],index[%s]"</span>, s, idx));</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/***</span></span><br><span class="line"><span class="comment">   * 递归实现二分查找</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> a 目标数组</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> from 开始索引</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> to 结果索引</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> tar 查找目标</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> 目标索引，查不到返回-1</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">bsearch_recurse</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> from, <span class="keyword">int</span> to, <span class="keyword">int</span> tar)</span> </span>&#123;</span><br><span class="line">      System.out.println(String.format(<span class="string">"search from[%s],to[%s]"</span>, from, to));</span><br><span class="line">      <span class="keyword">if</span> (from &gt; to || tar &lt; a[from] || tar &gt; a[to]) &#123;</span><br><span class="line">          <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar == a[from]) &#123;</span><br><span class="line">          <span class="keyword">return</span> from;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar == a[to]) &#123;</span><br><span class="line">          <span class="keyword">return</span> to;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">int</span> m = (to + from) / <span class="number">2</span>;</span><br><span class="line">          <span class="keyword">if</span> (tar &gt; a[m]) &#123;</span><br><span class="line">              <span class="keyword">return</span> bsearch_recurse(a, m, to, tar);</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar &lt; a[m]) &#123;</span><br><span class="line">              <span class="keyword">return</span> bsearch_recurse(a, from, m, tar);</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="keyword">return</span> m;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/***</span></span><br><span class="line"><span class="comment">   *循环实现二分查找</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> a 目标数组</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> tar 查找目标</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> 目标索引，查不到返回-1</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">bsearch_while</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> tar)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> from = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">int</span> to = a.length - <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">if</span> (to &lt; <span class="number">0</span> || tar &lt; a[from] || tar &gt; a[to]) &#123;</span><br><span class="line">          <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar == a[from]) &#123;</span><br><span class="line">          <span class="keyword">return</span> from;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar == a[to]) &#123;</span><br><span class="line">          <span class="keyword">return</span> to;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">int</span> m = <span class="number">0</span>;</span><br><span class="line">          <span class="keyword">while</span> (from &lt;= to) &#123;</span><br><span class="line">              m = (to + from) / <span class="number">2</span>;</span><br><span class="line">              System.out.println(String.format(<span class="string">"search from[%s],to[%s]"</span>, from, to));</span><br><span class="line">              <span class="keyword">if</span> (tar &lt; a[m]) &#123;</span><br><span class="line">                  to = m - <span class="number">1</span>;</span><br><span class="line">              &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tar &gt; a[m]) &#123;</span><br><span class="line">                  from = m + <span class="number">1</span>;</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                  <span class="keyword">return</span> m;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Array</tag>
      </tags>
  </entry>
  <entry>
    <title>查找链表的2等分点</title>
    <url>/2019/05/31/2019-6-%E6%9F%A5%E6%89%BE%E9%93%BE%E8%A1%A8%E7%9A%842%E7%AD%89%E5%88%86%E7%82%B9/</url>
    <content><![CDATA[<blockquote>
<p>给定一个带有头结点 head 的非空单链表，返回链表的中间结点。<br>如果有两个中间结点，则返回第二个中间结点。</p>
</blockquote>
<a id="more"></a>
<h1 id="查找链表的2等分点"><a href="#查找链表的2等分点" class="headerlink" title="查找链表的2等分点"></a>查找链表的2等分点</h1><blockquote>
<p>快慢指针法</p>
<ul>
<li>时间复杂度：O(N)O(N)，其中 NN 是给定列表的结点数目。</li>
<li>空间复杂度：O(1)O(1)，slow 和 fast 用去的空间。</li>
</ul>
</blockquote>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 快慢指针求中点</span></span><br><span class="line"><span class="comment">     * 快指针走2步，慢指针走1步，快指针到达链尾时，慢指针停止；</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> head 头节点指针</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 头部指针</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">middleNode</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">        ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        dummy.next = head;</span><br><span class="line">        ListNode q = dummy;</span><br><span class="line">        ListNode s = dummy;</span><br><span class="line">        <span class="keyword">while</span> (q != <span class="keyword">null</span>) &#123;</span><br><span class="line">            q = q.next;</span><br><span class="line">            s = s.next;</span><br><span class="line">            <span class="keyword">if</span> (q == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            q = q.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 根据数组构建链表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> vals 数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 链表头节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">newSingleLinkedList</span><span class="params">(<span class="keyword">int</span>[] vals)</span> </span>&#123;</span><br><span class="line">        ListNode[] nodes;</span><br><span class="line">        nodes = <span class="keyword">new</span> ListNode[vals.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; vals.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (nodes[i] == <span class="keyword">null</span>) &#123;</span><br><span class="line">                nodes[i] = <span class="keyword">new</span> ListNode(vals[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; vals.length - <span class="number">1</span>) &#123;</span><br><span class="line">                nodes[i + <span class="number">1</span>] = <span class="keyword">new</span> ListNode(vals[i + <span class="number">1</span>]);</span><br><span class="line">                nodes[i].next = nodes[i + <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nodes[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 单链表节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ListNode</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> val;</span><br><span class="line">        ListNode next;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">ListNode</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.val = val;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printNode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            ListNode printNode = <span class="keyword">this</span>;</span><br><span class="line">            StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">            <span class="keyword">while</span> (printNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">                sb.append(<span class="string">"--&gt;"</span>).append(printNode.val);</span><br><span class="line">                printNode = printNode.next;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(sb);</span><br><span class="line">        &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>链表有环,求环节点的入口</title>
    <url>/2019/05/31/2019-6-%E9%93%BE%E8%A1%A8%E6%9C%89%E7%8E%AF-%E6%B1%82%E7%8E%AF%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%A5%E5%8F%A3/</url>
    <content><![CDATA[<blockquote>
<p>给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。<br>为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。<br>说明：不允许修改给定的链表。<br><a id="more"></a></p>
</blockquote>
<h1 id="HashSet求解"><a href="#HashSet求解" class="headerlink" title="HashSet求解"></a>HashSet求解</h1><ul>
<li>时间复杂度：O(n)<ul>
<li>空间复杂度：O(n)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 求链表中环的入口节点</span><br><span class="line"> * 用Set 保存已经访问过的节点，遍历整个列表并返回第一个出现重复的节点。</span><br><span class="line"> * 时间复杂度：O(n)</span><br><span class="line"> * 空间复杂度：O(n)</span><br><span class="line"> *</span><br><span class="line"> * @param head 链表头节点</span><br><span class="line"> * @return 是否循环链表</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static ListNode detectCycle(ListNode head) &#123;</span><br><span class="line">    Set&lt;ListNode&gt; nodes &#x3D; new HashSet&lt;&gt;();</span><br><span class="line">    while (head !&#x3D; null) &#123;</span><br><span class="line">        if (nodes.contains(head)) &#123;</span><br><span class="line">            return head;</span><br><span class="line">        &#125;</span><br><span class="line">        nodes.add(head);</span><br><span class="line">        head &#x3D; head.next;</span><br><span class="line">    &#125;</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="Floyd算法求解"><a href="#Floyd算法求解" class="headerlink" title="Floyd算法求解"></a>Floyd算法求解</h1><p>Floyd判圈算法，也称龟兔赛跑算法，可用于判断链表、迭代函数、有限状态机是否有环。如果有，找出环的起点和大小。时间复杂度O(n)，空间复杂度O(1)。</p>
<h2 id="求解原理"><a href="#求解原理" class="headerlink" title="求解原理"></a>求解原理</h2><p><img src="https://user-images.githubusercontent.com/3156608/70372354-b97b5a80-1918-11ea-9f63-2d3a541b0daa.png" alt="image"><br>假设相遇于 D 点，则快指针应该这时刚好套慢指针一圈（ 2 倍速的必然结果，可以数学证明），<br>则此时快指针走的路程为 AB + BCDEB + BD （用 BCDEB 表示一圈）(字母序表示方向，AB 表示 A -&gt; B)</p>
<ul>
<li>慢指针走的路程为 AB + BD；<br>由于 SS(快指针) = 2 * S(慢指针) （因为 2 倍速）（ SS 表示总路程），</li>
<li>AB + BCDEB + BD = 2 * (AB + BD) ——-(1)</li>
<li>AB + BD = BCDEB ——-(2)<br>上式表明此时慢指针走过的全部路径刚好一圈，我们的目标是获得 BB 点这一入环点，又根据一圈的关系，有一圈剩余部分，</li>
<li>DB = BCDEB - BD ——-(3)<br>联立式(2)(3)，有</li>
<li>AB = DB ——-(4)<br>上式表示 DD 到 BB 的距离和 AA 到 BB 的距离是相等的<blockquote>
<p>在慢指针从相遇点 DD 继续向前走 DBDB 个长度，一个新指针从 AA 起始点用同样速度。<br>开始走，两个指针将会在 BB 点相遇，而 BB 点也正是我们想要的相遇点。<br><img src="https://user-images.githubusercontent.com/3156608/70375097-dd4c9980-1934-11ea-85a8-3c63e7246267.png" alt="image"></p>
</blockquote>
</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Floyd求链表中环的入口节点</span></span><br><span class="line"><span class="comment"> * 1.定义快慢指针求相遇点，快指针比慢指针快2倍；</span></span><br><span class="line"><span class="comment"> * 2.在相遇点，定义1个指针从头，1个指针从相遇点，一起开始逐步前进，下次相遇点即为环入口；</span></span><br><span class="line"><span class="comment"> * 时间复杂度：O(n)</span></span><br><span class="line"><span class="comment"> * 空间复杂度：O(1)</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 是否循环链表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">detectCycle</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//寻找相遇</span></span><br><span class="line">    ListNode slow = head.next;</span><br><span class="line">    ListNode fast = head.next.next;</span><br><span class="line">    <span class="keyword">while</span> (slow != fast) &#123;</span><br><span class="line">        <span class="keyword">if</span> (fast == <span class="keyword">null</span> || fast.next == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        slow = slow.next;</span><br><span class="line">        fast = fast.next.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//寻找环入口</span></span><br><span class="line">    ListNode meetSlow = head;</span><br><span class="line">    <span class="keyword">while</span> (meetSlow != fast) &#123;</span><br><span class="line">        fast = fast.next;</span><br><span class="line">        meetSlow = meetSlow.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> meetSlow;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>常用数据结构</title>
    <url>/2019/05/31/2019-6-%E9%93%BE%E8%A1%A8%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>列举常用数据结构：数组、链表、栈、堆、二叉树、红黑树<br><a id="more"></a></p>
<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><blockquote>
<p>链表（Linked List）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针（Pointer）。<br><img src="https://user-images.githubusercontent.com/3156608/70443816-cb552d00-1ad3-11ea-9893-357c395caa20.png" alt="image"><br>由于不必须按顺序存储，链表在插入的时候可以达到O(1) 的复杂度，比另一种线性表 —— 顺序表快得多，但是查找一个节点或者访问特定编号的节点则需要O(n) 的时间，而顺序表相应的时间复杂度分别是O(log n) 和O(1)。</p>
<p>使用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了结点的指针域，空间开销比较大。</p>
<p>在计算机科学中，链表作为一种基础的数据结构可以用来生成其它类型的数据结构。链表通常由一连串节点组成，每个节点包含任意的实例数据（data fields）和一或两个用来指向上一个/或下一个节点的位置的链接（links）。链表最明显的好处就是，常规数组排列关联项目的方式可能不同于这些数据项目在记忆体或磁盘上顺序，数据的访问往往要在不同的排列顺序中转换。而链表是一种自我指示数据类型，因为它包含指向另一个相同类型的数据的指针（链接）。</p>
<p>链表允许插入和移除表上任意位置上的节点，但是不允许随机存取。链表有很多种不同的类型：单向链表，双向链表以及循环链表。</p>
<p>链表通常可以衍生出循环链表，静态链表，双链表等。对于链表使用，需要注意头结点的使用。</p>
</blockquote>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>如何实现扫码登陆</title>
    <url>/2019/09/09/2019-9-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%89%AB%E7%A0%81%E7%99%BB%E9%99%86/</url>
    <content><![CDATA[<p>微信的扫码登陆风行，几乎所有的web端应用都给出了让用户从移动端扫码登入的入口；<br>本文主要描述如何用扫码形式在云端绑定硬件设备；<br><a id="more"></a></p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><ol>
<li>有一台设备，通过序列号确保唯一；</li>
<li>设备需要从云端获取token（长期有效，可重置）后才能与云端通信；</li>
<li>如何让设备获取这个token？</li>
</ol>
<h1 id="常用方案"><a href="#常用方案" class="headerlink" title="常用方案"></a>常用方案</h1><h2 id="方案1-手动绑定"><a href="#方案1-手动绑定" class="headerlink" title="方案1(手动绑定)"></a>方案1(手动绑定)</h2><ol>
<li>用户登陆云端；</li>
<li>用户在云端输入序列号完成设备添加后，获得token；</li>
<li>在设备上手输token，完成云端接入；</li>
<li>token变化后，设备需重新接入；</li>
</ol>
<h2 id="方案2-扫描绑定"><a href="#方案2-扫描绑定" class="headerlink" title="方案2(扫描绑定)"></a>方案2(扫描绑定)</h2><ol>
<li>设备从服务端获取授权sessionId，并以二维码形式展示；</li>
<li>设备等待授权动作（60s超时）；</li>
<li>用户登陆云端；</li>
<li>用户扫描设备二维码，完成绑定设备；</li>
<li>设备收到绑定信号，完成设备绑定；</li>
</ol>
<h2 id="方案比较"><a href="#方案比较" class="headerlink" title="方案比较"></a>方案比较</h2><ol>
<li>方案1的比较原始，设备情况比较复杂，输入困难，不适合手动操作；</li>
<li>方案2将复杂度交给服务端，用户体验上易于接受；</li>
</ol>
<h1 id="实现方案"><a href="#实现方案" class="headerlink" title="实现方案"></a>实现方案</h1><h2 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h2><p><img src="如何实现扫码登陆.png" alt="扫描绑定-时序图"> </p>
<p>要完成扫描绑定，服务端需要实现3个接口：</p>
<ol>
<li>获取二维码接口；</li>
<li>等待二维码授权接口；</li>
<li>二维码授权接口；<br>前2个接口成对使用，供应用入口调用；<br>第3个接口给授权端使用；</li>
</ol>
<h2 id="技术方案"><a href="#技术方案" class="headerlink" title="技术方案"></a>技术方案</h2><ol>
<li>等待二维码授权的长连接，采用<code>redis blocking queue</code>实现（非轮询）；</li>
<li>注意blpop会阻塞占用连接资源，在新的二维码生成时要主动释放；</li>
<li>每个接口的调用要注意防攻击，需对session规则校验，缓存命中校验；</li>
</ol>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><ol>
<li>扫描授权本质上是一个<code>以临时token换区长期token</code>的技术方案；</li>
<li>授权终端一般是微信小程序或者手机App，比PC端更为安全；同时也降低PC端授权开发的复杂度；</li>
</ol>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
  </entry>
  <entry>
    <title>Android平台的串口通信技术</title>
    <url>/2020/01/01/Android%E5%B9%B3%E5%8F%B0%E7%9A%84%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>安卓开发中的串口通信技术<br><a id="more"></a><br><img src="安卓串口通信.png" alt="串口"></p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="串口通信"><a href="#串口通信" class="headerlink" title="串口通信"></a>串口通信</h2><ul>
<li>概念；串口通信（Serial Communications）按位（bit）发送和接收字节。串口可以在使用一根线（Tx）发送数据的同时用另一根线（Rx）接收数据。</li>
<li>实现：通过打开JNI的调用，打开串口。获取串口通信中的输入输出流，通过操作IO流，达到能够利用串口接收数据和发送数据的目的</li>
</ul>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//打开串口</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">native</span> FileDescriptor <span class="title">open</span><span class="params">(String absolutePath, <span class="keyword">int</span> baudrate, <span class="keyword">int</span> dataBits, <span class="keyword">int</span> parity, <span class="keyword">int</span> stopBits, <span class="keyword">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>absolutePath：串口的物理地址，一般硬件工程师都会告诉你的例如ttyS0、ttyS1等，或者通过SerialPortFinder类获取可用的串口地址。</li>
<li>baudrate：串口传输速率，一个设备在一秒钟内发送（或接收）了多少码元的数据，用来衡量数据传输的快慢，<ul>
<li>即单位时间内载波参数变化的次数，如每秒钟传送240个字符，而每个字符格式包含10位（1个起始位，1个停止位，8个数据位），这时的波特率为240Bd，比特率为10位*240个/秒=2400bps。</li>
<li>波特率与距离成反比，波特率越大传输距离相应的就越短。 </li>
</ul>
</li>
<li>dataBits：数据位长度，标准的值是6、7和8位。</li>
<li>parity：奇偶校验位，在串口通信中一种简单的检错方式，0-不校验，1-奇校验，2-偶校验<ul>
<li>对于偶和奇校验的情况，串口会设置校验位（数据位后面的一位），用一个值确保传输的数据有偶个或者奇个逻辑高位。</li>
</ul>
</li>
<li>stopBits：停止位，用于表示单个包的最后一位。标准的值为1或2位。<ul>
<li>由于数据是在传输线上定时的，并且每一个设备有其自己的时钟，很可能在通信中两台设备间出现了小小的不同步。</li>
</ul>
</li>
<li>因此停止位不仅仅是表示传输的结束，并且提供计算机校正时钟同步的机会。</li>
<li>适用于停止位的位数越多，不同时钟同步的容忍程度越大，但是数据传输率同时也越慢。</li>
<li>flags：默认为0，表示可读可写，flags可通过与默认的O_RDWR（可读可写）进行位或计算来设置串口模式<ul>
<li>fd = open(path_utf, O_RDWR | flags);</li>
</ul>
</li>
</ul>
<h2 id="串口文件打开模式"><a href="#串口文件打开模式" class="headerlink" title="串口文件打开模式"></a>串口文件打开模式</h2><ul>
<li>O_RDONLY：以只读方式打开文件</li>
<li>O_WRONLY：以只写方式打开文件</li>
<li>O_RDWR：以读写方式打开文件</li>
<li>O_APPEND：写入数据时添加到文件末尾</li>
<li>O_CREATE：如果文件不存在则产生该文件，使用该标志需要设置访问权限位mode_t</li>
<li>O_EXCL：指定该标志，并且指定了O_CREATE标志，如果打开的文件存在则会产生一个错误</li>
<li>O_TRUNC：如果文件存在并且成功以写或者只写方式打开，则清除文件所有内容，使得文件长度变为0</li>
<li>O_NOCTTY：如果打开的是一个终端设备，这个程序不会成为对应这个端口的控制终端，如果没有该标志，任何一个输入，例如键盘中止信号等，都将影响进程。</li>
<li>O_NONBLOCK：该标志与早期使用的O_NDELAY标志作用差不多。程序不关心DCD信号线的状态，如果指定该标志，进程将一直在休眠状态，直到DCD信号线为0。</li>
</ul>
<blockquote>
<p>实际应用中，都会选择阻塞模式，这样更节省资源。但是如果希望在一个线程中同时进行读写操作，没数据反馈时，线程就会阻塞等待，就无法进行写数据了。</p>
</blockquote>
<h2 id="串口地址"><a href="#串口地址" class="headerlink" title="串口地址"></a>串口地址</h2><p>如下表不同操作系统的串口地址，Android是基于Linux的所以一般情况下使用Android系统的设备串口地址为/dev/ttyS0…</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>System</th>
<th>Port 1</th>
<th>Port 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>IRIX®</td>
<td>/dev/ttyf1</td>
<td>/dev/ttyf2</td>
</tr>
<tr>
<td>HP-UX</td>
<td>/dev/tty1p0</td>
<td>/dev/tty2p0</td>
</tr>
<tr>
<td>Solaris®/SunOS®</td>
<td>/dev/ttya</td>
<td>/dev/ttyb</td>
</tr>
<tr>
<td>Linux®</td>
<td>/dev/ttyS0</td>
<td>/dev/ttyS1</td>
</tr>
<tr>
<td>Digital UNIX®</td>
<td>/dev/tty01</td>
<td>/dev/tty02</td>
</tr>
</tbody>
</table>
</div>
<h1 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h1><ul>
<li>Android移植谷歌官方串口库支持校验位、数据位、停止位、流控配置：<a href="https://juejin.im/post/5c010a19e51d456ac27b40fc">https://juejin.im/post/5c010a19e51d456ac27b40fc</a></li>
<li>windows友善串口调试工具: <a href="http://www.darkwood.me/serialport/">http://www.darkwood.me/serialport/</a></li>
<li>Google开源的Android串口通信Demo：<a href="https://github.com/licheedev/Android-SerialPort-API">https://github.com/licheedev/Android-SerialPort-API</a></li>
</ul>
]]></content>
      <categories>
        <category>移动端</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android集成bugly异常监控插件</title>
    <url>/2019/12/31/Android%E9%9B%86%E6%88%90bugly%E5%BC%82%E5%B8%B8%E7%9B%91%E6%8E%A7%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>安卓开发中的异常监控方案-Bugly<br><a id="more"></a> </p>
<h1 id="bugly集成"><a href="#bugly集成" class="headerlink" title="bugly集成"></a>bugly集成</h1><p>主程序中集成bugly<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainApplication</span> <span class="keyword">extends</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.onCreate();</span><br><span class="line">        initBugly();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 初始化bugly</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initBugly</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    CrashReport.UserStrategy strategy = <span class="keyword">new</span> CrashReport.UserStrategy(getApplicationContext());</span><br><span class="line">    strategy.setAppVersion(BuildConfig.APPLICATION_ID);</span><br><span class="line">    strategy.setAppPackageName(BuildConfig.VERSION_NAME);</span><br><span class="line">    strategy.setDeviceID(ZqznFaceSDK.getDeviceIdNotSafe());</span><br><span class="line">    <span class="comment">//Bugly会在启动20s后联网同步数据</span></span><br><span class="line">    strategy.setAppReportDelay(<span class="number">20000</span>);</span><br><span class="line">    CrashReport.initCrashReport(getApplicationContext(), getString(R.string.bugly_app_id), <span class="keyword">true</span>);</span><br><span class="line">    CrashReport.setUserId(<span class="keyword">this</span>, ZqznFaceSDK.getDeviceIdNotSafe());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="符号表集成"><a href="#符号表集成" class="headerlink" title="符号表集成"></a>符号表集成</h1><h2 id="什么是符号表？"><a href="#什么是符号表？" class="headerlink" title="什么是符号表？"></a>什么是符号表？</h2><blockquote>
<p>符号表是内存地址与函数名、文件名、行号的映射表。符号表元素如下所示：<br>&lt;起始地址&gt; &lt;结束地址&gt; &lt;函数&gt; [&lt;文件名: 行号&gt;]</p>
</blockquote>
<h2 id="为什么要配置符号表"><a href="#为什么要配置符号表" class="headerlink" title="为什么要配置符号表"></a>为什么要配置符号表</h2><blockquote>
<p>为了能快速并准确地定位用户APP发生Crash的代码位置，Bugly使用符号表对APP发生Crash的程序``堆栈进行解析和还原。</p>
</blockquote>
<h2 id="配置全局build-gradle"><a href="#配置全局build-gradle" class="headerlink" title="配置全局build.gradle"></a>配置全局build.gradle</h2><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">buildscript</span> &#123;</span><br><span class="line">    <span class="keyword">repositories</span> &#123;</span><br><span class="line">        maven &#123;</span><br><span class="line">            url <span class="string">'https://maven.aliyun.com/repository/google'</span></span><br><span class="line">        &#125;</span><br><span class="line">        maven &#123;</span><br><span class="line">            url <span class="string">'https://maven.aliyun.com/repository/jcenter'</span></span><br><span class="line">        &#125;</span><br><span class="line">        maven &#123;</span><br><span class="line">            url <span class="string">'http://172.26.12.78:8081/repository/zqzn-release/'</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">dependencies</span> &#123;</span><br><span class="line">        <span class="keyword">classpath</span> <span class="string">'com.android.tools.build:gradle:3.5.1'</span></span><br><span class="line">        <span class="comment">//bugly symbol uploader</span></span><br><span class="line">        <span class="keyword">classpath</span> <span class="string">'com.tencent.bugly:symtabfileuploader:2.2.1'</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="配置项目build-gradle"><a href="#配置项目build-gradle" class="headerlink" title="配置项目build.gradle"></a>配置项目build.gradle</h2><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">apply plugin: <span class="string">'bugly'</span></span><br><span class="line">bugly &#123;</span><br><span class="line">    appId = <span class="string">'xxx'</span></span><br><span class="line">    appKey = <span class="string">'xxx'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>移动端</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>Hbase背景知识</title>
    <url>/2020/01/02/Hbase%E7%9A%84%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>介绍Hbase出场背景、解决问题、应用场景</p>
<blockquote>
<p>Hbase是山寨Google的Bigtable的开源、分布式、列数据库，可以解决海量数据的存储问题，适用于需要随机、实时读/写的场景；<br><a id="more"></a></p>
</blockquote>
<h1 id="官方Hbase简介"><a href="#官方Hbase简介" class="headerlink" title="官方Hbase简介"></a>官方Hbase简介</h1><blockquote>
<p>Use Apache HBase™ when you need random, realtime read/write access to your Big Data.<br>当需对大数据进行<code>随机</code>，<code>实时读/写</code>时采用Hbase；</p>
<p>This project’s goal is the hosting of very large tables — billions of rows X millions of columns — atop clusters of commodity hardware.<br>Hbase项目的目标是在集群中存储<code>数十亿行</code>，<code>数百万列</code>的超级大表；</p>
<p>Apache HBase is an open-source, distributed, versioned, <strong>non-relational database</strong> modeled after Google’s <a href="https://research.google.com/archive/bigtable.html">Bigtable: A Distributed Storage System for Structured Data</a> by Chang et al.<br>Hbase是一个开源的分布式的<code>非关系型</code>数据库，其数据模型是基于Google的Bigtable论文（结构化数据的分布式存储系统）开发的；</p>
<p>Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides <strong>Bigtable-like capabilities</strong> on top of Hadoop and HDFS.<br>正如Google的Bigtable用Google文件系统分布式存储数据，Hbase基于Hadoop的<code>HDFS(Hadoop File System)</code>来存储海量数据；</p>
<p>一句话：Hbase是山寨Google的Bigtable的开源、分布式、列数据库，可以解决海量数据的存储问题，适用于需要随机、实时读/写的场景；</p>
</blockquote>
<h1 id="Hbase的出场背景"><a href="#Hbase的出场背景" class="headerlink" title="Hbase的出场背景"></a>Hbase的出场背景</h1><p>HBase 是Powerset在2007年创建的，最初是Hadoop的一部分。之后，它逐渐成为Apache软件基金会旗下的顶级项目，具备Apache软件许可证，版本为2.0。 </p>
<blockquote>
<p>下面是一个HBase随时间发展的简短概述：<br>2006年11月：Google发布BigTable论文。<br>2007年2月：HBase宣布在Hadoop项目中成立。<br>2007年10月：HBase第一个“可用”版本（Hadoop 0.15.0）。<br>2008年1月：Hadoop成为Apache的顶级项目，HBase成为Hadoop的子项目。<br>2008年10月：Hadoop 0.18.1发布。<br>2009年1月：HBase 0.19.0发布。<br>2009年9月：HBase0.20.0发布，性能有明显提升。<br>2010年5月：HBase成为Apache的顶级项目。<br>2010年6月：HBase 0.89.20100621，第一个开发版本。<br>2011年1月：HBase 0.90.0发布，稳定性和持续性有所提升。<br>2011年年中：HBase 0.92.0发布，支持协议处理器和安全控制。<br>2010年5月前后，HBase的开发者决定打破一直依赖的、步调一致的Hadoop的版本编号。原因是HBase有一个更快的发布周期，同时更接近1.0版本的水平，比Hadoop的预期更快。<br>为此，版本号从0.20.x跳到了0.89.x，跳跃相当明显。此外，还做了一个决定，将0.89.x定为早期的开发版本。在0.89的基础上最终发布了0.90，即面向所有用户的稳定版。 </p>
<p>Powerset<br>公司位于旧金山，开发了一套用于互联网的自然语言搜索引擎。在2008年7越1日，微软公司收购了Powerset，之后Powerset放弃了对HBase开发的后续支持。</p>
</blockquote>
<h1 id="Hbase解决的问题"><a href="#Hbase解决的问题" class="headerlink" title="Hbase解决的问题"></a>Hbase解决的问题</h1><p>传统关系数据库的设计不能满足海量数据的读写需求：扩容问题、写单点问题；</p>
<p>Hbase的特点：</p>
<ul>
<li>可动态扩容，Hadoop/HDFS Integration</li>
<li>强一致性读写， Strongly consistent reads/writes</li>
<li>自动分片， Automatic sharding</li>
<li>失败自动切换，Automatic RegionServer failover</li>
</ul>
<h2 id="Hbase与Hive的关系"><a href="#Hbase与Hive的关系" class="headerlink" title="Hbase与Hive的关系"></a>Hbase与Hive的关系</h2><blockquote>
<p>联系</p>
</blockquote>
<ul>
<li>Hbase和Hive都是Hadoop生态中的重要组件，数据都是存储在HDFS上的；</li>
</ul>
<blockquote>
<p>区别</p>
</blockquote>
<ul>
<li>Hive时效性在秒-分钟级别，适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志；HiveSQL的执行可以基于Spark或者MapReduce；</li>
<li>HBase时效性在毫秒（100ms）级别，适合<code>准实时查询</code>，例如 Facebook 用 HBase 进行消息和实时的分析。Hbase可以基于Phoenix SQL访问；</li>
</ul>
<h2 id="Hbase与RDBMS的区别"><a href="#Hbase与RDBMS的区别" class="headerlink" title="Hbase与RDBMS的区别"></a>Hbase与RDBMS的区别</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">HBase</th>
<th>RDBMS</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">硬件架构</td>
<td style="text-align:left">类似于 Hadoop 的分布式集群，硬件成本低廉</td>
<td>传统的多核系统，硬件成本昂贵</td>
</tr>
<tr>
<td style="text-align:left">容错性</td>
<td style="text-align:left">由软件架构实现，由于由多个节点组成，<br />所以不担心一点或几点宕机</td>
<td>一般需要额外硬件设备实现 HA 机制</td>
</tr>
<tr>
<td style="text-align:left">数据库大小</td>
<td style="text-align:left">PB</td>
<td>GB、TB</td>
</tr>
<tr>
<td style="text-align:left">数据排布方式</td>
<td style="text-align:left">稀疏的、分布的多维的 Map</td>
<td>以行和列组织</td>
</tr>
<tr>
<td style="text-align:left">数据类型</td>
<td style="text-align:left">Bytes</td>
<td>丰富的数据类型</td>
</tr>
<tr>
<td style="text-align:left">事物支持</td>
<td style="text-align:left">ACID 只支持单个 Row 级别</td>
<td>全面的 ACID 支持，对 Row 和表</td>
</tr>
<tr>
<td style="text-align:left">查询语言</td>
<td style="text-align:left">只支持 Java API <br />（除非与其他框架一起使用，如 Phoenix、Hive）</td>
<td>SQL</td>
</tr>
<tr>
<td style="text-align:left">索引</td>
<td style="text-align:left">只支持 Row-key，<br />除非与其他技术一起应用，如 Phoenix、Hive</td>
<td>支持</td>
</tr>
<tr>
<td style="text-align:left">吞吐量</td>
<td style="text-align:left">百万查询/每秒</td>
<td>数千查询/每秒</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Hbase的适用场景"><a href="#Hbase的适用场景" class="headerlink" title="Hbase的适用场景"></a>Hbase的适用场景</h1><ol>
<li><code>写密集型</code>应用：每天写多读少的应用，比如IM的历史消息，游戏的日志；</li>
<li>查询场景明确且简单，如扫描一条记录或根据rowkey进行前缀扫描，因此Hbase需要根据查询需求设计RowKey；</li>
<li>对性能和<code>可靠性</code>要求非常高的应用，由于HBase本身没有单点故障，<code>可用性</code>非常高。</li>
<li>数据量较大，而且<code>增长量</code>无法预估的应用，HBase支持在线扩展，即使在一段时间内数据量呈井喷式增长，也可以通过HBase<code>横向扩展</code>来满足功能。</li>
</ol>
<h1 id="Hbase的限制场景"><a href="#Hbase的限制场景" class="headerlink" title="Hbase的限制场景"></a>Hbase的限制场景</h1><ul>
<li><p>不适合以<code>复杂查询条件</code>来查询数据的应用，原生HBase只支持基于rowkey的查询，对于HBase来说，单条记录或者小范围的查询是可以接受的，大范围的查询由于<code>分布式</code>的原因，在性能上没有保障；</p>
</li>
<li><p>不适合<code>事务要求高</code>的应用，如多表Join查询</p>
</li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker安装ETCD服务</title>
    <url>/2020/03/27/Docker%E5%AE%89%E8%A3%85ETCD%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p>记录docker容器安装etcd，以及etcd的日常使用命令<br><a id="more"></a>  </p>
<h1 id="制作etcd-docker镜像"><a href="#制作etcd-docker镜像" class="headerlink" title="制作etcd docker镜像"></a>制作etcd docker镜像</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">FROM alpine:latest</span><br><span class="line"></span><br><span class="line">ADD etcd /usr/local/bin/</span><br><span class="line">ADD etcdctl /usr/local/bin/</span><br><span class="line">RUN mkdir -p /var/etcd/</span><br><span class="line">RUN mkdir -p /var/lib/etcd/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Alpine Linux doesn<span class="string">'t use pam, which means that there is no /etc/nsswitch.conf,</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> but Golang relies on /etc/nsswitch.conf to check the order of DNS resolving</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (see https://github.com/golang/go/commit/9dee7771f561cf6aee081c0af6658cc81fac3918)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> To fix this we just create /etc/nsswitch.conf and add the following line:</span></span><br><span class="line">RUN echo 'hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4' &gt;&gt; /etc/nsswitch.conf</span><br><span class="line"></span><br><span class="line">EXPOSE 2379 2380</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Define default <span class="built_in">command</span>.</span></span><br><span class="line">CMD ["/usr/local/bin/etcd"]</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载etcd Releases </span></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.4.5/etcd-v3.4.5-linux-amd64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压文件</span></span><br><span class="line">tar -zxvf etcd-v3.4.5-linux-amd64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将etcd和etcdctl移动到和dockerfile同级目录</span></span><br><span class="line">mv etcd-v3.4.5-linux-amd64/etcd etcd-v3.4.5-linux-amd64/etcdctl -t ./</span><br><span class="line"><span class="meta">#</span><span class="bash"> 构建etcd镜像</span></span><br><span class="line">docker build -t etcd .</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看构建好的镜像</span></span><br><span class="line">docker images</span><br></pre></td></tr></table></figure>
<h1 id="启动-etcd-docker实例"><a href="#启动-etcd-docker实例" class="headerlink" title="启动 etcd docker实例"></a>启动 etcd docker实例</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d -v /usr/share/ca-certificates/:/etc/ssl/certs \</span><br><span class="line"> -p 4001:4001 -p 2380:2380 -p 2379:2379 \</span><br><span class="line"> --name etcd etcd /usr/local/bin/etcd \</span><br><span class="line"> -name etcd0 \</span><br><span class="line">--data-dir /etcd-data \</span><br><span class="line">--enable-v2=true \</span><br><span class="line">-advertise-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">-listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">-initial-advertise-peer-urls http://0.0.0.0:2380 \</span><br><span class="line">-listen-peer-urls http://0.0.0.0:2380 \</span><br><span class="line">-initial-cluster-token etcd-cluster-1 \</span><br><span class="line">-initial-cluster etcd0=http://0.0.0.0:2380 \</span><br><span class="line">-initial-cluster-state new \</span><br><span class="line">--log-level info \</span><br><span class="line">--logger zap \</span><br><span class="line">--log-outputs stderr</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看状态</span></span><br><span class="line">curl http://127.0.0.1:2379/version</span><br><span class="line">curl -L http://127.0.0.1:2379/health</span><br></pre></td></tr></table></figure>
<h1 id="验证etcd-http服务"><a href="#验证etcd-http服务" class="headerlink" title="验证etcd http服务"></a>验证etcd http服务</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 插入kv</span></span><br><span class="line">curl http://127.0.0.1:2379/v2/keys/message -XPUT -d value="Hello world"</span><br><span class="line">curl http://192.168.135.3:2379/v3/keys/message</span><br><span class="line">curl http://127.0.0.1:2379/v2/stats/store</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>ETCD</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>单链表区间反转</title>
    <url>/2019/05/31/2019-6-%E5%8D%95%E9%93%BE%E8%A1%A8%E5%8C%BA%E9%97%B4%E5%8F%8D%E8%BD%AC/</url>
    <content><![CDATA[<blockquote>
<p>反转从位置 m 到 n 的链表。请使用一趟扫描完成反转。<br>说明: 1 ≤ m ≤ n ≤ 链表长度。<br>示例:<br>输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, m = 2, n = 4<br>输出: 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;NULL</p>
</blockquote>
<a id="more"></a>
<h1 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h1><ol>
<li>反转[m,n]之间的子链表：需记录m的前一个节点，n的后一个节点</li>
<li>反转后链表插入原链表；</li>
</ol>
<blockquote>
<p>涉及单链表的按索引查找元素，插入，删除操作知识</p>
</blockquote>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">reverseBetween</span><span class="params">(ListNode head, <span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">       ListNode dummy = <span class="keyword">new</span> ListNode(-<span class="number">1</span>);</span><br><span class="line">       dummy.next = head;</span><br><span class="line">       <span class="comment">//遍历指针</span></span><br><span class="line">       ListNode cur = dummy;</span><br><span class="line">       <span class="comment">//找到m-n之间的节点，并反转</span></span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; m; i++) &#123;</span><br><span class="line">           cur = cur.next;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//m的后1个节点，反转后即为尾部的前一个节点</span></span><br><span class="line">       ListNode  last = cur.next;</span><br><span class="line">       <span class="comment">//m的前1个节点</span></span><br><span class="line">       ListNode front= cur;</span><br><span class="line">       <span class="comment">//反转的临时变量</span></span><br><span class="line">       ListNode pre= <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = m; i &lt;= n; i++) &#123;</span><br><span class="line">           cur = front.next;</span><br><span class="line">           front.next = cur.next;</span><br><span class="line">           cur.next = pre;</span><br><span class="line">           pre= cur;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//尾部：取n的后一个节点</span></span><br><span class="line">       cur= front.next;</span><br><span class="line">       <span class="comment">//插入反转后的链表</span></span><br><span class="line">       front.next = pre;</span><br><span class="line">       <span class="comment">//衔接尾部</span></span><br><span class="line">       last.next= cur;</span><br><span class="line">       <span class="keyword">return</span> dummy.next;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>判断单链表中是否有环</title>
    <url>/2019/05/31/2019-6-%E5%88%A4%E6%96%AD%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%AD%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF/</url>
    <content><![CDATA[<blockquote>
<p> 给定一个链表，判断链表中是否有环。<br>为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。<br><a id="more"></a></p>
</blockquote>
<h2 id="HashSe判断单链表中是否有环"><a href="#HashSe判断单链表中是否有环" class="headerlink" title="HashSe判断单链表中是否有环"></a>HashSe判断单链表中是否有环</h2><ul>
<li>时间复杂度：O(n)，对于含有 n 个元素的链表，我们访问每个元素最多一次。添加一个结点到哈希表中只需要花费 O(1) 的时间。</li>
<li>空间复杂度：O(n)，空间取决于添加到哈希表中的元素数目，最多可以添加 n 个元素。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 链表中是否有环</span></span><br><span class="line"><span class="comment"> * 1.定义HashSet存储链表节点</span></span><br><span class="line"><span class="comment"> * 2.遍历链表，如果链表的下一个节点存在链表中，则表示存在环，返回true</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 链表头节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 是否循环链表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">hasCycle3</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    HashSet&lt;ListNode&gt; nodes = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">while</span> (head != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (nodes.contains(head)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            nodes.add(head);</span><br><span class="line">        &#125;</span><br><span class="line">        head = head.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="快慢指针判断单链表中是否有环"><a href="#快慢指针判断单链表中是否有环" class="headerlink" title="快慢指针判断单链表中是否有环"></a>快慢指针判断单链表中是否有环</h2><ul>
<li>空间复杂度：O(1)，使用了慢指针和快指针两个结点，所以空间复杂度为 O(1)。</li>
<li>时间复杂度：O(n)，将 n 设为链表中结点的总数。</li>
</ul>
<p>为了分析<code>时间复杂度</code>，分别考虑下面两种情况。</p>
<ol>
<li><code>链表中不存在环</code>：快指针将会首先到达尾部，其时间取决于列表的长度，也就是 O(n)。</li>
<li><code>链表中存在环</code>：将慢指针的移动过程划分为两个阶段：非环部分与环形部分：<ul>
<li>慢指针在走完<code>非环部分</code>阶段后将进入环形部分：此时快指针已经进入环中，迭代次数=非环部分长度=N；</li>
<li>两个指针都在<code>环形区域</code>中：需要经过 {二者之间距离}/{速度差值}次循环后，快指针可以追上慢指针<br>这个距离几乎就是 {环形部分长度 K}，我们得出这样的结论{迭代次数} = {环形部分长度 K}<br>所以总时间复杂度为 <code>O(N+K)</code>，也就是 O(n)。</li>
</ul>
</li>
</ol>
<p>```java<br>    /**</p>
<pre><code> * 链表中是否有环
 * 1.定义2个哨兵节点指向链表head，快指针比慢指针快2步
 * 2.遍历链表，当快指针指想=向链表head时，返回true
 *
 * @param head 链表头节点
 * @return 是否循环链表
 */
public static boolean hasCycle(ListNode head) {
    if (head == null || head.next == null) {
        return false;
    }
    ListNode s = head;
    ListNode q = head.next;
    while (s != q) {
        if (q == null || q.next == null) {
            return false;
        }
        s = s.next;
        q = q.next.next;
    }
    return true;
}

/**
 * 链表中是否有环
 * 1.定义2个哨兵节点指向链表head，快指针比慢指针快2步
 * 2.遍历链表，当快指针指想=向链表head时，返回true；快指针到达链尾，则无环终止
 *
 * @param head 链表头节点
 * @return 是否循环链表
 */
public static boolean hasCycle2(ListNode head) {
    ListNode dummy = new ListNode(-1);
    dummy.next = head;
    ListNode s = dummy;
    ListNode q = dummy.next;

    while (q != null) {
        if (s == q) {
            return true;
        }
        //快指针到达链尾，无环终止
        if (q.next == null) {
            break;
        }
        s = s.next;
        q = q.next.next;
    }
    return false;
}
</code></pre><p>```java </p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker的安装与使用</title>
    <url>/2020/03/26/Docker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>记录docker的安装部署和日常使用命令<br><a id="more"></a>  </p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="确认系统版本"><a href="#确认系统版本" class="headerlink" title="确认系统版本"></a>确认系统版本</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.7.1908 (Core)</span><br></pre></td></tr></table></figure>
<h2 id="配置yum"><a href="#配置yum" class="headerlink" title="配置yum"></a>配置yum</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>
<p>如果出现dns解析问题，在网卡配置加上dns服务器配置<br>vi /etc/sysconfig/network-scripts/ifcfg-eth0<br>文末添加<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=8.8.4.4</span><br></pre></td></tr></table></figure><br>service network restart</p>
<h1 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum update</span><br><span class="line">sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加docker的yum源</span></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更新yum</span></span><br><span class="line">sudo yum update</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装docker</span></span><br><span class="line">sudo yum install docker-ce</span><br></pre></td></tr></table></figure>
<h1 id="配置docker"><a href="#配置docker" class="headerlink" title="配置docker"></a>配置docker</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 加入 docker 用户组命令</span></span><br><span class="line">sudo usermod -aG docker geolab</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开机启动</span></span><br><span class="line">sudo systemctl enable docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动docker</span></span><br><span class="line">sudo systemctl start docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证docker</span></span><br><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
<h2 id="配置阿里云镜像加速"><a href="#配置阿里云镜像加速" class="headerlink" title="配置阿里云镜像加速"></a>配置阿里云镜像加速</h2><p>关于加速器的地址，登陆<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors">阿里云控制台</a>获取<br>添加以下内容<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [<span class="string">"address"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br><span class="line"><span class="comment"># 将 --registry-mirror 加入到你的 Docker 配置文件</span></span><br><span class="line">curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">service docker restart</span><br></pre></td></tr></table></figure>
<h1 id="docker常用命令"><a href="#docker常用命令" class="headerlink" title="docker常用命令"></a>docker常用命令</h1><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1>]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>删除链表的倒数第N个元素</title>
    <url>/2019/05/31/2019-6-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%ACN%E4%B8%AA%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<p>给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。<br><a id="more"></a></p>
<h1 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h1><p>查找复杂度O(n)，删除O(1)，新增O(1)，<br>实际生产中，一般使用双向链表，空间换时间，但更实用；<br>比如这个查找倒数第n个节点的问题，</p>
<ul>
<li>单链表需要2个指针以不同速度遍历1次实现，或者是需要完全遍历2次；</li>
<li>双向链表只需遍历1次到达尾节点，再往前遍历n次就可以完成任务；</li>
</ul>
<h1 id="2个指针删除倒数第N个元素的复杂度"><a href="#2个指针删除倒数第N个元素的复杂度" class="headerlink" title="2个指针删除倒数第N个元素的复杂度"></a>2个指针删除倒数第N个元素的复杂度</h1><ul>
<li>时间复杂度：O(L)，该算法对含有 L个结点的列表进行了一次遍历。</li>
<li>空间复杂度：O(1)，只用了常量级的额外空间。</li>
</ul>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 2次遍历删倒数第n个节点，即删L-n+1个节点，转换为寻找L-n节点问题</span></span><br><span class="line"><span class="comment"> * 第1次遍历获得链表长度L，L-n+1即为要删的节点</span></span><br><span class="line"><span class="comment"> * 第2次遍历到第L-n节点，指向L-n+1.next节点，即完成删除L-n+1节点；</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 头节点指针</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> n    倒数第n个节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 头部指针</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">removeNthFromEnd2</span><span class="params">(ListNode head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">    dummy.next = head;</span><br><span class="line">    ListNode p = dummy;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (p.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">        p = p.next;</span><br><span class="line">        len++;</span><br><span class="line">    &#125;</span><br><span class="line">    p = dummy;</span><br><span class="line">    len -= n;</span><br><span class="line">    <span class="keyword">while</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        len--;</span><br><span class="line">        p = p.next;</span><br><span class="line">    &#125;</span><br><span class="line">    p.next = p.next.next;</span><br><span class="line">    <span class="keyword">return</span> dummy.next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 快慢指针，遍历一次，设链表长度为L，删倒数第n个节点，即删L-n+1个节点，转换为寻找L-n节点问题</span></span><br><span class="line"><span class="comment"> * 链表头部新增1个虚拟节点指向头节点，快q慢s指针都从虚拟节点开始；</span></span><br><span class="line"><span class="comment"> * 1.从虚拟节点开始遍历，s指针比q指针慢n+1步（间隔n个节点）</span></span><br><span class="line"><span class="comment"> * 2.快指针q到达链表尾部(null)时，慢指针s到达倒数第L-n个节点</span></span><br><span class="line"><span class="comment"> * 3.将第L-n个节点的next指向第L-n+1.next，即完成删除第L-n+1个节点；</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> head 头节点指针</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> n    倒数第n个节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 头部指针</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">removeNthFromEnd</span><span class="params">(ListNode head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//虚拟结点，用来简化某些极端情况，例如列表中只含有一个结点，或需要删除列表的头部。</span></span><br><span class="line">    ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">    dummy.next = head;</span><br><span class="line">    ListNode q = dummy;</span><br><span class="line">    ListNode s = dummy;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n + <span class="number">1</span>; i++) &#123;</span><br><span class="line">        q = q.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (q != <span class="keyword">null</span>) &#123;</span><br><span class="line">        s = s.next;</span><br><span class="line">        q = q.next;</span><br><span class="line">    &#125;</span><br><span class="line">    s.next = s.next.next;</span><br><span class="line">    <span class="keyword">return</span> dummy.next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***</span></span><br><span class="line"><span class="comment"> * 根据数组构建链表</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> vals 数组</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 链表头节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ListNode <span class="title">newSingleLinkedList</span><span class="params">(<span class="keyword">int</span>[] vals)</span> </span>&#123;</span><br><span class="line">    ListNode[] nodes;</span><br><span class="line">    nodes = <span class="keyword">new</span> ListNode[vals.length];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; vals.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (nodes[i] == <span class="keyword">null</span>) &#123;</span><br><span class="line">            nodes[i] = <span class="keyword">new</span> ListNode(vals[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; vals.length - <span class="number">1</span>) &#123;</span><br><span class="line">            nodes[i + <span class="number">1</span>] = <span class="keyword">new</span> ListNode(vals[i + <span class="number">1</span>]);</span><br><span class="line">            nodes[i].next = nodes[i + <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodes[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***</span></span><br><span class="line"><span class="comment"> * 单链表节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ListNode</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    ListNode next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ListNode</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.val = val;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printNode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ListNode printNode = <span class="keyword">this</span>;</span><br><span class="line">        StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">while</span> (printNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            sb.append(<span class="string">"--&gt;"</span>).append(printNode.val);</span><br><span class="line">            printNode = printNode.next;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sb);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>IO复用模型之Reactor</title>
    <url>/2020/03/23/IO%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B%E4%B9%8BReactor/</url>
    <content><![CDATA[<p>要学Netty，得先从IO模型入手，一点点来。从Unix系统的5个IO模型，JDK的3种IO模型，Reactor模式的3种实现，最后到Netty事件模型的3种实现。</p>
<p>本文主要搞清楚什么是Reactor模式？为什么要有Reactor模式？以及Reactor模式具体的3种实现方式是什么样的？</p>
<a id="more"></a>  
<h1 id="什么是Reactor模式？"><a href="#什么是Reactor模式？" class="headerlink" title="什么是Reactor模式？"></a>什么是Reactor模式？</h1><p>Wiki上Reactor模式的描述</p>
<blockquote>
<p>The reactor design pattern is an <a href="https://en.wikipedia.org/wiki/Event_handling">event handling</a> pattern for handling service requests delivered concurrently  to a service handler by one or more inputs.<br>The service handler then <a href="https://en.wikipedia.org/wiki/Demultiplex">demultiplexes</a> the incoming requests and dispatches them synchronously to the associated request handlers.</p>
</blockquote>
<ul>
<li>Reactor核心重点是：有多路复用的组件来支持并发，事件驱动，并且不同事件有对应的处理器；</li>
<li>Reactor模式本质是Unix系统5种I/O模型中的<strong>I/O复用(multiplexing)模型</strong>；</li>
</ul>
<p>JUC作者<code>Doug Lea</code> 在 《Scalable IO in Java 》中的介绍，Reacotr模型主要分为3个角色:</p>
<ol>
<li><strong>Reactor</strong>：把IO事件分配给对应的Handler处理</li>
<li><strong>Acceptor</strong>：处理客户端连接事件</li>
<li><strong>Handler</strong>：处理非阻塞的任务</li>
</ol>
<p>另外注意<code>Reactor</code>这个名词用到的地方比较多：</p>
<ul>
<li>Spring5的Reactor 反应式编程；</li>
<li>Node.js中用到的设计模式-Reactor Pattern（反应器模式）;</li>
<li>Netty中的ReactorI/O模型；</li>
</ul>
<p>我们这儿说的Reactor是指后面的2个相关，I/O事件模型相关的，和反应式编程不是一回事；</p>
<h1 id="为什么有Reactor模式？"><a href="#为什么有Reactor模式？" class="headerlink" title="为什么有Reactor模式？"></a>为什么有Reactor模式？</h1><p><img src="阻塞IO.jpg" alt="阻塞IO"></p>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><p>Reactor模式的出现原因要结合Unix系统的5个IO模型中提到的<code>阻塞IO</code>来说</p>
<p><strong>传统的阻塞IO模型的不足</strong></p>
<ol>
<li>每个连接都需要独立线程处理，但线程数受系统现在数多，所以<code>并发能力有限</code>，资源利用率低；</li>
<li>采用阻塞IO模型，连接建立后，若当前线程没有数据可读，线程会阻塞在读操作上，造成<code>资源浪费</code>；</li>
</ol>
<p>针对传统阻塞IO模型的两个问题，可以采用如下的方案进行优化</p>
<ol>
<li>基于<code>池化思想</code>，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理；</li>
<li>基于<code>IO复用模型</code>，多个连接共用同一个阻塞对象，不用等待所有的连接。遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理；</li>
</ol>
<p>Reactor线程模型的思想就是基于IO复用和线程池的结合体；</p>
<p>一般一个网络请求的数据处理过程包含：accept、read、decode、compute、encode、send；</p>
<p>按照分而治之的思想，可以将accept，read，send按需设计成独立的模块，<code>decode、compute、encode</code>内聚性比较强，可以作为数据处理单元用池化的思路来并行处理；</p>
<p>下面3种reactor模式就是不同拆分级别的优化；</p>
<h1 id="Reactor模式的3种实现"><a href="#Reactor模式的3种实现" class="headerlink" title="Reactor模式的3种实现"></a>Reactor模式的3种实现</h1><h2 id="单Reactor单线程"><a href="#单Reactor单线程" class="headerlink" title="单Reactor单线程"></a>单Reactor单线程</h2><p><img src="单Reactor单线程.jpg" alt="单Reactor单线程"></p>
<p>这种模型在Reactor中处理事件，并分发事件，如果是连接事件交给<code>acceptor</code>处理，如果是读写事件和业务处理就交给<code>handler</code>处理，但始终只有1个线程执行所有的事情；</p>
<p>单Reactor单线程模型的不足</p>
<ol>
<li>仅用1个线程处理请求，浪费多核机器的CPU资源；</li>
<li>单线程处理所有的读写任务，当线程负载过高后，处理速度下降，事件会堆积，严重的会超时，可能导致客户端重新发送请求，性能越来越差；</li>
<li>单线程会有可靠性的问题；</li>
</ol>
<p>针对上面的种种不足，就有了下面的单Reactor多线程模型：</p>
<blockquote>
<p>服务员解释Reactor：一个人既当接待员又做服务员，适合客流量少的场景；</p>
</blockquote>
<h2 id="单Reactor多线程"><a href="#单Reactor多线程" class="headerlink" title="单Reactor多线程"></a>单Reactor多线程</h2><p><img src="单Reactor多线程.jpg" alt="单Reactor多线程"></p>
<p>与单Reactor单线程相比，新增了池化手段，也就是Reactor线程只处理<code>accept,read,send</code>事件，耗资源的业务处理（<code>decode、compute、encode</code>）交给线程池处理，充分利用多核机器的资源、提高性能并且增加可靠性；</p>
<p>单Reactor多线程模型的不足：</p>
<p>Reactor线程承担所有的事件，例如监听和响应，<code>高并发场景</code>下单线程存在性能问题；</p>
<blockquote>
<p>服务员解释Reactor：1个接待员，n个服务员，适合中等流量的场景；</p>
</blockquote>
<h2 id="多Reactor多线程"><a href="#多Reactor多线程" class="headerlink" title="多Reactor多线程"></a>多Reactor多线程</h2><p><img src="多Reactor多线程.jpg" alt="多Reactor多线程"></p>
<p>与单Reactord多线程相比，把Reactor线程拆分了mainReactor和subReactor两个部分，mainReactor只处理连接事件（<code>accept</code>），读写事件（<code>read,send</code>）交给subReactor来处理。业务逻辑还是由线程池来处理；</p>
<ul>
<li>mainRactor只处理连接事件，用一个线程来处理就好；</li>
<li>处理读写事件的subReactor个数一般和CPU数量相等，一个subReactor对应一个线程；</li>
<li>耗资源的业务逻辑由线程池处理；</li>
</ul>
<p>这种模型使各个模块职责单一，耦合度低，性能和稳定性都有提高；</p>
<p>这种模型在许多项目中广泛应用，比如Netty的主从线程模型等；</p>
<blockquote>
<p>服务员解释Reactor：n个接待员，n个服务员，适合高并发流量的场景；</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">《Scalable IO in Java》-Doug Lea</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark作业的执行过程</title>
    <url>/2020/03/11/Spark%E4%BD%9C%E4%B8%9A%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>一个数据处理过程一般可划分为3个大的阶段：获取数据源，执行数据预处理，执行指标计算，输出处理结果；</p>
<p>那Spark的一个离线计算的作业执行流程是什么样的呢？</p>
<a id="more"></a> 
<h1 id="数据源获取"><a href="#数据源获取" class="headerlink" title="数据源获取"></a>数据源获取</h1><p>spark的数据源</p>
<h2 id="hdfs文件"><a href="#hdfs文件" class="headerlink" title="hdfs文件"></a>hdfs文件</h2><p>如json,csv,parquet等格式的数据源都可以直接读取为DataSet;<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Dataset&lt;Row&gt; people = spark.read().json(“data/people.json“);</span><br></pre></td></tr></table></figure></p>
<h2 id="hive表"><a href="#hive表" class="headerlink" title="hive表"></a>hive表</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Dataset&lt;Row&gt; people = spark.sql(“SELECT * FROM people“);</span><br></pre></td></tr></table></figure>
<p>一般都会将数据转换为hive表后再进行后续的预处理，因为hive表方便用SparkSQL进行探索性分析，在不清楚数据情况前，这很有用；</p>
<h2 id="RDBMS表数据"><a href="#RDBMS表数据" class="headerlink" title="RDBMS表数据"></a>RDBMS表数据</h2><p>通过<code>JDBC</code>连接将数据库的表作为数据源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Dataset&lt;Row&gt; people = spark.read.format(<span class="string">"jdbc"</span>)</span><br><span class="line">    .option(<span class="string">"url"</span>,<span class="string">"jdbc:mysql://localhost:3306/hive“)</span></span><br><span class="line"><span class="string">    .option("</span>dbtable<span class="string">", "</span>hive.TBLS<span class="string">")</span></span><br><span class="line"><span class="string">    .option("</span>user<span class="string">", "</span>root<span class="string">")</span></span><br><span class="line"><span class="string">    .option("</span>password<span class="string">", "</span>root<span class="string">")</span></span><br><span class="line"><span class="string">    .option("</span>driver<span class="string">", "</span>com.mysql.jdbc.Driver<span class="string">")</span></span><br><span class="line"><span class="string">    .load()</span></span><br></pre></td></tr></table></figure>
<h1 id="执行数据处理"><a href="#执行数据处理" class="headerlink" title="执行数据处理"></a>执行数据处理</h1><p>数据处理过程通常分2个部分：预处理（缺失值，重复值，异常值处理，聚合等操作），业务指标计算；预处理结果会以中间表的形式存在，用于作业恢复，最终处理完成后再删除。</p>
<p>Spark中1个Application的执行主要涉及Client、ClusterManager、Worker3个角色，具体涉及以下术语</p>
<ul>
<li><strong>ClusterManager</strong>：在集群上获取资源的外部服务（如Standalone，mesos，yarn）；</li>
<li><strong>Client</strong>：用户提交Application的客户端</li>
<li><strong>Driver</strong>：运行Application的main函数，并创建SparkContext；<ul>
<li><strong>Application</strong>：Spark的应用程序，包含1个Driver程序和若干Executor；</li>
<li><strong>SparkContext</strong>：Spark应用程序的入口，负责调度各个运算资源，协调各个Worker上的Executor；</li>
<li><strong>Job</strong>：SparkContext提交的具体的Action操作，常由Action触发；</li>
<li><strong>RDD</strong>：弹性分布式数据集，是Spark最核心的类和模块；</li>
<li><strong>DAGScheduler</strong>：根据Job构建基于Stage的DAG，并将Stage提交给TaskScheduler</li>
<li><strong>TaskScheduler</strong>：将Taskset提交给WorKer集群运行并返回结果；</li>
</ul>
</li>
<li><strong>Worker</strong>：集群中运行Application代码的物理节点，可运行n个Executor进程；<ul>
<li><strong>Executor</strong>：负责运行Task，将数据存储在内存或磁盘，每个Application都会申请各自的Executor来处理任务</li>
<li><strong>Task</strong>：运行在Executor上的工作单元</li>
</ul>
</li>
</ul>
<p>下面主要详细描述Spark中一个Job（作业）的执行过程：</p>
<h2 id="Driver任务提交流程"><a href="#Driver任务提交流程" class="headerlink" title="Driver任务提交流程"></a>Driver任务提交流程</h2><div id="sequence-0"></div>

<h3 id="Stage的划分"><a href="#Stage的划分" class="headerlink" title="Stage的划分"></a>Stage的划分</h3><p>用户提交的计算任务是由多个 RDD 构成的 DAG， 当 RDD 在转换时需要进行 Shuffle，Shuffle 的过程中就将这个 DAG 划分成了多个 Stage。由于后面的 Stage 依赖前面的 Stage 提供 Shuffle 的结果，因此不同的 Stage 不能并行计算。</p>
<p>那么 RDD 在哪些操作时需要进行 Shuffle 呢？这里涉及到 RDD 的两种依赖关系：宽依赖与窄依赖。</p>
<p><img src="spark-stage-split.png" alt="宽依赖与窄依赖"></p>
<ul>
<li><code>窄依赖（narrow shuffle deps）</code>：一个RDD 每个 partition 依赖固定数量的parent RDD的partition，所以可以通过 Task 来处理这些 partition。而且这些 partition 相互独立，所以 Task 可以并行计算；</li>
<li><code>宽依赖（wide shuffle deps）</code>：一个RDD的每个partition依赖parent RDD的所有partition；当前RDD必须等待上一个RDD计算完成，所以需要分割Stage；</li>
</ul>
<p>举例说明 Stage 的划分过程</p>
<p><img src="spark-stage-split-demo.png" alt="宽依赖与窄依赖示例"><br>如图，从触发 Action 的 RDD G 开始划分，G 依赖 B 和 F，处理 B 和 F 的顺序是随机的，假设先处理 B：</p>
<ul>
<li>G-B：由于 G 和 B 是窄依赖关系，可以划分到同一个 Stage3 ；</li>
<li>G-F： 由于F 和 G 是宽依赖关系，所以将 F 划分到一个新的 Stage2；</li>
<li>F-D-C或F-E：可合并的窄依赖关系，所以将CDE与F 划分到同一个的 Stage2；</li>
<li>B-A：B和 A 是宽依赖关系，所以将A 划分到一个新的 Stage1；</li>
</ul>
<p>接着以 Stage 1 为例看它的计算方式，如图所示 RDD A 有3个 Partition，因此会生成3个ShuffleMapTask，这3个 Task 会把结果输出到3个 Partition 中。</p>
<h2 id="Executor任务执行流程"><a href="#Executor任务执行流程" class="headerlink" title="Executor任务执行流程"></a>Executor任务执行流程</h2><p><div id="sequence-1"></div><br>运行过程中RDD可以自动容错：Task异常恢复，慢任务备份；也可对关键数据手动执行checkpoint备份，对重复利用的小数据执行cache提升处理速度；</p>
<p>注意在得到计算结果发回 Driver 的过程中，如果文件太大会被直接丢弃；</p>
<blockquote>
<p>可以通过 <code>spark.driver.maxResultSize</code> 来设定大小；</p>
<p>实际生产过程中都不会将大量的计算结果返回给Driver端；</p>
</blockquote>
<h1 id="输出处理结果"><a href="#输出处理结果" class="headerlink" title="输出处理结果"></a>输出处理结果</h1><p>处理结果通常输出到hive表中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ds.write.saveAsTable(<span class="string">'dbname.tablename'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="如何处理Spark计算过程中的数据倾斜问题？"><a href="#如何处理Spark计算过程中的数据倾斜问题？" class="headerlink" title="如何处理Spark计算过程中的数据倾斜问题？"></a>如何处理Spark计算过程中的数据倾斜问题？</h2><ul>
<li><p><strong>问题描述</strong>：大量的相同key在被分配到了同一个partition，导致1个executor耗时长，其他executor空闲，造成资源浪费；违背并行计算的初衷；</p>
</li>
<li><p><strong>示例场景</strong>：groupBy或reduceByKey等聚合算子生成的RDD可能会导致数据倾斜；</p>
</li>
<li><p><strong>解决方案</strong>：<br><img src="spark数据倾斜问题.jpg" alt="spark数据倾斜问题"></p>
</li>
</ul>
<ol>
<li>给每个partitionKey加上一个随机数后再聚合；</li>
<li>聚合后的数据map去掉前缀；</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU5ODU5MjM2Mw==&amp;mid=2247484147&amp;idx=2&amp;sn=cca8dc960db221fb920bfb545d357ad9&amp;chksm=fe409cf7c93715e1a2f76400f33e7b1e43b74d104bb73e2df5c2d66334708f2ab44affb32348&amp;mpshare=1&amp;scene=1&amp;srcid=0312255FDjhwPrXrFblNbRjY&amp;sharer_sharetime=1583976445311&amp;sharer_shareid=c34b9250c3b65723d4a3c176ade2782f#rd">美图技术团队-Spark从入门到精通</a></li>
</ul>
<p><script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script><textarea id="sequence-0-code" style="display: none">Title: Driver任务提交流程
SparkSubmit->SparkContext: 任务提交
SparkContext->SparkContext: 初始化SparkEnv
SparkContext->SparkContext: 初始化SecurityManager
SparkContext->SparkContext: 初始化SparkUI
SparkContext->SparkContext: 创建TaskScheduler
SparkContext->SparkContext: 创建DAGScheduler
SparkContext->ClusterManager: 注册并申请资源
SparkContext->DAGScheduler: 提交Job(runJob)
DAGScheduler->DAGScheduler: 划分stage
DAGScheduler->DAGScheduler: 生成TaskSet
DAGScheduler->TaskScheduler: TaskSet
TaskScheduler->Executor(Worker): 提交并监控Task</textarea><textarea id="sequence-0-options" style="display: none">{"theme":"simple"}</textarea><script>  var code = document.getElementById("sequence-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-0", options);</script><textarea id="sequence-1-code" style="display: none">Title: Executor任务执行流程
Driver->Executor: 序列化封装Task的依赖文件和自身信息
Executor->Executor: 反序列化得到 Task
Executor->Executor: TaskRunner执行计算
Executor->Driver: 执行结果数据</textarea><textarea id="sequence-1-options" style="display: none">{"theme":"simple"}</textarea><script>  var code = document.getElementById("sequence-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-1-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-1", options);</script></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Git提交日志规范</title>
    <url>/2020/03/29/git%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>git commit -m “commit message” 每次提交的时候，总得写点什么，如果团队中小伙伴都按一定的范式来书写提交记录，问题追溯将变的有迹可循；</p>
<p>目前，社区有多种 Commit message 的规范。不过一般采用较多的是Google的AngularJS的规范，有现配套的工具来实现规范化提交。</p>
<a id="more"></a>  
<h1 id="为什么要提交结构化的Commit-message？"><a href="#为什么要提交结构化的Commit-message？" class="headerlink" title="为什么要提交结构化的Commit message？"></a>为什么要提交结构化的Commit message？</h1><p>结构化的commit message ，有3点好处：</p>
<ul>
<li>提供更多的历史信息，方便快速浏览和问题追溯；<ul>
<li><code>git log &lt;last tag&gt; HEAD --pretty=format:%s</code></li>
</ul>
</li>
<li>可以按类型过滤，便于快速查找信息；<ul>
<li><code>git log &lt;last release&gt; HEAD --grep feature</code></li>
</ul>
</li>
<li>可以直接根据commit message生成Change log；<ul>
<li><code>conventional-changelog -p angular -i CHANGELOG.md -s -p</code></li>
</ul>
</li>
</ul>
<h1 id="怎么写结构化的Commit-message？"><a href="#怎么写结构化的Commit-message？" class="headerlink" title="怎么写结构化的Commit message？"></a>怎么写结构化的Commit message？</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;<span class="built_in">type</span>&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br><span class="line">// 空一行</span><br><span class="line">&lt;body&gt;</span><br><span class="line">// 空一行</span><br><span class="line">&lt;footer&gt;</span><br></pre></td></tr></table></figure>
<p>其中，<code>Header</code> 是必填，<code>Body</code> 和 <code>Footer</code> 是选填。</p>
<h2 id="Header"><a href="#Header" class="headerlink" title="Header"></a>Header</h2><p><code>Header</code> 包括三个字段：<code>type</code>（必填）、<code>scope</code>（选填）和 <code>subject</code>（必填）。</p>
<h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><ul>
<li><strong>feat</strong>：新增feature；</li>
<li><strong>fix</strong>：修复bug；</li>
<li><strong>docs</strong>：仅仅修改了文档，如修改了readme.md；</li>
<li><strong>style</strong>：仅仅修改了代码格式，未改变代码逻辑；</li>
<li><strong>refactor</strong>：代码重构，未新增功能或修复bug；</li>
<li><strong>test</strong>：测试用例新增/更新；</li>
<li><strong>chore</strong>：改变构建流程、或增加依赖库、工具等；</li>
<li><strong>revert</strong>：版本回滚；</li>
</ul>
<p>如果type 为 <code>feat</code>或<code>fix</code>，则该 commit 会生成到在 Change log 中。</p>
<h3 id="scope"><a href="#scope" class="headerlink" title="scope"></a>scope</h3><p>scope 用于说明 commit 影响的范围，比如dao、controller、dto等等，具体视项目情况而定。</p>
<h3 id="subject"><a href="#subject" class="headerlink" title="subject"></a>subject</h3><p>subject 本次commit 的简短描述，不超过<code>50</code>个字符。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">以动词开头，使用第一人称现在时，比如 change，而不是 changed 或 changes</span><br><span class="line">第一个字母小写</span><br><span class="line">结尾不加句号（.）</span><br></pre></td></tr></table></figure>
<h2 id="Body"><a href="#Body" class="headerlink" title="Body"></a>Body</h2><p>Body 部分是对本次 commit 的更详细的说明文本，建议<code>72</code>个字符以内。 </p>
<p>内容包括但不限于:</p>
<ul>
<li>为什么这个变更是必须的? 它可能是用来修复一个bug，增加一个feature，提升性能、可靠性、稳定性等等；</li>
<li>如何解决这个问题? 具体描述解决问题的步骤；</li>
<li>是否存在副作用、风险? </li>
</ul>
<h2 id="Footer"><a href="#Footer" class="headerlink" title="Footer"></a>Footer</h2><p>footer 部分只用于两种情况</p>
<ul>
<li>不兼容变动：如果当前代码与上一个版本不兼容，则 Footer 部分以 <code>BREAKING CHANGE</code> 开头，后面是对变动的描述、以及变动理由和迁移方法。</li>
<li>关闭Issuce：如果当前 commit 针对某个 issue，那么可以在 Footer 部分关闭这个 issue；<ul>
<li><code>Closes #123, #245, #992</code></li>
</ul>
</li>
</ul>
<h1 id="规范化Commit-Message的配套工具"><a href="#规范化Commit-Message的配套工具" class="headerlink" title="规范化Commit Message的配套工具"></a>规范化Commit Message的配套工具</h1><h2 id="Commitizen自动生成合格的-commit-message"><a href="#Commitizen自动生成合格的-commit-message" class="headerlink" title="Commitizen自动生成合格的 commit message"></a>Commitizen自动生成合格的 commit message</h2><ul>
<li>安装：<code>npm install -g commitizen</code></li>
<li>使用<ul>
<li>如果不是node项目，需新增一个package.json，内容写入<code>{}</code>；</li>
<li><code>commitizen init cz-conventional-changelog --save --save-exact</code>：初始化，使其支持angular的commit message格式；</li>
<li><code>git cz</code>：以后凡是用到<code>git commit</code>命令，一律改为使用<code>git cz</code>。这样就能按提示一步步写出符合格式的 Commit message了。</li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://docs.google.com/document/d/1QrDFcIiPjSLDn3EL15IJygNPiHORgU1_OOAqWjiDU5Y/edit#heading=h.greljkmo14y0">AngularJS Git Commit Message Conventions</a> </li>
</ul>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在ECS上动态部署Hexo博客</title>
    <url>/2020/03/25/%E5%A6%82%E4%BD%95%E5%9C%A8ECS%E4%B8%8A%E5%8A%A8%E6%80%81%E9%83%A8%E7%BD%B2Hexo%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>如何在ECS上部署Hexo博客，实现git提交markdown文档，静态博客自动刷新<br><a id="more"></a></p>
<h1 id="ECS购买"><a href="#ECS购买" class="headerlink" title="ECS购买"></a>ECS购买</h1><p>阿里云买3年套餐，</p>
<ul>
<li>开通80端口</li>
<li>重置Root密码</li>
<li>SSH连接ECS</li>
</ul>
<h1 id="ECS配置"><a href="#ECS配置" class="headerlink" title="ECS配置"></a>ECS配置</h1><h2 id="创建git用户"><a href="#创建git用户" class="headerlink" title="创建git用户"></a>创建git用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adduser git</span><br><span class="line">chmod 740 /etc/sudoers</span><br><span class="line">vim /etc/sudoers</span><br><span class="line"><span class="comment"># 找到以下内容</span></span><br><span class="line"><span class="comment">#Allow root to run any commands anywhereroot    ALL=(ALL)     ALL</span></span><br><span class="line"><span class="comment"># 在下面添加一行</span></span><br><span class="line">git ALL=(ALL) ALL</span><br><span class="line"><span class="comment"># 保存退出后改回权限</span></span><br><span class="line">chmod 400 /etc/sudoers</span><br><span class="line"><span class="comment"># 随后设置Git用户的密码，</span></span><br><span class="line">sudo passwd git</span><br></pre></td></tr></table></figure>
<h2 id="配置git用户免密登陆"><a href="#配置git用户免密登陆" class="headerlink" title="配置git用户免密登陆"></a>配置git用户免密登陆</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换至git用户，创建 ~/.ssh 文件夹和 ~/.ssh/authorized_keys 文件，并赋予相应的权限</span></span><br><span class="line">su git</span><br><span class="line">mkdir ~/.ssh</span><br><span class="line">vim ~/.ssh/authorized_keys</span><br><span class="line"><span class="comment">#然后将电脑中执行 cat ~/.ssh/id_rsa.pub | pbcopy ,将公钥复制粘贴到authorized_keys</span></span><br><span class="line">chmod 600 ~/.ssh/authorized_keys</span><br><span class="line">chmod 700 ~/.ssh</span><br></pre></td></tr></table></figure>
<h2 id="安装软件"><a href="#安装软件" class="headerlink" title="安装软件"></a>安装软件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y update</span><br><span class="line">yum install -y git nginx</span><br></pre></td></tr></table></figure>
<h2 id="创建静态文件目录"><a href="#创建静态文件目录" class="headerlink" title="创建静态文件目录"></a>创建静态文件目录</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;home&#x2F;geosmart.top</span><br></pre></td></tr></table></figure>
<h2 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name  geosmart.top;</span><br><span class="line">        root         /home/geosmart.top;</span><br><span class="line"></span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">            location = /40x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">            location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="配置git更新自动同步到静态目录"><a href="#配置git更新自动同步到静态目录" class="headerlink" title="配置git更新自动同步到静态目录"></a>配置git更新自动同步到静态目录</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#新建git库目录：</span></span><br><span class="line"><span class="built_in">cd</span> /home/git</span><br><span class="line">git init --bare blog.git</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用 git-hooks 同步网站根目录</span></span><br><span class="line">vim /home/git/blog.git/hooks/post-receive</span><br><span class="line"><span class="comment"># post-receive文件内容如下:</span></span><br><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">git --work-tree=/home/geosmart.top --git-dir=/home/git/blog.git checkout -f</span><br><span class="line"><span class="comment"># 设置权限</span></span><br><span class="line">chmod +x hooks/post-receive</span><br></pre></td></tr></table></figure>
<h1 id="配置hexo发布"><a href="#配置hexo发布" class="headerlink" title="配置hexo发布"></a>配置hexo发布</h1><p>_config.yml配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">    <span class="attr">repo:</span> <span class="string">git@47.114.57.4:/home/git/blog.git</span></span><br><span class="line">    <span class="attr">branch:</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">message:</span> <span class="string">u</span></span><br></pre></td></tr></table></figure>
<p>发布命令：hexo d -g</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="hexo-deploy权限问题"><a href="#hexo-deploy权限问题" class="headerlink" title="hexo deploy权限问题"></a>hexo deploy权限问题</h2><p>sudo chmod -R ug+w .;</p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>HEXO</tag>
      </tags>
  </entry>
  <entry>
    <title>如何用金字塔思维来写技术笔记</title>
    <url>/2020/03/07/%E5%A6%82%E4%BD%95%E7%94%A8%E9%87%91%E5%AD%97%E5%A1%94%E6%80%9D%E7%BB%B4%E6%9D%A5%E5%86%99%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>之前写笔记也有意识的遵循一些规范/套路，比如WWW（What-是什么问题，When-什么情况发生，Why-为什么会这样），但都是些零碎，不成系统的经验之谈；</p>
<p>偶然了解到《金字塔原理》，和当初第一次阅读《高效能认识的七个习惯》一样的感觉，相见恨晚！<br>金字塔思维里阐述的表达技巧有别于文学创作，更注重的是<code>信息传播的效率</code>，以最少的语言，最简洁的形式让读者get到作者想表达的内容，写技术笔记真是再适合不过了；</p>
<p>本文主要记录<code>如何运用金字塔思维来写技术笔记</code>，持续更新写笔记的方法论。</p>
<blockquote>
<p>注意一篇文章关注解决1个问题</p>
</blockquote>
<a id="more"></a>
<h1 id="什么是金字塔思维？"><a href="#什么是金字塔思维？" class="headerlink" title="什么是金字塔思维？"></a>什么是金字塔思维？</h1><p>金字塔原理的基本结构是：</p>
<ul>
<li>结论先行，以上统下，归类分组，逻辑递进；</li>
<li>先重要后次要，先总结后具体，先框架后细节，先结论后原因，先结果后过程，先论点后论据；</li>
</ul>
<p>搭建金字塔结构的具体做法是：</p>
<ul>
<li>自上而下<code>表达</code>，自下而上<code>思考</code>，纵向总结概括，横向归类分组；</li>
<li>序言讲故事，标题提炼思想精华；</li>
</ul>
<h2 id="怎么思考问题？"><a href="#怎么思考问题？" class="headerlink" title="怎么思考问题？"></a>怎么思考问题？</h2><blockquote>
<p>自下而上思考，先发散再收缩，找到核心问题；</p>
</blockquote>
<h3 id="纵向总结概括"><a href="#纵向总结概括" class="headerlink" title="纵向总结概括"></a>纵向总结概括</h3><h4 id="问题界定"><a href="#问题界定" class="headerlink" title="问题界定"></a>问题界定</h4><p>找到方向/核心问题/中心思想的步骤：</p>
<ul>
<li>出现了什么问题？</li>
<li>期望结果是什么？</li>
<li>非期望结果是什么？</li>
</ul>
<h3 id="横向分类归组"><a href="#横向分类归组" class="headerlink" title="横向分类归组"></a>横向分类归组</h3><h4 id="演绎推理法"><a href="#演绎推理法" class="headerlink" title="演绎推理法"></a>演绎推理法</h4><p>方式一</p>
<ul>
<li>阐述世界上已存在的某种情况。</li>
<li>阐述世界上同时存在的相关情况。</li>
<li>说明这两种情况同时存在时隐含的意义。</li>
</ul>
<p>方式二</p>
<ul>
<li>出现的问题或存在的现象；</li>
<li>产生问题的根源、原因；</li>
<li>解决问题的方案；</li>
</ul>
<h4 id="归纳推理法"><a href="#归纳推理法" class="headerlink" title="归纳推理法"></a>归纳推理法</h4><ul>
<li>将具有共同点的事实、思想或观点归类分组，并概括其共同性（或论点）</li>
<li>同组中的思想具有类似的主语或谓语。</li>
</ul>
<h2 id="怎么表达问题？"><a href="#怎么表达问题？" class="headerlink" title="怎么表达问题？"></a>怎么表达问题？</h2><blockquote>
<p>自上而下表达，结论先行</p>
</blockquote>
<ul>
<li><p>表达一般需回答最常有的4类疑问：</p>
<ul>
<li>是什么？</li>
<li>为什么？</li>
<li>如何做？</li>
<li>好不好？</li>
</ul>
</li>
<li><p>表达时重点突出、条理清晰，让人愿意看、看得懂、记得住，行文要思路清晰、言简意赅。</p>
</li>
</ul>
<h3 id="如何写序言？"><a href="#如何写序言？" class="headerlink" title="如何写序言？"></a>如何写序言？</h3><h4 id="序言4要素"><a href="#序言4要素" class="headerlink" title="序言4要素"></a>序言4要素</h4><ol>
<li>介绍背景（S, Situation）</li>
<li>指出冲突（C, Complication）</li>
<li>引发疑问（Q, Question）</li>
<li>给出答案（A, Answer）</li>
</ol>
<h4 id="序言回答的4类问题"><a href="#序言回答的4类问题" class="headerlink" title="序言回答的4类问题"></a>序言回答的4类问题</h4><ol>
<li>我们应该做什么？</li>
<li>我们应该如何做（将如何做/是如何做的）？</li>
<li>我们是否应该这样做？</li>
<li>为什么会发生这种情况？</li>
</ol>
<h2 id="怎么解决问题？"><a href="#怎么解决问题？" class="headerlink" title="怎么解决问题？"></a>怎么解决问题？</h2><h1 id="记哪些笔记？"><a href="#记哪些笔记？" class="headerlink" title="记哪些笔记？"></a>记哪些笔记？</h1><ul>
<li>记录踩坑过程</li>
<li>分析技术原理</li>
<li>总结效能工具</li>
</ul>
<h1 id="怎么写笔记？"><a href="#怎么写笔记？" class="headerlink" title="怎么写笔记？"></a>怎么写笔记？</h1><h2 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h2><ul>
<li>是什么？问题说明，背景示例</li>
<li>为什么？介绍问题产生的背景/原因，目前存在的冲突</li>
</ul>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><ul>
<li>如何做？分析问题的解决方案<ul>
<li>当前方案的实现细节<ul>
<li>类图</li>
<li>代码解读</li>
<li>流程图</li>
</ul>
</li>
<li>其他可选方案</li>
</ul>
</li>
<li>好不好？评价解决方案<ul>
<li>优缺点</li>
<li>适应场景</li>
<li>使用案例</li>
</ul>
</li>
</ul>
<h2 id="术语-附录"><a href="#术语-附录" class="headerlink" title="术语/附录"></a>术语/附录</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>博文链接</li>
<li>书籍名称</li>
</ul>
<h1 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="">《金字塔思维-芭芭拉.明托》</a></li>
</ul>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible安装MySQL</title>
    <url>/2020/04/24/Ansible%E5%AE%89%E8%A3%85MySQL/</url>
    <content><![CDATA[<p>ansible自动化运维-mysql<br><a id="more"></a></p>
<h1 id="role安装"><a href="#role安装" class="headerlink" title="role安装"></a>role安装</h1><p>ansible-galaxy install geerlingguy.mysql</p>
<h1 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h1><p>vars/main.yml:<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">mysql_root_password:</span> <span class="string">super-secure-password</span></span><br><span class="line"><span class="attr">mysql_databases:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example_db</span></span><br><span class="line">    <span class="attr">encoding:</span> <span class="string">utf8mb4</span></span><br><span class="line">    <span class="attr">collation:</span> <span class="string">utf8mb4_bin</span></span><br><span class="line"><span class="attr">mysql_users:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example_user</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">"%"</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">similarly-secure-password</span></span><br><span class="line">    <span class="attr">priv:</span> <span class="string">"example_db.*:ALL"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="playbook安装"><a href="#playbook安装" class="headerlink" title="playbook安装"></a>playbook安装</h2><p>install.yml<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">dbservers</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">yes</span></span><br><span class="line">  <span class="attr">vars_files:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">vars/main.yml</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">role:</span> <span class="string">geerlingguy.mysql</span> <span class="string">&#125;</span></span><br><span class="line"><span class="string">Inside</span></span><br></pre></td></tr></table></figure><br>执行mysql安装<br>ansible-playbook install.yml  </p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/geerlingguy/ansible-role-mysql">https://github.com/geerlingguy/ansible-role-mysql</a></p>
]]></content>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible自动化运维笔记</title>
    <url>/2020/04/01/Ansible%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Ansible自动化运维工具学习笔记，告别乱糟糟的shell脚本<br><a id="more"></a></p>
<h1 id="关于Ansible"><a href="#关于Ansible" class="headerlink" title="关于Ansible"></a>关于Ansible</h1><p>Ansilbe是一个部署一群远程主机的工具。远程的主机可以是远程虚拟机或物理机， 也可以是本地主机。<br>Ansilbe通过SSH协议实现远程节点和管理节点之间的通信。<br>理论上说，只要管理员通过ssh登录到一台远程主机上能做的操作，Ansible都可以做到。<br>包括：</p>
<ul>
<li>拷贝文件</li>
<li>安装软件包</li>
<li>启动服务</li>
<li>…</li>
</ul>
<h1 id="Ansible的安装"><a href="#Ansible的安装" class="headerlink" title="Ansible的安装"></a>Ansible的安装</h1><p>centos7环境安装<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install ansible</span><br></pre></td></tr></table></figure></p>
<h1 id="Ansible的理念"><a href="#Ansible的理念" class="headerlink" title="Ansible的理念"></a>Ansible的理念</h1><p>Ansilbe控制节点和远程主机节点通过ssh协议进行通信。<br>所以Ansible配置的时候只需要保证从Ansible控制节点通过SSH能够连接到被管理的主机节点即可。</p>
<h2 id="Control-node"><a href="#Control-node" class="headerlink" title="Control node"></a>Control node</h2><p>已安装Ansible的控制节点</p>
<h2 id="Managed-nodes"><a href="#Managed-nodes" class="headerlink" title="Managed nodes"></a>Managed nodes</h2><p>被管理节点，也成为主机（hosts），主机节点不安装Ansible；<br>在/etc/ansible/hosts中定义</p>
<h2 id="Inventory"><a href="#Inventory" class="headerlink" title="Inventory"></a>Inventory</h2><p>主机列表,inventory文件也称为hostfile；<br>如主机节点的ip地址，在/etc/ansible/hosts中定义</p>
<h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><p>模块为Ansible执行的代码代码单元，</p>
<h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><p>Ansible的执行动作单元</p>
<h2 id="Playbooks"><a href="#Playbooks" class="headerlink" title="Playbooks"></a>Playbooks</h2><p>Playbooks为有序的tasks列表，以yaml格式编写</p>
<h1 id="Ansible命令"><a href="#Ansible命令" class="headerlink" title="Ansible命令"></a>Ansible命令</h1><h2 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h2><p>ansible all -m ping -u root</p>
<h2 id="文件复制"><a href="#文件复制" class="headerlink" title="文件复制"></a>文件复制</h2><p>ansible blog -m copy -a “src=/mnt/hgfs/WorkSpace/NoteSpace/geosmart.github.io/hexo/public dest=/home/geosmart.top  owner=root group=root mode=0755”</p>
<h1 id="Ansible脚本-playbook"><a href="#Ansible脚本-playbook" class="headerlink" title="Ansible脚本(playbook)"></a>Ansible脚本(playbook)</h1><h2 id="文件复制-1"><a href="#文件复制-1" class="headerlink" title="文件复制"></a>文件复制</h2><p>利用ansible发布博客更新 ：<code>ansible-playbook  deploy.yml</code></p>
<p>deploy.yml内容<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">blog</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">clean</span> <span class="string">exist</span> <span class="string">blog</span> <span class="string">files</span></span><br><span class="line">      <span class="attr">shell:</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/home/geosmart.top/*</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">new</span> <span class="string">blog</span> <span class="string">files</span></span><br><span class="line">      <span class="attr">copy:</span></span><br><span class="line">        <span class="attr">src:</span> <span class="string">/mnt/hgfs/WorkSpace/NoteSpace/geosmart.github.io/hexo/public/</span></span><br><span class="line">        <span class="attr">dest:</span> <span class="string">/home/geosmart.top/</span></span><br></pre></td></tr></table></figure></p>
<h1 id="roles"><a href="#roles" class="headerlink" title="roles"></a>roles</h1><p>Roles 可以降低 Playbooks 的复杂性，增加 Playbooks 的可用性。<br>role库地址：<a href="https://galaxy.ansible.com/">ansible galaxy</a></p>
<h2 id="role的结构"><a href="#role的结构" class="headerlink" title="role的结构"></a>role的结构</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">└── example_role</span><br><span class="line">    ├── README.md     <span class="comment"># 说明文件</span></span><br><span class="line">    ├── defaults</span><br><span class="line">    │   └── main.yml  <span class="comment"># 可被覆写的变数。</span></span><br><span class="line">    ├── files         <span class="comment"># 需复制到 Managed node 的档案。</span></span><br><span class="line">    ├── handlers</span><br><span class="line">    │   └── main.yml  <span class="comment"># 主要的 handler。</span></span><br><span class="line">    ├── meta</span><br><span class="line">    │   └── main.yml</span><br><span class="line">    ├── tasks</span><br><span class="line">    │   └── main.yml  <span class="comment"># 主要的 task。</span></span><br><span class="line">    ├── templates     <span class="comment"># 集中存放 Jinja2 模板的目录。</span></span><br><span class="line">    ├── tests</span><br><span class="line">    │   ├── inventory</span><br><span class="line">    │   └── test.yml</span><br><span class="line">    └── vars</span><br><span class="line">        └── main.yml  <span class="comment"># 不该被覆写的变数。</span></span><br><span class="line"></span><br><span class="line">9 directories, 8 files</span><br></pre></td></tr></table></figure>
<h2 id="下载role"><a href="#下载role" class="headerlink" title="下载role"></a>下载role</h2><p><code>ansible-galaxy install mdklatt.python3 -p /etc/ansible/roles</code></p>
<h2 id="安装role"><a href="#安装role" class="headerlink" title="安装role"></a>安装role</h2><p>定义install_python3.yml<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">python3</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">blog</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mdklatt.python3</span></span><br><span class="line">      <span class="attr">python3_pyenv:</span> <span class="string">"3.6.4"</span></span><br><span class="line">      <span class="attr">python3_local:</span> <span class="string">"/opt/python3"</span></span><br></pre></td></tr></table></figure></p>
<p>安装命令： <code>ansible-playbook install_python3.yml -e &quot;tmpdir_path=/tmp&quot; --verbose</code>，<br>默认安装在主机节点的<code>/root/.pyenv/versions/3.6.4</code>目录</p>
<h1 id="template模板-jinja2"><a href="#template模板-jinja2" class="headerlink" title="template模板(jinja2)"></a>template模板(jinja2)</h1><h2 id="以Jinja2定义模板文件"><a href="#以Jinja2定义模板文件" class="headerlink" title="以Jinja2定义模板文件"></a>以Jinja2定义模板文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi hello_world.txt.j2</span><br><span class="line">Hello <span class="string">"&#123;&#123; dynamic_word &#125;&#125;"</span></span><br></pre></td></tr></table></figure>
<h2 id="在playbook中注入变量默认值"><a href="#在playbook中注入变量默认值" class="headerlink" title="在playbook中注入变量默认值"></a>在playbook中注入变量默认值</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">localhost</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">    <span class="attr">var1:</span> <span class="string">"World"</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">generate</span> <span class="string">hello_world.txt</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">         <span class="attr">src:</span> <span class="string">hello_world.txt.j2</span></span><br><span class="line">         <span class="attr">dest:</span> <span class="string">/tmp/hello_world.txt</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">show</span> <span class="string">file</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">cat</span> <span class="string">/tmp/hello_world.txt</span></span><br><span class="line">      <span class="attr">register:</span> <span class="string">result</span>    </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">print</span> <span class="string">stdout</span></span><br><span class="line">      <span class="attr">debug:</span></span><br><span class="line">        <span class="attr">msg:</span> <span class="string">""</span></span><br></pre></td></tr></table></figure>
<h2 id="运行playbook时设置变量值；"><a href="#运行playbook时设置变量值；" class="headerlink" title="运行playbook时设置变量值；"></a>运行playbook时设置变量值；</h2><p><code>ansible-playbook template_demo.yml -e &quot;dynamic_word=ansible&quot;</code></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.bejson.com/validators/yaml/">yaml格式校验工具</a></li>
<li><a href="https://github.com/ansible/ansible-examples">playbook-example</a></li>
<li><a href="https://www.gitbook.com/book/ansible-book/ansible-first-book">ansible-first-book</a></li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS升级Python3</title>
    <url>/2020/04/19/CentOS%E5%8D%87%E7%BA%A7Python3/</url>
    <content><![CDATA[<p>OPS笔记：centos7系统默认python2升级python3<br><a id="more"></a></p>
<h1 id="安装python"><a href="#安装python" class="headerlink" title="安装python"></a>安装python</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz</span><br><span class="line">tar -zxvf Python-3.7.0.tgz</span><br><span class="line">mkdir /usr/local/python3</span><br><span class="line">cd Python-3.7.0</span><br><span class="line">./configure --prefix=/usr/local/python3</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<h1 id="设置默认python软连接"><a href="#设置默认python软连接" class="headerlink" title="设置默认python软连接"></a>设置默认python软连接</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -rf /usr/bin/python</span><br><span class="line">rm -rf /usr/bin/pip</span><br><span class="line">rm -rf /usr/bin/python3-config</span><br><span class="line"></span><br><span class="line">ln -s /usr/local/python3/bin/python3.7 /usr/bin/python</span><br><span class="line">ln -s /usr/local/python3/bin/python3.7 /usr/bin/python3</span><br><span class="line">ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip</span><br><span class="line">ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip3</span><br><span class="line">ln -s /usr/local/python3/bin/python3.7-config /usr/bin/python3-config</span><br></pre></td></tr></table></figure>
<h1 id="测试python是否可用"><a href="#测试python是否可用" class="headerlink" title="测试python是否可用"></a>测试python是否可用</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python2 --version</span><br><span class="line">python3 --version</span><br><span class="line">python --version</span><br></pre></td></tr></table></figure>
<h1 id="yum改为python2"><a href="#yum改为python2" class="headerlink" title="yum改为python2"></a>yum改为python2</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /usr/bin/yum</span><br><span class="line">将第一行"#!/usr/bin/python" 改为 "#!/usr/bin/python2"。</span><br><span class="line"><span class="meta">#</span><span class="bash"> vi /usr/libexec/urlgrabber-ext-down</span></span><br><span class="line">将第一行"#!/usr/bin/python" 改为 "#!/usr/bin/python2"即可。</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>OPS</category>
      </categories>
  </entry>
  <entry>
    <title>Kuboard安装K8S集群</title>
    <url>/2020/04/01/Kuboard%E5%AE%89%E8%A3%85K8S%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>记录如何用kuboard工具安装k8s集群<br><a id="more"></a><br><a href="kuboard.jpg">kuboard界面</a></p>
<h1 id="检查网络"><a href="#检查网络" class="headerlink" title="检查网络"></a>检查网络</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> master  修改 hostname</span></span><br><span class="line">hostnamectl set-hostname k8s.master</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看修改结果</span></span><br><span class="line">hostnamectl status</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置 hostname 解析</span></span><br><span class="line">echo "127.0.0.1   $(hostname)" &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>
<h1 id="安装docker及kubelet"><a href="#安装docker及kubelet" class="headerlink" title="安装docker及kubelet"></a>安装docker及kubelet</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在 master 节点和 worker 节点都要执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 最后一个参数 1.18.0 用于指定 kubenetes 版本，支持所有 1.18.x 版本的安装</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 腾讯云 docker hub 镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> REGISTRY_MIRROR=<span class="string">"https://mirror.ccs.tencentyun.com"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> DaoCloud 镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> REGISTRY_MIRROR=<span class="string">"http://f1361db2.m.daocloud.io"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 华为云镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> REGISTRY_MIRROR=<span class="string">"https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 阿里云 docker hub 镜像</span></span><br><span class="line">export REGISTRY_MIRROR=https://registry.cn-hangzhou.aliyuncs.com</span><br><span class="line">curl -sSL https://kuboard.cn/install-script/v1.18.x/install_kubelet.sh | sh -s 1.18.2</span><br></pre></td></tr></table></figure>
<h1 id="master配置"><a href="#master配置" class="headerlink" title="master配置"></a>master配置</h1><h2 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 只在 master 节点执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换 x.x.x.x 为 master 节点实际 IP（请使用内网 IP）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> 命令只在当前 shell 会话中有效，开启新的 shell 窗口后，如果要继续安装过程，请重新执行此处的 <span class="built_in">export</span> 命令</span></span><br><span class="line">export MASTER_IP=192.168.135.130</span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换 apiserver.demo 为 您想要的 dnsName</span></span><br><span class="line">export APISERVER_NAME=k8s.master</span><br><span class="line"><span class="meta">#</span><span class="bash"> Kubernetes 容器组所在的网段，该网段安装完成后，由 kubernetes 创建，事先并不存在于您的物理网络中</span></span><br><span class="line">export POD_SUBNET=10.100.0.1/16</span><br><span class="line">echo "$&#123;MASTER_IP&#125;    $&#123;APISERVER_NAME&#125;" &gt;&gt; /etc/hosts</span><br><span class="line">curl -sSL https://kuboard.cn/install-script/v1.18.x/init_master.sh | sh -s 1.18.2</span><br></pre></td></tr></table></figure>
<h2 id="检查-master-初始化结果"><a href="#检查-master-初始化结果" class="headerlink" title="检查 master 初始化结果"></a>检查 master 初始化结果</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 只在 master 节点执行</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行如下命令，等待 3-10 分钟，直到所有的容器组处于 Running 状态</span></span><br><span class="line">watch kubectl get pod -n kube-system -o wide</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 master 节点初始化结果</span></span><br><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure>
<h1 id="worker配置"><a href="#worker配置" class="headerlink" title="worker配置"></a>worker配置</h1><p>master执行获取join命令<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>该 token 的有效时间为 2 个小时，2小时内，您可以使用此 token 初始化任意数量的 worker 节点。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 只在 worker 节点执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换 x.x.x.x 为 master 节点的内网 IP</span></span><br><span class="line">export MASTER_IP=192.168.135.130</span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换 apiserver.demo 为初始化 master 节点时所使用的 APISERVER_NAME</span></span><br><span class="line">export APISERVER_NAME=k8s.master</span><br><span class="line">echo "$&#123;MASTER_IP&#125;    $&#123;APISERVER_NAME&#125;" &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换为 master 节点上 kubeadm token create 命令的输出</span></span><br><span class="line">kubeadm join k8s.master:6443 --token bekn32.5jf2ih9zo2qptfw9     --discovery-token-ca-cert-hash sha256:3c8e58572a57f14b8de1ca3368d2c6eae9831a1fb6b1fcc6d35fce334bfaf78f</span><br></pre></td></tr></table></figure>
<p>// todo 重新加入master</p>
<h1 id="master检测配置结果"><a href="#master检测配置结果" class="headerlink" title="master检测配置结果"></a>master检测配置结果</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看 master 节点初始化结果</span></span><br><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure>
<h1 id="官方可视化工具Kubernetes-Dashboard"><a href="#官方可视化工具Kubernetes-Dashboard" class="headerlink" title="官方可视化工具Kubernetes Dashboard"></a>官方可视化工具Kubernetes Dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装 Kubernetes Dashboard</span></span><br><span class="line">kubectl apply -f https://kuboard.cn/install-script/k8s-dashboard/v2.0.0-beta5.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 Service Account 和 ClusterRoleBinding</span></span><br><span class="line">kubectl apply -f https://kuboard.cn/install-script/k8s-dashboard/auth.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取Bearer Token</span></span><br><span class="line">kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '&#123;print $1&#125;')</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动kubernetes dashboard</span></span><br><span class="line">nohup kubectl proxy --address='0.0.0.0' --port=9090 --accept-hosts='^*$' &amp;</span><br></pre></td></tr></table></figure>
<p>访问路径： <a href="http://192.168.135.130:9090/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/">http://192.168.135.130:9090/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</a></p>
<h1 id="Kuboard可视化工具"><a href="#Kuboard可视化工具" class="headerlink" title="Kuboard可视化工具"></a>Kuboard可视化工具</h1><h2 id="安装Kuboard"><a href="#安装Kuboard" class="headerlink" title="安装Kuboard"></a>安装Kuboard</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml</span><br><span class="line">kubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.6/metrics-server.yaml</span><br><span class="line">kubectl get pods -l k8s.eip.work/name=kuboard -n kube-system</span><br></pre></td></tr></table></figure>
<h2 id="获取Kuboard界面地址"><a href="#获取Kuboard界面地址" class="headerlink" title="获取Kuboard界面地址"></a>获取Kuboard界面地址</h2><p>获取Token<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '&#123;print $1&#125;') -o go-template='&#123;&#123;.data.token&#125;&#125;' | base64 -d</span><br></pre></td></tr></table></figure><br><a href="http://192.168.135.130:32567/dashboard?k8sToken=获取的Token">http://192.168.135.130:32567/dashboard?k8sToken=获取的Token</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://kuboard.cn/">kuboard</a></li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Kuboard</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库开发规范</title>
    <url>/2020/04/12/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>本文描述数据库表的设计流程以及DDL和DML的设计规约；<br><a id="more"></a></p>
<h1 id="表设计流程"><a href="#表设计流程" class="headerlink" title="表设计流程"></a>表设计流程</h1><ol>
<li><code>表设计</code>：用<a href="http://staruml.io/">StarUML</a>等UML建模工具中的ER图来设计表结构；</li>
<li><code>表创建</code>：导出DDL语句（yyyyMMddHHmmss_.sql）至项目的<code>Flyway</code>数据迁移目录，启动项目完成表的初始化；</li>
<li><code>ORM代码生成</code>：<ul>
<li>Idea中安装插件<a href="https://plugins.jetbrains.com/plugin/8321-free-mybatis-plugin/">free-mybatis-plugin</a>；</li>
<li>在database视图，连接db，选择生成的表右击选择mybatis-generator，在gui界面配置package和目录，完成生成DAO层的DaoMapper接口和Mapper.xml文件；</li>
</ul>
</li>
</ol>
<h1 id="DDL设计规约"><a href="#DDL设计规约" class="headerlink" title="DDL设计规约"></a>DDL设计规约</h1><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>通常不需要手动设置数据库存储引擎（如innodb,myisam），按数据库默认值即可；</p>
<ul>
<li>原因：客户的数据库可能是基于MySQL/MariaDB封装了自己的存储引擎，如果指定了会导致flyway初始化异常；</li>
</ul>
<h2 id="字符集"><a href="#字符集" class="headerlink" title="字符集"></a>字符集</h2><p>新系统的数据库本身库、表、列所有字符集必须保持一致，使用utf8mb4；</p>
<ul>
<li>示例：<code>create table(...) default charset = utf8mb4</code>；</li>
<li>原因：utf8mb4编码是utf8编码的超集，兼容utf8，并且能存储4字节的表情字符；采用utf8mb4编码的好处是存储与获取数据的时候，不用再考虑emoji字符的编码与解码问题；</li>
<li>注意：utf8mb4的最低mysql版本支持版本为5.5.3+；</li>
</ul>
<h2 id="字段类型和长度"><a href="#字段类型和长度" class="headerlink" title="字段类型和长度"></a>字段类型和长度</h2><ul>
<li><strong>整数类型</strong><ul>
<li><code>int</code>：次数，状态等类型字段存储</li>
</ul>
</li>
<li><strong>小数类型</strong><ul>
<li><code>decimal</code>：禁止使用float和double。float和double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 </li>
</ul>
</li>
<li><strong>布尔类型</strong><ul>
<li><code>unsigned_tinyint(1)</code>：1表示true，0表示false</li>
</ul>
</li>
<li><strong>文本类型</strong><ul>
<li>短字符：<code>varchar(64)</code>，如name,code,id</li>
<li>中字符：<code>varchar(190)</code>，如description<ul>
<li>需要建索引的字段，长度最好不超过190，因为utf8mb4编码单个索引最大长度是767字节（767/4约等于191） </li>
</ul>
</li>
<li>短文本：<code>text</code>，最大64kb</li>
<li>中文本：<code>mediumtext</code>，最大16MB，如存储HTML页面内容</li>
</ul>
</li>
<li><strong>时间类型</strong><ul>
<li>记录经常变化的时间：<code>timestamp</code>，时间范围（1970-2038），如更新/创建/发布/日志时间/注册时间等，并且是近来的时间，够用，区自动处理，比如说做海外购或者业务可能拓展到海外；</li>
<li>记录固定时间：<code>datetime</code>，时间范围（1000-9999），如服务器执行计划任务时间/健身锻炼计划时间等，在任何时区都是需要一个固定的时间要做某个事情；</li>
<li>自定义时间字段：<code>bigint</code>，不确定的时间范围存储；</li>
</ul>
</li>
</ul>
<h2 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h2><p><strong>库名、表名、列名的修改代价很大，命名时需要慎重考虑</strong></p>
<h3 id="公共命名规则"><a href="#公共命名规则" class="headerlink" title="公共命名规则"></a>公共命名规则</h3><ol>
<li>【强制】表名、列表都必须有comment注释；</li>
<li>【强制】表名、列名只能使用字母、数字和下划线，禁止出现数字开头，一律小写；</li>
</ol>
<h3 id="库名"><a href="#库名" class="headerlink" title="库名"></a>库名</h3><p>库名与应用名称尽量一致。 </p>
<h3 id="表名"><a href="#表名" class="headerlink" title="表名"></a>表名</h3><ol>
<li>【强制】表的命名规则：<code>业务名_表的作用</code>，如<code>scheduler_job</code>。 </li>
<li>【强制】表名带当前系统前缀，如<code>mlp_</code>，便于后续数据平台聚合使用；</li>
<li>【强制】表名不使用复数名词。</li>
</ol>
<h3 id="列名"><a href="#列名" class="headerlink" title="列名"></a>列名</h3><ol>
<li>【强制】列的命名规则：<code>实体类型_字段含义</code>，如<code>user_name、user_id</code>。 </li>
<li>【强制】FK外键保持原字段名，方便join；</li>
<li>【强制】字段名禁用数据库保留字；</li>
<li>表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。</li>
</ol>
<h3 id="索引名"><a href="#索引名" class="headerlink" title="索引名"></a>索引名</h3><ol>
<li>【强制】主键索引：uk_字段名；</li>
<li>【强制】普通索引：idx_字段名； </li>
<li>【强制】唯一索引：uk_字段名； </li>
</ol>
<h2 id="表必备字段"><a href="#表必备字段" class="headerlink" title="表必备字段"></a>表必备字段</h2><ol>
<li>【强制】{entity}_id：主键</li>
<li>【强制】create_time：记录创建时间，date_time，数据库默认值；</li>
<li>【强制】update_time：记录更新时间，date_time，数据库自动设置；</li>
<li>is_deleted：unsigned_inyint(1)，是否删除，需支持软删除的表必备；</li>
<li>create_by：创建人，varchar(64)，需权限控制的数据表必备；</li>
<li>update_by：更新人，varchar(64)，需权限控制的数据表必备；</li>
</ol>
<h1 id="DML设计规约"><a href="#DML设计规约" class="headerlink" title="DML设计规约"></a>DML设计规约</h1><ol>
<li>【强制】<code>alter table</code>：对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行；<ul>
<li>因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。</li>
</ul>
</li>
<li>【强制】<code>select或insert语句</code>必须指定具体字段名称，禁止写成<code>*</code>；<ul>
<li>因为<code>select *</code>会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错；</li>
</ul>
</li>
<li>【强制】除静态表或小表(100行以内)，DML语句必须有<code>where条件</code></li>
<li>【强制】<code>where条件</code>需用explain确认会使用索引；索引至少要达到 range 级别，要求是ref级别，如果可以是consts最好；</li>
<li>【强制】<code>where条件</code>中等号左右字段类型必须一致，且不要使用函数或表达式，否则无法利用索引；</li>
<li>【强制】<code>where条件</code>中禁止只使用全模糊的<code>like</code>条件进行查找，必须有其它等值或范围查询条件，否则无法利用索引。</li>
<li>select语句不要使用<code>union</code>，推荐使用<code>union all</code>，并且union子句个数限制在5个以内；<ul>
<li>因为union all不需要去重，节省数据库资源，提高性能；</li>
</ul>
</li>
</ol>
]]></content>
      <tags>
        <tag>MySQL</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>REST接口定义规范</title>
    <url>/2020/04/19/REST%E6%8E%A5%E5%8F%A3%E5%AE%9A%E4%B9%89%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>团队REST接口定义规范<br><a id="more"></a></p>
<h1 id="REST接口URL定义原则"><a href="#REST接口URL定义原则" class="headerlink" title="REST接口URL定义原则"></a>REST接口URL定义原则</h1><p>接口url的定义需遵守如下原则：</p>
<ul>
<li>URL中命名必须保持<code>Camel</code>风格<ul>
<li>由于团队内部的接口dto用java-swagger框架生成，故采用驼峰风格，如果不使用swagger也可采用纯小写+下划线，但需保持使用同一种风格以避免混乱；</li>
</ul>
</li>
<li>URL中资源（resource）的命名必须是<strong>名词</strong>，并且必须是<strong>复数</strong>形式；</li>
<li>URL必须是<strong>易读</strong>的；</li>
<li>URL一定不能暴露后端的架构；</li>
</ul>
<p>规范：<code>domain/api/{version}/{resources}/{action}</code><br>示例：服务组分页查询（mlp.com/api/v2/serviceGroups/page）</p>
<h1 id="Http-Method"><a href="#Http-Method" class="headerlink" title="Http Method"></a>Http Method</h1><p>只使用get和post两种方法使对接变得更简单，不使用put，delete，patch等http method。</p>
<ul>
<li>get：简单的只读操作，如通过id查询资源明细；</li>
<li>post：新增/更新/删除操作，其他复杂只读操作（如分页）；</li>
</ul>
<h2 id="URL示例"><a href="#URL示例" class="headerlink" title="URL示例"></a>URL示例</h2><p>app资源的crud操作<br>| operation    | method | url                                   |<br>| —————— | ——— | ——————————————————- |<br>| app分页查询 | POST   | <a href="https://mlp.com/apps/page">https://mlp.com/apps/page</a>            |<br>| app名称的模糊查询 | GET | <a href="https://mlp.com/apps/query?appName={appName}">https://mlp.com/apps/query?appName={appName}</a> |<br>| app新增     | POST   | <a href="https://mlp.com/apps/add">https://mlp.com/apps/add</a>             |<br>| app删除     | POST   | <a href="https://mlp.com/apps/{appId}/delete">https://mlp.com/apps/{appId}/delete</a> |<br>| app更新     | POST   | <a href="https://mlp.com/apps/{appId}/update">https://mlp.com/apps/{appId}/update</a> |<br>| app详情查询 | GET    | <a href="https://mlp.com/apps/{appId}/get">https://mlp.com/apps/{appId}/get</a>    |</p>
<p>solution的curd操作（app和solution是1:n关系）<br>| operation    | method | url                                   |<br>| —————— | ——— | ——————————————————- |<br>| 查询app关联的所有solution | POST | <a href="https://mlp.com/app/{appId}/solutions">https://mlp.com/app/{appId}/solutions</a> |<br>| solution新增     | POST   | <a href="https://mlp.com/solutions/add">https://mlp.com/solutions/add</a>             |<br>| solution删除     | POST   | <a href="https://mlp.com/solutions/{solutionId}/delete">https://mlp.com/solutions/{solutionId}/delete</a> |<br>| solution更新     | POST   | <a href="https://mlp.com/solutions/update">https://mlp.com/solutions/update</a> |<br>| solution详情查询 | GET    | <a href="https://mlp.com/solutions/{solutionId}/get">https://mlp.com/solutions/{solutionId}/get</a>    |</p>
<h1 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h1><h2 id="Response-Code"><a href="#Response-Code" class="headerlink" title="Response Code"></a>Response Code</h2><h3 id="Http状态码"><a href="#Http状态码" class="headerlink" title="Http状态码"></a>Http状态码</h3><div class="table-container">
<table>
<thead>
<tr>
<th>状态码</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1xx</td>
<td>代表请求已被接受，需要继续处理</td>
</tr>
<tr>
<td>2xx</td>
<td>请求已成功，请求所希望的响应头或数据体将随此响应返回</td>
</tr>
<tr>
<td>3xx</td>
<td>重定向</td>
</tr>
<tr>
<td>4xx</td>
<td>客户端原因引起的错误</td>
</tr>
<tr>
<td>5xx</td>
<td>服务端原因引起的错误</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>只有来自客户端的请求被正确的处理后才能返回 <code>2xx</code> 的响应，所以当 API 返回 <code>2xx</code> 类型的状态码时，前端 <code>必须</code> 认定该请求已处理成功。</p>
</blockquote>
<h3 id="业务错误码"><a href="#业务错误码" class="headerlink" title="业务错误码"></a>业务错误码</h3><p>6位数字，如000000</p>
<ul>
<li>前3位表示功能模块，</li>
<li>后3位表示错误码序号</li>
</ul>
<p>注意：需设计通用错误码模块，然后通过具体message进行区别，避免出现太多错误码；</p>
<p>如：100001，PARAMS_CHECK_ERROR，参数校验错误[%s]</p>
<h2 id="Response-Body"><a href="#Response-Body" class="headerlink" title="Response Body"></a>Response Body</h2><p>数据协议：application/json,charset=utf-8</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"success"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"value"</span>: &#123;&#125;,</span><br><span class="line">    <span class="attr">"resultMap"</span>: &#123;&#125;,</span><br><span class="line">    <span class="attr">"message"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="attr">"msgCode"</span>: <span class="string">""</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>字段名</th>
<th>必传</th>
<th>类型</th>
<th><span style="white-space:nowrap">字段说明&nbsp;</span></th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>success</td>
<td>Y</td>
<td>bool</td>
<td>是否成功</td>
<td>true/false</td>
</tr>
<tr>
<td><code>value</code></td>
<td>Y</td>
<td>object</td>
<td>结果数据</td>
<td><strong>JSON</strong>格式</td>
</tr>
<tr>
<td>resultMap</td>
<td>N</td>
<td>object</td>
<td>其他结果值Map</td>
<td>如分页结果数据</td>
</tr>
<tr>
<td>msgCode</td>
<td>N</td>
<td>String</td>
<td>错误码</td>
<td>见项目的错误码对照表</td>
</tr>
<tr>
<td>message</td>
<td>N</td>
<td>String</td>
<td>错误信息</td>
<td></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <tags>
        <tag>REST</tag>
      </tags>
  </entry>
  <entry>
    <title>如何从零搭建元数据管理平台</title>
    <url>/2020/04/24/%E5%A6%82%E4%BD%95%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<p>关键词：数据血缘、元数据治理、metadata<br><a id="more"></a><br>元数据平台的作用以及如何构建</p>
<h1 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h1><ul>
<li>怎么定义元数据？</li>
<li>元数据平台要解决哪些问题？</li>
<li>如何获取元数据？<ul>
<li>数据来源规划</li>
</ul>
</li>
<li>如何存储元数据？<ul>
<li>数据血缘如何构建</li>
</ul>
</li>
<li>如何提供元数据服务？<ul>
<li>数据源变更处理方式</li>
</ul>
</li>
</ul>
<h1 id="元数据是什么？"><a href="#元数据是什么？" class="headerlink" title="元数据是什么？"></a>元数据是什么？</h1><p>一般来说是数据的数据。具体来说，就是对动态数据的一种静态信息描述。狭义的元数据我们一般指的是数据集，表本身的信息（结构，量级，归属，修改历史）以及表与表之间的关系；实际在数据流处理中，元数据的类型可以按数据处理的生命周期来细分：</p>
<ol>
<li>最原始的数据实体，称为<code>模式元数据</code>，如数据的表结构Schema信息，业务属性信息</li>
<li>数据实体之间的处理逻辑，叫做etl数据处理，接着有了数据实体的<code>关系元数据</code>，数据的血缘关系信息</li>
<li>对于这些数据处理的逻辑形式，需要调度器来物理化执行，所以有了<code>调度元数据</code></li>
<li>数据处理完成之后，需要发布报表，就有了<code>报表元数据</code>，各类统计信息</li>
<li>整体系统中，会涉及不同的用户实体，就有了<code>用户元数据</code>，读写记录，权限归属<br>元数据系统的建立，是企业级的信息化建设过程。</li>
</ol>
<h1 id="元数据平台是什么？"><a href="#元数据平台是什么？" class="headerlink" title="元数据平台是什么？"></a>元数据平台是什么？</h1><p>数据治理是一个庞大的系统，其中主要包括数据管控，数据质量，数据安全，数据标准。其中数据管控的目标是让每一项数据变更都能得到明确记录及授权，使得数据系统变得可控，可追溯。而数据管控的核心就是搭建元数据平台，这样才能开始数据的规范化，才能做到管控；</p>
<h2 id="元数据平台解决什么问题？"><a href="#元数据平台解决什么问题？" class="headerlink" title="元数据平台解决什么问题？"></a>元数据平台解决什么问题？</h2><p>通过元数据建设，为使用数据提效，解决“找数、理解数、评估”难题以及“取数、数据可视化”等难题。</p>
<ul>
<li>数据问题：多种存储形式的数据来源（mysql、hive、hbase、es）、数据变化评率高；</li>
<li>数据使用问题：查看表信息（结构、量级、所属、是否可用）、表依赖（血缘统计）；</li>
<li>数据管理问题：表权限管理、数据质量管控、数据接入管理；</li>
</ul>
<h2 id="元数据平台包含哪些功能？"><a href="#元数据平台包含哪些功能？" class="headerlink" title="元数据平台包含哪些功能？"></a>元数据平台包含哪些功能？</h2><p>核心功能是实现数据地图功能；数据地图以数据搜索为基础，提供表使用说明、数据类目、数据血缘、字段血缘等工具，帮助数据表的使用者和拥有者更好地管理数据、协作开发。</p>
<ol>
<li>元数据采集</li>
<li>元模型构建</li>
<li>元数据服务</li>
<li>元数据应用</li>
</ol>
<h1 id="元数据来源"><a href="#元数据来源" class="headerlink" title="元数据来源"></a>元数据来源</h1><h2 id="元数据的获取形式"><a href="#元数据的获取形式" class="headerlink" title="元数据的获取形式"></a>元数据的获取形式</h2><ul>
<li><code>pull</code>：元数据管理平台根据用户的数据源定制工具抓取元数据<ul>
<li>优点：用户不需要对接平台</li>
<li>缺点：平台维护成本高，用户数据结构变更后，可能需要重新对接</li>
</ul>
</li>
<li><code>push</code>：用户调用元数据管理平台接口提交元数据更新<ul>
<li>元数据平台以消息队列异步处理</li>
</ul>
</li>
</ul>
<h2 id="元数据的业务来源"><a href="#元数据的业务来源" class="headerlink" title="元数据的业务来源"></a>元数据的业务来源</h2><ol>
<li>知识线：智能问答、问答社区的埋点、反馈数据；</li>
<li>营销线：财税学院、学会app的埋点、用户、课程数据；</li>
<li>金融线：企业风控特征、贷后数据。</li>
</ol>
<h2 id="如何存储元数据？"><a href="#如何存储元数据？" class="headerlink" title="如何存储元数据？"></a>如何存储元数据？</h2><p>元数据的主体主要是<code>实体</code>以及<code>关系</code>。</p>
<ul>
<li>实体：user、dataset、report、job、metrics</li>
<li>数据实体用关系数据库存储，如MySQL</li>
<li>元数据之间的关系用图数据库存储，如Neo4j</li>
<li>用全文索引实现快速搜索，如ElasticSearch</li>
</ul>
<h2 id="如何提供元数据服务？"><a href="#如何提供元数据服务？" class="headerlink" title="如何提供元数据服务？"></a>如何提供元数据服务？</h2><ul>
<li>API</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1>]]></content>
      <tags>
        <tag>DataHub</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库术语</title>
    <url>/2020/06/01/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9C%AF%E8%AF%AD/</url>
    <content><![CDATA[<p>本文记录数据仓库的术语<br><a id="more"></a></p>
<h1 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h1><p><code>DW，Data Warehouse，数据仓库</code>：DW是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策（Decision Making Support）；</p>
<h1 id="数据仓库流派"><a href="#数据仓库流派" class="headerlink" title="数据仓库流派"></a>数据仓库流派</h1><ul>
<li>kimbal模式（维度建模）：Kimball 模式从流程上看是是自底向上的，即数据集市&gt;数据仓库&gt;数据源，先有数据集市再有数据仓库的一种敏捷开发方法。</li>
<li>Inmon 模式：从流程上看是自顶向下的，即数据源&gt;数据仓库&gt;数据集市，先有数据仓库再有数据集市一种瀑布流开发方法。</li>
</ul>
<h1 id="维度建模"><a href="#维度建模" class="headerlink" title="维度建模"></a>维度建模</h1><ul>
<li><p>星型模型：一种非正规化的结构，多维数据集的每一个维度都直接与事实表相连接，不存在渐变维度，所以数据有一定的冗余；</p>
<ul>
<li>当所有维表都直接连接到“ 事实表”上时，整个图解就像星星一样，故将该模型称为星型模型</li>
<li>空间换时间：数据冗余，所以事实表的连接少，查询性能好</li>
<li>更易于指标分析</li>
</ul>
</li>
<li><p>雪花模型：雪花模型是对星型模型的扩展。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 “ 层次 “ 区域，这些被分解的表都连接到主维度表而不是事实表。</p>
<ul>
<li>当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。</li>
<li>时间换空间：数据冗余少，但事实表之间的连接多，性能相对较低</li>
<li>更易于维度分析</li>
</ul>
</li>
</ul>
<blockquote>
<p>在冗余可以接受的前提下，实际运用中星型模型使用更多，也更有效率。</p>
</blockquote>
<h1 id="数仓逻辑架构"><a href="#数仓逻辑架构" class="headerlink" title="数仓逻辑架构"></a>数仓逻辑架构</h1><ul>
<li>数据源；</li>
<li><code>ODS，Operation Data Store，原始数据层</code>：原始数据的copy，因此ODS层也经常会被称为准备区（Staging area）；</li>
<li><code>DW，Data Warehouse，数据仓库</code>：包含DWD和DWS，是ODS层ETL后的结果数据；<ul>
<li>各个系统的元数据通过ETL同步到操作性数据仓库ODS中，对ODS数据进行面向主题域建模形成DW（数据仓库）;</li>
<li>具备唯一性，权威性，准确性</li>
</ul>
</li>
<li><code>DM，Data Mart，数据集市</code>：DM是针对某一个业务领域建立模型，具体用户（决策层）查看DM生成的报表（ADS表）;<ul>
<li>以某个业务应用为出发点而建立的局部DW</li>
</ul>
</li>
</ul>
<blockquote>
<p>通过数据仓库不同层次之间的加工过程实现从数据资产向信息资产的转化，并且对整个过程进行有效的元数据管理及数据质量处理。</p>
</blockquote>
<h1 id="数仓分层"><a href="#数仓分层" class="headerlink" title="数仓分层"></a>数仓分层</h1><ul>
<li><code>ODS，Operation Data Store，原始数据层</code>：存放结构化的原始数据，直接加载原始日志、数据，数据保持原貌不做处理，禁止重复数据；</li>
<li><code>DWD，Data Warehouse Detail，基础数据层</code>：事实表，对ODS层数据进行清洗（去除空值，脏数据，超过极限范围的数据，行式存储改为列存储，改压缩格式） 解决一些数据质量问题和数据的完整度问题；</li>
<li><code>DWS，Daw Warehouse Summary，标签数据层</code>：事实表，轻度汇总层（面向分析型应用进行细粒度的统计和沉淀），对ODS层的操作数据进行轻度综合和汇总统计；</li>
<li><code>ADS，Application Data Store：应用数据层</code>:用于输出报表数据，根据业务需求组织数据；<ul>
<li>该层支持百花齐放、尽可能都依赖DWS，特殊情况可依赖DWD的数据；</li>
<li>该层定期需要定期review，将公共指标沉淀到DWS中；</li>
</ul>
</li>
</ul>
<p>其他公共层级</p>
<ul>
<li><code>DIM，Dimension，公共维表层</code>，为DWD、DWS、ADS提供维度字段说明，如国家代码和国家名、地理位置、中文名、国旗图片等信息；</li>
<li><code>EVL，Evaluate，数据质量评估层</code>,独立于ODS、DWD、DWS、ADS、DIM以外，对ODS、DWD、DWS、ADS、DIM的数据质量进行评估，存储评估指标数据；</li>
<li><code>TMP，TEMP,临时表层</code>：每一层的计算都会有很多临时表，专设TMP层来存储数据仓库的临时表；</li>
</ul>
]]></content>
      <tags>
        <tag>DW</tag>
      </tags>
  </entry>
  <entry>
    <title>用DataHub实践元数据管理</title>
    <url>/2020/04/19/%E7%94%A8DataHub%E5%AE%9E%E8%B7%B5%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>用linkedin开源框架datahub实现元数据管理<br><a id="more"></a></p>
<h1 id="Datahub"><a href="#Datahub" class="headerlink" title="Datahub"></a>Datahub</h1><p><img src="datahub-architecture.png" alt="datahub-architecture"></p>
<h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><h2 id="Metadata-Architecture"><a href="#Metadata-Architecture" class="headerlink" title="Metadata-Architecture"></a>Metadata-Architecture</h2><ul>
<li>GMA：Generalized Metadata Architecture，通用元数据架构，GMA通过Rest.li提供微服务（即GMS)。GMA的Generalized体现在存储层支持文档型CRUD，复杂Join，图遍历，全文索引；</li>
<li>GMS：Generalized Metadata Service，通用元数据服务，需通过GMA DAOS访问元数据；</li>
<li>GMA DAO：GMA的通用数据访问层，包含4种类型的DAO：<ul>
<li>Key-value DAO（LocalDAO）:kv本地搜索</li>
<li>Search DAO：文档搜索</li>
<li>Query DAO：图/非图搜索</li>
<li>Remote DAO：只读形式访问远程GMS元数据</li>
</ul>
</li>
</ul>
<h2 id="Metadata-Model"><a href="#Metadata-Model" class="headerlink" title="Metadata-Model"></a>Metadata-Model</h2><ul>
<li>URN：Uniform Resource Name，统一资源名称，如<code>urn:&lt;Namespace&gt;:&lt;Entity Type&gt;:&lt;ID&gt;</code>；</li>
<li>PDL： a schema definition language for Pegasus，用于服务端和客户端的数据序列化/反序列化，是Rest.li框架的一部分；<ul>
<li>Pegasus：支持丰富的语法，可实现对复杂关系做表示和建模；</li>
</ul>
</li>
<li>AVSC：avro序列化生成的文件格式，datahub支持用<code>Pegasus&#39;s DataTranslator</code>实现pdsc和avsc格式的相互转换；</li>
<li>PDSC：Pegasus schema definition language，一种定义schema的DSL语言，思想源于AVRO1.4.1；；</li>
</ul>
<h2 id="Metadata-Event"><a href="#Metadata-Event" class="headerlink" title="Metadata-Event"></a>Metadata-Event</h2><ul>
<li>MXE(Metadata Events)元数据事件<ul>
<li>MCE：Metata Change Event，元数据change事件，<ul>
<li>snapshot-oriented metadata change proposal</li>
<li>delta-oriented metadata change proposal</li>
</ul>
</li>
<li>FMCE：Failed Metadata Change Event</li>
<li>MAE：Metadata Audit Event，元数据commited change事件，</li>
</ul>
</li>
</ul>
<h2 id="FrameWork"><a href="#FrameWork" class="headerlink" title="FrameWork"></a>FrameWork</h2><ul>
<li>Rest.li：实现REST协议，服务端/客户端协议对象生成</li>
<li>Kafka：元数据事件异步解耦</li>
<li>ElasticSearch：全文索引</li>
<li>Neo4j：图检索</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/linkedin/datahub/tree/master/docs/what">datahub-what</a></li>
</ul>
]]></content>
      <tags>
        <tag>DataHub</tag>
      </tags>
  </entry>
  <entry>
    <title>JDL领域实体建模</title>
    <url>/2020/05/25/JDL%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/</url>
    <content><![CDATA[<p>传统领域实体建模一般采用PowerDesign等UML软件实现，设计更新没有版本控制，不易维护和团队分享；<br>可采用JDL（Jhipster Domain Language）实现document as code，编写jdl文件并用git进行版本控制；<br>JDL建模IDE可采用online,visual studio code,atom等通用文本编辑器，可导出图片预览UML效果；<br>JDL编写好后，可用jhipster import-jdl工具生成entity层的java代码。<br><a id="more"></a>  </p>
<h1 id="JDL介绍"><a href="#JDL介绍" class="headerlink" title="JDL介绍"></a>JDL介绍</h1><p>jhipster家的领域建模语言，可以用于实现document as code，实现对ER图的版本管理；</p>
<ul>
<li>sql生成JDL模型描述文件（sql-to-jdl）</li>
<li>用JDL生成UML图</li>
<li>用JDL生成java后端的domain实体</li>
<li>普通CRUD用JPA实现，复杂连接查询用Mybatis</li>
</ul>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p><a href="Xface.jdl">Xface.jdl</a><br><a href="MLP-biz.jdl">MLP.jdl</a><br><a href="MLP-mgmt.jdl">MLP.jdl</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://jhipster-china.github.io/jdl/">jdl语法</a></li>
<li><a href="https://github.com/jhipster/cn/blob/master/pages/jdl.md">JHipster域语言（JDL）</a></li>
</ul>
]]></content>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title>VUE基础知识</title>
    <url>/2020/05/25/VUE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>全栈之路必备springboot+vuejs，点亮vue</p>
<a id="more"></a>  
<h1 id="VUE介绍"><a href="#VUE介绍" class="headerlink" title="VUE介绍"></a>VUE介绍</h1><p>VUE.js是一套构建用户界面的渐进式框架。目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。</p>
<ul>
<li>组件系统是 Vue 的另一个重要概念，因为它是一种抽象，允许我们使用小型、独立和通常可复用的组件构建大型应用.</li>
</ul>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>在一个大型应用中，有必要将整个应用程序划分为组件，以使开发更易管理<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"app"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">app-nav</span>&gt;</span><span class="tag">&lt;/<span class="name">app-nav</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">app-view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">app-sidebar</span>&gt;</span><span class="tag">&lt;/<span class="name">app-sidebar</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">app-content</span>&gt;</span><span class="tag">&lt;/<span class="name">app-content</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">app-view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="VUE项目的目录结构"><a href="#VUE项目的目录结构" class="headerlink" title="VUE项目的目录结构"></a>VUE项目的目录结构</h1><h1 id="router"><a href="#router" class="headerlink" title="router"></a>router</h1><h1 id="vuex"><a href="#vuex" class="headerlink" title="vuex"></a>vuex</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://cn.vuejs.org/v2/guide/index.html">vue2-guide</a></li>
</ul>
]]></content>
      <tags>
        <tag>frontend</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是数据湖</title>
    <url>/2020/07/28/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%B9%96/</url>
    <content><![CDATA[<h1 id="什么是数据湖？"><a href="#什么是数据湖？" class="headerlink" title="什么是数据湖？"></a>什么是数据湖？</h1><p>数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。您可以按原样存储数据（无需先对数据进行结构化处理），并运行不同类型的分析 – 从控制面板和可视化到大数据处理、实时分析和机器学习，以指导做出更好的决策。</p>
<a id="more"></a>  
<h1 id="什么时候采用数据湖？"><a href="#什么时候采用数据湖？" class="headerlink" title="什么时候采用数据湖？"></a>什么时候采用数据湖？</h1><ul>
<li>数据形式多样，有结构化和半结构化数据，如基于事件的数据，服务器日志/点击流</li>
<li>ETL过程复杂，需要复杂的流程将非结构化数据结构化</li>
<li>需保留大量历史数据，需要存储低廉的存储成本</li>
<li>面向实验性的机器学习/预测分析的数据需求，没有固定的数据需求</li>
</ul>
<h1 id="为什么采用数据湖？"><a href="#为什么采用数据湖？" class="headerlink" title="为什么采用数据湖？"></a>为什么采用数据湖？</h1><p>通过数据成功创造商业价值的组织将胜过同行。<br>Aberdeen 的一项调查表明，实施数据湖的组织比同类公司在有机收入增长方面高出 9%。<br>这些领导者能够进行新类型的分析，例如通过日志文件、来自点击流的数据、社交媒体以及存储在数据湖中的互联网连接设备等新来源的机器学习。<br>这有助于他们通过吸引和留住客户、提高生产力、主动维护设备以及做出明智的决策来更快地识别和应对业务增长机会。</p>
<h1 id="数据湖与数据仓库相比–-两种不同的方法"><a href="#数据湖与数据仓库相比–-两种不同的方法" class="headerlink" title="数据湖与数据仓库相比– 两种不同的方法"></a>数据湖与数据仓库相比– 两种不同的方法</h1><p>根据要求，典型的组织将需要数据仓库和数据湖，因为它们可满足不同的需求和使用案例。</p>
<ul>
<li>数据仓库是一个优化的数据库，用于分析来自事务系统和业务线应用程序的关系数据。<ul>
<li>事先定义数据结构和 Schema 以优化快速 SQL 查询，其中结果通常用于操作报告和分析。</li>
<li>数据经过了清理、丰富和转换，因此可以充当用户可信任的“单一信息源”。</li>
</ul>
</li>
<li>数据湖有所不同，因为它存储来自业务线应用程序的关系数据，以及来自移动应用程序、IoT 设备和社交媒体的非关系数据。<ul>
<li>捕获数据时，未定义数据结构或 Schema。这意味着您可以存储所有数据，而不需要精心设计也无需知道将来您可能需要哪些问题的答案。</li>
<li>您可以对数据使用不同类型的分析（如 SQL 查询、大数据分析、全文搜索、实时分析和机器学习）来获得见解。</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>数据仓库</strong></th>
<th><strong>数据湖</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数据</strong></td>
<td>来自事务系统、运营数据库和业务线应用程序的  关系数据</td>
<td>来自 IoT 设备、网站、移动应用程序、社交媒体和企业应用程序的  非关系和关系数据</td>
</tr>
<tr>
<td><strong>Schema</strong></td>
<td>设计在数据仓库实施之前（写入型 Schema）</td>
<td>写入在分析时（读取型 Schema）</td>
</tr>
<tr>
<td><strong>性价比</strong></td>
<td>更快查询结果会带来较高存储成本</td>
<td>更快查询结果只需较低存储成本</td>
</tr>
<tr>
<td><strong>数据质量</strong></td>
<td>可作为重要事实依据的高度监管数据</td>
<td>任何可以或无法进行监管的数据（例如原始数据）</td>
</tr>
<tr>
<td><strong>用户</strong></td>
<td>业务分析师</td>
<td>数据科学家、数据开发人员和业务分析师（使用监管数据）</td>
</tr>
<tr>
<td><strong>分析</strong></td>
<td>批处理报告、BI 和可视化</td>
<td>机器学习、预测分析、数据发现和分析</td>
</tr>
</tbody>
</table>
</div>
<h1 id="数据湖和分析解决方案的基本要素"><a href="#数据湖和分析解决方案的基本要素" class="headerlink" title="数据湖和分析解决方案的基本要素"></a>数据湖和分析解决方案的基本要素</h1><p>组织构建数据湖和分析平台时，他们需要考虑许多关键功能，包括：</p>
<ul>
<li>数据移动：数据湖允许您导入任何数量的实时获得的数据。<ul>
<li>您可以从多个来源收集数据，并以其原始形式将其移入到数据湖中。此过程允许您扩展到任何规模的数据，同时节省定义数据结构、Schema 和转换的时间。</li>
</ul>
</li>
<li>安全地存储和编目数据：数据湖允许您存储关系数据（例如，来自业务线应用程序的运营数据库和数据）和非关系数据（例如，来自移动应用程序、IoT 设备和社交媒体的运营数据库和数据）。它们还使您能够通过对数据进行爬网、编目和建立索引来了解湖中的数据。最后，必须保护数据以确保您的数据资产受到保护。</li>
<li>分析：数据湖允许组织中的各种角色（如数据科学家、数据开发人员和业务分析师）通过各自选择的分析工具和框架来访问数据。这包括 Apache Hadoop、Presto 和 Apache Spark 等开源框架，以及数据仓库和商业智能供应商提供的商业产品。<ul>
<li>数据湖允许您运行分析，而无需将数据移至单独的分析系统。</li>
</ul>
</li>
<li>机器学习：数据湖将允许组织生成不同类型的见解，包括报告历史数据以及进行机器学习（构建模型以预测可能的结果），并建议一系列规定的行动以实现最佳结果。</li>
</ul>
<h1 id="数据湖的价值"><a href="#数据湖的价值" class="headerlink" title="数据湖的价值"></a>数据湖的价值</h1><p>能够在更短的时间内从更多来源利用更多数据，并使用户能够以不同方式协同处理和分析数据，从而做出更好、更快的决策。<br>数据湖具有增值价值的示例包括：</p>
<ul>
<li>改善客户互动：数据湖可以将来自 CRM 平台的客户数据与社交媒体分析相结合，有一个包括购买历史记录和事故单的营销平台，使企业能够了解最有利可图的客户群、客户流失的原因以及将提升忠诚度的促销活动或奖励。</li>
<li>改善研发创新选择：数据湖可以帮助您的研发团队测试其假设，改进假设并评估结果 – 例如在产品设计中选择正确的材料从而提高性能，进行基因组研究从而获得更有效的药物，或者了解客户为不同属性付费的意愿。</li>
<li>提高运营效率：物联网 (IoT) 引入了更多方式来收集有关制造等流程的数据，包括来自互联网连接设备的实时数据。使用数据湖，可以轻松地存储，并对机器生成的 IoT 数据进行分析，以发现降低运营成本和提高质量的方法。</li>
</ul>
<h1 id="数据湖的挑战"><a href="#数据湖的挑战" class="headerlink" title="数据湖的挑战"></a>数据湖的挑战</h1><p>数据湖架构的主要挑战是存储原始数据而不监督内容。对于使数据可用的数据湖，它需要有定义的机制来编目和保护数据。没有这些元素，就无法找到或信任数据，从而导致出现“数据沼泽”。<br>满足更广泛受众的需求需要数据湖具有<code>管理、语义一致性和访问控制</code>。</p>
]]></content>
      <tags>
        <tag>数据湖</tag>
      </tags>
  </entry>
  <entry>
    <title>任务调度系统之Airflow</title>
    <url>/2020/07/28/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E4%B9%8BAirflow/</url>
    <content><![CDATA[<p>airflow和传统的调度系统的最大区别是采用<code>workflow as code</code>思想，,dag是采用python代码定义，目标用户是熟悉python的工程师，普通用户使用成本较高。</p>
<a id="more"></a>  
<h1 id="airflow核心概念"><a href="#airflow核心概念" class="headerlink" title="airflow核心概念"></a>airflow核心概念</h1><ul>
<li>queue：任务执行环境依赖，按queue隔离执行机器</li>
<li>pool：任务执行资源依赖，限制任务并发数</li>
<li>dag：任务关系依赖</li>
<li>cron：任务时间依赖</li>
<li>hook：外部系统依赖</li>
</ul>
<h1 id="airflow架构"><a href="#airflow架构" class="headerlink" title="airflow架构"></a>airflow架构</h1><p>中心化思想的实现，master(scheduler)分发任务，worker执行工作。</p>
<ul>
<li>airflow-scheduler：调度器，轮询元数据库（Metastore）已注册的DAG是否需要被执行，如果DAG需要被执行，scheduler守护进程就会先在元数据库创建一个DagRun实例，并触发DAG内部的task，即推送task消息到消息队列；</li>
<li>airflow-webserver：dag管理；</li>
<li>rabbitmq：celery broker，存储task消息，每一个task消息都包含此task的DAGID、taskID及具体需要被执行的函数；</li>
<li>airflow-worker：任务执行，监听消息队列，如果有消息，就从消息队列中取出消息，当取出任务消息时，它会更新元数据中DagRun实例的状态为正在运行，并尝试执行DAG中的task。如果DAG执行成功，则更新DagRun实例的状态为成功，否则更新状态为失败。</li>
<li>airflow-flower：worker监控</li>
<li>airflow-metastore：调度数据存储</li>
</ul>
<h1 id="airflow选型考虑"><a href="#airflow选型考虑" class="headerlink" title="airflow选型考虑"></a>airflow选型考虑</h1><blockquote>
<p><strong>pros</strong></p>
<ul>
<li><code>code as workflow</code>的最佳实践，配置即代码，且提供dag管道可视化；</li>
<li>架构偏数据科学风格，插件化设计，可扩展性强；</li>
<li>代码少，简洁，易维护，适合深度定制；</li>
<li>丰富的任务类型，自定义任务类型非常简单；</li>
<li>丰富的告警/通知机制，提供sentry/dingtalk/email等集成；</li>
<li>可基于queue和pool实现任务隔离和资源限制；</li>
<li>提供backfill机制补数据；</li>
<li>可采集数据血缘与元数据系统集成；</li>
<li>slack和github社区活跃；</li>
</ul>
<p><strong>cons</strong></p>
<ul>
<li>功能定制成本高：弱类型的python源码，理解维护成本较高；</li>
<li>REST接口不成熟：目前处于experiment阶段，存在变动的；</li>
<li>流程定义方式工程化：dag文件定义需要依赖git或者分布式文件系统，没有使用数据库进行管理，不便于系统集成；</li>
<li>系统部署复杂：依赖组件多，与其他调度系统相比，需额外部署一个MQ集群；</li>
</ul>
</blockquote>
<h1 id="airflow调度规则"><a href="#airflow调度规则" class="headerlink" title="airflow调度规则"></a>airflow调度规则</h1><ul>
<li>cron：通过<code>croniter</code>实现<ul>
<li>每5分钟：<em>/5 </em> <em> </em> *</li>
</ul>
</li>
<li>预定义presets调度周期：<code>@once,@hourly,@daily,@weekly,@monthly,@quarterly,@yearly</code><ul>
<li>会转换为cron表达式执行（normalized_schedule_interval）</li>
</ul>
</li>
<li>timedelta:</li>
</ul>
<h1 id="airflow的job状态"><a href="#airflow的job状态" class="headerlink" title="airflow的job状态"></a>airflow的job状态</h1><p>对应<code>dag_run</code>表的state字段</p>
<ul>
<li>默认为running</li>
<li>执行成功：success</li>
<li>执行失败/超时：failed</li>
</ul>
<h1 id="airflow的task状态"><a href="#airflow的task状态" class="headerlink" title="airflow的task状态"></a>airflow的task状态</h1><p>对应<code>task_instance</code>表的state字段</p>
<ul>
<li>no_status：scheduler调度ti，初始化状态：</li>
<li>queued：scheduler将ti发送到队列后，等待pool的slot资源：</li>
<li>running：worker任务执行开始：</li>
<li>retry：worker任务执行失败后按配置的重试次数进行重试；</li>
<li>success：worker任务执行成功；</li>
<li>failed：worker任务执行失败/超时：</li>
<li>skipped：一般分支节点下游的某个分支会存在跳过的情况；</li>
<li>up_for_retry：task已failed但尚未进入retry状态；</li>
<li>up_for_reschedule：主要针对sensor，等待被再次调度，避免直接执行占用worker的slot；</li>
<li>upstream_failed：依赖的上游task执行失败后，下游task都标记为upstream_failed；</li>
</ul>
<blockquote>
<p>调度器处理的状态：NONE, SCHEDULED, QUEUED, UP_FOR_RETRY<br>任务运行状态：RETRY，RUNNING<br>任务终止状态：SUCCESS，FAILED，SKIPPED，UPSTREAM_FAILED</p>
</blockquote>
<h1 id="airflow任务触发规则"><a href="#airflow任务触发规则" class="headerlink" title="airflow任务触发规则"></a>airflow任务触发规则</h1><ul>
<li>all_success: 所有父节点都是success状态；</li>
<li>all_failed: 所有父节点都是failed或upstream_failed状态；</li>
<li>all_done: 所有父节点都是是终止状态状态；</li>
<li>one_failed: 至少有1个父节点状态为failed，不需要等待所有父节点执行完成；</li>
<li>one_failed: 至少有1个父节点状态为success，不需要等待所有父节点执行完成；</li>
<li>one_failed: 所有父节点状态都不是failed或upstream_failed状态，即所有父节点执行完成（succeeded或skipped）；</li>
<li>none_failed: 所有父节点状态都不是failed或upstream_failed状态，即所有父节点执行完成（succeeded或skipped）；</li>
<li>none_failed_or_skipped: 所有父节点状态都不是failed或upstream_failed状态，至少1个父节点是success状态；</li>
<li>none_skipped: 所有父节点都不是skipped状态；如所有父节点都是success, failed, 或 upstream_failed状态；</li>
<li>dummy: 演示用的节点状态，可随意触发</li>
</ul>
<h1 id="airflow核心参数"><a href="#airflow核心参数" class="headerlink" title="airflow核心参数"></a>airflow核心参数</h1><h2 id="dag调度参数"><a href="#dag调度参数" class="headerlink" title="dag调度参数"></a>dag调度参数</h2><ul>
<li>start_date：task调度起始日期</li>
<li>end_date：task调度截止日期</li>
<li>execution_date：task逻辑时间执行<pre><code>  * 逻辑执行时间：task理论上应该执行的时间
  * 物理执行时间：task执行时间可能由于服务阻塞而延迟
</code></pre></li>
<li>schedule_interval：任务调度周期，timedelta或cron表达式</li>
<li>execution_timeout: task执行超时时间</li>
<li>retries：task失败后最大重试次数</li>
<li>retry_delay: task失败后重试间隔</li>
</ul>
<h2 id="dag执行参数"><a href="#dag执行参数" class="headerlink" title="dag执行参数"></a>dag执行参数</h2><ul>
<li>parallelism：同时运行的最大task实例数，全局配置参数，默认32</li>
<li>max_active_runs：单个dag同时运行最大dag实例数，可在dag定义时传入</li>
<li>dag_concurrency：单个dag同时运行最大task数，可在dag定义时传入</li>
<li>pool：通过pool的slo大小限制task的并行执行数，超过容量后任务将会按priority_weight排队，直到有任务完成空出solt</li>
</ul>
<h1 id="airflow的数据结构"><a href="#airflow的数据结构" class="headerlink" title="airflow的数据结构"></a>airflow的数据结构</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>* </p>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式任务调度系统的技术选型</title>
    <url>/2020/07/28/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/</url>
    <content><![CDATA[<p>一个调度系统，涉及的功能可按任务执行周期分为3部分：</p>
<ul>
<li><strong>执行前：</strong><ul>
<li>任务定义，如任务关系可以用DAG定义；</li>
<li>任务调度，如按cron调度；</li>
<li>任务分发，如通过mq分发任务；</li>
</ul>
</li>
<li><strong>执行中：</strong><ul>
<li>任务执行资源隔离：不同作业可在不同的机器上执行；</li>
<li>任务执行并发控制：同一类型的作业可控制并发数；</li>
<li>任务执行进度查询：可查询作业中每个任务的执行情况；</li>
</ul>
</li>
<li><strong>任务后：</strong><ul>
<li>任务执行异常通知：任务执行异常有邮件/消息通知机制；</li>
<li>任务执行情况统计：可以分析历史执行情况，评估SLA；</li>
</ul>
</li>
</ul>
<a id="more"></a>  
<h1 id="典型的工作处理流程"><a href="#典型的工作处理流程" class="headerlink" title="典型的工作处理流程"></a>典型的工作处理流程</h1><p>工作流程通常由一系列的任务组成，并由调度器或事件触发，其通常包含5个步骤：</p>
<ul>
<li>下载任务数据；</li>
<li>分发任务数据到处理节点；</li>
<li>监控处理进度直到任务结束；</li>
<li>获取任务处理结果并生成任务处理报告；</li>
<li>发送任务处理报告；</li>
</ul>
<h1 id="选型要求"><a href="#选型要求" class="headerlink" title="选型要求"></a>选型要求</h1><ul>
<li>作业定义：支持DAG，DAG流程支持模板复用；</li>
<li>任务定义：至少支持bash，jdbc，hive，hdfs；</li>
<li>任务调度：支持CRON，支持事件触发，区间补数据（串行/并行）；</li>
<li>任务隔离：作业可隔离执行环境，如采用kubernetes，每个task实例启动一个pod，可采用不同的镜像；</li>
<li>任务执行：支持任务并行，支持重新执行；</li>
<li>任务回溯：支持补数据（backfill/catchup）：正向/逆向；</li>
<li>数据血缘：task节点可以手动配置/自动生成至少table级别的数据血缘，在任务执行成功后推送到元数据服务；</li>
<li>异常处理：资源不足时支持任务堆积，节点异常时支持故障转移，机器重启时支持任务恢复，任务超时/异常时可自动重试；</li>
<li>监控告警：监控任务状态，集成邮件/sentry/wechat告警；</li>
<li>安全权限：支持多租户，DAG流程图可按租户隔离，支持LDAP身份验证，Kerberos安全通信；</li>
<li>定制开发：有完善的API接口（REST/Java）</li>
<li>高可用：任务调度节点高可用（避免单点故障），任务执行节点高可用（避免任务过多时产生阻塞）；</li>
</ul>
<h1 id="选型比较"><a href="#选型比较" class="headerlink" title="选型比较"></a>选型比较</h1><ul>
<li>hadoop调度：oozie、azkaban</li>
<li>通用调度：airflow、xxl-job、dolphin scheduler</li>
<li>数据处理+调度：nifi</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/common-workflow-language/common-workflow-language/wiki/Existing-Workflow-systems">Existing-Workflow-systems</a></li>
<li><a href="https://github.com/pditommaso/awesome-pipeline">github-awesome-pipeline</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247488054&amp;idx=1&amp;sn=215ca504afbb3234acd1c4146173b3c7&amp;chksm=e9292f39de5ea62f05bbbc0140d2ef9e88fd1dd6900fd85a066f087c7700837fbef680ce3f86&amp;mpshare=1&amp;scene=1&amp;srcid=0816xzwzUqCYArqbaqiTkgd6&amp;sharer_sharetime=1593736825889&amp;sharer_shareid=c34b9250c3b65723d4a3c176ade2782f&amp;key=0e4d83a1aaa2ddc8403b62d5df36de3b90ae18d3d8065108234d8f22cd3a3d034fcf2df50e4cbf636c43c92a347f377318abc45427053e4b1453d4f3eb73ee212b2283f40d62ce17b68c9352a0f6684c&amp;ascene=1&amp;uin=MjMxNDgyMzI2MA%3D%3D&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=AbPMXYoZZfkTshlVVjR3z18%3D&amp;pass_ticket=VWMiNZeJNL4X5wHsDdDQ0H7rU6tCU9crSAS4TSJ%2BxvzD5v1xKQj3Wp7IomwNYx2Y">阿里-基于DAG的分布式任务调度平台：Maat</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTA4Mzg5NA==&amp;mid=2247484213&amp;idx=2&amp;sn=b1b43170b3f648c7614e4f6500198833&amp;chksm=cfd38e2cf8a4073a3f44bef1304d3309d151da44db8e2b480d7b0a55bce85ab38d09fd94ae51&amp;mpshare=1&amp;scene=1&amp;srcid=0624lsHbVCmyBRefcXoLxTf6&amp;sharer_sharetime=1592988350503&amp;sharer_shareid=c34b9250c3b65723d4a3c176ade2782f&amp;key=0f539cbc0453aa76380486ec4892819e9d4e62323f90a7c2b53f1b3384dc6a43d726deeb3df5136a78e280c2fb279473d264a2750b4ee2193e122843971eb865c390e5cd21a9023f0e7187553ad52814&amp;ascene=1&amp;uin=MjMxNDgyMzI2MA%3D%3D&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=AaRreYnA9Rqyij5w4%2Fzgnww%3D&amp;pass_ticket=eO1PEp6dyacyhKbCSkkBE42%2FiCouwxCJeSsk%2BMPRQfeQO861kaZF4865BimpAqEz">NiFi 在马蜂窝信息流推荐引擎中的使用及扩展</a></li>
<li><a href="http://docs.dc.servyou-it.com/download/attachments/58560520/Real-Time Data Flows with Apache NiFi.pdf?version=1&amp;modificationDate=1593430463000&amp;api=v2">Real-Time Data Flows with Apache NiFi.pdf</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1596567">Apache Nifi的工作原理</a></li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>DSS数据应用集成平台的系统架构</title>
    <url>/2020/12/25/Dss%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E9%9B%86%E6%88%90%E5%B9%B3%E5%8F%B0%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p><code>DataSphere Studio</code>（DSS）是一个数据应用集成平台的开源方案，已集成<code>scriptis</code>数据开发IDE，<code>davinci</code>可视化报表，和<code>qualitis</code>数据质量。<br>另外dss最强的是支持采用DAG工作流将上述组件进行可视化调度编排，目前调度系统支持接入<code>azkaban</code>和<code>airflow</code>，也可自行集成其他调度系统，调度任务底层的作业执行引擎可接入linkis计算中间件；</p>
<p>本文主要的关注点是dss的<code>组件构成</code>，以及<code>dss和linkis的组件交互</code>；<br><a id="more"></a></p>
<h1 id="dss组成"><a href="#dss组成" class="headerlink" title="dss组成"></a>dss组成</h1><p><img src="dss-component.png" alt="dss组件图"></p>
<p>系统组成</p>
<ol>
<li><code>dss-server</code>：通过第三方系统的<code>appjoint-sdk</code>实现和元数据同步（如project）；</li>
<li><code>dss-flow-execution-entrance</code>：工作流实时执行时的dag解析，补充，优化后调用<code>linkis-ujes-client</code>执行；</li>
<li><code>linkis-appjoint-entrance</code>：linkis的第三方系统的执行入口；<ul>
<li>调度系统内部dag解析后，通过调用<code>linkis-ujes-client</code>提交任务到ujes执行；</li>
<li>其他第三方系统（如visualis）除了会调用<code>linkis-ujes-client</code>提交任务到ujes执行，在实时任务执行时，<code>appjoint-entrance</code>也调用第三方服务鉴权和执行任务；</li>
</ul>
</li>
</ol>
<h1 id="dss和linkis交互"><a href="#dss和linkis交互" class="headerlink" title="dss和linkis交互"></a>dss和linkis交互</h1><p><img src="dss.png" alt="dss和linkis交互图"></p>
<h2 id="2种作业类型"><a href="#2种作业类型" class="headerlink" title="2种作业类型"></a>2种作业类型</h2><ol>
<li>appjoint类任务：通过自行实现的appjoint-sdk，调用第三方系统执行，第三方系统再接入linkis-ujes；</li>
<li>workflow类任务：用于实时执行的，从dss读取dag信息，然后解析dag依赖，调用linkis-client进行执行任务节点。</li>
</ol>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Linkis系统架构</title>
    <url>/2020/12/01/Linkis%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>Linkis作为一个计算中间件，是scritpis，visualis，qualitis，exchangis等数据应用组件的计算入口，至关重要。</p>
<p>本文主要的关注点是linkis的<code>组件构成</code>，以及<code>linkis中的作业执行流程</code>；<br><a id="more"></a>  </p>
<h1 id="linkis任务执行流程"><a href="#linkis任务执行流程" class="headerlink" title="linkis任务执行流程"></a>linkis任务执行流程</h1><p><img src="linkis-ujes-sequence.png" alt="linkis任务执行时序图"></p>
<blockquote>
<p>job简要执行流程</p>
<ol>
<li>gateway根据application_type路由任务到具体的entrance；</li>
<li>entrance解析、检查提交的job后转发后发送到scheduler；</li>
<li>job被调度时，向engine-manager申请engine用于执行job；</li>
<li>engine-manager将job提交给已有engine/申请一个新的engine执行;</li>
<li>entrance等待engine执行结果；</li>
</ol>
</blockquote>
<h1 id="linkis组成"><a href="#linkis组成" class="headerlink" title="linkis组成"></a>linkis组成</h1><p><img src="linkis-component.png" alt="linkis组件图"><br>linkis计算中间件核心的是ujes统一作业执行服务，但同时也包含计算所需的网关服务、资源管理服务、元数据服务、物料库和公共服务等；下面逐个说明</p>
<h2 id="eureka-注册中心"><a href="#eureka-注册中心" class="headerlink" title="eureka 注册中心"></a>eureka 注册中心</h2><p>实现服务注册和发现，后续会替换为nacos；</p>
<h2 id="linkis-gateway"><a href="#linkis-gateway" class="headerlink" title="linkis-gateway"></a>linkis-gateway</h2><p>网关，负责服务路由，依赖eureka服务发现，基于<code>spring-cloud gateway</code>实现;</p>
<h2 id="linkis-resourcemanager"><a href="#linkis-resourcemanager" class="headerlink" title="linkis-resourcemanager"></a>linkis-resourcemanager</h2><p>资源管理服务</p>
<h3 id="组件功能"><a href="#组件功能" class="headerlink" title="组件功能"></a>组件功能</h3><ol>
<li>dss查询em和engine的资源使用情况</li>
<li>em/engine资源的注册、锁定、注销</li>
</ol>
<h3 id="组件相关表"><a href="#组件相关表" class="headerlink" title="组件相关表"></a>组件相关表</h3><ul>
<li>linkis_em_meta_data：EngineManager元数据</li>
<li>linkis_em_resource_meta_data：EngineManager的实例元数据</li>
<li>linkis_user_resource_meta_data：用户占用的em和engine实例</li>
<li>linkis_resource_lock：用户engine实例锁</li>
</ul>
<h2 id="linkis-ujes"><a href="#linkis-ujes" class="headerlink" title="linkis-ujes"></a>linkis-ujes</h2><p>统一作业执行服务<br><img src="linkis-ujes.jpg" alt="ujes"></p>
<h3 id="组件功能-1"><a href="#组件功能-1" class="headerlink" title="组件功能"></a>组件功能</h3><p>包含entrance、enginemanager和engine三类服务</p>
<ul>
<li>entrance：服务入口，管理job的生命周期：Scheduled、Running、WaitForRetry、Failed、Cancelled、Timeout、Sucess；<ul>
<li>包含解析器、拦截器、监听器、调度器、执行器等多层过滤处理逻辑，超级复杂；</li>
</ul>
</li>
<li>enginemanager：执行引擎管理器，管理engine的生命周期：Starting,、Idle、Busy、ShuttingDown、Error、Dead、Success；</li>
<li>engine：执行引擎，提交任务和具体的执行着交互；</li>
</ul>
<h2 id="linkis-bml"><a href="#linkis-bml" class="headerlink" title="linkis-bml"></a>linkis-bml</h2><p>物料库</p>
<ol>
<li>查询/更新/删除资源版本</li>
<li>查询/下载/更新/删除资源<br>如：存储dag的历史版本</li>
</ol>
<h3 id="组件相关表-1"><a href="#组件相关表-1" class="headerlink" title="组件相关表"></a>组件相关表</h3><ul>
<li>linkis_resources：用户资源列表</li>
<li>linkis_resources_version：用户资源版本列表</li>
<li>linkis_resources_download_history：用户资源下载日志</li>
<li>linkis_resources_task：资源上传/更新日志</li>
<li>linkis_resources_permission：用户资源权限</li>
</ul>
<h2 id="linkis-metadata"><a href="#linkis-metadata" class="headerlink" title="linkis-metadata"></a>linkis-metadata</h2><p>元数据服务</p>
<h3 id="组件功能-2"><a href="#组件功能-2" class="headerlink" title="组件功能"></a>组件功能</h3><ul>
<li>scriptis的hive数据库/表/字段查询</li>
<li>scriptis的表创建向导，支持从已有表导入，会生成血缘数据</li>
</ul>
<h3 id="组件相关表-2"><a href="#组件相关表-2" class="headerlink" title="组件相关表"></a>组件相关表</h3><ul>
<li>linkis_mdq_table：表元数据</li>
<li>linkis_mdq_table_info：表统计信息</li>
<li>linkis_mdq_field：表字段</li>
<li>linkis_mdq_lineage：表级血缘</li>
<li>linkis_mdq_access：表/字段的访问记录</li>
<li>linkis_mdq_import：表导入记录</li>
</ul>
<h2 id="linkis-publicservice"><a href="#linkis-publicservice" class="headerlink" title="linkis-publicservice"></a>linkis-publicservice</h2><p>公共服务<br><img src="linkis-publicservice.jpg" alt="publicservice"><br>包含函数管理、变量管理、配置管理、工作空间管理、用户注册、任务管理等6个子模块</p>
<h3 id="udf-manager"><a href="#udf-manager" class="headerlink" title="udf-manager"></a>udf-manager</h3><p>函数管理</p>
<h4 id="组件功能-3"><a href="#组件功能-3" class="headerlink" title="组件功能"></a>组件功能</h4><p>udf和method定义</p>
<h4 id="组件相关表-3"><a href="#组件相关表-3" class="headerlink" title="组件相关表"></a>组件相关表</h4><ul>
<li>linkis_udf：udf列表</li>
<li>linkis_udf_tree：用户udf分类目录树</li>
<li>linkis_udf_user_load_info：用户udf加载列表</li>
<li>linkis_udf_shared_user：用户共享udf（未用）</li>
<li>linkis_udf_shared_group：用户组共享udf（未用）</li>
<li>linkis_udf_manager：用udf列表（未用）</li>
</ul>
<h3 id="variable-manager"><a href="#variable-manager" class="headerlink" title="variable-manager"></a>variable-manager</h3><p>变量管理</p>
<h4 id="组件功能-4"><a href="#组件功能-4" class="headerlink" title="组件功能"></a>组件功能</h4><ol>
<li>定义变量</li>
</ol>
<h4 id="组件相关表-4"><a href="#组件相关表-4" class="headerlink" title="组件相关表"></a>组件相关表</h4><ul>
<li>linkis_var_key：全局变量</li>
<li>linkis_var_key_user：用户自定义变量</li>
</ul>
<h3 id="workspace-manager"><a href="#workspace-manager" class="headerlink" title="workspace-manager"></a>workspace-manager</h3><p>工作空间管理</p>
<h4 id="组件功能-5"><a href="#组件功能-5" class="headerlink" title="组件功能"></a>组件功能</h4><ol>
<li>打开/保存脚本：依赖bml服务</li>
<li>IDE中日志/文件/目录的增删改查/下载：依赖mfs/hdfs</li>
</ol>
<h3 id="application-manager"><a href="#application-manager" class="headerlink" title="application-manager"></a>application-manager</h3><p>应用管理</p>
<h4 id="组件功能-6"><a href="#组件功能-6" class="headerlink" title="组件功能"></a>组件功能</h4><ol>
<li>用户注册</li>
</ol>
<h4 id="组件相关表-5"><a href="#组件相关表-5" class="headerlink" title="组件相关表"></a>组件相关表</h4><ul>
<li>linkis_user：用户表</li>
<li>linkis_project_list（弃用）</li>
<li>linkis_project_user（弃用）</li>
<li>linkis_develop_application（弃用）</li>
</ul>
<h3 id="job-manager"><a href="#job-manager" class="headerlink" title="job-manager"></a>job-manager</h3><p>任务管理</p>
<h4 id="组件功能-7"><a href="#组件功能-7" class="headerlink" title="组件功能"></a>组件功能</h4><ol>
<li>脚本任务执行记录查询</li>
<li>任务新增、任务执行状态更新</li>
</ol>
<h4 id="组件相关表-6"><a href="#组件相关表-6" class="headerlink" title="组件相关表"></a>组件相关表</h4><ul>
<li>linkis_task：用户任务执行日志表</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/WeBankFinTech/WeDataSphere/issues/29">DSS的CICD实践</a></li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>DSS工作流实现原理</title>
    <url>/2021/01/28/DSS%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>DSS工作流实现相关笔记<br><a id="more"></a>  </p>
<h1 id="BML"><a href="#BML" class="headerlink" title="BML"></a>BML</h1><ul>
<li>工作流的节点可以关联一个执行脚本，比如shell/python/sql</li>
<li>脚本保存时（saveScriptToBML）,会为文件新增1个版本，实际实现是追加字节到hdfs的文件尾部，linkis会在<code>linkis_resources_version</code>表存储每个版本起始字节偏移量；</li>
<li>脚本打开时（openScriptFromBML），会根据版本读取文件的起始字节内容；</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>DataSphereStudio工作流集成DolphinScheduler调度引擎</title>
    <url>/2021/01/28/DataSphereStudio%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%9B%86%E6%88%90DolphinScheduler%E8%B0%83%E5%BA%A6%E5%BC%95%E6%93%8E/</url>
    <content><![CDATA[<p>DataSphereStudio工作流集成DolphinScheduler调度引擎的实现思路梳理，从鉴权、资源同步、任务执行等角度分析<br><a id="more"></a>  </p>
<h1 id="DSS接入第三方应用（AppJoint）"><a href="#DSS接入第三方应用（AppJoint）" class="headerlink" title="DSS接入第三方应用（AppJoint）"></a>DSS接入第三方应用（AppJoint）</h1><p>DSS(DataSphere Studio)从一开始就被设计成为一个开放的、具有强扩展能力的系统。<br>DSS系统希望第三方系统是能以插拔式的方式接入，为了实现上述的理念，DSS提出了AppJoint(应用关节)的概念。<br>AppJoint从作用上来说是连接两个系统，并为两个系统的协调运行提供服务。 </p>
<h2 id="接入问题"><a href="#接入问题" class="headerlink" title="接入问题"></a>接入问题</h2><p>任务提交到DSS系统，并由DSS系统转发给第三方外部系统进行执行，必须要考虑并实现下面的几点功能。</p>
<ol>
<li>解决双方系统用户的鉴权问题；</li>
<li>双方系统都需要对用户提交任务的元数据进行正确处理；</li>
<li>DSS系统要能以同步或者异步的方式正确地提交任务给第三方系统进行执行；</li>
<li>任务提交到第三方系统之后，外部系统需要能将日志、状态等信息返回给DSS系统；</li>
<li>第三方系统在任务执行完毕之后，将可能产生的任务结果等信息持久化到执行的路径；</li>
</ol>
<h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><p>为了方便外部系统的接入，DSS提供了SDK的方式,maven依赖引入<code>dss-appjoint-core</code>，具体如下<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.webank.wedatasphere.dss<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dss-appjoint-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;dss.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><br>dss-appjoint-core提供了的AppJoint的顶级接口，想要接入DSS系统的第三方系统都需要实现该顶层接口，此接口有以下方法需要用户进行实现</p>
<h2 id="getSecurityService"><a href="#getSecurityService" class="headerlink" title="getSecurityService"></a>getSecurityService</h2><p>SecurityService是用来进行解决DSS系统与第三方系统的鉴权问题。<br>用户在DSS系统进行登录之后，并希望提交任务到第三方系统，首先第三方系统需要能够将这个用户进行鉴权。</p>
<h2 id="getProjectSerivice"><a href="#getProjectSerivice" class="headerlink" title="getProjectSerivice"></a>getProjectSerivice</h2><p>ProjectService是用来进行解决DSS系统与第三方系统的工程管理问题。<br>用户在DSS系统进行新增、删除、修改工程的时候，第三方系统也需要进行同步进行相同的动作，这样的目的是为了双方系统能够在工程层面实现统一。</p>
<h2 id="getNodeService"><a href="#getNodeService" class="headerlink" title="getNodeService"></a>getNodeService</h2><p>NodeService是用来解决用户在DSS提交的任务在第三方系统生成相应的任务的问题。<br>用户如果在DSS系统的工作流中新建了一个工作流节点并进行任务的编辑，第三方系统需要同步感知到</p>
<h2 id="getNodeExecution"><a href="#getNodeExecution" class="headerlink" title="getNodeExecution"></a>getNodeExecution</h2><p>NodeExecution接口是用来将任务提交到第三方系统进行执行的接口，NodeExecution 接口有支持短时间任务的和支持长时间任务的。</p>
<ul>
<li>短时间任务（NodeExecution），如邮件发送等，可以直接实现NodeExecution接口，并重写execute方法，DSS系统同步等待任务结束。</li>
<li>长时间任务（LongTermNodeExecution），如数据质量检测等，可以实现LongTermNodeExecution接口，并重写submit方法，返回一个NodeExecutionAction，DSS系统通过这个NodeExecutionAction可以向第三方系统获取任务的日志、状态等。</li>
</ul>
<h1 id="集成DolphinScheduler"><a href="#集成DolphinScheduler" class="headerlink" title="集成DolphinScheduler"></a>集成DolphinScheduler</h1><p>针对DSS接入需要解决的问题，DolphinScheduler（下面简称ds）中如何对应解决</p>
<h2 id="用户鉴权"><a href="#用户鉴权" class="headerlink" title="用户鉴权"></a>用户鉴权</h2><ul>
<li>ds调用linkis gateway：cookie中写入bdp-user-ticket-id</li>
<li>linkis调用ds：dss ldap登陆ds后可自动创建token，linkis调用ds接口前，先查询token并缓存（设置ttl)，然后用token调用ds接口；</li>
</ul>
<h2 id="资源同步"><a href="#资源同步" class="headerlink" title="资源同步"></a>资源同步</h2><p>ds中以下资源更新时，同步到dss：</p>
<ul>
<li>项目（project）</li>
<li>工作流（process_definition）：</li>
<li>文件：hdfs目录和文件：bml服务</li>
<li>UDF包/函数定义：hdfs目录和jar包</li>
<li>数据源：jdbc连接配置</li>
<li>队列：任务执行时可选择的yarn队列</li>
<li>告警组：任务执行异常时选择的告警组（包含用户列表）</li>
</ul>
<p>哪些需要在dss更新时，同步到ds</p>
<h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>项目增删改；</p>
<h2 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h2><p>工作流增删改<br>每次dss保存时，dss和ds有各自的工作流版本维护，不用额外双方同步；</p>
<p>针对ds中的任务类型，dss需要对应做适配</p>
<h3 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h3><p>脚本直接映射</p>
<h3 id="sql"><a href="#sql" class="headerlink" title="sql"></a>sql</h3><p>dss中hive、sql、jdbc需要映射成对应的sql任务</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p>脚本直接映射</p>
<h3 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h3><p>待支持</p>
<h3 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h3><p>待支持</p>
<h3 id="http"><a href="#http" class="headerlink" title="http"></a>http</h3><p>待支持</p>
<h3 id="datax"><a href="#datax" class="headerlink" title="datax"></a>datax</h3><p>待支持</p>
<h3 id="condition"><a href="#condition" class="headerlink" title="condition"></a>condition</h3><p>考虑基于dss signal实现</p>
<h3 id="dependent"><a href="#dependent" class="headerlink" title="dependent"></a>dependent</h3><p>考虑基于dss signal实现</p>
<h3 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h3><p>待支持</p>
<h3 id="procedure"><a href="#procedure" class="headerlink" title="procedure"></a>procedure</h3><p>待支持</p>
<h3 id="subprocess"><a href="#subprocess" class="headerlink" title="subprocess"></a>subprocess</h3><p>dss中subflow映射</p>
<h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p>DSS中DAG保存，DAG节点脚本脚本保存，资源上传都需同步</p>
<ul>
<li>dag任务节点关联的脚本，会通过linkis-bml服务保存为hdfs文件，存储在linkis_resources_version表，此时需要调用ds接口同步到ds的resource表</li>
<li>ds和linkis的source的根目录需设置一致，不然ds的web界面不能下载resource对应的文件<h2 id="UDF包-函数定义"><a href="#UDF包-函数定义" class="headerlink" title="UDF包/函数定义"></a>UDF包/函数定义</h2>dss的linkis_udf表新增udf时，需要调用ds接口同步到ds的t_ds_udfs表</li>
</ul>
<h2 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h2><p>dss有JDBC连接配置，但目前需要支持配置多个不同的数据源，不同类型的数据源配置参数会不一致。</p>
<p>如果要支持同步，dss的前后端都需要新增多jdbc源支持，改造好才能在dss编辑jdbc配置时同步到ds的数据源;</p>
<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><ul>
<li>dss不同用户可以在配置中设置默认任务提交的yarn队列名，每个工作流及节点也可以配置执行的yarn队列；</li>
<li>ds中每个工作流可以设置执行租户，租户可以预设置yarn队列；</li>
</ul>
<p>这儿如果需要做到队列配置的同步，需要在dss中添加租户的管理，dss为租户设置队列时需要调用ds接口同步到队列（t_ds_queue），租户（t_ds_tenant）表</p>
<blockquote>
<p>等linkis1.0发布之后支持协同开发，通过设置工程的租户来同步租户队列</p>
</blockquote>
<h2 id="任务执行"><a href="#任务执行" class="headerlink" title="任务执行"></a>任务执行</h2><p>dss任务执行分实时执行和定时执行2种，</p>
<ul>
<li>实时执行直接调用linkis的对应engine执行任务；</li>
<li>定时执行，dss工作流同步到ds后，由ds的调度器定时触发worker执行，此处worker不直接启动任务，而是将任务跳过linkis-ujes-client提交给具体的linkis engine执行，worker实时获取任务的执行日志/进度/状态等数据；</li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>Scheduler</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkOnYarn</title>
    <url>/2021/01/22/FlinkOnYarn/</url>
    <content><![CDATA[<p>dolphinscheduler这个dag的任务类型就差flink就都玩个遍了.<br>简单记录一下，flink word count入门小实验。</p>
<a id="more"></a>
<h1 id="Flink-on-Yarn执行流程"><a href="#Flink-on-Yarn执行流程" class="headerlink" title="Flink on Yarn执行流程"></a>Flink on Yarn执行流程</h1><p><img src="flink_on_yarn.jpg" alt="flink on yarn"></p>
<blockquote>
<p>yarn任务提交流程和<code>spark on yarn</code>类似<br>不过ui端口，spark是启在driver，flink是启在jobManager</p>
</blockquote>
<h1 id="Flink-on-Yarn-部署模式"><a href="#Flink-on-Yarn-部署模式" class="headerlink" title="Flink on Yarn 部署模式"></a>Flink on Yarn 部署模式</h1><p><img src="flink_deploy_mode.png" alt="flink deploy mode"></p>
<ul>
<li>Application Mode：JobManager独立，flink main()在cluster中执行</li>
<li>Per-Job Mode：JobManager独立，flink main()在client中执行</li>
<li>Session Mode：JobManager共享，flink main()在client中执行</li>
</ul>
<blockquote>
<p>数据加工时，由于采用flink定时跑批，租户隔离保证互不影响，所以采用第一种模式；</p>
</blockquote>
<h1 id="flink版本"><a href="#flink版本" class="headerlink" title="flink版本"></a>flink版本</h1><ul>
<li>flink 1.10.2</li>
</ul>
<blockquote>
<p>1.11和1.12的spark on yarn的参数改动有点大，还是保守点用1.10了。<br>其实是dolphinscheduler目前支持的是1.9…升级flink run的args拼起来太麻烦了-_-</p>
</blockquote>
<h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"><span class="built_in">export</span> FLINK_HOME=/opt/cloudera/parcels/CDH/lib/flink-1.10.2</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$FLINK_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<h1 id="kerberos初始化"><a href="#kerberos初始化" class="headerlink" title="kerberos初始化"></a>kerberos初始化</h1><p>kinit -kt /etc/krb5/$principle.keytab $principle</p>
<h1 id="Flink-WordCount"><a href="#Flink-WordCount" class="headerlink" title="Flink WordCount"></a>Flink WordCount</h1><h2 id="WordCount-batch"><a href="#WordCount-batch" class="headerlink" title="WordCount-batch"></a>WordCount-batch</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">flink run -m yarn-cluster  \</span><br><span class="line">-ys 4  \</span><br><span class="line">-ynm myapp \</span><br><span class="line">-yjm 1024  \</span><br><span class="line">-ytm 10240 \</span><br><span class="line">-d  \</span><br><span class="line">-c org.apache.flink.streaming.examples.wordcount.WordCount  \</span><br><span class="line">/opt/cloudera/parcels/CDH/lib/flink-1.10.2/examples/streaming/WordCount.jar</span><br></pre></td></tr></table></figure>
<h2 id="WordCount-streaming"><a href="#WordCount-streaming" class="headerlink" title="WordCount-streaming"></a>WordCount-streaming</h2><ul>
<li>在某个服务器192.168.1.6开启socket端口监听：nc -l 9000</li>
<li>启动flink streaming任务计算wordcount</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">flink run  \</span><br><span class="line">-m yarn-cluster  \</span><br><span class="line">-ys 1  \</span><br><span class="line">-yjm 1G  \</span><br><span class="line">-ytm 1G  \</span><br><span class="line">-d  \</span><br><span class="line">-c org.apache.flink.streaming.examples.socket.SocketWindowWordCount flink/WordCount-SocketWindow.jar  \</span><br><span class="line">--hostname 192.168.1.6   \</span><br><span class="line">--port 9000   \</span><br><span class="line">--qu default</span><br></pre></td></tr></table></figure>
<h1 id="flink-jobmanager"><a href="#flink-jobmanager" class="headerlink" title="flink jobmanager"></a>flink jobmanager</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Found Web Interface 192.168.1.7:40320 of application &#39;application_1611216022576_0309&#39;.</span><br><span class="line">Job has been submitted with JobID 42d4cc8ec8bdacc01e8678089152f414</span><br></pre></td></tr></table></figure>
<p><img src="flink_streaming_wordcount.jpg" alt="flink_streaming_wordcount"></p>
<blockquote>
<p>PS 不说流计算的时效性，flink的web ui比spark实在强太多了。</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/#deployment-modes">flink on yarn模式</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/config.html">flink config</a></li>
</ul>
]]></content>
      <tags>
        <tag>flink</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Visualis可视化工具的系统架构</title>
    <url>/2021/01/21/Visualis%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>visualis是微众基于宜信davinci，为dss定制二开的BI工具。界面清爽，功能齐全。<br>如果想独立部署一个BI工具，单独接davinci就可以。<br>davinci设计理念面向的是开发者，不是直接面向最终业务用户的，对非专业用户来说，用户体验不是特别好。</p>
<a id="more"></a>  
<h1 id="Visualis组件图"><a href="#Visualis组件图" class="headerlink" title="Visualis组件图"></a>Visualis组件图</h1><p><img src="Visualis组件图.jpg" alt="Visualis组件图"></p>
<h1 id="Visualis-E-R图"><a href="#Visualis-E-R图" class="headerlink" title="Visualis E-R图"></a>Visualis E-R图</h1><p><img src="Visualis-ER图.jpg" alt="Visualis ER图"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://edp963.github.io/davinci/docs/zh/1.1-deployment">用户文档</a></li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>BI</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS原理</title>
    <url>/2021/10/21/HDFS%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>binlog日志实时采集,支持按事物聚合输入到flink udf中进行处理<br><a id="more"></a></p>
<h1 id="HDFS需要搞懂的问题"><a href="#HDFS需要搞懂的问题" class="headerlink" title="HDFS需要搞懂的问题"></a>HDFS需要搞懂的问题</h1><h2 id="基础问题"><a href="#基础问题" class="headerlink" title="基础问题"></a>基础问题</h2><ul>
<li>HDFS是什么？</li>
<li>HDFS与常规的文件系统（nfs,oss）有什么区别？</li>
<li>HDFS的物理架构，有哪些角色和他们之间的关系？</li>
<li>HDFS的数据读＆写的流程？</li>
<li>HDFS的数据存储格式，元数据＆数据＋内存＆磁盘？</li>
</ul>
<h2 id="设计问题"><a href="#设计问题" class="headerlink" title="设计问题"></a>设计问题</h2><ul>
<li>HDFS的3类容错的设计方案：namenode容错，datanode容错，网络分区容错？</li>
<li>HDFS的文件存储格式</li>
<li>HDFS的数据一致性如何保证:raft?</li>
<li>HDFS的HA实现方式</li>
</ul>
<h2 id="实战问题"><a href="#实战问题" class="headerlink" title="实战问题"></a>实战问题</h2><ul>
<li>HDFS配置文件解读</li>
<li>HDFS的小文件优化方案</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://lanechen.gitbooks.io/spark-dig-and-buried/content/hadoop/hadoop-ipc.html">https://lanechen.gitbooks.io/spark-dig-and-buried/content/hadoop/hadoop-ipc.html</a></p>
]]></content>
      <tags>
        <tag>hdfs</tag>
      </tags>
  </entry>
  <entry>
    <title>SPARK_ON_MINIKUBE示例</title>
    <url>/2021/10/21/SPARK_ON_MINIKUBE%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<p>spark minikube测试<br><a id="more"></a></p>
<h2 id="启动minikube"><a href="#启动minikube" class="headerlink" title="启动minikube"></a>启动minikube</h2><p>minikube delete<br>minikube start —driver docker —cpus 8  —memory 8g<br>nohup minikube dashboard 2&amp;1 &gt;/dev/null &amp;                       </p>
<h2 id="docker镜像build"><a href="#docker镜像build" class="headerlink" title="docker镜像build"></a>docker镜像build</h2><p>./bin/docker-image-tool.sh   -r harbor.dc.servyou-it.com/geosmart-ops/spark -m -t spark:2.4.8 build</p>
<h2 id="rbac配置"><a href="#rbac配置" class="headerlink" title="　rbac配置"></a>　rbac配置</h2><p>k create namespace spark<br>k create serviceaccount spark  —namespace=spark<br>k create clusterrolebinding spark-role —clusterrole=edit —serviceaccount=spark:spark —namespace=spark</p>
<h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><p>export K8S_SERVER=$(k config view —output=jsonpath=’{.clusters[].cluster.server}’)<br>export K8S_SERVER=<a href="https://192.168.49.2:8443">https://192.168.49.2:8443</a><br>export SPARK_HOME=/opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/lib/spark-2.4.8-bin-hadoop2.6</p>
<h2 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="variable">$SPARK_HOME</span>/bin/spark-submit \</span><br><span class="line">  --master k8s://<span class="variable">$K8S_SERVER</span> \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --name spark-pi \</span><br><span class="line">  --conf spark.executor.instances=2 \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --verbose \</span><br><span class="line"><span class="built_in">local</span>:///opt/spark/examples/jars/spark-examples_2.11-2.4.8.jar 10000</span><br></pre></td></tr></table></figure>
<h2 id="s3a"><a href="#s3a" class="headerlink" title="s3a"></a>s3a</h2><p>$SPARK_HOME/bin/spark-submit \<br>  —master k8s://$K8S_SERVER \<br>  —deploy-mode cluster \<br>  —name spark-pi \<br>  —conf spark.executor.instances=2 \<br>  —class org.apache.spark.examples.SparkPi \<br>  —verbose \<br>s3a://dboard/user/geosmart/spark-examples_2.11-2.4.8.jar  10000</p>
<h1 id="log"><a href="#log" class="headerlink" title="　log"></a>　log</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">21/06/24 13:05:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy <span class="keyword">for</span> block replication policy</span><br><span class="line">21/06/24 13:05:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-pi-1624539948750-driver-svc.spark-demo.svc, 7079, None)</span><br><span class="line">21/06/24 13:05:58 INFO BlockManagerMasterEndpoint: Registering block manager spark-pi-1624539948750-driver-svc.spark-demo.svc:7079 with 413.9 MB RAM, BlockManagerId(driver, spark-pi-1624539948750-driver-svc.spark-demo.svc, 7079, None)</span><br><span class="line">21/06/24 13:05:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-pi-1624539948750-driver-svc.spark-demo.svc, 7079, None)</span><br><span class="line">21/06/24 13:05:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-pi-1624539948750-driver-svc.spark-demo.svc, 7079, None)</span><br><span class="line">21/06/24 13:06:06 INFO KubernetesClusterSchedulerBackend<span class="variable">$KubernetesDriverEndpoint</span>: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.17.0.7:39840) with ID 2</span><br><span class="line">21/06/24 13:06:07 INFO KubernetesClusterSchedulerBackend<span class="variable">$KubernetesDriverEndpoint</span>: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.17.0.6:49498) with ID 1</span><br><span class="line">21/06/24 13:06:07 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready <span class="keyword">for</span> scheduling beginning after reached minRegisteredResourcesRatio: 0.8</span><br><span class="line">21/06/24 13:06:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.0.7:43535 with 413.9 MB RAM, BlockManagerId(2, 172.17.0.7, 43535, None)</span><br><span class="line">21/06/24 13:06:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.0.6:43419 with 413.9 MB RAM, BlockManagerId(1, 172.17.0.6, 43419, None)</span><br><span class="line">21/06/24 13:06:08 INFO SparkContext: Starting job: reduce at SparkPi.scala:38</span><br><span class="line">21/06/24 13:06:08 INFO DAGScheduler: Got job 0 (reduce at SparkPi.scala:38) with 2 output partitions</span><br><span class="line">21/06/24 13:06:08 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at SparkPi.scala:38)</span><br><span class="line">21/06/24 13:06:08 INFO DAGScheduler: Parents of final stage: List()</span><br><span class="line">21/06/24 13:06:08 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">21/06/24 13:06:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34), <span class="built_in">which</span> has no missing parents</span><br><span class="line">21/06/24 13:06:09 INFO MemoryStore: Block broadcast_0 stored as values <span class="keyword">in</span> memory (estimated size 2.0 KB, free 413.9 MB)</span><br><span class="line">21/06/24 13:06:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes <span class="keyword">in</span> memory (estimated size 1381.0 B, free 413.9 MB)</span><br><span class="line">21/06/24 13:06:09 INFO BlockManagerInfo: Added broadcast_0_piece0 <span class="keyword">in</span> memory on spark-pi-1624539948750-driver-svc.spark-demo.svc:7079 (size: 1381.0 B, free: 413.9 MB)</span><br><span class="line">21/06/24 13:06:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1184</span><br><span class="line">21/06/24 13:06:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34) (first 15 tasks are <span class="keyword">for</span> partitions Vector(0, 1))</span><br><span class="line">21/06/24 13:06:09 INFO TaskSchedulerImpl: Adding task <span class="built_in">set</span> 0.0 with 2 tasks</span><br><span class="line">21/06/24 13:06:09 INFO TaskSetManager: Starting task 0.0 <span class="keyword">in</span> stage 0.0 (TID 0, 172.17.0.7, executor 2, partition 0, PROCESS_LOCAL, 7885 bytes)</span><br><span class="line">21/06/24 13:06:09 INFO TaskSetManager: Starting task 1.0 <span class="keyword">in</span> stage 0.0 (TID 1, 172.17.0.6, executor 1, partition 1, PROCESS_LOCAL, 7885 bytes)</span><br><span class="line">21/06/24 13:06:10 INFO BlockManagerInfo: Added broadcast_0_piece0 <span class="keyword">in</span> memory on 172.17.0.7:43535 (size: 1381.0 B, free: 413.9 MB)</span><br><span class="line">21/06/24 13:06:11 INFO TaskSetManager: Finished task 0.0 <span class="keyword">in</span> stage 0.0 (TID 0) <span class="keyword">in</span> 2093 ms on 172.17.0.7 (executor 2) (1/2)</span><br><span class="line">21/06/24 13:06:11 INFO BlockManagerInfo: Added broadcast_0_piece0 <span class="keyword">in</span> memory on 172.17.0.6:43419 (size: 1381.0 B, free: 413.9 MB)</span><br><span class="line">21/06/24 13:06:11 INFO TaskSetManager: Finished task 1.0 <span class="keyword">in</span> stage 0.0 (TID 1) <span class="keyword">in</span> 2443 ms on 172.17.0.6 (executor 1) (2/2)</span><br><span class="line">21/06/24 13:06:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool </span><br><span class="line">21/06/24 13:06:11 INFO DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished <span class="keyword">in</span> 3.020 s</span><br><span class="line">21/06/24 13:06:11 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 3.205210 s</span><br><span class="line">Pi is roughly 3.1459757298786495</span><br><span class="line">21/06/24 13:06:11 INFO SparkUI: Stopped Spark web UI at http://spark-pi-1624539948750-driver-svc.spark-demo.svc:4040</span><br></pre></td></tr></table></figure>
<h1 id="pyspark测试"><a href="#pyspark测试" class="headerlink" title="pyspark测试"></a>pyspark测试</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">**<span class="keyword">import</span> pyspark</span><br><span class="line"></span><br><span class="line">conf = pyspark.SparkConf()</span><br><span class="line">conf.setMaster(<span class="string">"k8s://https://192.168.49.2:8443"</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Worker pods are created from the base Spark docker image.</span></span><br><span class="line"><span class="comment"># If you use another image, specify its name instead.</span></span><br><span class="line">conf.set(<span class="string">"spark.kubernetes.container.image"</span>, <span class="string">"harbor.dc.servyou-it.com/geosmart-ops/dolphinscheduler:latest"</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Authentication certificate and token (required to create worker pods):</span></span><br><span class="line">conf.set(<span class="string">"spark.kubernetes.authenticate.caCertFile"</span>, <span class="string">"/opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/lib/spark/conf/serviceaccount/ca.crt"</span>)</span><br><span class="line">conf.set(<span class="string">"spark.kubernetes.authenticate.oauthTokenFile"</span>, <span class="string">"/opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/lib/spark/conf/serviceaccount/token"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Service account which should be used for the driver</span></span><br><span class="line">conf.set(<span class="string">"spark.kubernetes.authenticate.driver.serviceAccountName"</span>, <span class="string">"spark"</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 pods/workers will be created. Can be expanded for larger workloads.</span></span><br><span class="line">conf.set(<span class="string">"spark.executor.instances"</span>, <span class="string">"2"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The DNS alias for the Spark driver. Required by executors to report status.</span></span><br><span class="line">conf.set(<span class="string">"spark.driver.host"</span>, <span class="string">"192.168.49.2"</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Port which the Spark shell should bind to and to which executors will report progress</span></span><br><span class="line">conf.set(<span class="string">"spark.driver.port"</span>, <span class="string">"20020"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize spark context, create executors</span></span><br><span class="line">conf.setAppName(<span class="string">'spark-iotest'</span>)</span><br><span class="line">sc = pyspark.SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize Spark Session</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession(sc)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>SparkJdbc数据同步</title>
    <url>/2021/07/13/SparkJdbc%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<p>记录spark jdbc做数据同步的问题和解决方案</p>
<a id="more"></a>
<h1 id="数据重复问题"><a href="#数据重复问题" class="headerlink" title="数据重复问题"></a>数据重复问题</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ol>
<li><p>spark.speculation会启动一个线程执行slow task，２个task执行相同的数据写入，导致数据重复</p>
<blockquote>
<p>spark.config(‘spark.speculation’,’false’)，默认是false</p>
</blockquote>
</li>
<li><p>partition内transaction commit 后出现执行失败，任务重试，会导致数据重复</p>
<blockquote>
<p>先写入临时表（无unique index），去重后再写入目标表</p>
</blockquote>
</li>
</ol>
<h1 id="schema定义问题"><a href="#schema定义问题" class="headerlink" title="schema定义问题"></a>schema定义问题</h1>]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>dolphinscheduler之shell数据校验</title>
    <url>/2021/08/21/dolphinscheduler%E4%B9%8Bshell%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/</url>
    <content><![CDATA[<p>dolphinscheduler可以通过shell节点校验数据是否符合要求</p>
<h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PT_DATE=<span class="variable">$&#123;system.biz.date&#125;</span></span><br><span class="line">PT_PATH=/user/hive/warehouse/default.db/<span class="built_in">test</span>/pt_d=<span class="variable">$&#123;PT_DATE&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="校验hdfs分区是否存在"><a href="#校验hdfs分区是否存在" class="headerlink" title="校验hdfs分区是否存在"></a>校验hdfs分区是否存在</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"></span><br><span class="line">kinit -kt /etc/krb5/geosmart.keytab geosmart</span><br><span class="line">hdfs dfs -<span class="built_in">test</span> -e <span class="variable">$&#123;PT_PATH&#125;</span></span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ] ;<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">'partition  $&#123;PT_PATH&#125;  exist'</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'partition  $&#123;PT_PATH&#125; not exist'</span></span><br><span class="line"><span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure>
<h1 id="校验hive表中数据行数"><a href="#校验hive表中数据行数" class="headerlink" title="校验hive表中数据行数"></a>校验hive表中数据行数</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"></span><br><span class="line">TABLE=<span class="string">'default.test'</span></span><br><span class="line">MIN_PT_COUNT=5000</span><br><span class="line"></span><br><span class="line">pt_count=`spark-sql  \</span><br><span class="line">--keytab /etc/krb5/geosamrt.keytab  \</span><br><span class="line">--principal geosamrt -S \</span><br><span class="line">-e <span class="string">"select count(1) from <span class="variable">$TABLE</span> where pt_d='<span class="variable">$&#123;PT_DATE&#125;</span>'"</span></span><br><span class="line">`</span><br><span class="line"></span><br><span class="line">pt_count=`<span class="built_in">echo</span> <span class="string">"<span class="variable">$pt_count</span>"</span> | tail -1`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$pt_count</span>"</span> -gt <span class="string">"<span class="variable">$MIN_PT_COUNT</span>"</span> ] ;<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$TABLE</span> of partition <span class="variable">$&#123;PT_DATE&#125;</span>,count=[<span class="variable">$pt_count</span>],greater than min[<span class="variable">$MIN_PT_COUNT</span>]"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$TABLE</span> of partition <span class="variable">$&#123;PT_DATE&#125;</span>,count=[<span class="variable">$pt_count</span>],lower than min[<span class="variable">$MIN_PT_COUNT</span>]"</span></span><br><span class="line"><span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title>flinkx之kafka到hive数据的准实时同步</title>
    <url>/2021/08/21/flinkx%E4%B9%8Bkafka%E5%88%B0hive%E6%95%B0%E6%8D%AE%E7%9A%84%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<p>flinkx基于flink实现的数据管道<br>管道分reader和writer两部分，分别由不同的数据源插件实现</p>
<p>如：KafkaReader，HiveWriter<br><a id="more"></a></p>
<h1 id="KafkaReader"><a href="#KafkaReader" class="headerlink" title="KafkaReader"></a>KafkaReader</h1><ul>
<li>kafkaReader通过KafkaClient消费数据，解析数据，转化成row</li>
</ul>
<h1 id="HiveWriter"><a href="#HiveWriter" class="headerlink" title="HiveWriter"></a>HiveWriter</h1><h1 id="Reader的实现"><a href="#Reader的实现" class="headerlink" title="Reader的实现"></a>Reader的实现</h1><p>reader通过继承2个函数，</p>
<ol>
<li>InputFormatSourceFunction－&gt;RichParallelSourceFunction-&gt;AbstractRichFunction:RichFunction</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * An abstract stub implementation for rich user-defined functions.</span></span><br><span class="line"><span class="comment"> * Rich functions have additional methods for initialization (&#123;<span class="doctag">@link</span> #open(Configuration)&#125;) and</span></span><br><span class="line"><span class="comment"> * teardown (&#123;<span class="doctag">@link</span> #close()&#125;), as well as access to their runtime execution context via</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@link</span> #getRuntimeContext()&#125;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br></pre></td></tr></table></figure>
<ol>
<li>CheckpointedFunction</li>
</ol>
<h1 id="Writer的实现"><a href="#Writer的实现" class="headerlink" title="Writer的实现"></a>Writer的实现</h1><h2 id="file类型的writer"><a href="#file类型的writer" class="headerlink" title="file类型的writer"></a>file类型的writer</h2><p>writerRecord()内写入.data临时目录<br>flink的全局checkpoint触发close后将临时目录内文件复制到实际的数据目录</p>
<blockquote>
<p>flinkx的启动参数confProp中指定<code>flink.checkpoint.interval</code>开启checkpoint.</p>
</blockquote>
<h2 id="jdbc类型的writer"><a href="#jdbc类型的writer" class="headerlink" title="jdbc类型的writer"></a>jdbc类型的writer</h2>]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>flink</tag>
        <tag>cdh</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Flinkx同步BinLog数据</title>
    <url>/2021/10/21/Flinkx%E5%90%8C%E6%AD%A5BinLog%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>binlog日志实时采集,支持按事物聚合输入到flink udf中进行处理<br><a id="more"></a></p>
<h1 id="binlog数据源的实现"><a href="#binlog数据源的实现" class="headerlink" title="binlog数据源的实现"></a>binlog数据源的实现</h1><ul>
<li>通过canel获取mysql的binlog事件（CanalEntry.RowChange）</li>
<li>flinkx通过BinlogRowConverter实现日志数据的压平（新增before/after字段），添加insert/update/delete事件类型，put到内部的linkedBlockingQueue，然后BinlogInputFormat（Flink的SourceFunction）提供nextRecordInternal方法poll队列数据</li>
<li>flink通过checkpoint将canal的同步状态持久化，state对象为EntryPosition，flinkx的metric和state数据都存储在FormatState对象中</li>
</ul>
<h2 id="checkpoint如何做到不丢"><a href="#checkpoint如何做到不丢" class="headerlink" title="checkpoint如何做到不丢"></a>checkpoint如何做到不丢</h2><p>canal的EventParser在每个transaction的<code>sink</code>后会获取当前事物的position，然后persistLogPosition持久化点位信息。<br>flinkx实现了canal的logPositionManager，persistLogPosition会做２个动作：</p>
<ol>
<li>flink状态更新：format.setEntryPosition(logPosition.getPostion())</li>
<li>本地缓存更新：logPositionCache.put(destination, logPosition);</li>
</ol>
<p>flinkx的binlogReader的实现中，canal的sink是通过queue异步处理的，由flink的DtInputFormatSourceFunction在执行nextRecord时从queue中poll出来处理row。<br>那么问题来了，<br>如果此时server断电flink程序异常中断，format的state已经往前走，但是异步处理比较慢，还没处理完被异常中断了，<br>重启时读取的checkpoint的点位是后面的position，会导致有些日志数据未被处理。</p>
<h2 id="canal会在buffer中缓存binlog事件，然后一个transaction输出一次"><a href="#canal会在buffer中缓存binlog事件，然后一个transaction输出一次" class="headerlink" title="canal会在buffer中缓存binlog事件，然后一个transaction输出一次"></a>canal会在buffer中缓存binlog事件，然后一个transaction输出一次</h2><ol>
<li>MysqlMultiStageCoprocessor$SinkStoreStage.onEvent()接受事件.</li>
<li>获得事件(MessageEvent)里的内容(CanalEntry.Entry).</li>
<li>调用:EventTransactionBuffer.add(CanalEntry.Entry).</li>
<li>EventTransactionBuffer.add方法的会判断:CanalEntry.Entry是什么类型.<ul>
<li>如果:CanalEntry.Entry.getEntryType为:TRANSACTIONBEGIN/TRANSACTIONEND/HEARTBEAT就刷新缓存,并把CanalEntry.Entry添加到缓存中.这样意味着:每一次事务,刷新一次.</li>
<li>如果:CanalEntry.Entry.getEntryType为:ROWDATA,则CanalEntry.Entry添加到缓存中.</li>
</ul>
</li>
<li>最终会:调用flush时,集合一批数据,并回调:TransactionFlushCallback.flush(List).</li>
<li>TransactionFlushCallback.flush方法,会调用:CanalEventSink.sink方法进行数据的发送.</li>
</ol>
<h2 id="pavingData"><a href="#pavingData" class="headerlink" title="pavingData"></a>pavingData</h2><h2 id="gtid模式"><a href="#gtid模式" class="headerlink" title="gtid模式"></a>gtid模式</h2><blockquote>
<p><code>show global variables like &#39;gtid%&#39;</code><br><figure class="highlight cs"><table><tr><td class="code"><pre><span class="line">gtid_executed,<span class="string">"3528d5b7-e86d-11ea-8e5b-0242ac110004:9-7635928:7635930-7648258:7648260-7657211:7657213-7751431:7751433-7887164:7887166-7888815:7888817-7891772:7891774-7946407:7946409-8012629:8012631-8029084:8029086-8030188:8030190-14238956:14238958-24160895,</span></span><br><span class="line"><span class="string">5d0b498d-e388-11ea-a9ff-0242ac110004:2853-3315:3317-3468:170523-170632:170634-177867,</span></span><br><span class="line"><span class="string">66587608-45f0-11ea-85fe-001a4a1601db:1-13827942"</span></span><br><span class="line">gtid_executed_compression_period,<span class="number">1000</span></span><br><span class="line">gtid_mode,ON</span><br><span class="line">gtid_owned,<span class="string">""</span></span><br><span class="line">gtid_purged,<span class="string">"3528d5b7-e86d-11ea-8e5b-0242ac110004:9-7635928:7635930-7648258:7648260-7657211:7657213-7751431:7751433-7887164:7887166-7888815:7888817-7891772:7891774-7946407:7946409-8012629:8012631-8029084:8029086-8030188:8030190-14238956:14238958-22753778,</span></span><br><span class="line"><span class="string">5d0b498d-e388-11ea-a9ff-0242ac110004:2853-3315:3317-3468:170523-170632:170634-177867,</span></span><br><span class="line"><span class="string">66587608-45f0-11ea-85fe-001a4a1601db:1-12593227"</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>一个GTID由两部分组成：server id uuid 与递增序号，两者之间用英文冒号隔开，例如：1f0eee4c-a66e-11ea-8999-00dbdfe417b8:1。</p>
<ul>
<li>gtid_executed<br>当前MySQL实现已经执行过的事务。在开启GTID模块时每执行一个事务会产生一个全局唯一的事务ID。在每一台MySQL实例上执行的事务何止上亿，这个字段要存储所有已执行的的事务ID，怎么存储能节省空间就是一个需要解决的问题，稍后再进行展开说明。</li>
<li>gtid_executed_compression_period<br>在MySQL5.7版本专门引入了一个系统表：mysql.gtid_executed，gtid_executed_compression_period 参数就是设置每执行多个事务，对这个表进行压缩，默认值为1000。</li>
<li>gtid_mode<br>是否开启gtid模式。</li>
<li>gtid_purged<br>已不在 binlog 日志中的事务ID，Mysql 并不会永久存储 binlog 日志，而是通过 expire_logs_days 设置过期时间，单位为天，默认为10天。</li>
<li>gtid_next<br>session级别的变量，下一个gtid</li>
<li>gtid_owned<br>正在运行的gtid</li>
<li>enforce_gtid_consistency<br>保证GTID安全的参数</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.hldx.cc/270">基于gtid的复制</a></li>
<li><a href="https://www.lixin.help/2019/10/01/Canal-Server-MysqlEventParser-7.html">Canal-Server-MysqlEventParser</a></li>
</ul>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>dolphinscheduler中的zookeeper角色</title>
    <url>/2021/11/20/dolphinscheduler%E4%B8%AD%E7%9A%84zookeeper%E8%A7%92%E8%89%B2/</url>
    <content><![CDATA[<p>dolphinscheduler中使用zookeeper实现自杀机制，用于解决<br>dolphinscheduler和zookeeper网络分区时发生的脑裂问题，<br>比如master容错时，当前master与zk失联，任务被其他master接管，然后master又脸上了，这个时候要master需要自杀，避免master更新db造成混乱</p>
<a id="more"></a>
<h1 id="dolphinscheduler的zookeeper存储结构"><a href="#dolphinscheduler的zookeeper存储结构" class="headerlink" title="dolphinscheduler的zookeeper存储结构"></a>dolphinscheduler的zookeeper存储结构</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;dboard</span><br><span class="line"></span><br><span class="line"># lock</span><br><span class="line">&#x2F;dboard&#x2F;lock</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;masters</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;masters&#x2F;_c_36c30bcf-9334-4f93-8f8e-27029e881612-lock-0025272899</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;masters&#x2F;_c_3f098290-1b34-4e2e-9e3b-b00f9d3968c1-lock-0025272900</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;failover</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;failover&#x2F;startup-masters</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;failover&#x2F;masters</span><br><span class="line">&#x2F;dboard&#x2F;lock&#x2F;failover&#x2F;workers</span><br><span class="line"></span><br><span class="line"># dead-servers</span><br><span class="line">&#x2F;dboard&#x2F;dead-servers</span><br><span class="line">&#x2F;dboard&#x2F;dead-servers&#x2F;master_172.24.0.2:5678</span><br><span class="line">&#x2F;dboard&#x2F;dead-servers&#x2F;worker_172.24.0.1:1234</span><br><span class="line"></span><br><span class="line"># nodes</span><br><span class="line">&#x2F;dboard&#x2F;nodes</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;worker</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;worker&#x2F;default</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;worker&#x2F;default&#x2F;worker_172.24.0.4:1234</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;worker&#x2F;default&#x2F;worker_172.24.0.3:1234</span><br><span class="line"></span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;master</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;master&#x2F;master_172.24.0.5:5678</span><br><span class="line">&#x2F;dboard&#x2F;nodes&#x2F;master&#x2F;master_172.24.0.4:5678</span><br></pre></td></tr></table></figure>
<h1 id="dolphinscheduler中的zk监听顺序问题"><a href="#dolphinscheduler中的zk监听顺序问题" class="headerlink" title="dolphinscheduler中的zk监听顺序问题"></a>dolphinscheduler中的zk监听顺序问题</h1><p>AbstractListener有33个实现类</p>
<ol>
<li>NodeChangeListener：触发master和worker的容错逻辑；</li>
<li>MasterNodeListener:更新内存的master列表，master节点删除时新增告警记录</li>
<li>WorkerGroupNodeListener:更新内存的服务组列表</li>
</ol>
<ul>
<li>ZKMasterClient会通过NodeChangeListener监听master和worker的上线下线状态变更；</li>
<li>ServerNodeManager启动时会注册MasterNodeListener和WorkerGroupNodeListener</li>
</ul>
<p>之前没有顺序，导致１先执行，3和２后执行，</p>
<p>3种情况会导致这个问题</p>
<ol>
<li>QuartzExecutors先shutdown（quartz内部会close传给他的connection），MasterNodeListener和WorkerGroupNodeListener插入alert会报错；</li>
<li>master的HeartBeatTask会定期检测自己是否在zk的dead_server列表中，如果在master会自杀，触发QuartzExecutors先shutdown；</li>
<li>另外master也有可能随时收到zk发送过来的其他master/worker down的信息，此时update库也会报connection close错误</li>
</ol>
<p>应该是2,3先发生，再发生１</p>
<p>请教个ops的问题。ds在用ansible重新发布的时候，２个master配置了串行重启，检测到5678端口后再启动下一个。<br>现在发现总是只能启动１个，第二个手动重启才行。</p>
<p>我的理解：<br>有２个master：master1和master2<br>master1重启，master2会将master1放入/dead_server中（默认10s检查一次，第一次延迟10s）<br>master2重启，master２启动时会将自己从dead_server中移除</p>
<p>2个master同时存活时，<br>现在现象是master1启动成功，master2重启时，master1容错把master2放入dead_server，然后master2启动时自杀，没有从dead_server中移除自己</p>
<p>1个master存活时，重启偶尔能２个都成功</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// master registry</span></span><br><span class="line"><span class="comment">//10s后触发检测dead_server，自杀</span></span><br><span class="line">masterRegistry.registry();</span><br><span class="line">String registryPath = <span class="keyword">this</span>.masterRegistry.getMasterPath();</span><br><span class="line"><span class="comment">//将自己从dead_server中移除</span></span><br><span class="line">masterRegistry.getZookeeperRegistryCenter().getRegisterOperator().handleDeadServer(registryPath, ZKNodeType.MASTER, Constants.DELETE_ZK_OP);</span><br></pre></td></tr></table></figure>
<h1 id="master快速重启失败问题"><a href="#master快速重启失败问题" class="headerlink" title="master快速重启失败问题"></a>master快速重启失败问题</h1><p>由于master之间存在zk的相互watch，１个master挂了会被另一个master watch并标记为dead</p>
<h2 id="现象："><a href="#现象：" class="headerlink" title="现象："></a>现象：</h2><p>master1如果快速restart,会导致registry去删除/dead_server记录的时候，dead记录还不存在<br>当master2标记dead的时候，将导致master1停止stop quartz sheduler, close jdbc连接</p>
<h2 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h2><p>stop和start的间隔必须大于zk的session超时时间<code>zookeeper.session.timeout=60s</code></p>
<p>master和worker的重启时序：<br>stop 70s后再start,<br>server1 start 40s后再start server2.</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>*<a href="https://github.com/apache/dolphinscheduler/issues/6880">Master failover add dead-server should check zk the master node is not exist</a></p>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>dolphinscheduler流任务监控</title>
    <url>/2021/11/21/dolphinscheduler%E6%B5%81%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<p>dolphinscheduler的调度任务有flink流任务，flinkx数据同步，这两类任务目前是批任务的思路，阻塞等待任务结束，缺少流任务的异步监控，需要做一些非阻塞的改造。</p>
<a id="more"></a>
<h1 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h1><p>flink流任务在ds中调度存在２个问题</p>
<ol>
<li>flink task提交后，worker会一直在轮询yarn的api查状态等待结束，但是flink流任务是没有终点的，所以这儿很浪费资源。</li>
<li>如果出现worker容错，会kill掉flink任务，调度问题导致任务被中止，这个是不合理的。</li>
</ol>
<h1 id="修改思路"><a href="#修改思路" class="headerlink" title="修改思路"></a>修改思路</h1><ol>
<li>流任务提交后，将流程/任务状态设置为运行中，同时新增一张流任务监控表stream_task，</li>
<li>单独一个进程或者定时任务来轮询stream_task，查询yarn/k8s的任务状态，更新流程/任务状态，发现异常时触发告警，人工干预处理；</li>
<li>任务kill接口调用时，判断是不是流任务，如果是流任务，修改状态为ready_stop，由监控线程异步执行yarn/k8s的kill逻辑</li>
</ol>
<p>flink调度任务新增类型参数：离线/实时</p>
<ul>
<li>如果是离线任务：必须查询yarn/k8s任务状态轮询阻塞，dag调度时才能触发后续任务。</li>
<li>如果是实时任务：</li>
</ul>
<ol>
<li>任务提交成功后（ret_code=0），任务状态为success，同时新增一张流任务监控表stream_task(状态＝待查询)记录，状态为SUBMITTED_SUCCESS</li>
<li>scheduler-alert启动单独启动一个线程，轮询stream_task，用于处理任务异常或手动停止；</li>
</ol>
<blockquote>
<p>流任务＝1个流程套1个流task</p>
</blockquote>
<h2 id="任务停止"><a href="#任务停止" class="headerlink" title="任务停止"></a>任务停止</h2><ul>
<li>flink on k8s任务：执行<code>flink deploy delete $appId</code> 和<code>flink-ui ingress delete $appId</code></li>
<li>flink on yarn：启动shell进程执行<code>yarn kill -application $appId</code>,这儿得根据流程实例获取当前租户信息，然后获取kerberos认证文件.</li>
</ul>
<h2 id="任务状态监控"><a href="#任务状态监控" class="headerlink" title="任务状态监控"></a>任务状态监控</h2><p>查询任务在yarn/k8s的任务状态，并更新数据库的流程实例表和任务实例表的状态（运行中/结束），结束时触发sentry告警（tag：stream）；</p>
<ul>
<li>待查询：60s轮询一次，查询stream_task表的SUBMITTED_SUCCESS，修改为RUNNING，为了界面显示状态一致，相关的process_instance和task_instance表的状态也改为RUNNING，</li>
<li>运行中：5s轮询一次；查询stream_task表的READY_STOP, RUNNING_EXECUTION<ul>
<li>READY_STOP：执行kill操作，如果是yarn新建shell进程kill，如果是k8s，调用api执行delete deploy，最后触发告警</li>
<li>RUNNING_EXECUTION：查询yarn或者k8s的集群状态，如果异常，触发告警</li>
</ul>
</li>
</ul>
<p>master或worker容错时会查询<code>[RUNNING_EXECUTION，READY_PAUSE，READY_STOP]</code>状态的processInstance/taskInstance进行容错</p>
<ul>
<li>当master容错时，需要检查当前流程是否为stream_task相关的流程，如果是的话，不做容错；</li>
<li>当worker容错时，因为此时task_instance虽然显示的是RUNNING_EXECUTION，但是host不为空，所以不会触发kill并创建taskInstance；</li>
</ul>
<h1 id="流任务监控功能"><a href="#流任务监控功能" class="headerlink" title="流任务监控功能"></a>流任务监控功能</h1><p>列表查询：项目，流程名称，执行用户，起止时间</p>
<ol>
<li>日志查看：yarn日志,k8s日志</li>
<li>WebUI跳转：url由clusterId和任务类型获取</li>
<li>kill操作：中止流任务</li>
<li>restart：重启流任务</li>
</ol>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>flink</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title>如何让DolphinScheduler的Flink任务支持K8S部署</title>
    <url>/2021/11/28/%E5%A6%82%E4%BD%95%E8%AE%A9DolphinScheduler%E7%9A%84Flink%E4%BB%BB%E5%8A%A1%E6%94%AF%E6%8C%81K8S%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>dolphinscheduler的flink任务默认支持yarn。<br>本文主要梳理flinkTask如何支持早k8s部署的思路。</p>
<p>flink任务和spark任务支持类似<br><a id="more"></a></p>
<h1 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h1><ul>
<li>dolphinscheduler版本：1.3.6</li>
<li>flink版本：1.12.2</li>
</ul>
<p><img src="FlinkTask.OnK8S.png" alt="如何让DolphinScheduler的Flink任务支持K8S部署"></p>
<h1 id="apiserver"><a href="#apiserver" class="headerlink" title="apiserver"></a>apiserver</h1><p>向k8s提交任务，需要新增以下基础配置</p>
<ul>
<li>kubeconfig：包含k8s的token，k8s-client初始化需要</li>
<li>master：k8s apiserver的地址</li>
<li>image：制作好的镜像，提交到harbor的地址</li>
</ul>
<p>另外FlinkParameters需要新增</p>
<ul>
<li>deployMode:kubernetesApplication</li>
<li>flinkVersion:1.12.2</li>
</ul>
<h1 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h1><p>由于我采用的是flink native方式，不是google的spark on k8s operator。<br>所以worker主要问题是拼接flinkTask的flink run-application命令。<br>具体配置内容参考xmind脑图</p>
<p>另外可新增１个<code>spark_on_k8s.json</code>配置文件定义环境参数　<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"k8sIngressHttpUrl"</span>: <span class="string">"http://ip:port"</span>,</span><br><span class="line">  <span class="attr">"k8sNameSpace"</span>: <span class="string">"flink"</span>,</span><br><span class="line">  <span class="attr">"flinkContainerImage"</span>: <span class="string">"flink:latest"</span>,</span><br><span class="line">  <span class="attr">"flinkAppServiceAccountName"</span>: <span class="string">"flink"</span>,</span><br><span class="line">  <span class="attr">"flinkVersion"</span>: <span class="string">"1.12"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>flink基础配置<code>flink-conf.yaml</code><br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># k8s</span></span><br><span class="line"><span class="attr">kubernetes.rest-service.exposed.type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="attr">kubernetes.container.image.pull-policy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">kubernetes.jobmanager.cpu:</span> <span class="number">1.0</span></span><br><span class="line"><span class="attr">security.module.factory.classes :</span> <span class="string">;</span></span><br><span class="line"><span class="attr">security.context.factory.classes:</span> <span class="string">;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rpc</span></span><br><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">localhost</span></span><br><span class="line"><span class="attr">jobmanager.rpc.port:</span> <span class="number">6123</span></span><br><span class="line"><span class="attr">jobmanager.memory.process.size:</span> <span class="string">1gb</span></span><br><span class="line"><span class="attr">taskmanager.memory.process.size:</span> <span class="string">1gb</span></span><br><span class="line"><span class="attr">taskmanager.numberOfTaskSlots:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">parallelism.default:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">jobmanager.execution.failover-strategy:</span> <span class="string">region</span></span><br><span class="line"><span class="attr">akka.ask.timeout:</span> <span class="number">120</span> <span class="string">s</span></span><br><span class="line"><span class="attr">web.timeout:</span> <span class="number">120000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### history server</span></span><br><span class="line"><span class="attr">jobmanager.archive.fs.dir:</span> <span class="string">s3a://flink/__FLINK__/historylog</span></span><br><span class="line"><span class="attr">historyserver.archive.fs.dir:</span> <span class="string">s3a://flink/__FLINK__/historylog</span></span><br><span class="line"><span class="attr">historyserver.web.address:</span> <span class="number">10.199</span><span class="number">.150</span><span class="number">.161</span></span><br><span class="line"><span class="attr">historyserver.web.port:</span> <span class="number">30067</span></span><br><span class="line"><span class="attr">historyserver.archive.fs.refresh-interval:</span> <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># checkpoint</span></span><br><span class="line"><span class="attr">execution.checkpointing.timeout:</span> <span class="number">10</span> <span class="string">min</span></span><br><span class="line"><span class="attr">execution.checkpointing.max-concurrent-checkpoints:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">execution.checkpointing.mode:</span> <span class="string">EXACTLY_ONCE</span></span><br><span class="line"><span class="attr">execution.checkpointing.unaligned:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">execution.checkpointing.externalized-checkpoint-retention:</span> <span class="string">DELETE_ON_CANCELLATION</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># state</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">filesystem</span></span><br><span class="line"><span class="attr">state.backend.incremental:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">state.backend.fs.checkpointdir:</span> <span class="string">s3a://flink/__FLINK__/checkpoints/backend</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">s3a://flink/__FLINK__/checkpoints/metadata</span></span><br><span class="line"><span class="attr">state.savepoints.dir:</span> <span class="string">s3a://flink/__FLINK__/savepoints</span></span><br><span class="line"><span class="attr">state.checkpoints.num-retained:</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># filesystem-s3a</span></span><br><span class="line"><span class="attr">s3.access-key:</span> <span class="string">ak</span></span><br><span class="line"><span class="attr">s3.secret-key:</span> <span class="string">sk</span></span><br><span class="line"><span class="attr">s3.endpoint:</span> <span class="string">http://ip:port</span></span><br><span class="line"><span class="attr">s3.path.style.access:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<h1 id="master"><a href="#master" class="headerlink" title="master"></a>master</h1><p>flinkTask执行的worker宕机时，master会对worker执行容错，kill掉所有正在执行的task。<br>所以master也需要加载worker一样的配置，在容错时执行flink k8s集群的清理工作。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">flink run-application \</span><br><span class="line">--target kubernetes-application \</span><br><span class="line">-Dkubernetes.config.file&#x3D;&quot;&#x2F;opt&#x2F;flink&#x2F;config&#x2F;kube_config.yaml&quot; \</span><br><span class="line">-Dkubernetes.container.image&#x3D;&quot;flink:latest&quot; \</span><br><span class="line">-Dkubernetes.namespace&#x3D;&quot;flink&quot; \</span><br><span class="line">-Dkubernetes.service-account&#x3D;&quot;flink&quot; \</span><br><span class="line">-Dkubernetes.rest-service.exposed.type&#x3D;&quot;ClusterIP&quot; \</span><br><span class="line">-Dkubernetes.container.image.pull-policy&#x3D;&quot;Always&quot; \</span><br><span class="line">-Dkubernetes.jobmanager.cpu&#x3D;&quot;1.0&quot; \</span><br><span class="line">-Dkubernetes.cluster-id&#x3D;&quot;flink-0-0-0-0-0&quot; \</span><br><span class="line">-Dkubernetes.flink.conf.dir&#x3D;&quot;$&#123;FLINK_HOME&#125;&#x2F;conf&quot; \</span><br><span class="line">-Dkubernetes.flink.log.dir&#x3D;&quot;$&#123;FLINK_HOME&#125;&#x2F;log&quot; \</span><br><span class="line">-Dsecurity.module.factory.classes&#x3D;&quot;;&quot; \</span><br><span class="line">-Dsecurity.context.factory.classes&#x3D;&quot;;&quot; \</span><br><span class="line">-Djobmanager.rpc.address&#x3D;&quot;localhost&quot; \</span><br><span class="line">-Djobmanager.rpc.port&#x3D;&quot;6123&quot; \</span><br><span class="line">-Djobmanager.memory.process.size&#x3D;&quot;1gb&quot; \</span><br><span class="line">-Dtaskmanager.memory.process.size&#x3D;&quot;1gb&quot; \</span><br><span class="line">-Dtaskmanager.numberOfTaskSlots&#x3D;&quot;1&quot; \</span><br><span class="line">-Dparallelism.default&#x3D;&quot;1&quot; \</span><br><span class="line">-Djobmanager.execution.failover-strategy&#x3D;&quot;region&quot; \</span><br><span class="line">-Dakka.ask.timeout&#x3D;&quot;120 s&quot; \</span><br><span class="line">-Dweb.timeout&#x3D;&quot;120000&quot; \</span><br><span class="line">-Djobmanager.archive.fs.dir&#x3D;&quot;s3a:&#x2F;&#x2F;flink&#x2F;__FLINK__&#x2F;historylog&quot; \</span><br><span class="line">-Dhistoryserver.archive.fs.dir&#x3D;&quot;s3a:&#x2F;&#x2F;flink&#x2F;__FLINK__&#x2F;historylog&quot; \</span><br><span class="line">-Dhistoryserver.web.address&#x3D;&quot;10.199.150.161&quot; \</span><br><span class="line">-Dhistoryserver.web.port&#x3D;&quot;30067&quot; \</span><br><span class="line">-Dhistoryserver.archive.fs.refresh-interval&#x3D;&quot;1000&quot; \</span><br><span class="line">-Dexecution.checkpointing.timeout&#x3D;&quot;10 min&quot; \</span><br><span class="line">-Dexecution.checkpointing.max-concurrent-checkpoints&#x3D;&quot;1&quot; \</span><br><span class="line">-Dexecution.checkpointing.mode&#x3D;&quot;EXACTLY_ONCE&quot; \</span><br><span class="line">-Dexecution.checkpointing.unaligned&#x3D;&quot;false&quot; \</span><br><span class="line">-Dexecution.checkpointing.externalized-checkpoint-retention&#x3D;&quot;DELETE_ON_CANCELLATION&quot; \</span><br><span class="line">-Dstate.backend&#x3D;&quot;filesystem&quot; \</span><br><span class="line">-Dstate.backend.incremental&#x3D;&quot;true&quot; \</span><br><span class="line">-Dstate.backend.fs.checkpointdir&#x3D;&quot;s3a:&#x2F;&#x2F;flink&#x2F;__FLINK__&#x2F;checkpoints&#x2F;backend&quot; \</span><br><span class="line">-Dstate.checkpoints.dir&#x3D;&quot;s3a:&#x2F;&#x2F;flink&#x2F;__FLINK__&#x2F;checkpoints&#x2F;metadata&quot; \</span><br><span class="line">-Dstate.savepoints.dir&#x3D;&quot;s3a:&#x2F;&#x2F;flink&#x2F;__FLINK__&#x2F;savepoints&quot; \</span><br><span class="line">-Dstate.checkpoints.num-retained&#x3D;&quot;10&quot; \</span><br><span class="line">-Ds3.access-key&#x3D;&quot;DYaDwXsj8VRtWYPSbr7A&quot; \</span><br><span class="line">-Ds3.secret-key&#x3D;&quot;z7HAEhdyseNX9AVyzDLAJzEjZChJsnAf1f7VehE&quot; \</span><br><span class="line">-Ds3.endpoint&#x3D;&quot;http:&#x2F;&#x2F;10.199.150.160:32030&quot; \</span><br><span class="line">-Ds3.path.style.access&#x3D;&quot;true&quot; \</span><br><span class="line">-Djobmanager.memory.process.size&#x3D;&quot;4G&quot; \</span><br><span class="line">-Dtaskmanager.memory.process.size&#x3D;&quot;2G&quot; \</span><br><span class="line">-Dtaskmanager.numberOfTaskSlots&#x3D;&quot;2&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_HOST_ALIASES&#x3D;&quot;127.0.0.1	localhost&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_S3_ACCESS_KEY&#x3D;&quot;ak&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_S3_SECRET_KEY&#x3D;&quot;sk&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_S3_ENDPOINT&#x3D;&quot;xxx:xxx&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_S3_BUCKET&#x3D;&quot;xxx&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_REMOTE_MAIN_JAR&#x3D;&quot;&#x2F;flink&#x2F;WordCount-1.12.2.jar&quot; \</span><br><span class="line">-Dcontainerized.master.env.KUBERNETES_LOCAL_MAIN_JAR&#x3D;&quot;&#x2F;tmp&#x2F;WordCount-1.12.2.jar&quot; \</span><br><span class="line">-Dexecution.checkpointing.interval&#x3D;&quot;1 min&quot; \</span><br><span class="line">-d \</span><br><span class="line">-Dkubernetes.container.image.pull-policy&#x3D;Always \</span><br><span class="line">-c \</span><br><span class="line">org.apache.flink.examples.java.wordcount.WordCount \</span><br><span class="line">local:&#x2F;&#x2F;&#x2F;tmp&#x2F;WordCount-1.12.2.jar \</span><br><span class="line">--input &#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;flink-1.12.2&#x2F;conf&#x2F;flink-conf.yaml --output &#x2F;tmp&#x2F;flink-conf.yaml</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/apache/dolphinscheduler/issues/5648">task can run on kubernetes</a></li>
</ul>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>flink</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title>如何让DolphinScheduler的Spark任务支持K8S部署</title>
    <url>/2021/11/21/%E5%A6%82%E4%BD%95%E8%AE%A9DolphinScheduler%E7%9A%84Spark%E4%BB%BB%E5%8A%A1%E6%94%AF%E6%8C%81K8S%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>dolphinscheduler这个调度任务有spark，spark默认支持yarn。<br>本文主要梳理sparkTask如何支持早k8s部署的思路。</p>
<p>理论上dolphinscheduler只是一个调度平台，和task的resource provider是解耦合的。flink和spark这方面本身设计做的比较好，调试支持local，生产支持k8s,yarn,mesos。</p>
<p>目前ds的task从资源的角度可以分２类：</p>
<ol>
<li>ds自带的worker中作为独立的进程，无限制的使用worker的计算资源。如：shell,python；</li>
<li>任务提交到远程计算服务执行，本地和远程的计算服务保持连接轮询获取执行结果。如：http,sql,procedure，mapreduce，spark，sqoop，flink等。</li>
</ol>
<p>在云原生时代，<br>第１类任务：只需要制作对应的镜像，直接提交即可。<br>第２类任务：需要对应的task类型支持k8s部署，比如spark on k8s ,flink on k8s，然后客户端提交需要做各种pvc的配置。</p>
<p>目前只hive,sqoop,mapreduce等都是继承AbstractYarnTask。<br>和具体的实现绑定，应该是定义远程计算执行的task接口，task中根据需要，组合yarn或k8s等实现。</p>
<a id="more"></a>
<h1 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h1><ul>
<li>dolphinscheduler版本：1.3.6</li>
<li>spark版本：3.1.2</li>
</ul>
<p><img src="SparkTask.OnK8s.png" alt="如何让DolphinScheduler的Spark任务支持K8S部署"></p>
<h1 id="apiserver"><a href="#apiserver" class="headerlink" title="apiserver"></a>apiserver</h1><p>向k8s提交任务，需要新增以下基础配置</p>
<ul>
<li>kubeconfig：包含k8s的token，k8s-client初始化需要</li>
<li>master：k8s apiserver的地址</li>
<li>image：制作好的镜像，提交到harbor的地址</li>
</ul>
<p>另外SparkParameters需要新增</p>
<ul>
<li>deployMode:kubernetes</li>
<li>sparkVersion:spark3</li>
</ul>
<h1 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h1><p>由于我采用的是spark native方式，不是google的spark on k8s operator。<br>所以worker主要问题是拼接sparkTask的spark-submit命令。<br>具体配置内容参考xmind脑图</p>
<p>另外可新增１个<code>spark_on_k8s.json</code>配置文件定义环境参数　<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"k8sNameSpace"</span>: <span class="string">"spark"</span>,</span><br><span class="line">  <span class="attr">"sparkAppServiceAccountName"</span>: <span class="string">"spark"</span>,</span><br><span class="line">  <span class="attr">"sparkAppDriverImage"</span>: <span class="string">"bigdata/spark:latest"</span>,</span><br><span class="line">  <span class="attr">"sparkEventLogEnabled"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"pvcConfig"</span>: &#123;</span><br><span class="line">    <span class="attr">"EVENTLOG"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"spark-log"</span>,</span><br><span class="line">      <span class="attr">"mountPath"</span>: <span class="string">"/spark/spark-eventlog"</span>,</span><br><span class="line">      <span class="attr">"subPath"</span>: <span class="string">"spark-eventlog"</span>,</span><br><span class="line">      <span class="attr">"readonly"</span>: <span class="literal">false</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"CONFIG"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"spark-config"</span>,</span><br><span class="line">      <span class="attr">"mountPath"</span>: <span class="string">"/spark/config"</span>,</span><br><span class="line">      <span class="attr">"readonly"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"APPLICATION"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"spark-application"</span>,</span><br><span class="line">      <span class="attr">"mountPath"</span>: <span class="string">"/spark/application"</span>,</span><br><span class="line">      <span class="attr">"readonly"</span>: <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sparkVersion"</span>: <span class="string">"3"</span>,</span><br><span class="line">  <span class="attr">"hiveMetastoreVersion"</span>: <span class="string">"1.1"</span>,</span><br><span class="line">  <span class="attr">"hiveMetastoreJars"</span>: <span class="string">"path"</span>,</span><br><span class="line">  <span class="attr">"hiveMetastoreJarsPath"</span>: <span class="string">"file:///opt/cdh/lib/hive/lib/*.jar,file:///opt/cdh/lib/hadoop/client/*.jar"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="master"><a href="#master" class="headerlink" title="master"></a>master</h1><p>sparkTask执行的worker容错时，master会对worker执行容错，kill所有正在执行的task。<br>所以master也需要加载worker一样的配置，在容错时执行spark k8s集群的清理工作。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/apache/dolphinscheduler/issues/5648">task can run on kubernetes</a></li>
</ul>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>云环境搭建k3s集群实现gitlab的cicd</title>
    <url>/2021/12/09/%E4%BA%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BAk3s%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0gitlab%E7%9A%84cicd/</url>
    <content><![CDATA[<p><code>gitlab</code>搭建在自家的nas上，<code>k3s</code>部署于阿里云的ecs，自己提交代码后，通过gitlab runner自动执行pipeline。<br><code>cicd</code>自动执行2个操作：</p>
<ol>
<li>nas代码自动备份到github</li>
<li>博客自动发布到github pages<a id="more"></a>
</li>
</ol>
<h1 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h1><ul>
<li>master：1C2G,CentOS Linux 7 (Core)</li>
<li>agent1：2C8G,CentOS Linux 8</li>
<li>agent2：1C2G,Alibaba Cloud Linux 3 (Soaring Falcon)</li>
</ul>
<blockquote>
<p>别人的好机器只能当worker，自己的烂机器当master,-_-</p>
</blockquote>
<h2 id="端口开通"><a href="#端口开通" class="headerlink" title="端口开通"></a>端口开通</h2><p>阿里云ecs安全策略开通以下接口。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>协议</th>
<th>端口</th>
<th>源</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>6443</td>
<td>K3s agent 节点</td>
<td>Kubernetes API Server</td>
</tr>
<tr>
<td>UDP</td>
<td>8472</td>
<td>K3s server 和 agent 节点</td>
<td>仅对 Flannel VXLAN 需要</td>
</tr>
<tr>
<td>TCP</td>
<td>10250</td>
<td>K3s server 和 agent 节点</td>
<td>Kubelet metrics</td>
</tr>
<tr>
<td>TCP</td>
<td>2379-2380</td>
<td>K3s server 节点</td>
<td>只有嵌入式 etcd 高可用才需要　</td>
</tr>
</tbody>
</table>
</div>
<h1 id="master"><a href="#master" class="headerlink" title="master"></a>master</h1><p>master_ip=ip1</p>
<h2 id="安装master"><a href="#安装master" class="headerlink" title="安装master"></a>安装master</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sfL http:&#x2F;&#x2F;rancher-mirror.cnrancher.com&#x2F;k3s&#x2F;k3s-install.sh | \</span><br><span class="line">INSTALL_K3S_MIRROR&#x3D;cn \</span><br><span class="line">INSTALL_K3S_EXEC&#x3D;&quot;--tls-san $&#123;master_ip&#125;&quot; \</span><br><span class="line">sh  -s -</span><br></pre></td></tr></table></figure>
<h2 id="修改启动配置"><a href="#修改启动配置" class="headerlink" title="修改启动配置"></a>修改启动配置</h2><p>sudo vim /etc/systemd/system/multi-user.target.wants/k3s.service<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;k3s server  &#39;--tls-san&#39; &#39;$&#123;master_ip&#125;&#39;  write-kubeconfig-mode 664  --node-ip  $&#123;master_ip&#125; --node-external-ip $&#123;master_ip&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="apiserver地址"><a href="#apiserver地址" class="headerlink" title="apiserver地址"></a>apiserver地址</h2><p><a href="https://${master_ip}:6443">https://${master_ip}:6443</a></p>
<h2 id="master操作"><a href="#master操作" class="headerlink" title="master操作"></a>master操作</h2><ul>
<li>查看<code>join_token</code>：<code>cat /var/lib/rancher/k3s/server/node-token</code></li>
<li>查看kubeconfig：<code>cat /etc/rancher/k3s/k3s.yaml</code></li>
</ul>
<h1 id="agent"><a href="#agent" class="headerlink" title="agent"></a>agent</h1><p>agent_ip=ip2</p>
<h2 id="安装agent"><a href="#安装agent" class="headerlink" title="安装agent"></a>安装agent</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sfL http:&#x2F;&#x2F;rancher-mirror.cnrancher.com&#x2F;k3s&#x2F;k3s-install.sh | \</span><br><span class="line">INSTALL_K3S_MIRROR&#x3D;cn \</span><br><span class="line">sh  -s -</span><br></pre></td></tr></table></figure>
<h2 id="修改启动配置-1"><a href="#修改启动配置-1" class="headerlink" title="修改启动配置"></a>修改启动配置</h2><p>sudo vim /etc/systemd/system/multi-user.target.wants/k3s.service</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;k3s  agent --server https:&#x2F;&#x2F;$&#123;master_ip&#125;:6443 --node-name $&#123;agent_ip&#125; --with-node-id --node-ip  $&#123;agent_ip&#125; --node-external-ip $&#123;agent_ip&#125; --token  $&#123;join_token&#125;</span><br></pre></td></tr></table></figure>
<h2 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h2><p>systemctl daemon-reload<br>systemctl restart k3s</p>
<h1 id="dashboard"><a href="#dashboard" class="headerlink" title="dashboard"></a>dashboard</h1><ul>
<li>bear token生成：<code>k3s kubectl -n kubernetes-dashboard describe secret admin-user-token | grep &#39;^token&#39;</code></li>
<li>本地端口代理：<code>kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8080:443</code></li>
<li>浏览器访问<ul>
<li>firefox访问：<code>https://localhost:8080</code></li>
<li>chrome访问：<code>https://localhost:8080</code>,在打开后键盘输入：<code>thisisunsafe</code></li>
</ul>
</li>
</ul>
<h1 id="gitlab连接k3s集群"><a href="#gitlab连接k3s集群" class="headerlink" title="gitlab连接k3s集群"></a>gitlab连接k3s集群</h1><h2 id="api地址"><a href="#api地址" class="headerlink" title="api地址"></a>api地址</h2><p><a href="https://${master_ip}:6443">https://${master_ip}:6443</a></p>
<h2 id="certification"><a href="#certification" class="headerlink" title="certification"></a>certification</h2><p>k3s kubectl config view —raw -o=jsonpath=’{.clusters[0].cluster.certificate-authority-data}’ | base64 —decode</p>
<h2 id="创建账户"><a href="#创建账户" class="headerlink" title="创建账户"></a>创建账户</h2><p>kubectl apply -f gitlab_admin.yaml<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gitlab-admin</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gitlab-admin</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gitlab-admin</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure></p>
<h2 id="查看token"><a href="#查看token" class="headerlink" title="查看token"></a>查看token</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SECRET&#x3D;$(kubectl -n kube-system get secret | grep gitlab-admin | awk &#39;&#123;print $1&#125;&#39;)</span><br><span class="line">echo $SECRET</span><br><span class="line">TOKEN&#x3D;$(kubectl -n kube-system get secret $SECRET -o jsonpath&#x3D;&#39;&#123;.data.token&#125;&#39; | base64 --decode)</span><br><span class="line">echo $TOKEN</span><br></pre></td></tr></table></figure>
<h2 id="本地代理"><a href="#本地代理" class="headerlink" title="本地代理"></a>本地代理</h2><p>kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8080:443</p>
<h1 id="网络调试"><a href="#网络调试" class="headerlink" title="网络调试"></a>网络调试</h1><h2 id="调试工具"><a href="#调试工具" class="headerlink" title="调试工具"></a>调试工具</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.28.4</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"3600"</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br></pre></td></tr></table></figure>
<p>测试dns：<code>kubectl  exec -it busybox -- nslookup gitlab-org.gitlab.io</code></p>
<blockquote>
<p>用好<code>dig</code>和<code>nslookup</code>排查网络连接问题</p>
</blockquote>
<h2 id="coredns配置域名"><a href="#coredns配置域名" class="headerlink" title="coredns配置域名"></a>coredns配置域名</h2><p>gitlab-runner内部报错，不能访问外网的gitlab服务器<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">WARNING: Checking for jobs... failed runner&#x3D;6Kxs-qJj status&#x3D;couldn&#39;t execute POST against http:&#x2F;&#x2F;www.geosmart.top:40000&#x2F;api&#x2F;v4&#x2F;jobs&#x2F;request: Post http:&#x2F;&#x2F;www.geosmart.top:40000&#x2F;api&#x2F;v4&#x2F;jobs&#x2F;request: dial tcp: lookup www.geosmart.top on 10.43.0.10:53: no such host</span><br></pre></td></tr></table></figure></p>
<p>将root dns服务器由<code>forward /etc/resolv.conf</code>改为外网的<code>forward . 114.114.114.114</code>就可以了</p>
<p>针对不能连接的域名，在<code>kubectl -n kube-system  edit cm coredns</code>新增host配置即可<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts &#x2F;etc&#x2F;coredns&#x2F;NodeHosts &#123;</span><br><span class="line">         115.196.121.1 www.mydomain.top</span><br><span class="line">         ttl 60</span><br><span class="line">         reload 15s</span><br><span class="line">         fallthrough</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="k3s卸载"><a href="#k3s卸载" class="headerlink" title="k3s卸载"></a>k3s卸载</h1><p>/usr/local/bin/k3s-uninstall.sh</p>
<h1 id="gitlab-cicd"><a href="#gitlab-cicd" class="headerlink" title="gitlab.cicd"></a>gitlab.cicd</h1><p><img src="gitlab.cicd.jpg" alt="cicd"></p>
<p><code>gitlab-ci.yaml</code>示例<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="string">node:10.19.0</span></span><br><span class="line"></span><br><span class="line"><span class="attr">cache:</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hexo/node_modules/</span></span><br><span class="line"></span><br><span class="line"><span class="attr">before_script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">cd</span> <span class="string">hexo</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span> <span class="string">hexo-cli</span> <span class="string">-g</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">test</span> <span class="string">-e</span> <span class="string">package.json</span> <span class="string">&amp;&amp;</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">deploy</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">g</span> <span class="string">-d</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br></pre></td></tr></table></figure></p>
<h2 id="github推送问题"><a href="#github推送问题" class="headerlink" title="github推送问题"></a>github推送问题</h2><p> gnutls_handshake() failed: The TLS connection was non-properly terminated.<br>因为source有git修改记录，public网站不需要修改记录<br>所以改为<code>ssh</code>认证，每次<code>push -f</code>强制替换网站</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/wenerme/wener/blob/6b3009db70/notes/devops/kubernetes/distro/k3s.md">k3s笔记</a></li>
<li><a href="https://docs.rancher.cn/docs/k3s/installation/install-options/_index">k3s doc</a></li>
<li><a href="https://github.com/eyasliu/blog/issues/26">k3s 轻量级安装教程</a></li>
<li><a href="https://docs.rancher.cn/docs/k3s/installation/kube-dashboard/_index">dashboard安装</a></li>
<li><a href="https://www.infoq.cn/article/qksrebki3bqbzodcxgge">gitlab集成k3s</a></li>
</ul>
]]></content>
      <tags>
        <tag>k8s</tag>
        <tag>k3s</tag>
      </tags>
  </entry>
  <entry>
    <title>cdh集成minio做hdfs和minio对拷</title>
    <url>/2021/12/02/cdh%E9%9B%86%E6%88%90minio%E5%81%9Ahdfs%E5%92%8Cminio%E5%AF%B9%E6%8B%B7/</url>
    <content><![CDATA[<p>存储层由hdfs迁移到minio，基于hadoop的<code>distcp</code>做数据迁移<br><a id="more"></a></p>
<h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><p>更新aws sdk版本（option）<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 删除老版本的aws包</span><br><span class="line">&#96;find &#x2F;opt&#x2F;cdh -name &#39;*aws*.jar&#39; | grep hadoop | xargs -n1 rm&#96;</span><br><span class="line"></span><br><span class="line"># 下载aws依赖</span><br><span class="line">cd &#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hadoop</span><br><span class="line">wget https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;com&#x2F;amazonaws&#x2F;aws-java-sdk&#x2F;1.7.4&#x2F;aws-java-sdk-1.7.4.jar</span><br><span class="line">wget https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;hadoop&#x2F;hadoop-aws&#x2F;2.7.7&#x2F;hadoop-aws-2.7.7.jar</span><br></pre></td></tr></table></figure></p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>core-site.xml新增配置<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.access.key<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>DYaDwXsj8VRtWYPSbr7A<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.secret.key<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>z7HAEhdyseNX9AVyzDLAJzEjZChJsnAf1f7VehE<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.endpoint<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://10.199.150.160:32030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.path.style.access<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.impl<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.fs.s3a.S3AFileSystem<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.fast.upload<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.multipart.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>104857600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.multipart.threshold<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>268435456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.fast.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.threads.core<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>15<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.threads.max<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>256<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.s3a.block.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>33554432<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="hadoop-distcp"><a href="#hadoop-distcp" class="headerlink" title="hadoop distcp"></a>hadoop distcp</h1><p>hdfs复制到s3a:<br><code>hadoop distcp hdfs://ha/user/geosmart/spark s3a://bucket/spark</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2021-12-02 06:09:11,482 INFO  [main] tools.OptionsParser (OptionsParser.java:parseBlocksPerChunk(205)) - parseChunkSize: blocksperchunk false</span><br><span class="line">2021-12-02 06:09:13,651 INFO  [main] security.TokenCache (TokenCache.java:obtainTokensForNamenodesInternal(144)) - Got dt for hdfs:&#x2F;&#x2F;ha; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ha, Ident: (token for geosmart: HDFS_DELEGATION_TOKEN owner&#x3D;geosmart@HADOOP.COM, renewer&#x3D;yarn, realUser&#x3D;, issueDate&#x3D;1638425353607, maxDate&#x3D;1639030153607, sequenceNumber&#x3D;222397, masterKeyId&#x3D;432)</span><br><span class="line">2021-12-02 06:09:14,068 INFO  [main] tools.SimpleCopyListing (SimpleCopyListing.java:printStats(594)) - Paths (files+dirs) cnt &#x3D; 28; dirCnt &#x3D; 7</span><br><span class="line">2021-12-02 06:09:14,068 INFO  [main] tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(389)) - Build file listing completed.</span><br><span class="line">2021-12-02 06:09:14,474 INFO  [main] tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 28</span><br><span class="line">2021-12-02 06:09:15,407 INFO  [main] mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:4</span><br><span class="line">2021-12-02 06:09:15,732 INFO  [main] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(291)) - Submitting tokens for job: job_1634007232783_42646</span><br><span class="line">2021-12-02 06:09:16,287 INFO  [main] impl.YarnClientImpl (YarnClientImpl.java:submitApplication(260)) - Submitted application application_1634007232783_42646</span><br><span class="line">2021-12-02 06:09:16,362 INFO  [main] mapreduce.Job (Job.java:submit(1311)) - The url to track the job: http:&#x2F;&#x2F;hadoop-test-40:8088&#x2F;proxy&#x2F;application_1634007232783_42646&#x2F;</span><br><span class="line">2021-12-02 06:09:16,363 INFO  [main] tools.DistCp (DistCp.java:execute(193)) - DistCp job-id: job_1634007232783_42646</span><br><span class="line">2021-12-02 06:09:16,364 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1356)) - Running job: job_1634007232783_42646</span><br><span class="line">2021-12-02 06:09:23,757 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1377)) - Job job_1634007232783_42646 running in uber mode : false</span><br><span class="line">2021-12-02 06:09:23,761 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1384)) -  map 0% reduce 0%</span><br><span class="line">2021-12-02 06:09:37,366 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1384)) -  map 25% reduce 0%</span><br><span class="line">2021-12-02 06:11:53,468 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1384)) -  map 100% reduce 0%</span><br><span class="line">2021-12-02 06:12:08,928 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1395)) - Job job_1634007232783_42646 completed successfully</span><br><span class="line">2021-12-02 06:12:09,010 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1402)) - Counters: 38</span><br><span class="line">        File System Counters</span><br><span class="line">                FILE: Number of bytes read&#x3D;0</span><br><span class="line">                FILE: Number of bytes written&#x3D;641240</span><br><span class="line">                FILE: Number of read operations&#x3D;0</span><br><span class="line">                FILE: Number of large read operations&#x3D;0</span><br><span class="line">                FILE: Number of write operations&#x3D;0</span><br><span class="line">                HDFS: Number of bytes read&#x3D;728115665</span><br><span class="line">                HDFS: Number of bytes written&#x3D;0</span><br><span class="line">                HDFS: Number of read operations&#x3D;115</span><br><span class="line">                HDFS: Number of large read operations&#x3D;0</span><br><span class="line">                HDFS: Number of write operations&#x3D;8</span><br><span class="line">                S3A: Number of bytes read&#x3D;0</span><br><span class="line">                S3A: Number of bytes written&#x3D;728108596</span><br><span class="line">                S3A: Number of read operations&#x3D;261</span><br><span class="line">                S3A: Number of large read operations&#x3D;0</span><br><span class="line">                S3A: Number of write operations&#x3D;5991</span><br><span class="line">        Job Counters </span><br><span class="line">                Launched map tasks&#x3D;4</span><br><span class="line">                Other local map tasks&#x3D;4</span><br><span class="line">                Total time spent by all maps in occupied slots (ms)&#x3D;1583700</span><br><span class="line">                Total time spent by all reduces in occupied slots (ms)&#x3D;0</span><br><span class="line">                Total time spent by all map tasks (ms)&#x3D;395925</span><br><span class="line">                Total vcore-milliseconds taken by all map tasks&#x3D;395925</span><br><span class="line">                Total megabyte-milliseconds taken by all map tasks&#x3D;1621708800</span><br><span class="line">        Map-Reduce Framework</span><br><span class="line">                Map input records&#x3D;28</span><br><span class="line">                Map output records&#x3D;0</span><br><span class="line">                Input split bytes&#x3D;464</span><br><span class="line">                Spilled Records&#x3D;0</span><br><span class="line">                Failed Shuffles&#x3D;0</span><br><span class="line">                Merged Map outputs&#x3D;0</span><br><span class="line">                GC time elapsed (ms)&#x3D;514</span><br><span class="line">                CPU time spent (ms)&#x3D;40900</span><br><span class="line">                Physical memory (bytes) snapshot&#x3D;2998263808</span><br><span class="line">                Virtual memory (bytes) snapshot&#x3D;22389567488</span><br><span class="line">                Total committed heap usage (bytes)&#x3D;9028239360</span><br><span class="line">        File Input Format Counters </span><br><span class="line">                Bytes Read&#x3D;6605</span><br><span class="line">        File Output Format Counters </span><br><span class="line">                Bytes Written&#x3D;0</span><br><span class="line">        DistCp Counters</span><br><span class="line">                Bytes Copied&#x3D;728108596</span><br><span class="line">                Bytes Expected&#x3D;728108596</span><br><span class="line">                Files Copied&#x3D;28</span><br></pre></td></tr></table></figure>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="远程调试排查问题"><a href="#远程调试排查问题" class="headerlink" title="远程调试排查问题"></a>远程调试排查问题</h2><ol>
<li><p>/bin/hdfs中添加agentlib远程调试排查问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DEBUG_OPTS&#x3D;&quot; -agentlib:jdwp&#x3D;transport&#x3D;dt_socket,server&#x3D;y,suspend&#x3D;n,address&#x3D;19999 &quot;</span><br><span class="line">exec &quot;$JAVA&quot; $DEBUG_OPTS -Dproc_$COMMAND $JAVA_HEAP_MAX $HADOOP_OPTS $CLASS &quot;$@&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>idea中引用hdfs的相关jar包，添加remote jvm打断点调试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-agentlib:jdwp&#x3D;transport&#x3D;dt_socket,server&#x3D;y,suspend&#x3D;n,address&#x3D;19999</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Name-or-service-not-known"><a href="#Name-or-service-not-known" class="headerlink" title="Name or service not known"></a>Name or service not known</h2><p><code>java.net.UnknownHostException: ThinkT14: ThinkT14: Name or service not known</code><br>注意修改host为<code>ip 域名</code>，如<code>10.199.121.12 ThinkT14</code></p>
]]></content>
      <tags>
        <tag>cdh</tag>
        <tag>hdfs</tag>
        <tag>minio</tag>
      </tags>
  </entry>
  <entry>
    <title>《把时间当作朋友》读书笔记</title>
    <url>/2015/07/21/%E3%80%8A%E6%8A%8A%E6%97%B6%E9%97%B4%E5%BD%93%E4%BD%9C%E6%9C%8B%E5%8F%8B%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>把时间当作朋友李笑来-李笑来</p>
<p>We do not plan to fail, we fail to plan</p>
<hr>
<a id="more"></a>
<p>2015-06-12 18:00:14<br>柳比歇夫的日志，是“事件-时间日志”（event-time log）。他的方法要比李敖的方法更为高级。李敖的事件记录，往往只能记录事件的名称，是一种基于结果的记录；而柳比歇夫的“事件-时间日志”却是一种基于过程的记录。这里的细微差别是，基于过程的记录要比基于结果的记录只能更为详尽。</p>
<p>2015-06-12 18:01:22<br>“管理时间”是不可能的，那么解决方法就只能是，想尽一切办法真正了解自己，真正了解时间、精确地感知时间；而后再想尽一切办法使自己以及自己的行为与时间“合拍”，就是我的说法——“与时间做朋友”</p>
<p>2015-06-15 00:46:27<br>“We do not plan to fail, we fail to plan.”</p>
<p>2015-06-15 00:47:54<br>字典里说，所谓的成功就是达成预期目标</p>
<p>2015-06-15 00:48:14<br>“失败只有一种，就是半途而废。”<br>注: 希望为也能懂</p>
<p>2015-06-15 00:50:05<br>对像我这样的普通人来讲，证明我的目标现实可行的方法比较简单：1) 已经有人做到了；2) 我与那人没有太大的差距。</p>
<p>2015-06-15 08:04:30<br>时间的浪费，往往是因为1) 目标不现实或者目前暂时尚不可行；2) 为了达到目标而制定的实施策略有误。</p>
<p>2015-06-15 08:09:38<br>计划是必须的，目标当然应该是确定的。一般来讲，越是短期的目标，越容易清晰。越是清晰的目标越容易实现</p>
<p>2015-06-15 23:41:20<br>很多的时候，没必要做计划的原因有两个：除了前面提到过的“大多数计划其实非常简单”之外，另外一个是“初始状态下，我们往往实际上并没有能力去制定合理有效的计划”。因为做任何事情，我们都可能要经历相同的过程：逐步熟悉，小心摸索，失败失败再失败，认真反思，卷土重来，直至成功。而在最初甚至连基本的认知都没有的时候，制定出来的计划十有八九只不过是空谈<br>注: 走想停看</p>
<p>2015-06-15 23:47:00<br>除了“试错”、“观察”、“阅读”之外，“思考”，准确地说，“正确地思考”，才是获取真正意义上的知识的主要手段。</p>
<p>2015-06-18 08:01:37<br>写作能力在自学能力中占据着重要的地位。</p>
<p>2015-06-18 08:01:51<br>写出简捷、有效、朴素、准确、具体的说明性说理性文章的能力。</p>
<p>2015-06-18 08:09:11<br>无论如何，都不要也不应该用别人的错误惩罚自己，那么做不仅不对，并且愚蠢。</p>
<p>2015-06-18 21:29:47<br>热爱考试的理由很简单，它是通行证，它意味着机会，其他没有此通行证的人无法获得的机会。虽然有些人也许会用其他方式获得那个什么机会，但，既然你没有其他方式，就不要抱怨——反正抱怨没用。抱怨最浪费时间，即便抱怨得正确。举个极端的例子。如果这个社会确实不公平，你要是抱怨一下当然没什么不对的。可是，抱怨不仅要花费时间，还会引发负面情绪，使你丧失斗志。</p>
<p>2015-06-18 21:30:20<br>热爱考试的你，肯定应该有动力为了它做很多准备。首先要弄清楚这个考试对你的分量。对你很重要，那就要下苦功。</p>
<p>2015-06-18 21:33:03<br>如果，你是个完美主义者，总是想更上一层，那还有另外一个终极技巧——把你学会的东西教给别人。教是最好的方法。清楚明了地表述那些你自以为了解的东西并不像想象的那么容易。有的时候，你没能给别人讲清楚，可能是你自己没想明白。更多的时候，被教者的提问，往往会令你发现你的想法还有很多不全面的地方。不要吝啬你的时间，不要吝啬你的精力，更不要目光短浅，记住，教别人等于自己学，只有学好的人才可能教会别人。另外，随着时间的推移，你在知识上不吝共享的经历，最终会让你明白这是最好的助人为乐的方法，并且获得的永远只能是尊重。</p>
<p>2015-06-18 21:33:31<br>总结一下：</p>
<ol>
<li>要热爱考试，因为你喜欢通行证。</li>
<li>分辨考试的重要性。</li>
<li>提前很久开始准备重要的考试。</li>
<li>做题是最好的准备方法。</li>
<li>通过做题了解考试的重点、难点。</li>
<li>全面补习难点重点，并经常重新审视。</li>
<li>教是最好的学习方法。</li>
</ol>
<p>2015-06-19 09:23:33<br>笔记都起码有这样几个好处：<br>可以使自己保持参与状态。<br>提供一个完整的捕捉灵感、疑惑的机制。<br>可以用来与其他参与者沟通、讨论正确的信息。</p>
<h1 id="第五章-小心所谓“成功学”"><a href="#第五章-小心所谓“成功学”" class="headerlink" title="第五章: 小心所谓“成功学”"></a>第五章: 小心所谓“成功学”</h1><p>2015-06-22 22:24:56<br>最近《新周刊》[1] 有一篇不错的文章，标题是《有一种毒药叫成功》。对于“成功学”对“成功”庸俗而又过分简单化的定义，《新周刊》如此讽刺：<br>……在成功学的逻辑中，如果你没有赚到“豪宅、名车、年入百万”，如果你没有成为他人艳羡的成功人士，就证明你不行，你犯了“不成功罪”！<br>助你“实现人生价值”、“开发个人潜能”、“三个月赚到一百万”、“有车有房”、“三十五岁以前退休”……成功学泛滥于职场和网络，上进人群迷失在多款提升课程和短期培训班里，成功学大师满天飞，成功学培训蔚为大观成产业。<br>……当全民成功变成狂热风潮，成功上升为绝对真理般的、人人趋之若鹜的主流价值观，成功学就是一粒毒药，而信奉成功学的人就沦为牺牲品。</p>
<p>2015-06-22 22:30:32<br>我做完这件事之后所获得的欢乐和幸福是不是一定要建立在比较的基础上才可以获得的？然后标记出并优先实施那些无需比较就可以获得欢乐和幸福的行动方案。时间会一如既往地分分钟钟、岁岁年年地流逝，但，你会惊讶于你生活的变化。每一分钟，每一秒，每一天，每一年，时间的质量竟然会如此不同。</p>
<p>2015-06-22 22:30:46<br>马丁 塞利格曼——Positive Psychology的鼻祖。最近哈佛大学里窜红的那个“快乐学”教授，就可以算作是塞利格曼的传人。 [↩]</p>
<p>2015-06-24 21:32:19<br>资源不仅稀缺，并且分布很不均匀</p>
<p>2015-06-24 21:39:38<br>人类拥有的普遍的认知偏差之一就是：把成功揽到自己身上，把失败归咎于别人或者坏运气。（心理学上有个专门的名词：self-serving bias 。</p>
<p>2015-06-25 08:05:23<br>努力从失败者身上汲取经验。不要说模仿成功者，就算观察成功者很难。成功者很多，但是，你身边的真正的成功者却很少；成功背后的东西很难看清楚，所谓成功的真实性也很难判断，而成功者们又会有意无意的美化包装他们的经验，而这一切，都在干扰你的判断。但观察失败者却要相对容易得多，因为他们的失败往往是显然而确定的，而失败的原因往往很容易确定，尽管失败者会找各种各样的借口。并且，你身边的失败者数量，显然要多于成功者的数量，于是，你就有了更多的观察机会。</p>
<p>2015-06-25 08:07:42<br>从理性角度出发，所谓我们能体会的运气，只不过因小概率事件发生而产生的感受而已</p>
<p>2015-06-25 08:10:59<br>Shallow men believe in luck. Strong men believe in cause and effect.</p>
<p>2015-06-25 08:12:16<br>骤然临之而不惊， 无故加之而不怒</p>
<p>2015-06-25 21:19:30<br>尽管不应该盲目乐观，但一定不能悲观地生活。神奇的是，努力往往真的会改变一个人的运气。将近两千五百年前，塞涅卡（罗马哲学家、悲剧作家、政治家）就把这件事儿说得非常清楚“所谓的幸运就是当你准备好了的时候机会来了。”（Luck is what happens when preparation meets opportunity.）</p>
<p>2015-06-25 21:38:47<br>专心做可以提升自己的事情；学习并拥有更多更好的技能；成为一个值得交往的人；<br>• 学会独善其身，以不给他人制造麻烦为美德；用你的独立赢得尊重；<br>• 除非有特殊原因，应该尽量回避那些连在物质生活上都不能独善其身的人；那些精神生活上都不能独善其身的，就更应该回避了——尽管甄别起来比较困难；<br>• 真正关心一个朋友的意思是说，你情愿在他身上花费甚至浪费更多的时间；<br>• 记住，一个人的幸福程度，往往取决于他多大程度上可以脱离对外部世界的依附。</p>
<p>2015-06-26 18:25:22<br>每个人各不相同，有些人在工作学习上可以获得更多的乐趣，有的人在生活琐事中可以获得更得的幸福。</p>
<p>2015-06-29 08:07:10<br>凡是值得做的事情，都值得慢慢做——做很久很久。</p>
<p>2015-06-29 08:11:39<br>. 养成规律生活的习惯</p>
<p>2015-06-29 08:11:56<br>每天检查自己的时间表至少三次</p>
<p>2015-06-29 08:12:31<br>完成任何一项任务都要实际上花费比原计划更多的时间</p>
<p>2015-06-29 08:12:38<br>假定你永远都会遇到交通堵塞。</p>
<p>2015-06-29 08:13:11<br>意外总是发生的原因绝对不是因为你的运气格外差，而往往只不过是因为你考虑得不够周全。</p>
<p>2015-06-30 08:03:05<br>假定其他人都会迟到</p>
<p>2015-06-30 08:03:11<br>尽量不要因为别人迟到而责怪他们</p>
<p>2015-06-30 08:05:55<br>姑娘当初生我们的时候我们没有说愿意！</p>
<p>2014-01-01 11:11:39<br>在几乎所有的社会里，对每一个个体的心理健康最不利的，来自于整个社会的，也许就是对“自卑”的定义了。古今中外，几乎所有的社会里，“自卑”被都定义为是负面的，“自信”才是健康的，而“自负”也是负面的。其实，假想一下，在一个“感觉”自然就是准确的社会里，所有的“自卑”、“自信”、“自负”都是没有必要存在的概念了。然而现实却是我们生活在一个因“感觉”的本性而自然扭曲的世界。<br>为了自己的心理健康，很多的时候我们确实有必要漠视甚至忽略整个社会灌输给我们的观念——因为很多的时候那不过是“整个社会的扭曲的感觉”而已。所以，我在课堂上无数次提到自卑不是缺点。该自卑的时候就要自卑，这才是正常的。</p>
<p>2014-01-01 11:15:54<br>停止嘲弄他人。</p>
<p>2014-01-01 11:16:56<br>忘记自己的优点。</p>
<p>2014-01-01 11:20:24<br>。拿出一张纸，一支笔，罗列一下。左面罗列你的优点，右面罗列你的缺点——花上一天时间也不过分，因为你需要分辨“这个真的是我的优点么？”以及“这个真的是我的缺点么？”而后，再尝试着猜想一下别人是如何看待你的优点或者缺点的。甚至你可以旁敲侧击地去了解一下——</p>
<p>2014-01-01 11:21:06<br>我们描述一个事物的方式往往会限制我们对那个事物的了解。所以，有的时候，精巧恰当的比喻往往会仅仅因为不同的表述方法就会颠覆我们对同一事物的看法。</p>
<p>2014-01-01 11:23:52<br>马太福音里说，“他有的，就再给他，让他多余；他没有的，就连同他所有的，一并夺走。</p>
<p>2014-01-01 11:24:54<br>，时间不一定就是金钱。毕竟，不是每个人都有能力把时间转换成金钱，也不是所有人都可以把时间转换成同等高额的金钱。拿出纸笔、列一列，然后问问自己，“我的时间究竟可以标价多少？”——这就是一个人决心不再浪费时间的最有效的起点和动力。只有爱惜才可能产生节约的动力。</p>
<p>2014-01-03 03:06:38<br>急功近利是一个贬义词，多少是有些肤浅的。其实，急功近利是所有人的本性，只不过，只有少数人最终通过心智的力量彻底想清楚，事实上急功近利往往是一个风险高于回报的行为模式。</p>
<p>2014-01-03 03:08:40<br>这一刻之后的任何时间都充满了变数——保守的选择通常是避免风险的最佳行为模式</p>
<h1 id="第七章-真正的解决方案"><a href="#第七章-真正的解决方案" class="headerlink" title="第七章 真正的解决方案"></a>第七章 真正的解决方案</h1><p>2014-01-03 16:29:50<br>文章本天成，妙手偶得之”</p>
<p>2014-01-03 16:40:19<br>，贫穷，从整体上来看是“永存之困境”（persistent problem）。无论这世界发展成什么样子，都不可能彻底根除贫困，因为最终，所谓的贫困是相对的。</p>
<p>2014-01-04 03:12:58<br>耐心究竟从何而来呢？首先，所有的耐心都来自于了解。</p>
<p>2014-01-04 03:15:19<br>爱因斯坦确实曾用这样的一个比喻解释相对论：“一位先生和一位漂亮女孩在一起呆上一小时，他会感觉像一分钟；但如果让他在火炉子上呆上一分钟，他会感觉比一小时还长。这就是相对论。”但</p>
<p>2015-07-08 21:29:50<br>We can’t solve problems by using the same kind of thinking we used when we created them. — Albert Einstein<br>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>鸡汤</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群部署</title>
    <url>/2015/08/08/Hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="Hadoop版本区别"><a href="#Hadoop版本区别" class="headerlink" title="Hadoop版本区别"></a>Hadoop版本区别</h1><p>目前不收费的Hadoop版本主要有三个，分别是：</p>
<ol>
<li>Apache（最原始的版本，所有发行版均基于这个版本进行改进）</li>
<li>Cloudera版本（Cloudera’s Distribution Including Apache Hadoop，简称CDH）</li>
<li>Hortonworks版本(Hortonworks Data Platform，简称“HDP”），对于国内而言，绝大多数选择CDH版本，</li>
</ol>
<p>CDH和Apache版本主要区别：</p>
<ul>
<li>CDH对Hadoop版本的划分非常清晰，目前维护的有两个系列的版本，分别是cdh4和cdh5</li>
<li>由于Cloudera做Hadoop开发的，其他厂商仅是做Hadoop集成或CDH集成，和Hadoop trunk能最快的同步，保证业务的前向兼容性；</li>
<li>安全 CDH支持Kerberos安全认证，apache hadoop则使用简陋的用户名匹配认证</li>
<li>CDH文档清晰（包括中文文档），很多采用Apache版本的用户都会阅读CDH提供的文档，包括安装文档、升级文档等。</li>
<li>CDH支持Yum/Apt包，Tar包，RPM包，CM安装，Cloudera Manager三种方式安装,Apache hadoop只支持Tar包安装。</li>
</ul>
<hr>
<a id="more"></a>
<h1 id="关于CDH"><a href="#关于CDH" class="headerlink" title="关于CDH"></a>关于CDH</h1><p><a href="http：//www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html">官方介绍</a><br>Cloudera 提供一个可扩展、灵活、集成的平台，可用来方便地管理您的企业中快速增长的多种多样的数据。业界领先的 Cloudera 产品和解决方案使您能够部署并管理 Apache Hadoop 和相关项目、操作和分析您的数据以及保护数据的安全。</p>
<p>Cloudera 提供下列产品和工具：</p>
<ul>
<li>CDH — Cloudera 分发的 Apache Hadoop 和其他相关开放源代码项目，包括 Impala 和 Cloudera Search。CDH 还提供安全保护以及与许多硬件和软件解决方案的集成。</li>
<li>Cloudera Manager — 一个复杂的应用程序，用于部署、管理、监控您的 CDH 部署并诊断问题。Cloudera Manager 提供 Admin Console，这是一种基于 Web 的用户界面，使您的企业数据管理简单而直接。它还包括 Cloudera Manager API，可用来获取群集运行状况信息和度量以及配置 Cloudera Manager。</li>
<li>Cloudera Navigator — CDH 平台的端到端数据管理工具。Cloudera Navigator 使管理员、数据经理和分析师能够了解 Hadoop 中的大量数据。Cloudera Navigator 中强大的审核、数据管理、沿袭管理和生命周期管理使企业能够遵守严格的法规遵从性和法规要求。</li>
<li>Cloudera Impala — 一种大规模并行处理 SQL 引擎，用于交互式分析和商业智能。其高度优化的体系结构使它非常适合用于具有联接、聚合和子查询的传统 BI 样式的查询。它可以查询来自各种源的 Hadoop 数据文件，包括由 MapReduce 作业生成的数据文件或加载到 Hive 表中的数据文件。YARN 和 Llama 资源管理组件让 Impala 能够共存于使用 Impala SQL 查询并发运行批处理工作负载的群集上。您可以通过 Cloudera Manager 用户界面管理 Impala 及其他 Hadoop 组件，并通过 Sentry 授权框架保护其数据。</li>
</ul>
<h1 id="Cloudera-QuickStart-VM"><a href="#Cloudera-QuickStart-VM" class="headerlink" title="Cloudera QuickStart VM"></a>Cloudera QuickStart VM</h1><p><a href="http：//www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-4-x.html">下载地址</a><br>为方便开始使用CDH、Cloudera Manager、Cloudera Impala 和 Cloudera Search，这些虚拟机器包含您所需的一切。</p>
<h1 id="CDH安装步骤"><a href="#CDH安装步骤" class="headerlink" title="CDH安装步骤"></a>CDH安装步骤</h1><h2 id="CDH安装参考资料"><a href="#CDH安装参考资料" class="headerlink" title="CDH安装参考资料"></a>CDH安装参考资料</h2><ul>
<li><a href="http：//zh-cn.cloudera.com/content/cloudera/en/products-and-services/cloudera-enterprise.html">cloudera简介</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html">cdh5官方文档</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cdh_ig_req_supported_versions.html">CDH5安装环境要求</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/installation_installation.html">CDH5的3种安装方式</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cm_ig_install_path_a.html#concept_vk4_psb_zm_unique_4">在线Yum/Wget安装教程</a></li>
<li><a href="http：//www.aboutyun.com/thread-9219-1-1.html">在线Yum/Wget安装教程-中文</a></li>
</ul>
<h2 id="在线安装优势"><a href="#在线安装优势" class="headerlink" title="在线安装优势"></a>在线安装优势</h2><ol>
<li>联网安装、升级，非常方便</li>
<li>自动下载依赖软件包</li>
<li>Hadoop生态系统包自动匹配，不需要你寻找与当前Hadoop匹配的Hbase，Flume，Hive等软件，Yum/Apt会根据当前安装Hadoop版本自动寻找匹配版本的软件包，并保证兼容性。</li>
<li>自动创建相关目录并软链到合适的地方（如conf和logs等目录）；自动创建hdfs, mapred用户，hdfs用户是HDFS的最高权限用户，mapred用户则负责mapreduce执行过程中相关目录的权限。</li>
</ol>
<h2 id="在线安装步骤"><a href="#在线安装步骤" class="headerlink" title="在线安装步骤"></a>在线安装步骤</h2><h3 id="静态IP配置"><a href="#静态IP配置" class="headerlink" title="静态IP配置"></a>静态IP配置</h3><p><code>cd /mnt/scripts/batch-update-ip &amp;&amp; chmod +x static-ip.sh &amp;&amp; ./static-ip.sh localhost eth1 192.168.1 81 1</code><br>示例：<code>cd /mnt/scripts/batch-update-ip &amp;&amp; chmod +x static-ip.sh &amp;&amp; ./static-ip.sh slave3.lt.com eth1 192.168.1 103 1</code></p>
<p><a href="todo">脚本地址</a></p>
<h3 id="HostName配置-FQDN配置"><a href="#HostName配置-FQDN配置" class="headerlink" title="HostName配置/FQDN配置"></a>HostName配置/FQDN配置</h3><p>FQDN是Fully Qualified Domain Name的缩写, 含义是完整的域名. 例如, 一台机器主机名(hostname)是www, 域后缀(domain)是example.com, 那么该主机的FQDN应该是www.example.com.<br>注意：hosts配置不当，后面server和agent间通讯会存在问题，参考host配置如下：</p>
<ul>
<li>server/agent配置(master)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/hosts</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> solr/hue/hive server</span></span><br><span class="line">127.0.0.1 localhost.localdomain localhost</span><br><span class="line"></span><br><span class="line">192.168.1.90   cdhagent.lt.com cdhagent</span><br><span class="line"></span><br><span class="line">192.168.1.91   server1.lt.com server1</span><br><span class="line">192.168.1.92   server2.lt.com server2</span><br><span class="line">192.168.1.93   server3.lt.com server3</span><br><span class="line">192.168.1.94   server4.lt.com server4</span><br><span class="line">192.168.1.95   server5.lt.com server5</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> HDFS NameNode</span></span><br><span class="line">192.168.1.100  master.lt.com master</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> HDFS DataNode</span></span><br><span class="line">192.168.1.101  slave1.lt.com slave1</span><br><span class="line">192.168.1.102  slave2.lt.com slave2</span><br><span class="line">192.168.1.103  slave3.lt.com slave3</span><br><span class="line">192.168.1.104  slave4.lt.com slave4</span><br><span class="line">192.168.1.105  slave5.lt.com slave5</span><br><span class="line">192.168.1.106  slave6.lt.com slave6</span><br><span class="line">192.168.1.107  slave7.lt.com slave7</span><br><span class="line">192.168.1.108  slave8.lt.com slave8</span><br><span class="line">192.168.1.109  slave9.lt.com slave9</span><br><span class="line">192.168.1.110  slave10.lt.com slave10</span><br></pre></td></tr></table></figure>
<ul>
<li>network配置</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/sysconfig/network</span></span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=master.lt.com</span><br><span class="line">NTPSERVERARGS=iburst</span><br></pre></td></tr></table></figure>
<p><em>TODO：可局域网搭建DNS服务器，Slave机器即可不配配置hosts</em></p>
<h3 id="SSH无密码登陆配置"><a href="#SSH无密码登陆配置" class="headerlink" title="SSH无密码登陆配置"></a>SSH无密码登陆配置</h3><p><em>TODO：补充github脚本地址</em><br>删除现有ssh配置（可选）：rm /root/.ssh/authorized_keys &amp;&amp; rm /root/.ssh/known_hosts<br><code>cd /mnt/scripts/batch-ssh &amp;&amp; chmod +x keygen_master.sh &amp;&amp; ./keygen_master.sh</code></p>
<h3 id="iptables防火墙配置"><a href="#iptables防火墙配置" class="headerlink" title="iptables防火墙配置"></a>iptables防火墙配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看防火墙状态</span></span><br><span class="line">service iptables status</span><br><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">service iptables stop</span><br><span class="line"><span class="comment">#永久关闭防火墙</span></span><br><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure>
<h3 id="selinux强制访问控制安全配置"><a href="#selinux强制访问控制安全配置" class="headerlink" title="selinux强制访问控制安全配置"></a>selinux强制访问控制安全配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看SELinux状态</span></span><br><span class="line">/usr/sbin/sestatus -v</span><br><span class="line"><span class="meta">#</span><span class="bash">或命令</span></span><br><span class="line">getenforce</span><br><span class="line"><span class="meta">#</span><span class="bash">关闭SELinux</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1. 临时关闭（不用重启机器）：</span></span><br><span class="line">setenforce 0                  ##设置SELinux 成为permissive模式</span><br><span class="line">                              ##setenforce 1 设置SELinux 成为enforcing模式</span><br><span class="line"><span class="meta">#</span><span class="bash">2. 修改配置文件</span></span><br><span class="line">vim /etc/selinux/config</span><br><span class="line"><span class="meta">#</span><span class="bash">将SELINUX=enforcing改为SELINUX=disabled</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3. reboot</span></span><br></pre></td></tr></table></figure>
<h3 id="swap配置"><a href="#swap配置" class="headerlink" title="swap配置"></a>swap配置</h3><p>Cloudera 建议将 /proc/sys/vm/swappiness 设置为 0。默认设置为 60。<br>查看当前swap分区设置<code>cat /proc/sys/vm/swappiness</code><br>临时修改值：<code>sudo sysctl vm.swappiness=0</code><br>永久修改值：<code>vim /etc/sysctl.conf</code>，在最后加一行<code>vm.swappiness = 0</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swappiness的值的大小对如何使用swap分区是有着很大的联系</span><br><span class="line">swappiness&#x3D;0的时候表示最大限度使用物理内存，然后才是 swap空间</span><br><span class="line">swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面</span><br></pre></td></tr></table></figure>
<h3 id="安装NTP服务"><a href="#安装NTP服务" class="headerlink" title="安装NTP服务"></a>安装NTP服务</h3><p><a href="http://acooly.iteye.com/blog/1993484">NTP配置教程</a><br>集群中所有主机必须保持时间同步，如果时间相差较大会引起各种问题。 具体思路如下：<br>master节点作为ntp服务器与外界对时中心同步时间，随后对所有datanode节点提供时间同步服务。<br>所有datanode节点以master节点为基础同步时间。<br>所有节点安装相关组件： <code>yum install ntp</code> 。<br>配置开机启动： <code>chkconfig ntpd on</code> ,<br>检查是否设置成功： <code>chkconfig --list ntpd</code> 其中2-5为on状态就代表成功。</p>
<ul>
<li>主节点配置<br>在配置之前，先使用ntpdate手动同步一下时间，免得本机与对时中心时间差距太大，使得ntpd不能正常同步。 ntpdate -u 202.112.29.82<br>编辑<code>/etc/ntp.conf</code>配置文件，配置完成后启动服务<code>service ntpd start</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"></span><br><span class="line">restrict default kod nomodify notrap nopeer noquery</span><br><span class="line">restrict -6 default kod nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict -6 ::1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">允许内网其他机器同步时间</span></span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 中国这边最活跃的时间服务器 : http://www.pool.ntp.org/zone/cn</span></span><br><span class="line">server 3.cn.pool.ntp.org perfer  </span><br><span class="line">server 1.asia.pool.ntp.org         </span><br><span class="line">server 3.asia.pool.ntp.org</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 外部时间服务器不可用时，以本地时间作为时间服务</span></span><br><span class="line">server  127.127.1.0     # local clock</span><br><span class="line">fudge   127.127.1.0 stratum 10</span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line">server 127.127.1.0 iburst</span><br></pre></td></tr></table></figure>
<p>查看配置结果：   </p>
<ul>
<li><code>netstat -tlunp | grep ntp</code> 查看服务连接和监听</li>
<li><code>ntpq -p</code>查看网络中的NTP服务器，同时显示客户端和每个服务器的关系</li>
<li><p><code>ntpstat</code> 查看时间同步状态</p>
</li>
<li><p>NTP客户端配置<br>编辑<code>/etc/ntp.conf</code>配置文件，配置完成后启动服务<code>service ntpd restart</code></p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict -6 ::1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置时间服务器为本地的时间服务器</span></span><br><span class="line">server 192.168.1.100</span><br><span class="line"></span><br><span class="line">restrict 192.168.1.100 nomodify notrap noquery</span><br><span class="line"></span><br><span class="line">server  127.127.1.0     # local clock</span><br><span class="line">fudge   127.127.1.0 stratum 10</span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line">keys /etc/ntp/keys</span><br></pre></td></tr></table></figure>
<h3 id="cloudera-manager-installer-bin安装"><a href="#cloudera-manager-installer-bin安装" class="headerlink" title="cloudera-manager-installer.bin安装"></a>cloudera-manager-installer.bin安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http：//archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin</span><br><span class="line">chmod u+x cloudera-manager-installer.bin</span><br><span class="line">sudo ./cloudera-manager-installer.bin</span><br></pre></td></tr></table></figure>
<h3 id="在线配置"><a href="#在线配置" class="headerlink" title="在线配置"></a>在线配置</h3><p>打开http：//{host}：7180/cmf/login<br>默认用户名/密码：admin/admin<br><a href="http：//www.aboutyun.com/thread-9189-1-1.html">cloudera配置文件</a></p>
<h1 id="CDH5运维相关"><a href="#CDH5运维相关" class="headerlink" title="CDH5运维相关"></a>CDH5运维相关</h1><h2 id="系统服务"><a href="#系统服务" class="headerlink" title="系统服务"></a>系统服务</h2><p>服务查询：<code>service --status-all| grep cloudera</code><br><em>服务端</em>  </p>
<ul>
<li>cloudera-scm-server</li>
<li>cloudera-scm-server-db<br><em>客户端</em>  </li>
<li>cloudera-scm-agent</li>
</ul>
<h2 id="嵌入式-PostgreSQL-数据库"><a href="#嵌入式-PostgreSQL-数据库" class="headerlink" title="嵌入式 PostgreSQL 数据库"></a>嵌入式 PostgreSQL 数据库</h2><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_embed_pstgrs.html">嵌入式 PostgreSQL 数据库</a><br><a href="http://www.linuxidc.com/Linux/2013-10/91446.htm">修改postgresql配置允许远程访问</a>  </p>
<ul>
<li>scm数据库密码</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat /etc/cloudera-scm-server/db.properties</span></span><br><span class="line">com.cloudera.cmf.db.type=postgresql</span><br><span class="line">com.cloudera.cmf.db.host=localhost:7432</span><br><span class="line">com.cloudera.cmf.db.name=scm</span><br><span class="line">com.cloudera.cmf.db.user=scm</span><br><span class="line">com.cloudera.cmf.db.password=30MCe9Mxuk</span><br></pre></td></tr></table></figure>
<ul>
<li>root密码： <code>/var/lib/cloudera-scm-server-db/data/generated_password.txt</code></li>
</ul>
<h2 id="卸载Cloudera"><a href="#卸载Cloudera" class="headerlink" title="卸载Cloudera"></a>卸载Cloudera</h2><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_uninstall_cm.html">卸载 Cloudera Manager 和托管软件</a><br><a href="http://student-lp.iteye.com/blog/2158887">参考博客</a></p>
<h2 id="Cloudera-Manager-API"><a href="#Cloudera-Manager-API" class="headerlink" title="Cloudera Manager API"></a>Cloudera Manager API</h2><p><a href="http://zh-cn.cloudera.com/content/cloudera/en/documentation.html">官方文档</a><br>Cloudera Manager API 提供了配置和服务生命周期管理、服务运行状况信息和指标，并允许您配置 Cloudera Manager 本身。此 API 与 Cloudera Manager Admin Console 在同一主机和端口上接受服务，不需要任何额外过程或额外配置。此 API 支持 HTTP 基本验证，接受的用户和凭据与 Cloudera Manager Admin Console 相同。</p>
<h2 id="Cloudera-Management-Service"><a href="#Cloudera-Management-Service" class="headerlink" title="Cloudera Management Service"></a>Cloudera Management Service</h2><p>Cloudera Management Service 可作为一组角色实施各种管理功能：<br>Activity Monitor - 收集有关 MapReduce 服务运行的活动的信息。默认情况下未添加此角色。<br>Host Monitor - 收集有关主机的运行状况和指标信息<br>Service Monitor - 收集有关服务的运行状况和指标信息以及 YARN 和 Impala 服务中的活动信息<br>Event Server - 聚合 relevant Hadoop 事件并将其用于警报和搜索<br>Alert Publisher - 为特定类型的事件生成和提供警报<br>Reports Manager - 生成报告，它提供用户、用户组和目录的磁盘使用率的历史视图，用户和 YARN 池的处理活动，以及 HBase 表和命名空间。此角色未在 Cloudera Express 中添加。<br>Cloudera Manager 将单独管理每个角色，而不是作为 Cloudera Manager Server 的一部分进行管理，可实现可扩展性（例如，在大型部署中，它可用于将监控器角色置于自身的主机上）和隔离。</p>
<p>此外，对于特定版本的 Cloudera Enterprise 许可证，Cloudera Management Service 还为 Cloudera Navigator 提供 Navigator Audit Server 和 Navigator Metadata Server 角色。</p>
<h1 id="安装问题记录"><a href="#安装问题记录" class="headerlink" title="安装问题记录"></a>安装问题记录</h1><ol>
<li>无法发出查询：未能连接到 Host Monitor</li>
</ol>
<p>解决方式：新增cloudera management services ,注意新增的目标机器因为scm-server安装的同一台机器，机器内存最好&gt;=8G</p>
<ol>
<li>urlopen error [Errno 111] Connection refused</li>
</ol>
<ul>
<li>问题场景：CM中主机CDH5安装Parcel完成后无法分配和激活Agent</li>
<li>详细日志<blockquote>
<p>downloader INFO  Finished download [ url： http：//master.lt.com：7180/cmf/parcel/download/CDH-5.4.4-1.cdh5.4.4.p0.4-el6.parcel, state： exception, total_bytes： 0, downloaded_bytes： 0, start_time： 2015-08-11 22：18：32, download_end_time： , end_time： 2015-08-11 22：18：33, code： 600, exception： <urlopen error [Errno 111] Connection refused>, path： None ]</p>
</blockquote>
</li>
<li>错误分析：在slave机器执行<code>nc -v master.lt.com  7182</code> 返回refused，判断是host配置有误导致dns解析不了</li>
<li>解决方式：在slave1的hosts中新增master的域名解析</li>
</ul>
<ol>
<li>正在获取安装锁问题</li>
</ol>
<ul>
<li>问题描述：意外中止安装后重新安装提示”正在获取安装锁…“  ；</li>
<li>问题解决：在Manager节点运行<code>rm /tmp/.scm_prepare_node.lock</code>删除Manager的lock文件后重新安装即可；</li>
</ul>
<ol>
<li>对于此 Cloudera Manager 版本 (5.4.7) 太新的 CDH 版本不会显示</li>
</ol>
<ul>
<li>问题描述：Versions of CDH that are too new for this version of Cloudera Manager (5.4.7) will not be shown.</li>
<li>问题定位：PARCELS表fileName=CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel的hash值为null，判断为parcel文件问题或scm数据库生成干扰问题</li>
<li>解决思路：判断为/opt/cloudera/parcel-repo/目录内的本地parcel应该在scm数据库初始化结束后再放入</li>
<li>问题解决：停止server&gt;重置scm数据库&gt;启动server&gt;复制parcel到/opt/cloudera/parcel-repo/目录</li>
</ul>
<p><a href="https://community.cloudera.com/t5/Cloudera-Manager-Installation/Can-t-find-CM-5-4-2-for-Trusty-or-Precise/td-p/28685">参考</a></p>
<ol>
<li><p>[Errno 2] No such file or directory: u’/opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/meta/parcel.json’ - master.lt.com<br>需要存在目录：/opt/cloudera/parcel-cache</p>
</li>
<li><p>启用透明大页面问题</p>
</li>
</ol>
<ul>
<li>问题描述：已启用“透明大页面”，它可能会导致重大的性能问题。版本为“CentOS release 6.5 (Final)”且发行版为“2.6.32-431.el6.x86_64”的 Kernel 已将 enabled 设置为“[always] madvise never”，并将 defrag 设置为“[always] madvise never”。</li>
<li>问题解决：运行“echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/defrag”以禁用此设置，然后将同一命令添加到一个 init 脚本中，如 /etc/rc.local，</li>
</ul>
<ol>
<li>修改Cloudera Manager 管理机器的IP<br><a href="http://www.cnblogs.com/chenfool/archive/2014/05/27/3756066.html">解决方案</a></li>
</ol>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CDH</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>《数学之美》读书笔记</title>
    <url>/2015/09/22/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E/</url>
    <content><![CDATA[<p>谷歌吴军：数学之美</p>
<p>如何化繁为简，如何用数学去解决工程问题，如何跳出固有思维不断去思考创新。</p>
<hr>
<a id="more"></a>
<h1 id="系列二-—-谈谈中文分词"><a href="#系列二-—-谈谈中文分词" class="headerlink" title="系列二 — 谈谈中文分词"></a>系列二 — 谈谈中文分词</h1><p>2015-09-13 16:31:25<br>一般来讲，根据不同应用，汉语分词的颗粒度大小应该不同。比如，在机器翻译中，颗粒度应该大一些，“北京大学”就不能被分成两个词。而在语音识别中，“北京大学”一般 是被分成两个词。因此，不同的应用，应该有不同的分词系统</p>
<h1 id="系列三-—-隐含马尔可夫模型在语言处理中的应用"><a href="#系列三-—-隐含马尔可夫模型在语言处理中的应用" class="headerlink" title="系列三 — 隐含马尔可夫模型在语言处理中的应用"></a>系列三 — 隐含马尔可夫模型在语言处理中的应用</h1><p>2015-09-13 16:34:02<br>自然语言是人类交流信息的工具。很多自然语言处理问题都可以等同于通信系统中的解码问题 — 一个人根据接收到的信息，去猜测发话人要表达的意思。这其实就象通信中，我们根据接收端收到的信号去分析、理解、还原发送端传送过来的信息。</p>
<p>2015-09-13 16:35:28<br>在计算机中，如果我们要根据接收到的英语信息，推测说话者的汉语意思，就是机器翻译；如果我们要根据带有拼写错误的语句推测说话者想表达的正确意思，那就是自动纠错。</p>
<h1 id="系列-4-—-怎样度量信息"><a href="#系列-4-—-怎样度量信息" class="headerlink" title="系列 4 — 怎样度量信息?"></a>系列 4 — 怎样度量信息?</h1><p>2015-09-13 21:37:46<br>Google 一直以 “整合全球信息，让人人能获取，使人人能受益” 为使命</p>
<p>2015-09-13 21:40:33<br>一条信息的信息量大小和它的不确定性有直接的关系。</p>
<p>2015-09-13 21:40:44<br>信息量的度量就等于不确定性的多少。</p>
<p>2015-09-13 21:47:32<br>不同语言的冗余度差别很大，而汉语在所有语言中冗余度是相对小的。这和人们普遍的认识”汉语是最简洁的语言”是一致的。</p>
<h1 id="系列五-—-简单之美：布尔代数和搜索引擎的索引"><a href="#系列五-—-简单之美：布尔代数和搜索引擎的索引" class="headerlink" title="系列五 — 简单之美：布尔代数和搜索引擎的索引"></a>系列五 — 简单之美：布尔代数和搜索引擎的索引</h1><p>2015-09-13 21:48:42<br>建立一个搜索引擎大致需要做这样几件事：自动下载尽可能多的网页；建立快速有效的索引；根据相关性对网页进行公平准确的排序</p>
<p>2015-09-14 22:31:43<br>搜索引擎的索引就变成了一张大表：表的每一行对应一个关键词，而每一个关键词后面跟着一组数字，是包含该关键词 的文献序号。</p>
<p>2015-09-14 22:32:45<br>每当接受一个查询时，这个查询就被分送到许许多多服务器中，这些服务器 同时并行处理用户请求，并把结果送到主服务器进行合并处理，最后将结果返回给用户。</p>
<p>2015-09-14 22:33:05<br>不管索引如何复杂，查找的基本操作仍然是布尔运算。布尔运算把逻辑和数学联系起来了。它的最大好处是容易实现，速度快，这对于海量的信息查找是至关重要的。它的不足是只能给出是与否的判断，而不能给出量化的 度量。因此，所有搜索引擎在内部检索完毕后，都要对符合要求的网页根据相关性排序，然后才返回给用户。</p>
<h1 id="系列六-—-图论和网络爬虫"><a href="#系列六-—-图论和网络爬虫" class="headerlink" title="系列六 — 图论和网络爬虫"></a>系列六 — 图论和网络爬虫</h1><p>2015-09-14 22:33:57<br>如何自动下载互联网所有的网页呢，它要用到图论中的遍历（Traverse) 算法。</p>
<p>2015-09-14 22:35:57<br>“广度优先算法”（BFS)，因为它先要尽可能广地访问每个节点所直接连接的其他节点。</p>
<p>2015-09-14 22:36:22<br>“深度优先算法”（DFS)，因为它是一条路走到黑。</p>
<h1 id="系列七-—-信息论在信息处理中的应用"><a href="#系列七-—-信息论在信息处理中的应用" class="headerlink" title="系列七 — 信息论在信息处理中的应用"></a>系列七 — 信息论在信息处理中的应用</h1><p>2015-09-14 22:41:23<br>李开复博士在介绍他发明的 Sphinx 语音识别系统时谈到，如果不用任何语言模型（即零元语言模型）时，复杂度为997，也就是说句子中每个位置有 997 个可能的单词可以填入。如果（二元）语言模型只考虑前后词的搭配不考虑搭配的概率时，复杂度为60。虽然它比不用语言模型好很多，但是和考虑了搭配概率的二元语言模型相比要差很多，因为后者的复杂度只有20。</p>
<p>2015-09-14 22:41:40<br>信息论中仅次于熵的另外两个重要的概念是“互信息”（Mutual Information) 和“相对熵”（Kullback-Leibler Divergence)。</p>
<p>2015-09-14 22:42:00<br>“互信息”是信息熵的引申概念，它是对两个随机事件相关性的度量。</p>
<p>2015-09-14 22:45:15<br>信息论中另外一个重要的概念是“相对熵”，在有些文献中它被称为成“交叉熵”。在英语中是 Kullback-Leibler Divergence， 是以它的两个提出者库尔贝克和莱伯勒的名字命名的。相对熵用来衡量两个正函数是否相似，对于两个完全相同的函数，它们的相对熵等于零。在自然语言处理中可 以用相对熵来衡量两个常用词（在语法上和语义上）是否同义，或者两篇文章的内容是否相近等等。利用相对熵，我们可以到处信息检索中最重要的一个概念：词频率-逆向文档频率（TF/IDF)。</p>
<h1 id="系列八—-贾里尼克的故事和现代语言处理"><a href="#系列八—-贾里尼克的故事和现代语言处理" class="headerlink" title="系列八— 贾里尼克的故事和现代语言处理"></a>系列八— 贾里尼克的故事和现代语言处理</h1><p>2015-09-14 22:53:52<br>七十年代的 IBM 有点像九十年代的微软和今天的 Google, 给于杰出科学家作任何有兴趣研究的自由。在那种宽松的环境里，贾里尼克等人提出了统计语音识别的框架结构。 在贾里尼克以前，科学家们把语音识别问题当作人工智能问题和模式匹配问题。而贾里尼克把它当成通信问题，并用两个隐含马尔可夫模型（声学模型和语言模型） 把语音识别概括得清清楚楚。这个框架结构对至今的语音和语言处理有着深远的影响，它从根本上使得语音识别有实用的可能。 贾里尼克本人后来也因此当选美国工程院院士。</p>
<h1 id="系列九-—-如何确定网页和查询的相关性"><a href="#系列九-—-如何确定网页和查询的相关性" class="headerlink" title="系列九 — 如何确定网页和查询的相关性"></a>系列九 — 如何确定网页和查询的相关性</h1><p>2015-09-15 22:48:01<br>如果一个关键词只在很少的网页中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量网页中出现，我们看到它仍 然不很清楚要找什么内容，因此它应该小。概括地讲，假定一个关键词w在DW个网页中出现过，那么DW越大，w的权重越小，反之亦然。在信息检索中，使用最多的权重是“逆文本频率指数”</p>
<p>2015-09-15 22:49:07<br>ＴＦ／ＩＤＦ（term frequency/inverse document frequency) 的概念被公认为信息检索中最重要的发明。在搜索、文献分类和其他相关领域有广泛的应用。</p>
<p>2015-09-15 22:50:46<br>信息论的学者们已经发现并指出，其实 IDF 的概念就是一个特定条件下、关键词的概率分布的交叉熵（Kullback-Leibler Divergence)（详见上一系列）。这样，信息检索相关性的度量，又回到了信息论。</p>
<h1 id="系列十-有限状态机和地址识别"><a href="#系列十-有限状态机和地址识别" class="headerlink" title="系列十 有限状态机和地址识别"></a>系列十 有限状态机和地址识别</h1><p>2015-09-16 22:00:29<br>地址的识别和分析是本地搜索必不可少的技术，尽管有许多识别和分析地址的方法，最有效的是有限状态机。</p>
<p>2015-09-16 22:00:55<br>一个有限状态机是一个特殊的有向图（参见有关图论的系列），它包括一些状态（节点）和连接这些状态的有向弧。</p>
<p>2015-09-16 22:02:38<br>使用有限状态机识别地址，关键要解决两个问题，即通过一些有效的地址建立状态机，以及给定一个有限状态机后，地址字串的匹配算法。</p>
<p>2015-09-16 22:04:22<br>基于有限状态机的地址识别方法在实用中会有一些问题：当用户输入的地址不太标准或者有错别字时，有限状态机会束手无策，因为它只能进行严格匹配。（其实，有限状态机在计算机科学中早期的成功应用是在程序语言编译器的设计中。一个能运行的程序在语法上必须是没有错的，所以不需要模糊匹配。而自然语言则很随意，无法用简单的语法描述。）<br>为了解决这个问题，我们希望有一个能进行模糊匹配、并给出一个字串为正确地址的可能性。为了实现这一目的，科学家们提出了基于概率的有限状态机。这种基于概率的有限状态机和离散的马尔可夫链（详见前面关于马尔可夫模型的系列）基本上等效。</p>
<h1 id="十四-谈谈数学模型的重要性"><a href="#十四-谈谈数学模型的重要性" class="headerlink" title="十四 谈谈数学模型的重要性"></a>十四 谈谈数学模型的重要性</h1><p>2015-09-17 21:57:04</p>
<ol>
<li>一个正确的数学模型应当在形式上是简单的。（托勒密的模型显然太复杂。）</li>
<li>一个正确的模型在它开始的时候可能还不如一个精雕细琢过的错误的模型来的准确，但是，如果我们认定大方向是对的，就应该坚持下去。（日心说开始并没有地心说准确。）</li>
<li>大量准确的数据对研发很重要。</li>
<li>正确的模型也可能受噪音干扰，而显得不准确；这时我们不应该用一种凑合的修正方法来弥补它，而是要找到噪音的根源，这也许能通往重大发现。</li>
</ol>
<p>2015-09-17 21:57:17<br>在网络搜索的研发中，我们在前面提到的单文本词频/逆文本频率指数（TF/IDF) 和网页排名（page rank)都相当于是网络搜索中的”椭圆模型”，它们都很简单易懂。</p>
<h1 id="系列十六（上）-不要把所有的鸡蛋放在一个篮子里"><a href="#系列十六（上）-不要把所有的鸡蛋放在一个篮子里" class="headerlink" title="系列十六（上） 不要把所有的鸡蛋放在一个篮子里"></a>系列十六（上） 不要把所有的鸡蛋放在一个篮子里</h1><p>2015-09-21 22:08:08<br>最大熵原理指出，当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。（不做主观假设这点很重要。）在这种情况下，概率分布最均匀，预测的风险最小。因为这时概率分布的信息熵最大，所以人们称这种模型叫”最大熵模型”。我们常说，不要把所有的鸡蛋放在一个篮子里，其实就是最大熵原理的一个朴素的说法，因为当我们遇到不确定性时，就要保留各种可能性。</p>
<h1 id="系列十六-（下）－-不要把所有的鸡蛋放在一个篮子里"><a href="#系列十六-（下）－-不要把所有的鸡蛋放在一个篮子里" class="headerlink" title="系列十六 （下）－ 不要把所有的鸡蛋放在一个篮子里"></a>系列十六 （下）－ 不要把所有的鸡蛋放在一个篮子里</h1><p>2015-09-21 22:14:07<br>最原始的最大熵模型的训练方法是一种称为通用迭代算法 GIS(generalized iterative scaling) 的迭代 算法。GIS 的原理并不复杂，大致可以概括为以下几个步骤：</p>
<ol>
<li>假定第零次迭代的初始模型为等概率的均匀分布。</li>
<li>用第 N 次迭代的模型来估算每种信息特征在训练数据中的分布，如果超过了实际的，就把相应的模型参数变小；否则，将它们便大。</li>
<li>重复步骤 2 直到收敛。</li>
</ol>
<p>2015-09-21 22:19:29<br>最大熵模型，可以说是集简与繁于一体，形式简单，实现复杂。</p>
<h1 id="系列十八-－-矩阵运算和文本处理中的分类问题"><a href="#系列十八-－-矩阵运算和文本处理中的分类问题" class="headerlink" title="系列十八 － 矩阵运算和文本处理中的分类问题"></a>系列十八 － 矩阵运算和文本处理中的分类问题</h1><p>2015-09-21 22:36:15<br>分类的关键是计算相关性。我们首先对两个文本计算出它们的内容词，或者说实词的向量，然后求这两个向量的夹角。当这两个向量夹角为零时，新闻就相关；当它们垂直或者说正交时，新闻则无关。</p>
<h1 id="系列十九-－-马尔可夫链的扩展-贝叶斯网络"><a href="#系列十九-－-马尔可夫链的扩展-贝叶斯网络" class="headerlink" title="系列十九 － 马尔可夫链的扩展 贝叶斯网络"></a>系列十九 － 马尔可夫链的扩展 贝叶斯网络</h1><p>2015-09-21 22:39:58<br>马尔可夫链 (Markov Chain)，它描述了一种状态序列，其每个状态值取决于前面有限个状态。这种模型，对很多实际问题来讲是一种很粗略的简化。在现实生活中，很多事物相互的关系并不能用一条链来串起来。它们之间的关系可能是交叉的、错综复杂的。</p>
<p>2015-09-21 22:39:35<br>贝叶斯网络。其中每个圆圈表示一个状态。状态之间的连线表示它们的因果关系。比如从心血管疾病出发到吸烟的弧线表示心血管疾病可能和吸烟有关。当然，这些关系可以有一个量化的可信度 (belief)，用一个概率描述。我们可以通过这样一张网络估计出一个人的心血管疾病的可能性。在网络中每个节点概率的计算，可以用贝叶斯公式来进行，贝叶斯网络因此而得名。由于网络的每个弧有一个可信度，贝叶斯网络也被称作信念网络 (belief networks)。</p>
<h1 id="系列二十-－自然语言处理的教父-马库斯"><a href="#系列二十-－自然语言处理的教父-马库斯" class="headerlink" title="系列二十 －自然语言处理的教父 马库斯"></a>系列二十 －自然语言处理的教父 马库斯</h1><p>2015-09-21 22:43:25<br>PennTree Bank 覆盖多种语言（包括中文）。每一种语言，它有几十万到几百万字的有代表性的句子，每个句子都有的词性标注，语法分析树等等。LDC 语料库如今已成为全世界自然语言处理科学家共用的数据库。如今，在自然语言处理方面发表论文，几乎都要提供基于 LDC 语料库的测试结果。</p>
<h1 id="系列二十二-由电视剧《暗算》所想到的"><a href="#系列二十二-由电视剧《暗算》所想到的" class="headerlink" title="系列二十二 由电视剧《暗算》所想到的"></a>系列二十二 由电视剧《暗算》所想到的</h1><p>2015-09-21 22:54:10<br>来设计一个密码系统，对这个明码加密。<br>1，找两个很大的素数（质数）P 和 Q，越大越好，比如 100 位长的, 然后计算它们的乘积 N=P×Q，M=（P-1）×（Q-1）。<br>2，找一个和 M 互素的整数 E，也就是说 M 和 E 除了 1 以外没有公约数。<br>3，找一个整数 D，使得 E×D 除以 M 余 1，即 E×D mod M = 1。<br>现在，世界上先进的、最常用的密码系统就设计好了，其中 E 是公钥谁都可以用来加密，D 是私钥用于解密，一定要自己保存好。乘积 N 是公开的，即使敌人知道了也没关系。<br>现在，我们用下面的公式对 X 加密，得到密码 Y。<br>好了，现在没有密钥 D，神仙也无法从 Y 中恢复 X。如果知道 D，根据费尔马小定理，则只要按下面的公式就可以轻而易举地从 Y 中得到 X。</p>
<hr>
<p>多看笔记 来自多看阅读 for Kindle<br>多看ID: geosmart</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Solr的Hbase二级索引</title>
    <url>/2015/09/01/%E5%9F%BA%E4%BA%8ESolr%E7%9A%84Hbase%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<h1 id="关于Hbase二级索引"><a href="#关于Hbase二级索引" class="headerlink" title="关于Hbase二级索引"></a>关于Hbase二级索引</h1><p>HBase 是一个列存数据库，每行数据只有一个主键RowKey，无法依据指定列的数据进行检索。查询时需要通过RowKey进行检索，然后查看指定列的数据是什么，效率低下。在实际应用中，我们经常需要根据指定列进行检索，或者几个列进行组合检索，这就提出了建立 HBase 二级索引的需求。</p>
<p>二级索引构建方式：表索引、列索引、全文索引  </p>
<ul>
<li>表索引是将索引数据单独存储为一张表，通过 HBase Coprocessor 生成并访问索引数据。</li>
<li>列索引是将索引数据与源数据存储在相同的 Region 里，索引数据定义为一个单独的列族，也是利用 Coprocessor 来生成并访问索引数据。对于表索引，源数据表与索引表的数据一致性很难保证，访问两张不同的表也会增加 IO 开销和远程调用的次数。对于列索引，单表的数据容量会急剧增加，对同一 Region 里的多个列族进行 Split 或 Merge 等操作时可能会造成数据丢失或不一致。  </li>
<li>全文索引：以CDH5中的Lily HBase Indexer服务实现，其使用SolrCloud存储HBase的索引数据，Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</li>
</ul>
<hr>
<a id="more"></a>
<p><img src="solr-query.png" alt="通过solr查询rowkey再查询Hbase"></p>
<h1 id="关于Key-Value-Indexer组件"><a href="#关于Key-Value-Indexer组件" class="headerlink" title="关于Key-Value Indexer组件"></a>关于Key-Value Indexer组件</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/search_use_hbase_indexer_service.html?scroll=xd_583c10bfdbd326ba-204beb9-13ef1573a9e--7fbb">CDH官方文档</a><br><a href="https://github.com/NGDATA/hbase-indexer/wiki">hbase-indexer官方WIKI</a><br><a href="http://blog.cloudera.com/blog/2013/11/email-indexing-using-cloudera-search-and-hbase/">参考博客：Email Indexing Using Cloudera Search and HBase</a><br><a href="http://blog.csdn.net/kissmelove01/article/details/45043955">参考博客： Cloudera Search Solr初探</a><br><a href="http://ae.yyuap.com/pages/viewpage.action?pageId=920173">参考博客：一种基于UDH Search的HBase二级索引构建方案</a>     </p>
<p>CDH5.4中的Key-Value Indexer使用的是Lily HBase NRT Indexer服务，Lily HBase Indexer是一款灵活的、可扩展的、高容错的、事务性的，并且近实时的处理HBase列索引数据的分布式服务软件。它是NGDATA公司开发的Lily系统的一部分，已开放源代码。<br>Lily HBase Indexer使用SolrCloud来存储HBase的索引数据，当HBase执行写入、更新或删除操作时，Indexer通过HBase的replication功能来把这些操作抽象成一系列的Event事件，并用来保证写入Solr中的HBase索引数据的一致性。并且Indexer支持用户自定义的抽取，转换规则来索引HBase列数据。Solr搜索结果会包含用户自定义的columnfamily:qualifier字段结果，这样应用程序就可以直接访问HBase的列数据。而且Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。<br>Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</p>
<h1 id="使用-Lily-HBase-Batch-Indexer-进行索引"><a href="#使用-Lily-HBase-Batch-Indexer-进行索引" class="headerlink" title="使用 Lily HBase Batch Indexer 进行索引"></a>使用 Lily HBase Batch Indexer 进行索引</h1><p>借助 Cloudera Search，您可以利用 MapReduce 作业对 HBase 表进行批量索引。批量索引不需要以下操作：</p>
<ul>
<li>HBase 复制</li>
<li>Lily HBase Indexer 服务</li>
<li>通过 Lily HBase Indexer 服务注册 Lily HBase Indexer 配置<br>该索引器支持灵活的、自定义的、特定于应用程序的规则来将 HBase 数据提取、转换和加载到 Solr。Solr 搜索结果可以包含到存储在 HBase 中的数据的 columnFamily:qualifier 链接。这样，应用程序可以使用搜索结果集直接访问匹配的原始 HBase 单元格。</li>
</ul>
<h1 id="创建HBase集群的表中列索引的步骤："><a href="#创建HBase集群的表中列索引的步骤：" class="headerlink" title="创建HBase集群的表中列索引的步骤："></a>创建HBase集群的表中列索引的步骤：</h1><p><a href="https://github.com/NGDATA/hbase-indexer/wiki/Tutorial">Tutorial教程</a>  </p>
<ul>
<li>填充 HBase 表。</li>
<li>创建相应的 SolrCloud 集合</li>
<li>创建 Lily HBase Indexer 配置</li>
<li>创建 Morphline 配置文件</li>
<li>注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service</li>
</ul>
<h2 id="填充-HBase-表"><a href="#填充-HBase-表" class="headerlink" title="填充 HBase 表"></a>填充 HBase 表</h2><p>在配置和启动系统后，创建 HBase 表并向其添加行。例如：<br>对于每个新表，在需要通过发出格式命令进行索引的每个列系列上设置 REPLICATION_SCOPE：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> hbase shell </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">测试数据：列簇设置REPLICATION_SCOPE</span></span><br><span class="line">disable 'User'</span><br><span class="line">drop  'User'</span><br><span class="line">create 'User', &#123;NAME =&gt; 'data', REPLICATION_SCOPE =&gt; 1&#125;  </span><br><span class="line"></span><br><span class="line">disable 'User'</span><br><span class="line">alter 'User', &#123;NAME =&gt; 'detail', REPLICATION_SCOPE =&gt; 1&#125;  </span><br><span class="line">enable 'User'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">新增CF</span></span><br><span class="line">disable 'User'</span><br><span class="line">alter 'User', &#123;NAME =&gt; 'detail', REPLICATION_SCOPE =&gt; 1&#125; </span><br><span class="line">enable 'User'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改现有</span></span><br><span class="line">disable 'User'</span><br><span class="line">alter 'User', &#123;NAME =&gt; 'data', REPLICATION_SCOPE =&gt; 1&#125; </span><br><span class="line">enable 'User'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 插入测试数据 </span></span><br><span class="line">put 'User','row1','data:name','u1'</span><br><span class="line">put 'User','row1','data:psd','123'</span><br></pre></td></tr></table></figure>
<h2 id="创建相应的-SolrCloud-集合"><a href="#创建相应的-SolrCloud-集合" class="headerlink" title="创建相应的 SolrCloud 集合"></a>创建相应的 SolrCloud 集合</h2><p>用于 HBase 索引的 SolrCloud 集合必须具有可容纳 HBase 列系列的类型和要进行索引处理的限定符的 Solr 架构。若要开始，请考虑将包括一切 data 的字段添加到默认schema。一旦您决定采用一种schema，使用以下表单命令创建 SolrCloud 集合：</p>
<h3 id="user示例配置"><a href="#user示例配置" class="headerlink" title="user示例配置"></a>user示例配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 生成实体配置文件：</span></span><br><span class="line">solrctl instancedir --generate $HOME/hbase-indexer/User</span><br></pre></td></tr></table></figure>
<p>编辑schema，需包含以下内容<br><code>vim $HOME/hbase-indexer/User/conf/schema.xml</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 绑定rowkey--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"id"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> <span class="attr">required</span>=<span class="string">"true"</span> <span class="attr">multiValued</span>=<span class="string">"false"</span> /&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"psd"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"address"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"photo"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建 collection实例并将配置文件上传到 zookeeper：</span></span><br><span class="line">solrctl instancedir --create User  $HOME/hbase-indexer/User</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传到 zookeeper 之后，其他节点就可以从zookeeper下载配置文件。接下来创建 collection:</span></span><br><span class="line">solrctl collection --create User</span><br></pre></td></tr></table></figure>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>在schema.xml中uniqueKey必须为rowkey,而rowkey默认使用’id’字段表示，<field>中必须要有uniqueKey对应的id字段。</p>
<h2 id="创建-Lily-HBase-Indexer-配置"><a href="#创建-Lily-HBase-Indexer-配置" class="headerlink" title="创建 Lily HBase Indexer 配置"></a>创建 Lily HBase Indexer 配置</h2><p><a href="https://github.com/NGDATA/hbase-indexer/wiki/Indexer-configuration">Indexer-configuration官方参考</a><br>在HBase-Solr的安装目录/usr/lib/hbase-solr/下，创建morphline-hbase-mapper.xml文件，文件内容如下：   </p>
<p><code>$ vim  $HOME/hbase-indexer/morphline-hbase-mapper.xml</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- table：需要索引的HBase表名称--&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- mapper：用来实现和读取指定的Morphline配置文件类，固定为MorphlineResultToSolrMapper--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">indexer</span> <span class="attr">table</span>=<span class="string">"User"</span> <span class="attr">mapper</span>=<span class="string">"com.ngdata.hbaseindexer.morphline.MorphlineResultToSolrMapper"</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">   <span class="comment">&lt;!--param中的name参数用来指定当前配置为morphlineFile文件 --&gt;</span></span><br><span class="line">   <span class="comment">&lt;!--value用来指定morphlines.conf文件的路径，绝对或者相对路径用来指定本地路径，如果是使用Cloudera Manager来管理morphlines.conf就直接写入值morphlines.conf"--&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"morphlineFile"</span> <span class="attr">value</span>=<span class="string">"morphlines.conf"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">&lt;!-- The optional morphlineId identifies a morphline if there are multiple morphlines in morphlines.conf --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"morphlineId"</span> <span class="attr">value</span>=<span class="string">"userMap"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">indexer</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>注意：当使用绝对或者相对路径来指定路径时，集群中的其它机器也要在配置路径上有该文件，如果是通过Cloudera Manager管理的话只需要在CM中修改后即可，CM会自动分发给集群。当然该配置文件还有很多其它参数可以配置，<a href="https://github.com/NGDATA/hbase-indexer/wiki/Indexer-configuration#table">扩展阅读</a>。</p>
<h2 id="创建-Morphline-配置文件"><a href="#创建-Morphline-配置文件" class="headerlink" title="创建 Morphline 配置文件"></a>创建 Morphline 配置文件</h2><p>Morphlines是一款开源的，用来减少构建hadoop ETL数据流程时间的应用程序。它可以替代传统的通过MapReduce来抽取、转换、加载数据的过程，提供了一系列的命令工具，<br>具体可以参见：<a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。">http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。</a>  </p>
<p>对于HBase的其提供了extractHBaseCells命令来读取HBase的列数据。我们采用Cloudera Manager来管理morphlines.conf文件，使用CM来管理morphlines.  conf文件除了上面提到的好处之外，还有一个好处就是当我们需要增加索引列的时候，如果采用本地路径方式将需要重新注册Lily HBase Indexer的配置文件，而采用CM管理的话只需要修改morphlines.conf文件后重启Key-Value HBase Indexer服务即可。<br>具体操作为：进入Key-Value Store Indexer面板-&gt;配置-&gt;服务范围-&gt;Morphlines-&gt;Morphlines文件。在该选项加入如下配置：</p>
<p>注意：每个Collection对应一个morphline-hbase-mapper.xml    </p>
<p><img src="indexerConfig.png" alt="cdh lily hbase indexer config"></p>
<p><code>$ vim  /$HOME/morphlines.conf</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">SOLR_LOCATOR :</span> <span class="string">&#123;</span></span><br><span class="line">  <span class="comment"># Name of solr collection</span></span><br><span class="line">  <span class="attr">collection :</span> <span class="string">collection</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ZooKeeper ensemble</span></span><br><span class="line">  <span class="attr">zkHost :</span> <span class="string">"$ZK_HOST"</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">morphlines :</span> <span class="string">[</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="attr">id :</span> <span class="string">morphline</span></span><br><span class="line"><span class="attr">importCommands :</span> <span class="string">["org.kitesdk.**",</span> <span class="string">"com.ngdata.**"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="attr">commands :</span> <span class="string">[</span></span><br><span class="line">  <span class="string">&#123;</span></span><br><span class="line">    <span class="string">extractHBaseCells</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="attr">mappings :</span> <span class="string">[</span></span><br><span class="line">        <span class="string">&#123;</span></span><br><span class="line">          <span class="attr">inputColumn :</span> <span class="string">"data:name"</span></span><br><span class="line">          <span class="attr">outputField :</span> <span class="string">"data_name"</span></span><br><span class="line">          <span class="attr">type :</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">source :</span> <span class="string">value</span></span><br><span class="line">        <span class="string">&#125;,</span></span><br><span class="line">        <span class="string">&#123;</span></span><br><span class="line">          <span class="attr">inputColumn :</span> <span class="string">"data:psd"</span></span><br><span class="line">          <span class="attr">outputField :</span> <span class="string">"data_psd"</span></span><br><span class="line">          <span class="attr">type :</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">source :</span> <span class="string">value</span></span><br><span class="line">        <span class="string">&#125;,</span></span><br><span class="line">        <span class="string">&#123;</span></span><br><span class="line">          <span class="attr">inputColumn :</span> <span class="string">"data:address"</span></span><br><span class="line">          <span class="attr">outputField :</span> <span class="string">"data_address"</span></span><br><span class="line">          <span class="attr">type :</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">source :</span> <span class="string">value</span></span><br><span class="line">        <span class="string">&#125;,</span></span><br><span class="line">        <span class="string">&#123;</span></span><br><span class="line">          <span class="attr">inputColumn :</span> <span class="string">"data:photo"</span></span><br><span class="line">          <span class="attr">outputField :</span> <span class="string">"data_photo"</span></span><br><span class="line">          <span class="attr">type :</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">source :</span> <span class="string">value</span></span><br><span class="line">        <span class="string">&#125;</span></span><br><span class="line">      <span class="string">]</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&#123;</span> <span class="string">logDebug</span> <span class="string">&#123;</span> <span class="attr">format :</span> <span class="string">"output record: &#123;&#125;"</span><span class="string">,</span> <span class="attr">args :</span> <span class="string">["@&#123;&#125;"]</span> <span class="string">&#125;</span> <span class="string">&#125;</span></span><br><span class="line"><span class="string">]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">]</span></span><br></pre></td></tr></table></figure>
<h2 id="注册-Lily-HBase-Indexer-Configuration-和-Lily-HBase-Indexer-Service"><a href="#注册-Lily-HBase-Indexer-Configuration-和-Lily-HBase-Indexer-Service" class="headerlink" title="注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service"></a>注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service</h2><p>当 Lily HBase Indexer 配置 XML文件的内容令人满意，将它注册到 Lily HBase Indexer Service。上传 Lily HBase Indexer 配置 XML文件至 ZooKeeper，由给定的 SolrCloud 集合完成此操作。例如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase-indexer add-indexer \</span><br><span class="line">--name userIndexer \</span><br><span class="line">--indexer-conf $HOME/hbase-indexer/User/conf/morphline-hbase-mapper.xml \</span><br><span class="line">--connection-param solr.zk=server1:2181/solr \</span><br><span class="line">--connection-param solr.collection=User \</span><br><span class="line">--zookeeper server1:2181</span><br></pre></td></tr></table></figure>
<h2 id="验证索引器是否已成功创建"><a href="#验证索引器是否已成功创建" class="headerlink" title="验证索引器是否已成功创建"></a>验证索引器是否已成功创建</h2><p>执行<code>$ hbase-indexer list-indexers</code>验证索引器是否已成功创建</p>
<p>更多帮助，请使用以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase-indexer add-indexer --help</span><br><span class="line">hbase-indexer list-indexers --help</span><br><span class="line">hbase-indexer update-indexer --help</span><br><span class="line">hbase-indexer delete-indexer --help</span><br></pre></td></tr></table></figure>
<h2 id="测试是solr是否已新建索引"><a href="#测试是solr是否已新建索引" class="headerlink" title="测试是solr是否已新建索引"></a>测试是solr是否已新建索引</h2><p>写入数据时，在solr-webui控制台查看日志是否更新 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put 'User','row1','data','u1'</span><br><span class="line"></span><br><span class="line">put 'User','row1','data:name','u2'</span><br><span class="line"></span><br><span class="line">put 'User','row2','data:name','u2'</span><br><span class="line">put 'User','row2','data:psd','123'   </span><br><span class="line">put 'User','row2','data:address','address2'   </span><br><span class="line">put 'User','row2','data:photo','photo2'   </span><br><span class="line"></span><br><span class="line">put 'User','row2','data:name','u2'</span><br><span class="line">put 'User','row2','data:psd','123'   </span><br><span class="line">put 'User','row2','detail:address','address2'   </span><br><span class="line">put 'User','row2','detail:photo','photo2'  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">put 'User','row3','data:name','u2'</span><br><span class="line">put 'User','row3','data:psd','123'   </span><br><span class="line">put 'User','row3','detail:address','江苏省南京市'   </span><br><span class="line">put 'User','row3','detail:photo','phto3'</span><br></pre></td></tr></table></figure>
<p><img src="solr.png" alt="solr web ui查看最终结果"></p>
<p>折腾几天弄好，下一步是如何以构建好的索引Hbase实现多列条件的组合查询。  </p>
<h2 id="扩展命令"><a href="#扩展命令" class="headerlink" title="扩展命令"></a>扩展命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> solrctl</span></span><br><span class="line">solrctl instancedir --list </span><br><span class="line">solrctl collection --list </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更新coolection配置</span></span><br><span class="line">solrctl instancedir --update User $HOME/hbase-indexer/User</span><br><span class="line">solrctl collection --reload  User</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删除instancedir</span></span><br><span class="line">solrctl instancedir  --delete  User</span><br><span class="line"><span class="meta">#</span><span class="bash">删除collection</span></span><br><span class="line">solrctl collection --delete  User</span><br><span class="line"><span class="meta">#</span><span class="bash">删除collection所有doc</span></span><br><span class="line">solrctl collection --deletedocs User</span><br><span class="line"><span class="meta">#</span><span class="bash">删除User配置目录</span></span><br><span class="line">rm -rf $HOME/hbase-indexer/User</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> hbase-indexer</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 若修改了morphline-hbase-mapper.xml，需更新索引</span></span><br><span class="line">hbase-indexer update-indexer  -n userIndexer</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除索引</span></span><br><span class="line">hbase-indexer delete-indexer  -n userIndexer</span><br></pre></td></tr></table></figure>
<h1 id="所遇问题QA"><a href="#所遇问题QA" class="headerlink" title="所遇问题QA"></a>所遇问题QA</h1><h2 id="Lily-HBase-Indexer-Service注册错误"><a href="#Lily-HBase-Indexer-Service注册错误" class="headerlink" title="Lily HBase Indexer Service注册错误"></a>Lily HBase Indexer Service注册错误</h2><p>详细日志<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">[WARN ][<span class="number">08</span>:<span class="number">56</span>:<span class="number">49</span>,<span class="number">677</span>][.com:<span class="number">2181</span>)] org.apache.zookeeper.ClientCnxn - Session <span class="number">0x0</span> <span class="keyword">for</span> server <span class="keyword">null</span>, unexpected error, closing socket connection and attempting reconnect</span><br><span class="line">java.net.ConnectException: Connection refused</span><br><span class="line">     at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</span><br><span class="line">     at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:<span class="number">739</span>)</span><br><span class="line">     at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:<span class="number">350</span>)</span><br><span class="line">     at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:<span class="number">1081</span>)</span><br></pre></td></tr></table></figure><br>解决：将帮助文档原文中的-zookeeper hbase-cluster-zookeeper:2181中hbase-cluster-zookeeper换成zoomkeeper的主机名</p>
<h2 id="schema-xm和morphline-conf配置问题"><a href="#schema-xm和morphline-conf配置问题" class="headerlink" title="schema.xm和morphline.conf配置问题"></a>schema.xm和morphline.conf配置问题</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ERROR  org.apache.solr.common.SolrException: ERROR: [doc=row3] unknown field <span class="string">'data'</span></span><br><span class="line">trueat org.apache.solr.update.DocumentBuilder.toDocument(DocumentBuilder.java:<span class="number">185</span>)</span><br></pre></td></tr></table></figure>
<p>解决方式：<br>Thanks for the response. In the meantime I got a solution which is fine for me using: <dynamicField name="*" type="string" indexed="true" stored="true" /> But type=”ignored” is a good hint once I want to get rid of the fields I do not need, thanks. –</p>
<p>schema新增配置：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dynamicField</span> <span class="attr">name</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"data"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> <span class="attr">multiValued</span>=<span class="string">"true"</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改schema.xml后，执行以下命令更新配置：<br>solrctl instancedir —update hbase-collection-user   $HOME/hbase-collection-user<br>solrctl collection  —reload  hbase-collection-user </p>
<p>修改Collection<br>当我们创建Collection完成后，如果需要修改schema.xml文件重新配置需要索引的字段可以按如下操作：  </p>
<ul>
<li>如果是修改原有schema.xml中字段值，而在solr中已经插入了索引数据，那么我们需要清空索引数据集，清空数据集可以通过solr API来完成。  </li>
<li>如果是在原有schema.xml中加入新的索引字段，那么可以跳过1，直接执行：  </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">solrctl instancedir --update solrtest $HOME/solrtest   </span><br><span class="line">solrctl collection --reload solrtest</span><br></pre></td></tr></table></figure>
<h2 id="多个HbaseTable配置schema-xml和morphline-conf"><a href="#多个HbaseTable配置schema-xml和morphline-conf" class="headerlink" title="多个HbaseTable配置schema.xml和morphline.conf"></a>多个HbaseTable配置schema.xml和morphline.conf</h2><p>解决方式：<br><a href="https://github.com/jshmain/cloudera-search/blob/master/email-search/email-schema.xml">email-schema示例</a></p>
<p>Q：morphline.conf和morphline-hbase-mapper.xml文件是否每个HbaseTable都要对应配置一个?<br>A：每一个Hbase Table对应生成一个Solr的Collection索引，每个索引对应一个Lily HBase Indexer 配置文件morphlines.conf和morphline配置文件morphline-hbase-mapper.xml，其中morphlines.conf可由CDH的Key-Value Store Indexer控制台管理，以id区分</p>
<p>官方说明：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Creating a Lily HBase Indexer configuration  </span><br><span class="line">Individual Lily HBase Indexers are configured using the hbase-indexer command line utility.   </span><br><span class="line">Typically, there is one Lily HBase Indexer configuration for each HBase table,   </span><br><span class="line">but there can be as many Lily HBase Indexer configurations as there are tables and column families and corresponding collections in the SolrCloud.   </span><br><span class="line">Each Lily HBase Indexer configuration is defined in an XML file such as morphline-hbase-mapper.xml.</span><br></pre></td></tr></table></figure></p>
<h2 id="对HBaseTable已有数据新建索引"><a href="#对HBaseTable已有数据新建索引" class="headerlink" title="对HBaseTable已有数据新建索引"></a>对HBaseTable已有数据新建索引</h2><p>需要用到Lily HBase Indexer的批处理索引功能了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo hadoop --config /etc/hadoop/conf \</span><br><span class="line">jar /usr/lib/hbase-solr/tools/hbase-indexer-mr-1.5-cdh5.4.4-job.jar \</span><br><span class="line">--conf /etc/hbase/conf/hbase-site.xml \</span><br><span class="line">-D 'mapred.child.java.opts=-Xmx500m' \</span><br><span class="line">--hbase-indexer-zk master:2181 \</span><br><span class="line">--collection hbase-collection-user \</span><br><span class="line">--hbase-indexer-name userIndexer \</span><br><span class="line">--hbase-indexer-file $HOME/hbase-collection-user/conf/morphline-hbase-mapper.xml \</span><br><span class="line">--go-live \</span><br><span class="line">``` </span><br><span class="line">错误日志  </span><br><span class="line"></span><br><span class="line">``` java</span><br><span class="line">Caused by: java.io.IOException Can not find resource  solrconfig.xml in classpath </span><br><span class="line">or  /root/file:/tmp/hadoop-root/mapred/local/1441858645500/6a1a458e-35e2-4f66-82df-02795ba44e2c.solr.zip/collection1/conf</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CDH</tag>
        <tag>Hadoop</tag>
        <tag>Hbase</tag>
        <tag>Solr</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH使用问题记录</title>
    <url>/2015/10/27/CDH%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="如何制作CDH-Agent-虚拟机模板"><a href="#如何制作CDH-Agent-虚拟机模板" class="headerlink" title="如何制作CDH Agent 虚拟机模板"></a>如何制作CDH Agent 虚拟机模板</h1><ul>
<li>问题描述：CDH Manager安装配置好一台Agent机器A（VM虚拟机）后，如果以A复制出B，在集群中B与A会冲突，每次Host Inspector只能检测到一个</li>
<li>问题定位：判断为SCM库中HOSTS表的HOST_IDENTIFIER字段冲突导致</li>
<li>解决思路：ClouderaManager是根据什么自动生成HOST_IDENTIFIER的？ 如何复制VM虚拟机才能不冲突？</li>
<li>问题解决：由于在复制cm-5.4.7到agent之前启动了cloudera-scm-agent，在/opt/cm-5.4.7/lib/cloudera-scm-agent中生成response.avro和uuid两个文件，cloudera的HOST_IDENTIFIER读取的就是uuid文件的文本，停止agent&gt;删除response.avro和uuid&gt;启动agent，问题解决</li>
</ul>
<h1 id="Cloudera-Manager无法删除某项服务"><a href="#Cloudera-Manager无法删除某项服务" class="headerlink" title="Cloudera Manager无法删除某项服务"></a>Cloudera Manager无法删除某项服务</h1><p>删除依赖关系或在命令中查看正在执行的（卡死）的命令，中止即可</p>
<h1 id="Key-Value-Store-Indexer服务总是异常终止"><a href="#Key-Value-Store-Indexer服务总是异常终止" class="headerlink" title="Key-Value Store Indexer服务总是异常终止"></a>Key-Value Store Indexer服务总是异常终止</h1><ul>
<li>问题描述：重新构建的Solr Collection和Index，数据写入少量没问题，程序批量写入时（&gt;250条）服务就自动终止   </li>
<li>问题定位：Java OOM虚拟机内存溢出问题</li>
<li>解决方式：hbase-indexer github-issues：<a href="https://github.com/NGDATA/hbase-indexer/issues/66">Lily Hbase Indexers always auto exit</a>，<br>通过向hbase-indexer官方github提交issue寻求帮助，确认是OOM问题！<ul>
<li>运行<code>hbase-indexer server</code>在单个hbase-server服务器调试运行（不在cloudera管理下运行），不会发生OOM</li>
<li>CM集中修改参数<em>Lily HBase Indexer的Java堆栈大小</em>，默认设置的是131M，改为1GB后重新启动服务，往Hbase写入数据时，SOlr索引生成正常，Hbase-Indexer未自动退出。</li>
</ul>
</li>
</ul>
<p>其他参考资料：<a href="https://github.com/NGDATA/hbase-indexer/blob/master/hbase-indexer-morphlines/src/main/java/com/ngdata/hbaseindexer/morphline/LocalMorphlineResultToSolrMapper.java">LocalMorphlineResultToSolrMapper源码</a></p>
<h1 id="创建-Hive-Metastore-数据库表失败"><a href="#创建-Hive-Metastore-数据库表失败" class="headerlink" title="创建 Hive Metastore 数据库表失败"></a>创建 Hive Metastore 数据库表失败</h1><p>问题日志：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">++ exec /opt/cloudera/parcels/CDH-<span class="number">5.4</span><span class="number">.7</span>-<span class="number">1</span>.cdh5<span class="number">.4</span><span class="number">.7</span>.p0<span class="number">.3</span>/lib/hadoop/bin/hadoop jar /opt/cloudera/parcels/CDH-<span class="number">5.4</span><span class="number">.7</span>-<span class="number">1</span>.cdh5<span class="number">.4</span><span class="number">.7</span>.p0<span class="number">.3</span>/lib/hive/lib/hive-cli-<span class="number">1.1</span><span class="number">.0</span>-cdh5<span class="number">.4</span><span class="number">.7</span>.jar org.apache.hive.beeline.HiveSchemaTool -verbose -dbType mysql -initSchema</span><br><span class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driver</span><br><span class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driver</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:<span class="number">79</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaTool.getConnectionToMetastore(HiveSchemaTool.java:<span class="number">113</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaTool.testConnectionToMetastore(HiveSchemaTool.java:<span class="number">159</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaTool.doInit(HiveSchemaTool.java:<span class="number">257</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaTool.doInit(HiveSchemaTool.java:<span class="number">243</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:<span class="number">473</span>)</span><br><span class="line">trueat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">trueat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line">trueat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">trueat java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line">trueat org.apache.hadoop.util.RunJar.run(RunJar.java:<span class="number">221</span>)</span><br><span class="line">trueat org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">136</span>)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver</span><br><span class="line">trueat java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">366</span>)</span><br><span class="line">trueat java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">trueat java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">trueat java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">trueat java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">trueat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">trueat java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">trueat java.lang.Class.forName0(Native Method)</span><br><span class="line">trueat java.lang.Class.forName(Class.java:<span class="number">195</span>)</span><br><span class="line">trueat org.apache.hive.beeline.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:<span class="number">70</span>)</span><br><span class="line">true... <span class="number">11</span> more</span><br><span class="line">true*** schemaTool failed ***</span><br></pre></td></tr></table></figure>
<h1 id="CDH5使用端口"><a href="#CDH5使用端口" class="headerlink" title="CDH5使用端口"></a>CDH5使用端口</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cdh_ig_ports_cdh5.html"> CDH 5 组件使用的端口</a></p>
<h1 id="Hbase运行中止问题"><a href="#Hbase运行中止问题" class="headerlink" title="Hbase运行中止问题"></a>Hbase运行中止问题</h1><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//cat /var/log/hbase/hbase-cmf-hbase-REGIONSERVER-slave3.lt.com.log.out</span></span><br><span class="line"></span><br><span class="line">Error syncing, request close of wal</span><br><span class="line">java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: <span class="string">"slave3.lt.com/192.168.1.103"</span>; destination host is: <span class="string">"server1.lt.com"</span>:<span class="number">8020</span>;  </span><br><span class="line">trueat com.sun.proxy.$Proxy20.updateBlockForPipeline(Unknown Source)</span><br><span class="line">Caused by: java.io.IOException: Connection reset by peer</span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Unable</span> <span class="string">to</span> <span class="string">reconnect</span> <span class="string">to</span> <span class="string">ZooKeeper</span> <span class="string">service,</span> <span class="string">session</span> <span class="number">0x1508e4d86eb8047</span> <span class="string">has</span> <span class="string">expired,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Client</span> <span class="string">session</span> <span class="string">timed</span> <span class="string">out,</span> <span class="string">have</span> <span class="string">not</span> <span class="string">heard</span> <span class="string">from</span> <span class="string">server</span> <span class="string">in</span> <span class="string">40003ms</span> <span class="string">for</span> <span class="string">sessionid</span> <span class="number">0x1508e4d86eb88ef</span><span class="string">,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span> <span class="string">and</span> <span class="string">attempting</span> <span class="string">reconnect</span></span><br><span class="line"></span><br><span class="line"><span class="string">Unable</span> <span class="string">to</span> <span class="string">reconnect</span> <span class="string">to</span> <span class="string">ZooKeeper</span> <span class="string">service,</span> <span class="string">session</span> <span class="number">0x1508e4d86eb88f5</span> <span class="string">has</span> <span class="string">expired,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Opening</span> <span class="string">socket</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">server</span> <span class="string">server1.lt.com/192.168.1.91:2181.</span> <span class="string">Will</span> <span class="string">not</span> <span class="string">attempt</span> <span class="string">to</span> <span class="string">authenticate</span> <span class="string">using</span> <span class="string">SASL</span> <span class="string">(unknown</span> <span class="string">error)</span></span><br></pre></td></tr></table></figure>
<ul>
<li>参数说明<br>hbase参数</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">hbase.regionserver.lease.period</span></span><br><span class="line"><span class="string">默认值：60000</span></span><br><span class="line"><span class="string">说明：客户端租用HRegion</span> <span class="string">server</span> <span class="string">期限，即超时阀值。</span></span><br><span class="line"><span class="string">调优：这个配合hbase.client.scanner.caching使用，如果内存够大，但是取出较多数据后计算过程较长，可能超过这个阈值，适当可设置较长的响应时间以防被认为宕机</span></span><br></pre></td></tr></table></figure>
<p>zookeeper参数<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">zookeeper.session.timeout</span></span><br><span class="line"><span class="string">默认值：60000</span></span><br><span class="line"><span class="string">说明：ZooKeeper</span> <span class="string">服务器允许客户端协商的最大会话超时时间（以毫秒为单位）</span></span><br><span class="line"><span class="string">调优：zookeeper的超时时间不要设置太大，在服务挂掉的情况下，会反映很慢。</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>解决方式<br>在CM的Hbase配置hbase.regionserver.lease.period默认值改为4（分钟）<br>在CM的Hbase配置hbase.rpc.timeout默认值改为5（分钟）</li>
</ul>
<h1 id="Hbase数据操作失败"><a href="#Hbase数据操作失败" class="headerlink" title="Hbase数据操作失败"></a>Hbase数据操作失败</h1><p>问题描述：connection to slave3.lt.com/192.168.1.103:60020 from geosmart: closing ipc connection to slave3.lt.com/192.168.1.103:60020: Connection refused: no further information<br>java.net.ConnectException: Connection refused: no further information</p>
<h1 id="Hive-UDTF问题"><a href="#Hive-UDTF问题" class="headerlink" title="Hive UDTF问题"></a>Hive UDTF问题</h1><p>问题日志：Error while compliling statement:Failed IndexOutOfBoundException Index.1 Size.1<br>解决方案：<br>init初始化中的ArrayList<ObjectInspector> 和fieldNames个数和类型要对应一致</p>
<h1 id="Hive-UDTF-code-2问题"><a href="#Hive-UDTF-code-2问题" class="headerlink" title="Hive UDTF code 2问题"></a>Hive UDTF code 2问题</h1><p>问题日志：Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask<br>解决方案：/var/log/hive中查看错误日志定位错误</p>
<h1 id="HUE新建HDFS目录"><a href="#HUE新建HDFS目录" class="headerlink" title="HUE新建HDFS目录"></a>HUE新建HDFS目录</h1><p>问题描述: you are a Hue admin but not a HDFS superuser, “hdfs” or part of HDFS supergroup, “supergroup”<br>解决方案：在hue中新增hdfs用户，以hdfs用户登录创建目录和上传文件</p>
<h1 id="Hive-Metastore-canary-创建数据库失败"><a href="#Hive-Metastore-canary-创建数据库失败" class="headerlink" title="Hive Metastore canary 创建数据库失败"></a>Hive Metastore canary 创建数据库失败</h1><p>问题描述： Hive Metastore canary 创建数据库失败<br>日志：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">Caused by: org.datanucleus.exceptions.NucleusException:</span> <span class="string">Attempt</span> <span class="string">to</span> <span class="string">invoke</span> <span class="string">the</span> <span class="string">"BONECP"</span> <span class="attr">plugin to create a ConnectionPool gave an error :</span></span><br><span class="line"><span class="string">The</span> <span class="string">specified</span> <span class="string">datastore</span> <span class="string">driver</span> <span class="string">("com.mysql.jdbc.Driver")</span> <span class="string">was</span> <span class="string">not</span> <span class="string">found</span> <span class="string">in</span> <span class="string">the</span> <span class="string">CLASSPATH.</span> <span class="string">Please</span> <span class="string">check</span> <span class="string">your</span> <span class="string">CLASSPATH</span> <span class="string">specification,</span> <span class="string">and</span> <span class="string">the</span> <span class="string">name</span> <span class="string">of</span> <span class="string">the</span> <span class="string">driver</span></span><br></pre></td></tr></table></figure>
<p>问题定位：读取hive数据时报找不到mysql驱动<br>问题解决：</p>
<pre><code>*    尝试1
</code></pre><p><code>/opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hive/lib</code><br><code>cp  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib/mysql-connector-java-5.1.36-bin.jar   /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hive/lib</code></p>
<pre><code>*  尝试2
</code></pre><p>在<code>/etc/hive/conf.cloudera.hive/hive-env.sh</code>中发现一句<code>$(find /usr/share/java/mysql-connector-java.jar</code><br>于是将驱动拷贝到指定目录解决问题<br><code>cp  /mnt/mysql-connector-java-5.1.36-bin.jar     /usr/share/java/mysql-connector-java.jar</code><br><code>cp  /mnt/mysql-connector-java-5.1.36-bin.jar    /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hadoop</code><br>解决问题</p>
<p>2）hive数据库初始化问题<br>问题日志：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Query</span> <span class="string">for</span> <span class="string">candidates</span> <span class="string">of</span> <span class="string">org.apache.hadoop.hive.metastore.model.MVersionTable</span> <span class="string">and</span> <span class="string">subclasses</span> <span class="string">resulted</span> <span class="string">in</span> <span class="literal">no</span> <span class="string">possible</span> <span class="string">candidates</span></span><br><span class="line"><span class="attr">Required table missing :</span> <span class="string">"`VERSION`"</span> <span class="string">in</span> <span class="string">Catalog</span> <span class="string">""</span> <span class="string">Schema</span> <span class="string">""</span><span class="string">.</span> <span class="string">DataNucleus</span> <span class="string">requires</span> <span class="string">this</span> <span class="string">table</span> <span class="string">to</span> <span class="string">perform</span> <span class="string">its</span> <span class="string">persistence</span> <span class="string">operations.</span> <span class="string">Either</span> <span class="string">your</span> <span class="string">MetaData</span> <span class="string">is</span> <span class="string">incorrect,</span> <span class="string">or</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">enable</span> <span class="string">"datanucleus.autoCreateTables"</span></span><br><span class="line"><span class="attr">org.datanucleus.store.rdbms.exceptions.MissingTableException: Required table missing :</span> <span class="string">"`VERSION`"</span> <span class="string">in</span> <span class="string">Catalog</span> <span class="string">""</span> <span class="string">Schema</span> <span class="string">""</span><span class="string">.</span> <span class="string">DataNucleus</span> <span class="string">requires</span> <span class="string">this</span> <span class="string">table</span> <span class="string">to</span> <span class="string">perform</span> <span class="string">its</span> <span class="string">persistence</span> <span class="string">operations.</span> <span class="string">Either</span> <span class="string">your</span> <span class="string">MetaData</span> <span class="string">is</span> <span class="string">incorrect,</span> <span class="string">or</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">enable</span> <span class="string">"datanucleus.autoCreateTables"</span></span><br><span class="line">    <span class="string">at</span> <span class="string">org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:485)</span></span><br></pre></td></tr></table></figure>
<p><a href="http://community.cloudera.com/t5/Batch-SQL-Apache-Hive/Reinstalling-Hive-Metastore-Database/td-p/24015">解决参考:Reinstalling-Hive-Metastore-Database</a></p>
<h2 id="在cm中删除oozie、hue和hive服务，重建数据库"><a href="#在cm中删除oozie、hue和hive服务，重建数据库" class="headerlink" title="在cm中删除oozie、hue和hive服务，重建数据库"></a>在cm中删除oozie、hue和hive服务，重建数据库</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql -uroot -proot</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> hive;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> hue;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> oozie;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;  </span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hue <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br></pre></td></tr></table></figure>
<h2 id="重新添加hive服务"><a href="#重新添加hive服务" class="headerlink" title="重新添加hive服务"></a>重新添加hive服务</h2><p>配置数据库192.168.1.1(server)/hive(db)/root(user)/root(psd)</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CDH</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB3离线部署</title>
    <url>/2015/12/28/MongoDB3%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>基于Ops Manager的MongoDB 3.2集群离线部署笔记</p>
<hr>
<a id="more"></a>
<h1 id="MongoDB3带来的改变"><a href="#MongoDB3带来的改变" class="headerlink" title="MongoDB3带来的改变"></a>MongoDB3带来的改变</h1><p>MongoDB 3.0新版重点主要在效能的提升以及可扩展性，这些改变来自于储存层（Storage Layer）的强化，<br>MongoDB 2.8版本开始引入支持Latch-free、Non-blocking算法的WiredTiger储存引擎，因此可以开始使用新硬件才有的功能，比如大量的高速缓存（On-chip Cache）和多执行架构。<br>MongoDB 3.0 还提供了企业Ops Manager管理工具，用来管理大规模的 MongoDB 架构。</p>
<h2 id="个人测试"><a href="#个人测试" class="headerlink" title="个人测试"></a>个人测试</h2><ol>
<li>数据恢复（mongorestore）支持并行导入了，性能有所提升；</li>
<li>数据存储变成了*.wt后缀的，待确认具体更新；</li>
</ol>
<p>MongoDB的管理服务（MMS）是用于监控和备份MongoDB的基础设施服务。其中监控的服务是免费的，备份的服务是需要收费的。</p>
<h1 id="Ops-Manager"><a href="#Ops-Manager" class="headerlink" title="Ops Manager"></a>Ops Manager</h1><p><code>The Best Way to Run MongoDB: Ops Manager</code><br><a href="https://www.mongodb.com/products/ops-manager">Ops Manager官网</a></p>
<p>Ops Manager能做什么？</p>
<blockquote>
<p>Deployment. Any topology, at any scale<br>Management. Deploy new clusters. Manage, monitor, and back up existing ones<br>Upgrades. In minutes, with no downtime<br>Scaling. Add capacity, without taking the application offline<br>Point-in-time, Scheduled Backups. Restore to any point in time, because disasters aren’t predictable<br>Performance Alerts. Monitor 100+ system metrics and get custom alerts before the system degrades<br>Add Query Optimization. Identify slow-running queries, get index suggestions, automate index builds</p>
</blockquote>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><h2 id="服务器准备"><a href="#服务器准备" class="headerlink" title="服务器准备"></a>服务器准备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#mms应用服务器</span></span><br><span class="line">192.168.1.80</span><br><span class="line"></span><br><span class="line"><span class="comment">#mms监控数据服务器，Monitor Agent部署</span></span><br><span class="line">192.168.1.51</span><br><span class="line"></span><br><span class="line">192.168.1.52：shard</span><br><span class="line">192.168.1.54：config server</span><br><span class="line">192.168.1.58：mongos</span><br></pre></td></tr></table></figure>
<h2 id="域名解析配置"><a href="#域名解析配置" class="headerlink" title="域名解析配置"></a>域名解析配置</h2><h3 id="HostName配置-FQDN配置"><a href="#HostName配置-FQDN配置" class="headerlink" title="HostName配置/FQDN配置"></a>HostName配置/FQDN配置</h3><p>FQDN是Fully Qualified Domain Name的缩写, 含义是完整的域名. 例如, 一台机器主机名(hostname)是www, 域后缀(domain)是example.com, 那么该主机的FQDN应该是www.example.com.<br>注意：hosts配置不当，后面server和agent间通讯会存在问题，参考host配置如下：</p>
<ul>
<li>server/agent配置(master)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/hosts</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># localhost</span></span><br><span class="line">127.0.0.1 localhost.localdomain localhost</span><br><span class="line"></span><br><span class="line"><span class="comment">#mongodb ops manager server</span></span><br><span class="line">192.168.1.80   opsserver.lt.com opsserver</span><br><span class="line"></span><br><span class="line"><span class="comment">#mongodb ops monitor agent</span></span><br><span class="line">192.168.1.51   opsagent1.lt.com opsagent1</span><br><span class="line">192.168.1.52   opsagent2.lt.com opsagent2</span><br><span class="line">192.168.1.53   opsagent3.lt.com opsagent3</span><br><span class="line">192.168.1.54   opsagent4.lt.com opsagent4</span><br><span class="line">192.168.1.58   opsagent8.lt.com opsagent8</span><br></pre></td></tr></table></figure>
<h3 id="network配置"><a href="#network配置" class="headerlink" title="network配置"></a>network配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/sysconfig/network</span></span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=opsserver</span><br><span class="line">NTPSERVERARGS=iburst</span><br></pre></td></tr></table></figure>
<h2 id="安装Ops-Manager-Application-Database"><a href="#安装Ops-Manager-Application-Database" class="headerlink" title="安装Ops Manager Application Database"></a>安装Ops Manager Application Database</h2><p>可选：Backup Database</p>
<p>设置最大文件打开数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /etc/rc.local</span></span><br><span class="line"><span class="built_in">ulimit</span> -n 65536</span><br></pre></td></tr></table></figure></p>
<h2 id="安装Ops-Manager集群监控"><a href="#安装Ops-Manager集群监控" class="headerlink" title="　安装Ops Manager集群监控"></a>　安装Ops Manager集群监控</h2><h3 id="关于Ops-Manager"><a href="#关于Ops-Manager" class="headerlink" title="关于Ops Manager"></a>关于Ops Manager</h3><p><a href="https://www.mongodb.com/presentations/webinar-introducing-ops-manager">视频教程</a><br><a href="http://www.slideshare.net/mongodb/ops-manager-webinar-mar-5-2015">视频教程</a></p>
<p><a href="https://docs.opsmanager.mongodb.com/master/application/">介绍文档</a><br>MongoDB Ops Manager is a service for managing, monitoring and backing up a MongoDB infrastructure. Ops Manager provides the services described here.<br><img src="https://docs.opsmanager.mongodb.com/master/_images/opsmanager-network-diagram-fullsize.png" alt="组成部分"></p>
<p><img src="https://docs.opsmanager.mongodb.com/master/_images/opsmanager-large.png" alt="Production Install with a Highly Available Ops Manager Application and Multiple Backup Databases¶"></p>
<p>备注：目前Ops Manager只能完成从无到有的集群部署，sharding集群的shard key等配置需在xshell中手动配置</p>
<h3 id="centos6安装Ops-Manager"><a href="#centos6安装Ops-Manager" class="headerlink" title="centos6安装Ops Manager"></a>centos6安装Ops Manager</h3><p><a href="https://docs.opsmanager.mongodb.com/current/tutorial/install-on-prem-with-rpm-packages/">RPM安装参考教程</a><br><a href="http://www.ttlsa.com/mms/follow-me-to-use-mongodb-mms-services/">中文配置教程</a></p>
<ol>
<li>配置ops manager application data数据服务器（192.168.1.51），安装mongodb并启动服务<br>从其他机器复制mongodb：<code>scp -r root@192.168.1.52:/usr/local/mongodb /usr/local</code></li>
<li>安装ops manager server<ul>
<li>复制到<code>mongodb-mms-2.0.0.327-1.x86_64.rpm</code>到<code>/mnt</code></li>
<li>执行<code>sudo rpm -ivh  /mnt/mongodb-mms-2.0.0.327-1.x86_64.rpm</code>，mms将默认安装到<code>/opt/mongodb/mms/</code></li>
<li>配置/opt/mongodb/mms/conf/conf-mms.properties,设置mongo.mongoUri等参数</li>
<li>启动服务<code>sudo service mongodb-mms start</code></li>
<li>设置mongodb-mms为开机自启动：chkconfig  mongodb-mms  on</li>
<li>登录http://<host>:8080/注册用户</li>
</ul>
</li>
<li>agent节点分别配置安装automation agent  </li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以下具体参数参考http://192.168.1.80:8080/settings/agents/中的Automation选项卡的操作步骤</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Download the agent</span></span><br><span class="line">curl -OL http://192.168.1.80:8080/download/agent/automation/mongodb-mms-automation-agent-manager-2.5.11.1484-1.x86_64.rpm</span><br><span class="line"><span class="comment">#and install the package.</span></span><br><span class="line">sudo rpm -U mongodb-mms-automation-agent-manager-2.5.11.1484-1.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#Open the config file</span></span><br><span class="line">sudo vi /etc/mongodb-mms/automation-agent.config</span><br><span class="line"><span class="comment">#配置唯一 API key, Group ID, and Ops Manager Base URL</span></span><br><span class="line">mmsGroupId=568486a424ac2c591d35e00c</span><br><span class="line">mmsApiKey=e4db7d0b6757a704271d04e25748ac41</span><br><span class="line">mmsBaseUrl=http://192.168.1.80:8080</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prepare a directory in which to store your MongoDB data. This directory must be owned by the mongod user. Any directory is fine, but the default is /data. This directory can be created with a command similar to below.</span></span><br><span class="line">sudo mkdir /data</span><br><span class="line">sudo chown mongod:mongod /data</span><br><span class="line"></span><br><span class="line"><span class="comment">#Start the agent.</span></span><br><span class="line">sudo service mongodb-mms-automation-agent start</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置mongodb-mms-automation-agent为开机自启动</span></span><br><span class="line">chkconfig  mongodb-mms-automation-agent on</span><br></pre></td></tr></table></figure>
<p>其他shard节点可从monitor节点复制automation-agent配置文件：<code>scp root@192.168.1.51:/etc/mongodb-mms/automation-agent.config /etc/mongodb-mms/automation-agent.config</code><br>重启automation-agent服务：<code>sudo service mongodb-mms-automation-agent restart</code></p>
<ol>
<li>在web控制台Deployment中选1台性能较好的服务器配置monitoring agent（如在ops manager application data数据服务器）</li>
<li>zai Deployment模块Add New Cluster,配置mongos,config server和shards</li>
<li>集群测试<br>服务器主机名regex过滤:(opsagent2|opsagent4|opsagent8)<br>集群服务器配置:mongos:1/mongod:3/config server:1<br>端口配置，shards(27000-28000),mongos(27017)config server(27019)<br>分片数配置<br>配置完成确认执行后，ops会按顺序自动安装部署shard&gt;config server&gt;mongos，再也不用kb手动去安装了！<br>mongodb安装的默认位置：/var/lib/mongodb-mms-automation</li>
</ol>
<h3 id="windows-server安装Ops-Manager"><a href="#windows-server安装Ops-Manager" class="headerlink" title="windows server安装Ops Manager"></a>windows server安装Ops Manager</h3><p><a href="https://docs.opsmanager.mongodb.com/current/tutorial/install-on-prem-windows/">参考教程</a></p>
<ol>
<li>安装mongodb</li>
<li>安装Install Ops Manager</li>
<li>配置<code>C:\MMSData\Server\Config\conf-mms.properties</code>（默认路径）中的<code>mongo.mongoUri</code>等连接配置属性</li>
<li>在windows服务列表启动服务<code>MongoDB Ops Manager HTTP Service</code></li>
<li>登录http://<host>:8080/注册用户，admin/1qaz@WSX</li>
</ol>
<h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><ol>
<li>No MongoDB versions have been made available for use in your deployment. Visit the Version Manager to enable MongoDB versions.<br>重新配置，将version manager参数设置为internet而非local</li>
<li>There are a mix of Agents that are installed manually and managed by your Automation Agents. This configuration is not supported.<br>You will not be able to add new hosts to monitoring or create new automated hosts while in this state. The Agents that should be removed are indicated on the table above.<br>After stopping an Agent it can take up to 5 minutes to take effect.</li>
<li>添加集群报错： Unable to create member 2 of myShard_0. Unable to find enough servers. Requested port range was 27000 to 27000. Excluding port ranges 27019 to 27019, 27017 to 27017. Please ensure all agents are running.<br>shard server port设置在27000-28000范围内，不能设置为27000</li>
<li>mongos服务无法启动<br>错误日志：<code>not master or secondary; cannot currently read from this replSet member ns,config.settings query,config.shards query</code><br>解决方案：pkill mongod 强制关闭mongo进程，删除/data目录内的shard数据(不能删automation的数据)，重新添加集群</li>
<li>shard集群分片测试，目前数据量小，数据存储表现为replica set，待测试分片效果！</li>
</ol>
<h1 id="MongoDB离线部署配置"><a href="#MongoDB离线部署配置" class="headerlink" title="MongoDB离线部署配置"></a>MongoDB离线部署配置</h1><p><a href="https://docs.opsmanager.mongodb.com/v2.0/tutorial/configure-local-mode/">Configure Local Mode if Servers Have No Internet Access</a></p>
<h2 id="设置为Local"><a href="#设置为Local" class="headerlink" title="设置为Local"></a>设置为Local</h2><p>在Ops Manager控制台，单击右上角Admin，General&gt;Ops Manager Config&gt; Miscellaneous&gt;设置Version Manifest Source 为Local<br>设置 Versions Directory存储MongoDB binaries，默认<code>/opt/mongodb/mms/mongodb-releases</code></p>
<h2 id="下载MongoDB离线Binaries"><a href="#下载MongoDB离线Binaries" class="headerlink" title="下载MongoDB离线Binaries"></a>下载MongoDB离线Binaries</h2><p>cd /opt/mongodb/mms/mongodb-releases<br>curl -OL <a href="http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.0.tgz">http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.0.tgz</a></p>
<h2 id="设置Versions-Directory目录权限"><a href="#设置Versions-Directory目录权限" class="headerlink" title="设置Versions Directory目录权限"></a>设置Versions Directory目录权限</h2><ol>
<li>查看目录权限：<code>ls -l /opt/mongodb/mms/mongodb-releases</code></li>
<li>设置mongodb-mms用户对Versions Directory中文件有读写权限：<code>sudo chown -R  mongodb-mms:mongodb-mms /opt/mongodb/mms/mongodb-releases</code></li>
</ol>
<h2 id="编辑conf-mms-properties"><a href="#编辑conf-mms-properties" class="headerlink" title="编辑conf-mms.properties"></a>编辑conf-mms.properties</h2><p>在conf-mms.propertie最后新增两行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /opt/mongodb/mms/conf/conf-mms.properties</span></span><br><span class="line">automation.versions.source=<span class="built_in">local</span></span><br><span class="line">automation.versions.directory=/opt/mongodb/mms/mongodb-releases/</span><br></pre></td></tr></table></figure></p>
<h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><p><code>sudo service mongodb-mms restart</code></p>
<h2 id="部署截图"><a href="#部署截图" class="headerlink" title="部署截图"></a>部署截图</h2><p><img src="01_deployment.png" alt="deployment"><br><img src="02_statis_chart.png" alt="statis_chart"><br><img src="03_statis_table.png" alt="statis_table"></p>
<h2 id="Version-Manager配置MongoDB版本"><a href="#Version-Manager配置MongoDB版本" class="headerlink" title="Version Manager配置MongoDB版本"></a>Version Manager配置MongoDB版本</h2><p>在Ops Manager控制台，Deployment&gt;Version Manager&gt;选择离线的mongodb版本&gt;Review &amp; Deploy&gt;Confirm &amp; Deploy.</p>
<h1 id="MongoDB-数据备份与恢复"><a href="#MongoDB-数据备份与恢复" class="headerlink" title="MongoDB 数据备份与恢复"></a>MongoDB 数据备份与恢复</h1><p><a href="https://docs.mongodb.org/manual/tutorial/backup-small-sharded-cluster-with-mongodump/">backup-small-sharded-cluster-with-mongodump</a><br>在mongodb primary节点执行mongorestore<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin</span><br><span class="line">mongorestore -drop  -d uadb  /mnt/dump/dump/uadb_dump/uadb</span><br><span class="line">mongorestore -drop  -d uadb_attachment  /mnt/dump/dump/uadb_attachment_dump/uadb_attachment</span><br></pre></td></tr></table></figure></p>
<h1 id="Route-Server配置chunk-size"><a href="#Route-Server配置chunk-size" class="headerlink" title="Route Server配置chunk size"></a>Route Server配置chunk size</h1><p><a href="https://docs.mongodb.org/manual/tutorial/modify-chunk-size-in-sharded-cluster/">参考文档：modify-chunk-size-in-sharded-cluster</a></p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>Automatic splitting only occurs on insert or update.</li>
<li>If you lower the chunk size, it may take time for all chunks to split to the new size.</li>
<li>Splits cannot be undone.</li>
<li>If you increase the chunk size, existing chunks grow only through insertion or updates until they reach the new size.</li>
<li>The allowed range of the chunk size is between 1 and 1024 megabytes, inclusive.</li>
</ol>
<h2 id="修改步骤"><a href="#修改步骤" class="headerlink" title="修改步骤"></a>修改步骤</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#连接Route Server(mongos shell)</span></span><br><span class="line"><span class="string">/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo</span> <span class="string">opsagent2.lt.com:27017</span>  </span><br><span class="line"> <span class="comment">#切换到config数据库</span></span><br><span class="line"> <span class="string">use</span> <span class="string">config</span></span><br><span class="line"> <span class="comment">#修改chunk size</span></span><br><span class="line"> <span class="string">db.settings.save(</span> <span class="string">&#123;</span> <span class="string">_id:"chunksize",</span> <span class="attr">value:</span> <span class="string">&lt;sizeInMB&gt;</span> <span class="string">&#125;</span> <span class="string">)</span></span><br><span class="line"> <span class="string">如</span> <span class="string">db.settings.save(</span> <span class="string">&#123;</span> <span class="string">_id:"chunksize",</span> <span class="attr">value:</span> <span class="number">64</span> <span class="string">&#125;</span> <span class="string">)</span></span><br></pre></td></tr></table></figure>
<h1 id="数据库启用分片：enableSharding"><a href="#数据库启用分片：enableSharding" class="headerlink" title="数据库启用分片：enableSharding"></a>数据库启用分片：enableSharding</h1><p><a href="https://docs.mongodb.org/manual/tutorial/deploy-shard-cluster/">参考文档：deploy-shard-cluster</a><br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#连接以mingo连接route server（mongo shell）</span></span><br><span class="line"><span class="string">mongo</span> <span class="string">--host</span> <span class="string">&lt;hostname</span> <span class="string">of</span> <span class="string">machine</span> <span class="string">running</span> <span class="string">mongos&gt;</span> <span class="string">--port</span> <span class="string">&lt;port</span> <span class="string">mongos</span> <span class="string">listens</span> <span class="string">on&gt;</span></span><br><span class="line"><span class="string">如/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo</span> <span class="string">--host</span> <span class="string">opsagent2.lt.com</span> <span class="string">--port</span> <span class="number">27017</span></span><br><span class="line"><span class="comment">#启用分片</span></span><br><span class="line"><span class="string">sh.enableSharding("&lt;database&gt;")</span> <span class="string">或者</span> <span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">&lt;database&gt;</span> <span class="string">&#125;</span> <span class="string">)</span></span><br><span class="line"><span class="string">如</span></span><br><span class="line"><span class="string">sh.enableSharding("uadb")</span></span><br><span class="line"><span class="string">sh.enableSharding("uadb_attachment")</span></span><br><span class="line"><span class="string">或</span></span><br><span class="line"><span class="string">use</span> <span class="string">admin</span></span><br><span class="line"><span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">"uadb"</span><span class="string">&#125;</span> <span class="string">);</span></span><br><span class="line"><span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">"uadb_attachment"</span><span class="string">&#125;</span> <span class="string">);</span></span><br><span class="line"><span class="comment"># collection分片</span></span><br><span class="line"><span class="string">sh.shardCollection("&lt;database&gt;.&lt;collection&gt;",</span> <span class="string">shard-key-pattern)</span></span><br><span class="line"><span class="string">如</span> <span class="string">sh.shardCollection("uadb.AddressNode",</span> <span class="string">&#123;</span> <span class="attr">"_id":</span> <span class="number">1</span><span class="string">,</span> <span class="attr">"ruleabbr":</span> <span class="number">1</span> <span class="string">&#125;</span> <span class="string">)</span></span><br><span class="line"><span class="comment">#查看是否成功启用分片</span></span><br><span class="line"><span class="string">use</span> <span class="string">uadb;</span></span><br><span class="line"><span class="string">db.AddressNode.stats();</span></span><br></pre></td></tr></table></figure></p>
<h1 id="shard集群测试"><a href="#shard集群测试" class="headerlink" title="shard集群测试"></a>shard集群测试</h1><p><a href="http://janephp.blog.51cto.com/4439680/1330656">Sharding 分片分片测试</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#mongo连接admin库</span></span><br><span class="line">/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo admin --host opsagent2.lt.com --port 27017</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置分片存储数据库</span></span><br><span class="line">sh.enableSharding(<span class="string">"test"</span>)</span><br><span class="line">sh.shardCollection(<span class="string">'test.users'</span>, &#123; <span class="string">"_id"</span>: 1&#125; )</span><br><span class="line"></span><br><span class="line"><span class="comment">#插入测试数据</span></span><br><span class="line">use <span class="built_in">test</span></span><br><span class="line"><span class="keyword">for</span>(var i=1;i&lt;50000;i++) db.users.insert(&#123;age:i,name:<span class="string">'geosmart'</span>,address:<span class="string">'anhui_chuzhou'</span>,country:<span class="string">'china'</span>&#125;)</span><br><span class="line"><span class="comment">#查询分片状态</span></span><br><span class="line">db.users.stats();</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Neo4j图数据库学习笔记</title>
    <url>/2016/01/25/Neo4j%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Explore the World of Graphs – From Query Efficiency to Business Performance</p>
<hr>
<a id="more"></a>
<h1 id="关于图形数据库"><a href="#关于图形数据库" class="headerlink" title="关于图形数据库"></a>关于图形数据库</h1><p>图形数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见的一个例子，就是社会网络中人与人之间的关系。</p>
<ul>
<li>当前有流行图形数据库：Neo4j、FlockDB、AllegroGraph、GraphDB、InfiniteGraph、OrientDB、InfoGrid和HypergraphDB等等，<br>另有自称比MongoDB和Neo4j性能更佳的多模型数据库ArangoDB,见<a href="https://github.com/weinberger/nosql-tests">nosql-tests</a></li>
<li>关系型数据库用于存储“关系型”数据的效果并不好，其查询复杂、缓慢、超出预期，而图形数据库的独特设计恰恰弥补了这个缺陷。  </li>
</ul>
<h1 id="Neo4j简介"><a href="#Neo4j简介" class="headerlink" title="Neo4j简介"></a>Neo4j简介</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/">官方Manual</a><br><a href="http://www.infoq.com/articles/full-stack-web-development-using-neo4j">参考full-stack-web-development-using-neo4j</a><br><a href="http://neo4j.com/">Neo4j</a>是一个用Java实现、完全兼容ACID的图形数据库。数据以一种针对图形网络进行过优化的格式保存在磁盘上。Neo4j的内核是一种极快的图形引擎，具有数据库产品期望的所有特性，如恢复、两阶段提交、符合XA等。自2003年起，Neo4j就已经被作为24/7的产品使用。<br>Neo4j是目前主流的一个图数据库，相比传统的关系型数据库，它可以快速的进行基于人际社交网络类的查询查询和检索;它同时提供了cypher语言来方便进行图数据库的操作和查询，该查询语言类似SQL语言。<br>Neo4j的数据并非保存在表或集合中，而是保存为节点以及节点之间的关系。在Neo4j中，节点以及关系都能够包含保存值的属性，此外：</p>
<ul>
<li>可以为节点设置零或多个标签（例如Author或Book）</li>
<li>每个关系都对应一种类型（例如WROTE或FRIEND_OF）</li>
<li>关系总是从一个节点指向另一个节点（但可以在不考虑指向性的情况下进行查询）</li>
</ul>
<h1 id="为什么要选择Neo4j？"><a href="#为什么要选择Neo4j？" class="headerlink" title="为什么要选择Neo4j？"></a>为什么要选择Neo4j？</h1><p>在考虑为web应用选择某个数据库时，我们需要考虑对它有哪些方面的期望，其中最重要的一些条件包括：</p>
<ul>
<li>它是否易于使用？</li>
<li>它是否允许你方便地回应对需求的变更？</li>
<li>它是否支持高性能查询？</li>
<li>是否能够方便地对其进行数据建模？</li>
<li>它是否支持事务？</li>
<li>它是否支持大规模应用？</li>
<li>它是否足够有趣（很遗憾的是对于数据库的这方面要求经常被忽略）？</li>
</ul>
<p>从这以下几个方面来说，Neo4j是一个合适的选择。Neo4j……</p>
<ul>
<li>自带一套易于学习的查询语言（名为Cypher）</li>
<li>不使用schema，因此可以满足你的任何形式的需求</li>
<li>与关系型数据库相比，对于高度关联的数据（图形数据）的查询快速要快上许多</li>
<li>它的实体与关系结构非常自然地切合人类的直观感受</li>
<li>支持兼容ACID的事务操作</li>
<li>提供了一个高可用性模型，以支持大规模数据量的查询，支持备份、数据局部性以及冗余</li>
<li>提供了一个可视化的查询控制台，你不会对它感到厌倦的</li>
</ul>
<h1 id="什么时候不应使用Neo4j？"><a href="#什么时候不应使用Neo4j？" class="headerlink" title="什么时候不应使用Neo4j？"></a>什么时候不应使用Neo4j？</h1><p>作为一个图形NoSQL数据库，Neo4j提供了大量的功能，但没有什么解决方案是完美的。在以下这些用例中，Neo4j就不是非常适合的选择：</p>
<ul>
<li>记录大量基于事件的数据（例如日志条目或传感器数据）</li>
<li>对大规模分布式数据进行处理，类似于Hadoop</li>
<li>二进制数据存储</li>
<li>适合于保存在关系型数据库中的结构化数据</li>
</ul>
<p>虽然Neo4j也能够处理“大数据”，但它毕竟不是Hadoop、HBase或Cassandra，通常来说不会在Neo4j数据库中直接处理海量数据（以PB为单位）的分析。但如果你乐于提供关于某个实体及其相邻数据关系（比如你可以提供一个web页面或某个API返回其结果），那么它是一种良好的选择。无论是简单的CRUD访问，或是复杂的、深度嵌套的资源视图都能够胜任。</p>
<p>虽然关系型数据库对于保存结构化数据来说依然是最佳的选择，但NoSQL数据库更适合于管理半结构化数据、非结构化数据以及图形数据。如果数据模型中包括大量的关联数据，并且希望使用一种直观的、有趣的并且快速的数据库进行开发，那么可以考虑尝试Neo4j。</p>
<h1 id="Neo4j图模型"><a href="#Neo4j图模型" class="headerlink" title="Neo4j图模型"></a>Neo4j图模型</h1><p>Neo4J中的图形模型要点：Nodes与Relationships可以被赋予Properties(key-value); Nodes可按label分组；Relationships可赋予direction和type并最终构成数据形态；Neo4j可存储10亿级别的数据量<br>Neo4J使用以下索引机制：一个超级参考节点通过一条特殊类别的边线“REFERENCE”与所有节点相连。这实际上允许创建多个索引，借以通过不同的边线类别对其加以区分。Neo4J还提供了一些特殊功能，如列出特定节点的相邻诸节点或是两节点间长度最短的诸类路径等。注意要使用上述各类“遍历”功能，Neo4J要求指定路径中经过的边线类别。</p>
<h1 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h1><p>enterprise和community公共特性<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Property Graph Model</span><br><span class="line">Native Graph Processing &amp; Storage</span><br><span class="line">ACID</span><br><span class="line">Cypher – Graph Query Language</span><br><span class="line">Language Drivers most popular languages</span><br><span class="line">REST API</span><br><span class="line">High-Performance Native API</span><br><span class="line">HTTPS (via Plug-in)</span><br></pre></td></tr></table></figure><br>enterprise性能扩展特性<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enterprise Lock Manager</span><br><span class="line">Cache Sharding</span><br><span class="line">Clustered Replication</span><br><span class="line">Cypher Query Tracing</span><br><span class="line">Property Existence Constraints</span><br><span class="line">Hot Backups</span><br><span class="line">Advanced Monitoring</span><br></pre></td></tr></table></figure></p>
<h1 id="嵌入式使用"><a href="#嵌入式使用" class="headerlink" title="嵌入式使用"></a>嵌入式使用</h1><p>可不必将Neo4J作为软件加以安装。可在项目中导入JAR文件来建立嵌入式图形数据库，该操作将在硬盘上建立对应的目录，类似sqlite。</p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>Neo4j HA(Neo4j High Availability)，高可用性主要指其包含容错机制和可进行水平扩展，即Neo4j Cluster</p>
<h1 id="Neo4j相关技术选型"><a href="#Neo4j相关技术选型" class="headerlink" title="Neo4j相关技术选型"></a>Neo4j相关技术选型</h1><p>所有主流的编程语言都通过HTTP_API的方式支持Neo4j，或者采用基本的HTTP类库，或是通过某些原生的类库提供更高层的抽象。此外，由于Neo4j是以Java语言编写的，因此所有包含JVM接口的语言都能够充分利用Neo4j中的高性能API。</p>
<p>Neo4j本身也提供了一个“技术栈”，它允许你选择不同的访问方式，包括简单访问乃至原生性能等等。它提供的特性包括：</p>
<ul>
<li>通过一个HTTP API执行Cypher查询，并获取JSON格式的结果</li>
<li>一种“非托管扩展”机制，允许你为Neo4j数据库编写自己的终结点</li>
<li>通过一个高层Java API指定节点与关系的遍历</li>
<li>通过一个低层的批量加载API处理海量初始数据的获取</li>
<li>通过一个核心Java API直接访问节点与关系，以获得最大的性能</li>
</ul>
<h2 id="Jcypher"><a href="#Jcypher" class="headerlink" title="Jcypher"></a>Jcypher</h2><ol>
<li>集成Remote、Emberded和InMemmory三种Neo4j数据库访问形式，在程序测试和Neo4j Browserz间切换很方便；</li>
<li>无需在POJO中手动标注实现OGM，会自动将对象嵌套关系转换为Graph Relationship，可更专注与业务逻辑；</li>
</ol>
<h2 id="NativeAPI"><a href="#NativeAPI" class="headerlink" title="NativeAPI"></a>NativeAPI</h2><p>Neo4j官方原生API，需手动进行事物管理，实现较为繁琐；</p>
<h2 id="Spring-Data-for-Neo4j"><a href="#Spring-Data-for-Neo4j" class="headerlink" title="Spring Data for Neo4j"></a>Spring Data for Neo4j</h2><p><a href="http://docs.spring.io/spring-data/data-neo4j/docs/4.0.0.RELEASE/api/">doc-api</a><br><a href="http://docs.spring.io/spring-data/data-neo4j/docs/4.0.0.RELEASE/reference/html/">The Spring Data Neo4j Guide Book</a><br><a href="https://github.com/geosmart/me.demo.neo4j/tree/master/neo4j.springdata">demo.neo4j.springdata</a></p>
<ul>
<li>spring-data-neo4j<br>Spring Data Neo4j</li>
<li>spring-data-neo4j-rest<br>pring Data Neo4j Wrapper for the Neo4j REST API, provides a Graph Database proxy for the remote invocation</li>
<li>spring-data-neo4j-aspects<br>Advanced Mapping support for Spring Data Neo4j</li>
</ul>
<h1 id="Cypher"><a href="#Cypher" class="headerlink" title="Cypher"></a>Cypher</h1><p>Cypher(Neo4j’s graph query language)，类似SQL<br>Cypher为ASCII风格的语法，它在括号内表示节点名称，并用箭头表示一个节点指向另一个节点的关系。Cypher通过这种方式允许你匹配某个指定的子图形模式。</p>
<h2 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h2><p>Create(Create Nodes and Relationships)<br><img src="query_template_create.png" alt="create模版"><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">CREATE (ee:Person &#123; name: "Emil", from: "Sweden", klout: 99 &#125;)</span><br><span class="line"><span class="meta">#</span><span class="bash"> () parenthesis to indicate a node</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ee:Person a variable <span class="string">'ee'</span> and label <span class="string">'Person'</span> <span class="keyword">for</span> the new node</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &#123;&#125; brackets to add properties to the node</span></span><br><span class="line"></span><br><span class="line">CREATE多个Nodes和Relationships</span><br><span class="line">MATCH (ee:Person) where ee.name = "Emil"</span><br><span class="line">CREATE (js:Person &#123; name: "Johan", from: "Sweden", learn: "surfing" &#125;),</span><br><span class="line">(ir:Person &#123; name: "Ian", from: "England", title: "author" &#125;),</span><br><span class="line">(rvb:Person &#123; name: "Rik", from: "Belgium", pet: "Orval" &#125;),</span><br><span class="line">(ally:Person &#123; name: "Allison", from: "California", hobby: "surfing" &#125;),</span><br><span class="line">(ee)-[:KNOWS &#123;since: 2001&#125;]-&gt;(js),(ee)-[:KNOWS &#123;rating: 5&#125;]-&gt;(ir),</span><br><span class="line">(js)-[:KNOWS]-&gt;(ir),(js)-[:KNOWS]-&gt;(rvb),</span><br><span class="line">(ir)-[:KNOWS]-&gt;(js),(ir)-[:KNOWS]-&gt;(ally),</span><br><span class="line">(rvb)-[:KNOWS]-&gt;(ally)</span><br></pre></td></tr></table></figure><br><img src="sns.png" alt="sns graph"></p>
<h2 id="MATCH"><a href="#MATCH" class="headerlink" title="MATCH"></a>MATCH</h2><p>MATCH(Finding nodes)<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MATCH (ee:Person) WHERE ee.name = "Emil" RETURN ee;</span><br><span class="line"><span class="comment"># (ee:Person) a single node pattern with label 'Person' which will assign matches to the variable 'ee'</span></span><br><span class="line"><span class="comment"># WHERE clause to constrain the results</span></span><br><span class="line"><span class="comment"># ee.name = "Emil" compares name property to the value "Emil"</span></span><br><span class="line"><span class="comment"># RETURN clause used to request particular results</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Pattern-matching"><a href="#Pattern-matching" class="headerlink" title="Pattern matching"></a>Pattern matching</h2><p>Pattern matching(Describe what to find in the graph)<br><img src="query_template_find.png" alt="Finding模版"></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find Emil's friends:</span></span><br><span class="line">MATCH (ee:Person)-[:KNOWS]-(friends) WHERE ee.name = "Emil" RETURN ee, friends</span><br><span class="line"><span class="comment"># MATCHclause to describe the pattern from known Nodes to found Nodes</span></span><br><span class="line"><span class="comment"># (ee)starts the pattern with a Person (qualified by WHERE)</span></span><br><span class="line"><span class="comment"># -[:KNOWS]-matches "KNOWS" relationships (in either direction)</span></span><br><span class="line"><span class="comment"># (friends)will be bound to Emil's friends</span></span><br></pre></td></tr></table></figure>
<h2 id="Recommend"><a href="#Recommend" class="headerlink" title="Recommend"></a>Recommend</h2><p>Pattern matching can be used to make recommendations，这个赞，天然的可以进行推荐，如六度分割（Six Degrees of Kevin Bacon），即Bacon Path最短路径问题<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Johan is learning to surf, so he may want to find a new friend who already does:</span></span><br><span class="line">MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer) WHERE js.name = "Johan" AND surfer.hobby = "surfing" RETURN DISTINCT surfer</span><br><span class="line"><span class="comment"># ()empty parenthesis to ignore these nodes</span></span><br><span class="line"><span class="comment"># DISTINCTbecause more than one path will match the pattern</span></span><br><span class="line"><span class="comment"># surferwill contain Allison, a friend of a friend who surfs</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Analyze"><a href="#Analyze" class="headerlink" title="Analyze"></a>Analyze</h2><p>可视化查询计划理解Cypher查询如何工作（EXPLAIN/PROFILE）<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">PROFILE MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer)</span><br><span class="line">WHERE js.name = "Johan" AND surfer.hobby = "surfing"</span><br><span class="line">RETURN DISTINCT surfer</span><br></pre></td></tr></table></figure></p>
<h1 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h1><p><a href="http://neo4j.com/developer/guide-data-visualization/">visualization</a></p>
<h1 id="Neo4j可用性测试"><a href="#Neo4j可用性测试" class="headerlink" title="Neo4j可用性测试"></a>Neo4j可用性测试</h1><p><a href="http://neo4j.com/developer/in-production/">Neo4j in Production</a><br>读写性能测试</p>
<h1 id="Neo4j性能优化配置"><a href="#Neo4j性能优化配置" class="headerlink" title="Neo4j性能优化配置"></a>Neo4j性能优化配置</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/configuration-introduction.html">neo4j-configuration-introduction</a>  </p>
<ul>
<li>确认JVM没有在GC垃圾回收上耗费太多时间,以确保有足够的heap避免heavy/peak引起GC-trashing时，GC-trashing时性能会下降两个数量级</li>
<li>JVM以-server参数启动，并设置一个合理的heap size，太大的heap也会损害性能，所以需要尝试不同的heap size</li>
<li>用并发的GC垃圾回收器，在大多数情况下<code>-XX:+UseG1GC</code>是最佳实践</li>
<li>给Neo4j page cache 设置大量的内存，在一个专用服务器上，需要平衡4大部分内存分配：操作系统、Neo4j JVM、Neo4j page cache和Neo4j Lucene全文索引用到的paging memory  <ul>
<li>服务器操作系统一般需要1到2GB的内存，服务器物理内存越大，操作系统需要分配的内存越大；  </li>
<li>由于Neo4j JVM和内存回收器的head-room消耗，需要足够大的heap   memory用来进行事物状态和查询处理；因为工作负载非常依赖heap memory，所以配置heap memory从1G到32G都很常见；  </li>
<li>Neo4j page cache 最好有足够的内存来保持整个数据集在内存中，也就是说page cache应该足够大，以适应所有的neostore.<em> 文件（不是neostore.transaction.db.</em> 文件）；  </li>
<li>配置足够的操作系统page cache以适应索引的内容和schema目录,因为如果索引不能装入内存,它将会影响索引查找性能；</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title>Sqoop使用笔记</title>
    <url>/2016/02/24/Sqoop%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Sqoop是Apache顶级项目，主要用来在Hadoop和关系数据库中传递数据。通过sqoop，可以方便的将数据从关系数据库导入到HDFS，或将数据从HDFS导出到关系数据库。</p>
<hr>
<a id="more"></a>
<h1 id="关于Sqoop"><a href="#关于Sqoop" class="headerlink" title="关于Sqoop"></a>关于Sqoop</h1><p><a href="http://sqoop.apache.org/">官网</a><br>Sqoop架构整合了Hive、Hbase和Oozie，通过map-reduce任务来传输数据，从而提供并发特性和容错。<br>Sqoop主要通过JDBC和关系数据库进行交互。理论上支持JDBC的database都可以使用sqoop和hdfs进行数据交互。但只有一小部分经过sqoop官方测试，如：HSQLDB（1.8.0+），MySQL（5.0+），Oracle（10.2.0+），PostgreSQL（8.3+ ）；<br>MySQL和PostgreSQL支持direct；较老的版本有可能也被支持，但未经过测试。出于性能考虑，sqoop提供不同于JDBC的快速存取数据的机制，可以通过—direct使用。</p>
<h1 id="Sqoop与MySQL数据交换"><a href="#Sqoop与MySQL数据交换" class="headerlink" title="Sqoop与MySQL数据交换"></a>Sqoop与MySQL数据交换</h1><p>版本：sqoop-1.4.5-cdh5.4.0<br><a href="http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.5-cdh5.4.0/SqoopUserGuide.html">sqoop-1.4.5-cdh5.4.0官方文档</a><br><a href="http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.5-cdh5.4.0/SqoopUserGuide.html#_example_invocations">数据导入示例</a></p>
<h2 id="mysql-drive导入sqoop"><a href="#mysql-drive导入sqoop" class="headerlink" title="mysql drive导入sqoop"></a>mysql drive导入sqoop</h2><p>cp  /tmp/mysql-connector-java-5.1.36-bin.jar  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib<br>cp  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib/mysql-connector-java-5.1.36-bin.jar   /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hadoop/lib/<br>备注：官方文档是要导入到sqoop2目录，但copy到sqoop2目录无效，sqoop目录生效</p>
<h2 id="MySQL表导入HDFS然后导入Hive"><a href="#MySQL表导入HDFS然后导入Hive" class="headerlink" title="MySQL表导入HDFS然后导入Hive"></a>MySQL表导入HDFS然后导入Hive</h2><ul>
<li>切换到hdfs用户执行：<code>su hdfs</code></li>
<li>将MySQL数据库geocodingdb的MatchingAddress表导入HDFS用户目录<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb   \</span><br><span class="line">--driver com.mysql.jdbc.Driver   \</span><br><span class="line">--username geocodingdb --password geocodingdb  \</span><br><span class="line">--table MatchingAddress       \</span><br><span class="line">--fields-terminated-by '\t'  --lines-terminated-by '\n' --optionally-enclosed-by '\"'</span><br><span class="line">--direct</span><br></pre></td></tr></table></figure></li>
<li><p>附加<code>--direct</code>参数快速完成MySQL数据导入/导出操作<br>与selects和inserts操作相比，MySQL Direct Connector可以用mysqldump and mysqlimport工具对MySQL数据进行更快的导入和导出操作</p>
</li>
<li><p>hive新建表结构并导入数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> geocodingdb.MatchingAddress;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> geocodingdb.MatchingAddress (source_address_id <span class="keyword">string</span>,source_address <span class="keyword">string</span> ,head_splitted_address <span class="keyword">string</span>,splitted_skeleton_addressnode <span class="keyword">string</span>,skeleton_addressnode <span class="keyword">string</span>,skeleton_addressnode_type <span class="keyword">string</span>,tail_address <span class="keyword">string</span>,tail_splitted_address <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>  <span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> inpath <span class="string">'/user/hdfs/MatchingAddress/*'</span>  <span class="keyword">into</span> <span class="keyword">table</span> geocodingdb.MatchingAddress;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="MySQL表直接导入Hive"><a href="#MySQL表直接导入Hive" class="headerlink" title="MySQL表直接导入Hive"></a>MySQL表直接导入Hive</h2><ul>
<li><p>MySQL表授权</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'geocodingdb'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'geocodingdb'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>hive-import命令<br>注意导入MySQL表结构字段顺序需与Hive表结构字段顺序一致</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">import</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.1.161:3306/geocodingdb</span>   <span class="string">\</span></span><br><span class="line"><span class="string">--driver</span> <span class="string">com.mysql.jdbc.Driver</span>   <span class="string">\</span></span><br><span class="line"><span class="string">--username</span> <span class="string">geocodingdb</span> <span class="string">--password</span> <span class="string">geocodingdb</span>  <span class="string">\</span></span><br><span class="line"><span class="string">--table</span> <span class="string">MatchingAddress</span>       <span class="string">\</span></span><br><span class="line"><span class="string">--fields-terminated-by</span> <span class="string">'\t'</span>  <span class="string">--lines-terminated-by</span> <span class="string">'\n'</span> <span class="string">--optionally-enclosed-by</span> <span class="string">'\"'</span>     <span class="string">\</span></span><br><span class="line"><span class="string">--direct</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Hive表导出到MySQL"><a href="#Hive表导出到MySQL" class="headerlink" title="Hive表导出到MySQL"></a>Hive表导出到MySQL</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">export</span> <span class="string">--direct</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.1.161:3306/geocodingdb</span> <span class="string">--driver</span> <span class="string">com.mysql.jdbc.Driver</span>   <span class="string">\</span></span><br><span class="line"><span class="string">--username</span> <span class="string">geocodingdb</span> <span class="string">--password</span> <span class="string">geocodingdb</span>  <span class="string">\</span></span><br><span class="line"><span class="string">--table</span> <span class="string">MatchedAddressGroupbySkeleton</span> <span class="string">\</span></span><br><span class="line"><span class="string">--export-dir</span> <span class="string">/user/hive/warehouse/geocodingdb.db/matchedaddressgroupbyskeleton</span>  <span class="string">\</span></span><br><span class="line"><span class="string">--input-fields-terminated-by</span> <span class="string">"\t"</span>   <span class="string">\</span></span><br><span class="line"><span class="string">--input-null-string</span> <span class="string">"\\\\N"</span> <span class="string">--input-null-non-string</span> <span class="string">"\\\\N"</span></span><br></pre></td></tr></table></figure>
<h1 id="Sqoop-MySQL-常用命令"><a href="#Sqoop-MySQL-常用命令" class="headerlink" title="Sqoop(MySQL)常用命令"></a>Sqoop(MySQL)常用命令</h1><h2 id="指定列"><a href="#指定列" class="headerlink" title="指定列"></a>指定列</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—columns “employee_id,first_name,last_name,job_title”</p>
<h2 id="使用8个线程"><a href="#使用8个线程" class="headerlink" title="使用8个线程"></a>使用8个线程</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>-m 8</p>
<h2 id="快速模式"><a href="#快速模式" class="headerlink" title="快速模式"></a>快速模式</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—direct</p>
<h2 id="使用sequencefile作为存储方式"><a href="#使用sequencefile作为存储方式" class="headerlink" title="使用sequencefile作为存储方式"></a>使用sequencefile作为存储方式</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—class-name com.foocorp.Employee —as-sequencefile</p>
<h2 id="分隔符"><a href="#分隔符" class="headerlink" title="分隔符"></a>分隔符</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—fields-terminated-by ‘\t’ —lines-terminated-by ‘\n’ \<br>—optionally-enclosed-by ‘\”‘</p>
<h2 id="导入到hive"><a href="#导入到hive" class="headerlink" title="导入到hive"></a>导入到hive</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—hive-import</p>
<h2 id="条件过滤"><a href="#条件过滤" class="headerlink" title="条件过滤"></a>条件过滤</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—where “start_date &gt; ‘2010-01-01’”</p>
<h2 id="用dept-id作为分个字段"><a href="#用dept-id作为分个字段" class="headerlink" title="用dept_id作为分个字段"></a>用dept_id作为分个字段</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/corp —table EMPLOYEES \<br>—split-by dept_id</p>
<h2 id="追加导入"><a href="#追加导入" class="headerlink" title="追加导入"></a>追加导入</h2><p>sqoop import —connect jdbc:mysql://db.foo.com/somedb —table sometable \<br>—where “id &gt; 100000” —target-dir /incremental_dataset —append</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="sqoop-export-—direct导出mysqlimport错误"><a href="#sqoop-export-—direct导出mysqlimport错误" class="headerlink" title="sqoop export —direct导出mysqlimport错误"></a>sqoop export —direct导出mysqlimport错误</h2><p>错误描述：Cannot run program “mysqlimport”: error=2, No such file or directory<br>解决办法：附加<code>--driver com.mysql.jdbc.Driver</code>参数</p>
<h2 id="sqoop-export-—direct导出mapreduce程序错误"><a href="#sqoop-export-—direct导出mapreduce程序错误" class="headerlink" title="sqoop export —direct导出mapreduce程序错误"></a>sqoop export —direct导出mapreduce程序错误</h2><p>错误描述1：Caused by: java.lang.RuntimeException: Can’t parse input data: ‘长浜    STR    18119    B316D057CE523018E0430A23A2C13018’<br>解决办法：附加<code>--input-fields-terminated-by &quot;\t&quot;</code>参数</p>
<p>错误描述2：com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry ‘1614’ for key ‘PRIMARY’<br>解决办法：附加<code>--input-null-string &quot;\\\\N&quot; --input-null-non-string &quot;\\\\N&quot;</code>如果遇到空值就插入null</p>
<h2 id="Sqoop-导入-Hive-导致发生-Null-Pointer-Exception-NPE"><a href="#Sqoop-导入-Hive-导致发生-Null-Pointer-Exception-NPE" class="headerlink" title="Sqoop 导入 Hive 导致发生 Null Pointer Exception (NPE)"></a>Sqoop 导入 Hive 导致发生 Null Pointer Exception (NPE)</h2><p>解决办法：首先通过 Sqoop 将数据导入 HDFS，然后将其从 HDFS 导入 Hive。</p>
<h2 id="MySQL导入Hive表报错"><a href="#MySQL导入Hive表报错" class="headerlink" title="MySQL导入Hive表报错"></a>MySQL导入Hive表报错</h2><p>Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘쀀’ )’ at line 1<br>解决：hive表编码问题；导入时不附加—hcatalog-table，手动新建表，然后导入数据</p>
<h1 id="Sqoop导入MySQL大表内存溢出问题"><a href="#Sqoop导入MySQL大表内存溢出问题" class="headerlink" title="Sqoop导入MySQL大表内存溢出问题"></a>Sqoop导入MySQL大表内存溢出问题</h1><p><a href="https://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html">SqoopUserGuide</a><br>抛出异常java.lang.OutOfMemoryError：GC overhead limit exceeded导致服务起不来</p>
<p>参考：<a href="http://www.hadooptechs.com/sqoop/handling-database-fetch-size-in-sqoop">http://www.hadooptechs.com/sqoop/handling-database-fetch-size-in-sqoop</a></p>
<p>修改yarn的nodemanager xmx还是sqoop 的xmx</p>
<h1 id="分页查询写入"><a href="#分页查询写入" class="headerlink" title="分页查询写入"></a>分页查询写入</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb  --username geocodingdb --password geocodingdb  \</span><br><span class="line">--query <span class="string">'select * from  MatchingAddress  WHERE $CONDITIONS  limit 0,100000'</span>  \</span><br><span class="line">--split-by  guid  \</span><br><span class="line">--fields-terminated-by <span class="string">'\t'</span>  --lines-terminated-by <span class="string">'\n'</span> --optionally-enclosed-by <span class="string">'\"'</span>  \</span><br><span class="line">--target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \</span><br><span class="line">--append</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb  --username geocodingdb --password geocodingdb  \</span><br><span class="line">--query <span class="string">'select * from  MatchingAddress  WHERE $CONDITIONS'</span>  \</span><br><span class="line">--split-by  guid  \</span><br><span class="line">--fields-terminated-by <span class="string">'\t'</span>  --lines-terminated-by <span class="string">'\n'</span> --optionally-enclosed-by <span class="string">'\"'</span>  \</span><br><span class="line">--target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \</span><br><span class="line">--append</span><br></pre></td></tr></table></figure>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb?user=geocodingdb&amp;password=geocodingdb&amp;dontTrackOpenResources=true&amp;defaultFetchSize=10000&amp;useCursorFetch=true  —query ‘select * from MatchingAddress  WHERE $CONDITIONS’ —split-by  guid \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>—driver com.mysql.jdbc.Driver  \<br>—username geocodingdb —password geocodingdb  \<br>—direct  \<br>—table MatchingAddress1  \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>—driver com.mysql.jdbc.Driver  \<br>—username geocodingdb —password geocodingdb  \<br>—direct  \<br>—table MatchingAddress2  \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>—driver com.mysql.jdbc.Driver  \<br>—username geocodingdb —password geocodingdb  \<br>—direct  \<br>—table MatchingAddress3  \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>—driver com.mysql.jdbc.Driver  \<br>—username geocodingdb —password geocodingdb  \<br>—direct  \<br>—table MatchingAddress4  \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>sqoop import —connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>—driver com.mysql.jdbc.Driver  \<br>—username geocodingdb —password geocodingdb  \<br>—direct  \<br>—table MatchingAddress5  \<br>—fields-terminated-by ‘\t’  —lines-terminated-by ‘\n’ —optionally-enclosed-by ‘\”‘  \<br>—target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>—append</p>
<p>Stack trace: ExitCodeException exitCode=255:</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
        <tag>Sqoop</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM学习笔记（二）Java内存区域与内存溢出异常</title>
    <url>/2016/03/07/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</url>
    <content><![CDATA[<p>《深入理解Java虚拟机 JVM高级特性与最佳实践》 第二章 Java内存区域与内存溢出异常</p>
<hr>
<a id="more"></a>
<h1 id="运行时的数据区域"><a href="#运行时的数据区域" class="headerlink" title="运行时的数据区域"></a>运行时的数据区域</h1><p><img src="Java虚拟机运行时数据区.jpg" alt="Java虚拟机运行时数据区"></p>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><ul>
<li>程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器；</li>
<li>PCR为线程私有内存；</li>
<li>是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域；</li>
</ul>
<h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2><p><img src="JavaStacks.jpg" alt="Java虚拟机栈"></p>
<ul>
<li>Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在在执行的同时都会创建一个栈帧（Stack Frame）用于存储<code>局部变量表、操作数栈、动态链接、方法接口</code>等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈出栈的过程。</li>
<li>Java虚拟机栈也是线程私有，它的生命周期与线程相同。</li>
<li>Java内存区常分为堆内存（Heap）和栈内存（Stack）；</li>
<li>OOM情况：（1）线程请求的栈深度&gt;虚拟机所运行的最大深度；（2）虚拟机动态扩展时无法申请到足够的内存</li>
</ul>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p><img src="Java本地方法栈.png" alt="Java本地方法栈"> 本地方法栈（Native Method Stack）与虚拟机所发挥的作用非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机所使用的Native方法服务。</p>
<ul>
<li>HotSpot虚拟机把本地方法栈和虚拟机栈合二为一；</li>
<li>此区域会抛StackOverflowError 和 OutofMemoryError异常</li>
</ul>
<h2 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h2><p><img src="JavaHeap.gif" alt="Java堆"> Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块，Java Heap是所有线程共享的一块内存区域，在VM启动时创建。</p>
<ul>
<li><code>所有的对象实例以及数组都要在堆上分配</code>（不绝对：栈上分配、标量替换优化技术）；</li>
<li>Java堆是垃圾收集器管理的主要区域，也可称做GC堆（Garbage Collected Heap）</li>
<li>从内存回收的角度，现代收集器基本都采用分代收集算法，Java Heap可细分为新生代和老年代，再细致可分为Eden空间、From Survivor空间、To Survivor空间等—&gt;更好回收内存。</li>
<li>从内存分配的角度，线程共享的Java堆中可能分出多个线程私有的分配缓存区（TLAB：Thread Local Allocation Buffer）—&gt;更快分配内存。</li>
<li>Java堆出于逻辑连续的内存空间中，物理上可不连续，如磁盘空间一样；</li>
<li>Java堆在实现上可时，可以实现成固定大小的，也可以按照可扩展实现（-Xmx和-Xms控制）；</li>
<li>OOM情况：堆中没有内存完成实例分配，堆也无法再扩展时</li>
</ul>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储<code>已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码</code>等数据。</p>
<ul>
<li>也称为永久代（Permanent Generation）但随着Java8的到来，已放弃永久代改为采用Native Memory来实现方法区的规划。</li>
<li>此区域回收目标主要是针对常量池的回收和对类型的卸载。</li>
</ul>
<h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p><img src="Java虚拟机运行时数据区拓扑关系.png" alt="Java虚拟机运行时数据区拓扑关系"> 运行时常量池（Runtime Constants Pool）是方法区的一部分</p>
<ul>
<li>Class文件中除了有<code>类的版本、字段、方法、接口</code>等描述的信息外，还有一项信息是常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。</li>
</ul>
<h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。</p>
<ul>
<li>能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</li>
<li>直接内存的分配不会受到Java堆大小的限制，但会收到本机总内存（RAM以及SWAP/分页文件）大小以及处理器寻址空间的限制。</li>
<li>设置Xmx等参数信息时注意不能忽略直接内存，不然会引起OOM。</li>
</ul>
<h1 id="HotSpot虚拟机"><a href="#HotSpot虚拟机" class="headerlink" title="HotSpot虚拟机"></a>HotSpot虚拟机</h1><h2 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h2><p>为新生对象分配内存的分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾回收器是否带有压缩整理功能决定。</p>
<ul>
<li>指针碰撞（Bump the Pointer）分配方式：Serial、ParNew等带有Compact过程的收集器</li>
<li>空闲列表（Free List）分配方式：类CMS这种基于Mark-Sweep算法的收集器</li>
<li>对分配内存空间的动作进行同步处理—-VM采用CAS配上失败重试的方式保证更新操作的原子性；</li>
<li>本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）：把内存分配动作按线程划分在不同空间中进行，即每个线程在Java堆中预先分配一小块内存，虚拟机是否启用TLAB，可由-XX:+/-UseTLAB参数设定；</li>
</ul>
<h2 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h2><p><img src="对象内存布局1.jpg" alt="对象的内存布局1"> 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）、和对齐填充（Padding）;</p>
<ul>
<li>对象头包含2部分信息</li>
<li><p><img src="对象内存布局2.png" alt="对象的内存布局2"></p>
<ul>
<li>Mark Word,存储对象自身的运行时数据（如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）；由于对象头与对象自身定义的数据存储大小无关，考虑到VM的空间效率，Mark Word被设计成非固定的数据结构以便在极小的空间内存储尽量多的信息，他会根据对象的状态复用自己的存储空间。</li>
<li>类型指针，即对象指向它的类元数据的指针，VM通过这个指针来确定这个对象是哪个类的实例。</li>
</ul>
</li>
<li><p>实例数据是对象真正存储的有效信息，也似乎程序代码中定义的各种类型的字段内容。</p>
</li>
<li>对齐填充，并不必然存在，没有特别含义，仅仅起占位符的作用，8byte对齐。</li>
</ul>
<h2 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h2><p>Java程序需要通过栈上的reference数据来操作堆上的具体对象，对象访问方法取决于VM实现而定，目前主流访问方式有使用句柄和直接指针2种：</p>
<h3 id="句柄访问"><a href="#句柄访问" class="headerlink" title="句柄访问"></a>句柄访问</h3><p>Java堆中划分出一块内存作为句柄池，reference中存储对象的句柄地址，句柄中包含对象实例数据与类型数据各自的具体地址信息； <img src="句柄访问对象.jpg" alt="句柄访问对象"></p>
<h3 id="直接指针访问"><a href="#直接指针访问" class="headerlink" title="直接指针访问"></a>直接指针访问</h3><p>Java堆对象的布局中必须考虑如何放置访问类型数据的相关信息，reference中存储对象地址； <img src="直接指针访问对象.jpg" alt="直接指针访问对象"></p>
<h3 id="两种访问方式各有优势"><a href="#两种访问方式各有优势" class="headerlink" title="两种访问方式各有优势"></a>两种访问方式各有优势</h3><ul>
<li>使用句柄访问最大的好处是reference中存储的是稳定的句柄地址，在对象被移动（GC时移动对象是很普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改；</li>
<li>使用直接指针访问方式的最大好处是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本；</li>
<li>HotSpot虚拟机采用指针访问方式进行对象访问，从整个软件开发范围看，各种语言和框架使用句柄来访问的情况也非常常见。</li>
</ul>
<h2 id="实战OOM异常"><a href="#实战OOM异常" class="headerlink" title="实战OOM异常"></a>实战OOM异常</h2><h3 id="Java堆溢出"><a href="#Java堆溢出" class="headerlink" title="Java堆溢出"></a>Java堆溢出</h3><p>Java堆用于存储对象实例，只要不断创建对象，并保证GC Roots到对象之间有可达路径来避免回收机制清除这些对象，那么当对象数量到达最大堆的容量限制后就会产生OOM。</p>
<h4 id="控制参数"><a href="#控制参数" class="headerlink" title="控制参数"></a>控制参数</h4><ul>
<li>-Xms：堆最小值</li>
<li>-Xmx：堆最大值</li>
<li>-XX:+HeapDumpOnOutOfMemoryError：让虚拟机在出现OOM异常时Dump出当前内存堆转储快照以便事后进行分析</li>
</ul>
<h4 id="异常信息"><a href="#异常信息" class="headerlink" title="异常信息"></a>异常信息</h4><p><code>Java.lang.OutOfMemory</code> + <code>Java Heap Space</code></p>
<h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>以内存映像分析工具（Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，即判断是内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）</p>
<ul>
<li>如果是内存泄漏：通过工具查看泄漏对象到GC Roots的引用链，掌握泄漏对象的类型信息及引用链的信息后可较准确的定位代码位置；</li>
<li>如果是内存溢出：可通过检查VM的堆参数（-Xmx和-Xms），与机器物理内存对比看是否可以调大；从代码检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗  </li>
</ul>
<h3 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h3><h4 id="控制参数-1"><a href="#控制参数-1" class="headerlink" title="控制参数"></a>控制参数</h4><p>HotSpot虚拟机不区分虚拟机栈和本地方法栈，</p>
<ul>
<li>-Xoss（设置本地方法栈大小）：参数设置无效;</li>
<li>-Xss（栈容量）;</li>
</ul>
<h4 id="异常信息-1"><a href="#异常信息-1" class="headerlink" title="异常信息"></a>异常信息</h4><p>关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常：</p>
<ul>
<li>如果线程请求的栈深度 &gt; 虚拟机所允许的最大深度，抛出<code>StackOverFlowError</code>异常</li>
<li>如果虚拟机在扩展栈时无法申请到足够的内存空间，抛出<code>OutOfMemoryError</code>异常  </li>
</ul>
<h4 id="解决办法-1"><a href="#解决办法-1" class="headerlink" title="解决办法"></a>解决办法</h4><p>操作系统分配给每个进程的内存是有限制的，如32位Windwos限制为2G。虚拟机提供了参数来控制Java堆和方法区这两部分内存的最大值， <code>虚拟机栈和本地方法栈可瓜分的剩余内存=2G（操作系统限制）-Xmx（最大堆容量）-MaxPermSize（最大方法区容量）-虚拟机进程本身耗费内存</code>；程序计数器消耗内存很小，可以忽略。</p>
<ul>
<li>每个线程分配到的栈容量越大，可以建立的线程数就越少，建立线程时候就越容易耗尽剩余内存。</li>
<li>按虚拟机默认参数，栈深度在大多数情况下达到1000~2000完全没问题，对于正常方法调用（包括递归），这个深度应该完全够用；但如果是建立过多线程导致内存溢出，在不能<strong>减少线程数或者更换X64位虚拟机</strong>的情况下，就只能通过<strong>减少最大堆和减少栈容量</strong>来换取更多的线程</li>
</ul>
<h3 id="方法区和运行时常量区溢出"><a href="#方法区和运行时常量区溢出" class="headerlink" title="方法区和运行时常量区溢出"></a>方法区和运行时常量区溢出</h3><p>运行时常量池是方法区的一部分，因此这两个区域的溢出可放在一起进行。</p>
<h4 id="控制参数-2"><a href="#控制参数-2" class="headerlink" title="控制参数"></a>控制参数</h4><ul>
<li>-XX:PermSize（方法区最小容量）</li>
<li>-XX:MaxPermSize （方法区最大容量）</li>
</ul>
<h4 id="异常信息-2"><a href="#异常信息-2" class="headerlink" title="异常信息"></a>异常信息</h4><p><code>OutOfMemoryError</code> 后面跟随<code>PermGen space</code> 说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分</p>
<h3 id="本机直接内存溢出"><a href="#本机直接内存溢出" class="headerlink" title="本机直接内存溢出"></a>本机直接内存溢出</h3><h4 id="控制参数-3"><a href="#控制参数-3" class="headerlink" title="控制参数"></a>控制参数</h4><p>DirectMemory容量可通过<code>-XX:MaxDirectMemorySize</code>指定，不指定默认与-Xmx(Java堆最大值)一样。</p>
<h4 id="异常信息-3"><a href="#异常信息-3" class="headerlink" title="异常信息"></a>异常信息</h4><p>由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常； 如果发现OOM之后Dump文件很小，而程序又直接或简介使用了NIO，可以考虑是不是这方面的原因。</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Lucene学习笔记</title>
    <url>/2016/04/29/Lucene%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Neo4j图数据库的索引采用的是Lucene全文索引，特别是LegacyIndex部分，需要深入了解Lucene进行索引定制，之前以IK分词在Solr中建索引和检索浅尝辄止，对Lucene也是停留在概念层。<br>Solr对Lucene商业封装后的易用性很强，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面。Solr的封装屏蔽了许多技术细节，但是对于开发人员来说，最好还是自下而上循序渐进比较好。<br>lucene（全文检索引擎工具包）&gt;solr（企业级搜索应用服务器）&gt;nutch（分布式检索引擎）和打Boss一样，得一个个来。</p>
<hr>
<a id="more"></a>
<h1 id="Apache-Lucene简介"><a href="#Apache-Lucene简介" class="headerlink" title="Apache Lucene简介"></a>Apache Lucene简介</h1><p>The Apache LuceneTM project develops open-source search software, including:</p>
<ul>
<li>Lucene Core, our flagship sub-project, provides Java-based indexing and search technology, as well as spellchecking, hit highlighting and advanced analysis/tokenization capabilities.</li>
<li>SolrTM  is a high performance search server built using Lucene Core, with XML/HTTP and JSON/Python/Ruby APIs, hit highlighting, faceted search, caching, replication, and a web admin interface.</li>
<li>PyLucene is a Python port of the Core project.</li>
</ul>
<h1 id="Lucene-Core简介"><a href="#Lucene-Core简介" class="headerlink" title="Lucene Core简介"></a>Lucene Core简介</h1><p>Apache LuceneTM is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform.</p>
<h1 id="Lucene-Features"><a href="#Lucene-Features" class="headerlink" title="Lucene Features"></a>Lucene Features</h1><h2 id="可扩展、高性能索引"><a href="#可扩展、高性能索引" class="headerlink" title="可扩展、高性能索引"></a>可扩展、高性能索引</h2><ul>
<li>over 150GB/hour on modern hardware</li>
<li>small RAM requirements — only 1MB heap</li>
<li>incremental indexing as fast as batch indexing</li>
<li>index size roughly 20-30% the size of text indexed</li>
</ul>
<h2 id="强大、精准、高效的检索算法"><a href="#强大、精准、高效的检索算法" class="headerlink" title="强大、精准、高效的检索算法"></a>强大、精准、高效的检索算法</h2><ul>
<li>ranked searching — best results returned first</li>
<li>many powerful query types: phrase queries, wildcard queries, proximity queries, range queries and more</li>
<li>fielded searching (e.g. title, author, contents)</li>
<li>sorting by any field</li>
<li>multiple-index searching with merged results</li>
<li>allows simultaneous update and searching</li>
<li>flexible faceting, highlighting, joins and result grouping</li>
<li>fast, memory-efficient and typo-tolerant suggesters</li>
<li>pluggable ranking models, including the Vector Space Model and Okapi BM25</li>
<li>configurable storage engine (codecs)</li>
</ul>
<h2 id="跨平台的解决方案"><a href="#跨平台的解决方案" class="headerlink" title="跨平台的解决方案"></a>跨平台的解决方案</h2><ul>
<li>Available as Open Source software under the Apache License which lets you use Lucene in both commercial and Open Source programs</li>
<li>100%-pure Java</li>
<li>Implementations in other programming languages available that are index-compatible</li>
</ul>
<h1 id="Lucene的总体架构"><a href="#Lucene的总体架构" class="headerlink" title="Lucene的总体架构"></a>Lucene的总体架构</h1><p><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623596.html">http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623596.html</a></p>
<h1 id="Lucene索引结构"><a href="#Lucene索引结构" class="headerlink" title="Lucene索引结构"></a>Lucene索引结构</h1><p>Lucene的索引结构是有层次结构的，主要分以下几个层次：</p>
<h2 id="索引-Index"><a href="#索引-Index" class="headerlink" title="索引(Index)"></a>索引(Index)</h2><p>在Lucene中一个索引是放在一个文件夹中的，同一文件夹中的所有的文件构成一个Lucene索引。</p>
<h2 id="段-Segment"><a href="#段-Segment" class="headerlink" title="段(Segment)"></a>段(Segment)</h2><p>一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并。<br>具有相同前缀文件的属同一个段，segments.gen和segments_5是段的元数据文件，也即它们保存了段的属性信息。</p>
<h2 id="文档-Document"><a href="#文档-Document" class="headerlink" title="文档(Document)"></a>文档(Document)</h2><p><code>A document is a sequence of fields.</code><br>文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档。<br>新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中。</p>
<h2 id="域-Field"><a href="#域-Field" class="headerlink" title="域(Field)"></a>域(Field)</h2><p><code>A field is a named sequence of terms.</code><br>一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里（不同域的索引方式可以不同）。</p>
<h3 id="Field类型"><a href="#Field类型" class="headerlink" title="Field类型"></a>Field类型</h3><ul>
<li>field的text以文本形式存储在index中，field倒排后即为index，也可配置为只存储不建index；<br>Field.Store.* field存储选项通过倒排序索引来控制文本是否可以搜索；</li>
<li>field的text看分词为term后建立index，或者field的text直接以原始文本作为term存储为index；大多数field是分词后建立索引的，但有时候指定一些identifier field只存储原始文本是很有用的；<br>Field.Index.*  field索引选项确定是否要存储域的真实值；<h2 id="词元-Term"><a href="#词元-Term" class="headerlink" title="词元(Term)"></a>词元(Term)</h2><code>A term is a string.</code><br>词元是索引的最小单位，是经过词法分析和语言处理后的字符串。<br>在不同field中的相同字符串是不同的term，因此term表示一对字符串，第一个用以命名field，第二个用以命名field中的text；<br>文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域的容器，而域则是依次包含“真正的”被搜索的内容，域值通过分词技术处理，得到多个词元。</li>
</ul>
<h1 id="索引可视化工具"><a href="#索引可视化工具" class="headerlink" title="索引可视化工具"></a>索引可视化工具</h1><p><a href="https://github.com/DmitryKey/luke">Luke</a></p>
<h1 id="倒排-反向索引（Inverted-Indexing）"><a href="#倒排-反向索引（Inverted-Indexing）" class="headerlink" title="倒排/反向索引（Inverted Indexing）"></a>倒排/反向索引（<a href="https://zh.wikipedia.org/wiki/倒排索引">Inverted Indexing</a>）</h1><p>定义：存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射<br>为了使得基于term的检索更高效，index中存储了term的统计数据；lucene的索引在索引家族中被称为倒排/反向索引，这是因为它能列出所有包含某个term的document，而这与根据document列出terms的自然联系是倒置的</p>
<h2 id="Lucene索引中的正向信息"><a href="#Lucene索引中的正向信息" class="headerlink" title="Lucene索引中的正向信息"></a>Lucene索引中的正向信息</h2><p>正向信息按层次保存了从index一直到term的包含关系：<code>索引(Index) –&gt; 段(segment) –&gt; 文档(Document) –&gt; 域(Field) –&gt; 词(Term)</code><br>也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词。既然是层次结构，则每个层次都保存了本层次的信息以及下一层次的元信息，也即属性信息。<br>包含正向信息的文件有：</p>
<ul>
<li>segments_N保存了此索引包含多少个段，每个段包含多少篇文档。</li>
<li>XXX.fnm保存了此段包含了多少个域，每个域的名称及索引方式。</li>
<li>XXX.fdx，XXX.fdt保存了此段包含的所有文档，每篇文档包含了多少域，每个域保存了那些信息。</li>
<li>XXX.tvx，XXX.tvd，XXX.tvf保存了此段包含多少文档，每篇文档包含了多少域，每个域包含了多少词，每个词的字符串，位置等信息。</li>
</ul>
<p>示例：如一本介绍中国地理的书，应该首先介绍中国地理的概况，以及中国包含多少个省，每个省介绍本省的基本概况及包含多少个市，每个市介绍本市的基本概况及包含多少个县，每个县具体介绍每个县的具体情况。</p>
<h2 id="Lucene索引中的反向信息"><a href="#Lucene索引中的反向信息" class="headerlink" title="Lucene索引中的反向信息"></a>Lucene索引中的反向信息</h2><p>反向信息保存了词典到倒排表的映射：<code>词(Term) –&gt; 文档(Document)</code><br>包含反向信息的文件有：</p>
<ul>
<li>XXX.tis，XXX.tii保存了词典(Term Dictionary)，也即此段包含的所有的词按字典顺序的排序。</li>
<li>XXX.frq保存了倒排表，也即包含每个词的文档ID列表。</li>
<li>XXX.prx保存了倒排表中每个词在包含此词的文档中的位置。</li>
</ul>
<h2 id="倒排索引的应用"><a href="#倒排索引的应用" class="headerlink" title="倒排索引的应用"></a>倒排索引的应用</h2><ul>
<li>反向索引数据结构是典型的搜索引擎检索算法重要的部分。</li>
<li>一个搜索引擎执行的目标就是优化查询的速度：找到某个单词在文档中出现的地方。以前，正向索引开发出来用来存储每个文档的单词的列表，接着掉头来开发了一种反向索引。 正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。</li>
<li>实际上，时间、内存、处理器等等资源的限制，技术上正向索引是不能实现的。</li>
<li>为了替代正向索引的每个文档的单词列表，能列出每个查询的单词所有所在文档的列表的反向索引数据结构开发了出来。</li>
<li>随着反向索引的创建，如今的查询能通过立即的单词标示迅速获取结果（经过随机存储）。随机存储也通常被认为快于顺序存储。</li>
</ul>
<h1 id="Lucene索引文件的基本类型"><a href="#Lucene索引文件的基本类型" class="headerlink" title="Lucene索引文件的基本类型"></a>Lucene索引文件的基本类型</h1><p>Lucene索引文件中，用一下基本类型来保存信息：  </p>
<ul>
<li>Byte：是最基本的类型，长8位(bit)。</li>
<li>UInt32：由4个Byte组成。</li>
<li>UInt64：由8个Byte组成。</li>
<li>VInt：变长的整数类型，它可能包含多个Byte，对于每个Byte的8位，其中后7位表示数值，最高1位表示是否还有另一个Byte，0表示没有，1表示有。<br>越前面的Byte表示数值的低位，越后面的Byte表示数值的高位。<br>例如130化为二进制为 1000, 0010，总共需要8位，一个Byte表示不了，因而需要两个Byte来表示，第一个Byte表示后7位，并且在最高位置1来表示后面还有一个Byte，所以为(1) 0000010，第二个Byte表示第8位，并且最高位置0来表示后面没有其他的Byte了，所以为(0) 0000001。</li>
<li>Chars：是UTF-8编码的一系列Byte。</li>
<li>String：一个字符串首先是一个VInt来表示此字符串包含的字符的个数，接着便是UTF-8编码的字符序列Chars。</li>
</ul>
<h1 id="Lucene索引存储的基本规则"><a href="#Lucene索引存储的基本规则" class="headerlink" title="Lucene索引存储的基本规则"></a>Lucene索引存储的基本规则</h1><p>Lucene为了使的信息的存储占用的空间更小，访问速度更快，采取了一些特殊的技巧.</p>
<h2 id="前缀后缀规则-Prefix-Suffix"><a href="#前缀后缀规则-Prefix-Suffix" class="headerlink" title="前缀后缀规则(Prefix+Suffix)"></a>前缀后缀规则(Prefix+Suffix)</h2><p>Lucene在反向索引中，要保存词典(Term Dictionary)的信息，所有的词(Term)在词典中是按照字典顺序进行排列的，然而词典中包含了文档中的几乎所有的词，并且有的词还是非常的长的，这样索引文件会非常的大，所谓前缀后缀规则，即当某个词和前一个词有共同的前缀的时候，后面的词仅仅保存前缀在词中的偏移(offset)，以及除前缀以外的字符串(称为后缀)。</p>
<h2 id="差值规则-Delta"><a href="#差值规则-Delta" class="headerlink" title="差值规则(Delta)"></a>差值规则(Delta)</h2><p>在Lucene的反向索引中，需要保存很多整型数字的信息，比如文档ID号，比如词(Term)在文档中的位置等等。<br>整型数字是以VInt的格式存储的。随着数值的增大，每个数字占用的Byte的个数也逐渐的增多。所谓差值规则(Delta)就是先后保存两个整数的时候，后面的整数仅仅保存和前面整数的差即可。</p>
<h2 id="或然跟随规则-A-B"><a href="#或然跟随规则-A-B" class="headerlink" title="或然跟随规则(A, B?)"></a>或然跟随规则(A, B?)</h2><p>Lucene的索引结构中存在这样的情况，某个值A后面可能存在某个值B，也可能不存在，需要一个标志来表示后面是否跟随着B。<br>一般的情况下，在A后面放置一个Byte，为0则后面不存在B，为1则后面存在B，或者0则后面存在B，1则后面不存在B。  </p>
<h2 id="跳跃表规则-Skip-list"><a href="#跳跃表规则-Skip-list" class="headerlink" title="跳跃表规则(Skip list)"></a>跳跃表规则(Skip list)</h2><p>为了提高查找的性能，Lucene在很多地方采取的跳跃表的数据结构。<br>跳跃表(Skip List)是如图的一种数据结构，有以下几个基本特征：</p>
<ul>
<li>元素是按顺序排列的，在Lucene中，或是按字典顺序排列，或是按从小到大顺序排列。</li>
<li>跳跃是有间隔的(Interval)，也即每次跳跃的元素数，间隔是事先配置好的，如图跳跃表的间隔为3。</li>
<li>跳跃表是由层次的(level)，每一层的每隔指定间隔的元素构成上一层，如图跳跃表共有2层。</li>
</ul>
<h1 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h1><p>TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术。</p>
<h2 id="Lucene词元权重计算"><a href="#Lucene词元权重计算" class="headerlink" title="Lucene词元权重计算"></a>Lucene词元权重计算</h2><ul>
<li>Term Frequency（tf）：此term在文档中出现的次数，tf越大则该词元越重要。</li>
<li>Document Frequency（df）：有多少文档包含此term，df越大该词元越不重要。<br>计算夹角的余弦值，夹角越小，余弦值越大，分值越大，从而相关性越大。</li>
</ul>
<h1 id="Lucene检索"><a href="#Lucene检索" class="headerlink" title="Lucene检索"></a>Lucene检索</h1><h2 id="TokenStream"><a href="#TokenStream" class="headerlink" title="TokenStream"></a>TokenStream</h2><p>TokenStream extends AttributeSource implements Closeable:<br>incrementToken,end,reset,close</p>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h2><p>Tokenizers perform the task of breaking a string into separate tokens.<br>Tokenizer直接继承至TokenStream,其输入input是一个reader</p>
<h2 id="TokenFilter"><a href="#TokenFilter" class="headerlink" title="TokenFilter"></a>TokenFilter</h2><p>Token filters act on each token that is generated by a tokenizer and apply some set of operations that alter or normalize them.<br>TokenFilter也直接继承TokenStream,但input是一个TokenStream。</p>
<h2 id="TokenStreamComponents"><a href="#TokenStreamComponents" class="headerlink" title="TokenStreamComponents"></a>TokenStreamComponents</h2><p>TokenStreamComponents其实是将tokenizer和tokenfilter包装起来的(也可以只是tokenizer,两个成员叫source和sink),可以setReader,getTokenStream方法返回sink。</p>
<h2 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h2><p><a href="http://www.citrine.io/blog/2015/2/14/building-a-custom-analyzer-in-lucene">如何自定义Analyzer</a><br>Analyzer就是一个TokenStreamComponents的容器，因此需要确定ReuseStrategy,重写createComponents(fieldName,reader)方法,使用时调用tokenStream(fieldName,reader)方法获取TokenStream就可以了。</p>
<h1 id="Lucene常用组件"><a href="#Lucene常用组件" class="headerlink" title="Lucene常用组件"></a>Lucene常用组件</h1><ul>
<li>lucene-core</li>
<li>lucene-analyzers-common</li>
<li>lucene-analyzers</li>
<li>lucene-queryparser</li>
<li>lucene-codecs</li>
</ul>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title>Neo4j空间索引学习笔记</title>
    <url>/2016/04/03/Neo4j%E7%A9%BA%E9%97%B4%E7%B4%A2%E5%BC%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Neo4j采用Neo4j Spatial插件实现空间索引，Neo4j Spatial可使用API或Cypher执行空间查询操作，另作为插件可部署于GeoServer与uDig；与Oracle/MySQL Spatial Extention/MongoDB 2dSphere等空间模块相比，这种结合关系与空间的分析更值得尝试！</p>
<hr>
<a id="more"></a>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="http://neo4j-contrib.github.io/spatial/">neo4j spatial github官网</a><br><a href="http://www.lyonwj.com/">lyonwj博客</a></p>
<h1 id="Neo4j-Spatial简介"><a href="#Neo4j-Spatial简介" class="headerlink" title="Neo4j Spatial简介"></a>Neo4j Spatial简介</h1><p>Neo4j Spatial is a library of utilities for Neo4j that faciliates the enabling of spatial operations on data.</p>
<ul>
<li>Utilities for importing from ESRI Shapefile as well as Open Street Map files</li>
<li>Support for all the common geometry types</li>
<li>An RTree index for fast searches on geometries</li>
<li>Support for topology operations during the search (contains, within, intersects, covers, disjoint, etc.)</li>
<li>The possibility to enable spatial operations on any graph of data, regardless of the way the spatial data is stored, as long as an adapter is provided to map from the graph to the geometries.</li>
<li>Ability to split a single layer or dataset into multiple sub-layers or views with pre-configured filters</li>
</ul>
<h1 id="neo4j-spatial-安装"><a href="#neo4j-spatial-安装" class="headerlink" title="neo4j spatial 安装"></a>neo4j spatial 安装</h1><ol>
<li>在<a href="https://github.com/neo4j-contrib/m2/tree/master/releases/org/neo4j/neo4j-spatial">neo4j spatial github maven库</a>下载最新服务端Neo4j Spatial Server插件，下载后解压到neo4j plugin目录；</li>
<li>验证安装状态：以<a href="http://localhost:7474/db/data/ext/SpatialPlugin验证是否成功安装，将返回以下几类graphdb的操作">http://localhost:7474/db/data/ext/SpatialPlugin验证是否成功安装，将返回以下几类graphdb的操作</a><ul>
<li>addSimplePointLayer,addEditableLayer,addCQLDynamicLayer,addGeometryWKTToLayer</li>
<li>addNodeToLayer,addNodesToLayer,updateGeometryFromWKT</li>
<li>getLayer,findClosestGeometries, findGeometriesWithinDistance,findGeometriesInBBox</li>
</ul>
</li>
<li>索引新建<ul>
<li>Create a Spatial index</li>
<li>Create nodes with lat/lon data as properties</li>
<li>Add these nodes to the Spatial index</li>
</ul>
</li>
<li>RTree关系可视化<br><img src="RTreeRelationship.png" alt="RTree索引"><br>Neo4j Spatial REST服务可参考<a href="http://neo4j-contrib.github.io/spatial/">Neo4j Spatial v0.12-neo4j-2.0.0-SNAPSHOT文档</a></li>
</ol>
<h1 id="neo4j-spatial应用"><a href="#neo4j-spatial应用" class="headerlink" title="neo4j spatial应用"></a>neo4j spatial应用</h1><p>The technology industry and open source groups are building <strong>Spatial tools (“where” analysis) and Graph tools (relationship analysis)</strong> so that businesses can improve their insight on patterns, trends, and (perhaps most importantly) outliers in the networks.</p>
<ul>
<li><a href="http://www.lyonwj.com/using-neo4j-spatial-and-leaflet-js-with-mapbox">using-neo4j-spatial-and-leaflet-js-with-mapbox</a></li>
<li><a href="http://neo4j.com/blog/neo4j-spatial-part1-finding-things-close-to-other-things/">neo4j-spatial-part1-finding-things-close-to-other-thing</a></li>
<li><a href="http://www.lyonwj.com/mapping-the-worlds-airports-with-neo4j-spatial-and-openflights-part-1">Mapping the World’s Airports With Neo4j Spatial and Openflights</a></li>
<li><a href="http://neo4j.com/blog/geospatial-indexing-us-congress-neo4j/">Geospatial Indexing US Congressional Districts with Neo4j-spatial</a></li>
<li><a href="http://neo4j.com/news/webinar-recommend-restaurants-intro-neo4j-spatial/">Webinar: Recommend Restaurants Near Me: Introduction to Neo4j Spatial</a></li>
<li><a href="http://neo4j.com/blog/outliers-opportunities-graph-spatial/">Finding Valuable Outliers and Opportunities Using Graph and Spatial</a></li>
<li><a href="http://legis-graph.github.io/legis-graph-spatial/">legis-graph-spatial</a></li>
</ul>
<h1 id="Java构建Neo4j-空间索引"><a href="#Java构建Neo4j-空间索引" class="headerlink" title="Java构建Neo4j 空间索引"></a>Java构建Neo4j 空间索引</h1><p><a href="https://structr.org/blog/distance-queries-with-neo4j-spatial">参考distance-queries-with-neo4j-spatial</a><br><a href="https://gist.github.com/geosmart/0559745a69875e9f8876aeecda10f86b">gist代码示例：Neo4j Emberded 嵌入式SpringBean配置</a><br><a href="https://gist.github.com/geosmart/19e6e4cb0c953e1b63e9afe48425de8f">gist代码示例：Java实现Neo4j Spatial新建索引和空间查询测试用例</a>  </p>
<h1 id="关于withinDistance查询结果排序问题"><a href="#关于withinDistance查询结果排序问题" class="headerlink" title="关于withinDistance查询结果排序问题"></a>关于withinDistance查询结果排序问题</h1><ul>
<li><p>球面距离计算采用OrthodromicDistance算法<br><a href="http://www.movable-type.co.uk/scripts/latlong-db.html">OrthodromicDistance算法</a>：<code>d = acos( sin(lat1)*sin(lat2) + cos(lat1)*cos(lat2)*cos(lon2-lon1) ) * R</code>，<br>Neo4j-Spatial中的实现：<code>org.neo4j.gis.spatial.pipes.processing.OrthodromicDistance</code></p>
</li>
<li><p>返回结果默认以命中目标坐标与查询中心点坐标的距离进行排序<br>参考Neo4j Spatial 源码测试用例中的：<a href="https://github.com/neo4j-contrib/spatial/blob/ca7bb0f6db16bf1b012a4365bc17ca2881816106/src/test/java/org/neo4j/gis/spatial/TestSimplePointLayer.java">TestSimplePointLayer</a>中的checkPointOrder，<br>查询示例：<code>List&lt;GeoPipeFlow&gt; res = GeoPipeline. startNearestNeighborLatLonSearch( layer, start, distance).sort(&quot;OrthodromicDistance&quot;).toList();</code></p>
</li>
</ul>
<h1 id="neo4j-spatial-query-示例"><a href="#neo4j-spatial-query-示例" class="headerlink" title="neo4j spatial query 示例"></a>neo4j spatial query 示例</h1><h2 id="withinDistance缓存区查询"><a href="#withinDistance缓存区查询" class="headerlink" title="withinDistance缓存区查询"></a>withinDistance缓存区查询</h2><p>查询点120.678966,31.300864周边0.1km范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;withinDistance:[&lt;y&gt;, &lt;x&gt;, &lt;max distance in km&gt;]&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>) <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>
<h2 id="bbox矩形查询"><a href="#bbox矩形查询" class="headerlink" title="bbox矩形查询"></a>bbox矩形查询</h2><p>查询由点1(120.678966,31.300864)与点2(120.978966,31.330864)构成的BBox矩形范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;bbox:[&lt;min x&gt;, &lt;max x&gt;, &lt;min y&gt;, &lt;max y&gt;]&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'bbox:[120.678966,120.978966,31.300864,31.330864]'</span>) <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>
<h2 id="withinWKTGeometry查询"><a href="#withinWKTGeometry查询" class="headerlink" title="withinWKTGeometry查询"></a>withinWKTGeometry查询</h2><p>查询由点1(120.678966,31.300864)与点2(120.978966,31.330864)构成的Polygon多边形范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;withinWKTGeometry:POLYGON((&lt;x1&gt; &lt;y1&gt;, ..., &lt;xN&gt; &lt;yN&gt;, &lt;x1&gt; &lt;y1&gt;))&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> n = node:geoindex(<span class="string">'withinWKTGeometry:POLYGON ((120.678966 31.300864, 120.678966 31.330864, 120.978966 31.330864, 120.978966 31.300864, 120.678966 31.300864))'</span>)  <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>
<h2 id="空间索引和关系遍历联合查询"><a href="#空间索引和关系遍历联合查询" class="headerlink" title="空间索引和关系遍历联合查询"></a>空间索引和关系遍历联合查询</h2><p>联合geom索引图层和match进行查询</p>
<ul>
<li>查询指定范围&amp;&amp;指定path路径中的节点</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>)</span><br><span class="line"><span class="keyword">match</span> <span class="keyword">path</span>=(:DIS&#123;<span class="built_in">text</span>:<span class="string">'工业园区'</span>&#125;)-[:BELONGTO ]-(:POI&#123;<span class="built_in">text</span>:<span class="string">'拙政别墅'</span>&#125;)</span><br><span class="line"><span class="keyword">where</span> n <span class="keyword">in</span> nodes(<span class="keyword">path</span>)</span><br><span class="line"><span class="keyword">return</span> n,<span class="keyword">path</span></span><br></pre></td></tr></table></figure>
<p>优化后</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile <span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>)</span><br><span class="line"><span class="keyword">match</span> <span class="keyword">path</span>=(:DIS&#123;<span class="built_in">text</span>:<span class="string">'工业园区'</span>&#125;)&lt;-[:BELONGTO ]-(n)</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">path</span></span><br></pre></td></tr></table></figure>
<p>查询结果可视化效果图<br><img src="spatialQuery.png" alt="空间索引和关系遍历联合查询"></p>
<ul>
<li>联合查询：withinWKTGeometry空间过滤与match属性过滤</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">profile <span class="keyword">start</span> n = node:geoindex(<span class="string">'withinWKTGeometry:POLYGON ((120.678966 31.300864, 120.678966 31.330864, 120.978966 31.330864, 120.978966 31.300864, 120.678966 31.300864))'</span>)</span><br><span class="line"><span class="keyword">match</span> (n)</span><br><span class="line"><span class="keyword">where</span> (n.ruleabbr <span class="keyword">in</span> [<span class="string">'POI'</span>,<span class="string">'STR'</span>]) <span class="keyword">and</span> n.spapriority=<span class="number">1</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">ANY</span>(adtext <span class="keyword">IN</span> n.adtext <span class="keyword">WHERE</span> adtext =~ <span class="string">'.*公司.*'</span> )</span><br><span class="line"><span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>
<ul>
<li>CypherQL必须先执行空间索引，再执行Relation过滤，这样每个空间围内的Node都要进行Relationship过滤，效率较低；  </li>
<li>若能先执行Match再执行空间过滤，可提高SpatialIndex命中率</li>
<li>若无分页需求，可临时采用NativeAPI进行Match过滤，再以SpatialIndex withinDiatance过滤。  </li>
<li>若需要分页的话skip limit必须在CypherQL中实现，但是空间索引与关系遍历并行的CQL怎么写？暂时无解！</li>
</ul>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="建空间索引内存溢出问题"><a href="#建空间索引内存溢出问题" class="headerlink" title="建空间索引内存溢出问题"></a>建空间索引内存溢出问题</h2><p>neo4j transaction优化方案：每n条手动提交事物  </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="comment">// 获取所有地址节类型，针对不同地址节分别构建R树索引</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createAddressNodeIndex_spatial</span><span class="params">(Set&lt; String&gt; addressNodes)</span> </span>&#123;</span><br><span class="line">true<span class="keyword">final</span> <span class="keyword">long</span> commitInterval = <span class="number">10000</span>;</span><br><span class="line">trueTransaction tx = graphDBService.beginTx();</span><br><span class="line">true<span class="keyword">try</span> &#123;</span><br><span class="line">truetrue<span class="keyword">long</span> i = <span class="number">0L</span>;</span><br><span class="line">truetrue<span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">truetrue<span class="keyword">for</span> (String addressNodeLabel : addressNodes) &#123;</span><br><span class="line">truetruetrueIndex&lt; Node&gt; index = getSpatialIndex(UADBLabel.valueOf(addressNodeLabel));</span><br><span class="line">truetruetrueResourceIterator&lt; Node&gt; nodes = graphDBService.findNodes(createAddresseNodeLable(addressNodeLabel));</span><br><span class="line"></span><br><span class="line">truetruetrue<span class="keyword">while</span> (nodes.hasNext()) &#123;</span><br><span class="line">truetruetruetrueNode node = nodes.next();</span><br><span class="line">truetruetruetrue<span class="keyword">if</span> (node.getProperty(<span class="string">"lon"</span>, <span class="keyword">null</span>) != <span class="keyword">null</span> &amp;&amp; node.getProperty(<span class="string">"lat"</span>, <span class="keyword">null</span>) != <span class="keyword">null</span>) &#123;</span><br><span class="line">truetruetruetruetrueindex.add(node, <span class="string">""</span>, <span class="string">""</span>);</span><br><span class="line">truetruetruetruetruei++;</span><br><span class="line">truetruetruetrue&#125;</span><br><span class="line">truetruetruetrue<span class="comment">// 处理内存溢出</span></span><br><span class="line">truetruetruetrue<span class="keyword">if</span> (i % commitInterval == <span class="number">0</span>) &#123;</span><br><span class="line">truetruetruetruetruetx.success();</span><br><span class="line">truetruetruetruetruetx.close();</span><br><span class="line">truetruetruetruetruelog.info(<span class="string">"indexing (&#123;&#125; nodes added) ... time in seconds:&#123;&#125;"</span>, i,</span><br><span class="line">truetruetruetruetruetruetrueDateUtil.convertMillis2DateStr(System.currentTimeMillis() - startTime));</span><br><span class="line">truetruetruetruetruetx = graphDBService.beginTx();</span><br><span class="line">truetruetruetrue&#125;</span><br><span class="line">truetruetrue&#125;</span><br><span class="line">truetrue&#125;</span><br><span class="line">truetruetx.success();</span><br><span class="line">true&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">truetruetx.close();</span><br><span class="line">true&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建空间索引速度还是偏慢，35万左右的数据量建索引花了将近1.5小时。</p>
]]></content>
      <categories>
        <category>存储层</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title>JMS学习笔记</title>
    <url>/2016/07/27/JMS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>JMS即Java消息服务（Java Message Service）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。<br>Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。</p>
<blockquote>
<p>JMS (Java Message Service) is an API that provides the facility to create， send and read messages。<br>It provides loosely coupled（松耦合）， reliable（可靠） and asynchronous（异步） communication。</p>
</blockquote>
<hr>
<a id="more"></a> 
<h1 id="JMS简介"><a href="#JMS简介" class="headerlink" title="JMS简介"></a>JMS简介</h1><p>JMS全称是Java Message Service。其是JavaEE技术规范中的一个重要组成部分，是一种企业消息处理的规范。它的作用就像一个智能交换机，负责路由分布式应用中各个组件所发出的消息；</p>
<ul>
<li>JMS提供了一组通用的Java API，开发者可以通过API来 创建，发送，接收，读取 、消息；</li>
<li>JMS是一种和具体实现厂商无关的API。它的作用类似于JDBC。不管底层采用何种消息服务器的实现，应用程序总是面向通用的JMS API编程；</li>
<li>常用的有apache的ActiveMQ，Jboss的HornetQ</li>
</ul>
<h1 id="JMS优势"><a href="#JMS优势" class="headerlink" title="JMS优势"></a>JMS优势</h1><p>1。 异步 Asynchronous: To receive the message， client is not required to send request。 Message will arrive automatically to the client。 消息采用异步处理机制，避免客户机等待。<br>2。 可靠 Reliable: It provides assurance that message is delivered。<br>JMS可以持久的保存消息，因而提高系统的可靠性。<br>3。 效率：JMS允许一条消息同时发给多个接受者，更具效率。</p>
<h1 id="JMS总体架构"><a href="#JMS总体架构" class="headerlink" title="JMS总体架构"></a>JMS总体架构</h1><p>JMS的架构总体架构分3部分：<br>1。 JMS服务器，路由消息的服务系统，广义上说就是服务器，比如JBOSS，GLASSFISH，WAS8；<br>2。 JMS生产者，负责创建并发送消息的程序组件；<br>3。 JMS消费者，负责读取并处理消息的程序组件。</p>
<h1 id="JMS的消息机制模型"><a href="#JMS的消息机制模型" class="headerlink" title="JMS的消息机制模型"></a>JMS的消息机制模型</h1><p>JMS的消息机制模型主要分2类:</p>
<h2 id="点对点PTP模型"><a href="#点对点PTP模型" class="headerlink" title="点对点PTP模型"></a>点对点PTP模型</h2><ul>
<li>PTP消息处理模型为应用中的各个逻辑处理单元提供可靠的通信支持；</li>
<li>在PTP通信中，JMS把每一个消息传递给一个消息消费者；</li>
<li>JMS系统保证消息传递给消费者，消息不会同时被多个消费者接受；</li>
<li>如果消息消费者不在连接范围内，JMS会自动保证消息不会丢失。直到消息消费者进入连接，消息将自动送达。因此JMS需要将消息保存到永久介质上如数据库；</li>
</ul>
<h2 id="发布-订阅Pub-Sub模型"><a href="#发布-订阅Pub-Sub模型" class="headerlink" title="发布/订阅Pub-Sub模型"></a>发布/订阅Pub-Sub模型</h2><ul>
<li>在这种模型中，每个消息被发送到一个消息主题，该主题可以拥有多个订阅者。</li>
<li>JMS系统负责将消息的副本传给该主题的每个订阅者。</li>
</ul>
<hr>
<h1 id="Point-to-Point-PTP-Messaging-Domain"><a href="#Point-to-Point-PTP-Messaging-Domain" class="headerlink" title="Point-to-Point (PTP) Messaging Domain"></a>Point-to-Point (PTP) Messaging Domain</h1><p>Point-to-Point (PTP) Messaging Domain(点对点通信模型)是基于队列(Queue)的，对于PTP消息模型而言，它的消息目的是一个消息队列(Queue)，消息生产者每次发送消息总是把消息送入消息队列中，消息消费者总是从消息队列中读取消息。先进队列的消息将先被消息消费者读取。<br><img src="JMS_PTP_Model.png" alt="JMS PTP Model"></p>
<blockquote>
<p>In PTP model， one message is delivered to one receiver only。 Here，<br>Queue is used as a message oriented middleware (MOM) 面向消息的中间件。<br>The Queue is responsible to hold the message until receiver is ready。（串行）<br>In PTP model， there is no timing dependency between sender and receiver。</p>
</blockquote>
<h2 id="PTP模型的对象的主要概念和方法"><a href="#PTP模型的对象的主要概念和方法" class="headerlink" title="PTP模型的对象的主要概念和方法"></a>PTP模型的对象的主要概念和方法</h2><h3 id="Queue（队列）"><a href="#Queue（队列）" class="headerlink" title="Queue（队列）"></a>Queue（队列）</h3><p>Queue由JMS Provider 管理，队列由队列名识别，客户端可以通过JNDI 接口用队列名得到一个队列对象。</p>
<h3 id="TemporaryQueue（临时队列）"><a href="#TemporaryQueue（临时队列）" class="headerlink" title="TemporaryQueue（临时队列）"></a>TemporaryQueue（临时队列）</h3><p>由QueueConnection 创建，而且只能由创建它的QueueConnection 使用。</p>
<h3 id="QueueConnectionFactory"><a href="#QueueConnectionFactory" class="headerlink" title="QueueConnectionFactory"></a>QueueConnectionFactory</h3><p>客户端用QueueConnectionFactory 创建QueueConnection 对象。</p>
<h3 id="QueueConnection"><a href="#QueueConnection" class="headerlink" title="QueueConnection"></a>QueueConnection</h3><p>一个到JMS PTP provider 的连接，客户端可以用QueueConnection 创建QueueSession 来发送和接收消息。</p>
<h3 id="QueueSession"><a href="#QueueSession" class="headerlink" title="QueueSession"></a>QueueSession</h3><p>QueueSession提供一些方法创建QueueReceiver，QueueSender，QueueBrowser 和TemporaryQueue。<br>如果在QueueSession 关闭时，有一些消息已经被收到，但还没有被签收(acknowledged)，那么，当接收者下次连接到相同的队列时，这些消息还会被再次接收。</p>
<h3 id="QueueReceiver"><a href="#QueueReceiver" class="headerlink" title="QueueReceiver"></a>QueueReceiver</h3><p>客户端用QueueReceiver 接收队列中的消息，如果用户在QueueReceiver中设定了消息选择条件，那么不符合条件的消息会留在队列中，不会被接收到。</p>
<h3 id="QueueSender"><a href="#QueueSender" class="headerlink" title="QueueSender"></a>QueueSender</h3><p>客户端用QueueSender 发送消息到队列</p>
<h3 id="QueueBrowser"><a href="#QueueBrowser" class="headerlink" title="QueueBrowser"></a>QueueBrowser</h3><p>客户端可以QueueBrowser 浏览队列中的消息，但不会收走消息。</p>
<h3 id="QueueRequestor"><a href="#QueueRequestor" class="headerlink" title="QueueRequestor"></a>QueueRequestor</h3><p>JMS 提供QueueRequestor 类简化消息的收发过程。<br>QueueRequestor 的构造函数有两个参数:QueueSession 和queue，QueueRequestor 通过创建一个临时队列来完成最终的收发消息请求。</p>
<h3 id="Reliability可靠性"><a href="#Reliability可靠性" class="headerlink" title="Reliability可靠性"></a>Reliability可靠性</h3><p>队列可以长久地保存消息直到接收者收到消息。<br>接收者不需要因为担心消息会丢失而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。</p>
<hr>
<h1 id="Publisher-Subscriber-Pub-Sub-Messaging-Domain"><a href="#Publisher-Subscriber-Pub-Sub-Messaging-Domain" class="headerlink" title="Publisher/Subscriber (Pub/Sub) Messaging Domain"></a>Publisher/Subscriber (Pub/Sub) Messaging Domain</h1><p>JMS Publisher/Subscriber (Pub/Sub) Messaging Domain(出版者/订阅者模型)模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作主题(topic)。</p>
<ul>
<li>主题可以被认为是消息的传输中介；</li>
<li>发布者(publisher)发布消息到主题；</li>
<li>订阅者(subscribe) 从主题订阅消息；</li>
<li>主题使得消息订阅者和消息发布者保持互相独立，不需要接触即可保证消息的传送。</li>
</ul>
<p><img src="JMS_Pub-Sub_Model.png" alt="JMS Pub/Sub Model"></p>
<blockquote>
<p>In Pub/Sub model， one message is delivered to all the subscribers。 It is like broadcasting。 Here，<br>Topic（主题） is used as a message oriented middleware that is responsible to hold and deliver messages。<br>In PTP model， there is timing dependency between publisher and subscriber。</p>
</blockquote>
<h2 id="JMS-Pub-Sub-模型中的主要概念和对象"><a href="#JMS-Pub-Sub-模型中的主要概念和对象" class="headerlink" title="JMS Pub/Sub 模型中的主要概念和对象"></a>JMS Pub/Sub 模型中的主要概念和对象</h2><h3 id="subscription（订阅）"><a href="#subscription（订阅）" class="headerlink" title="subscription（订阅）"></a>subscription（订阅）</h3><p>消息订阅分为非持久订阅(non-durable subscription)和持久订阅(durable subscrip-tion)：</p>
<ul>
<li>非持久订阅只有当客户端处于激活状态，也就是和JMS Provider 保持连接状态才能收到发送到某个主题的消息，而当客户端处于离线状态，这个时间段发到主题的消息将会丢失，永远不会收到。</li>
<li>持久订阅时，客户端向JMS 注册一个识别自己身份的ID，当这个客户端处于离线时，JMS Provider 会为这个ID 保存所有发送到主题的消息，当客户再次连接到JMS Provider时，会根据自己的ID 得到所有当自己处于离线时发送到主题的消息。</li>
</ul>
<h3 id="Topic（主题）"><a href="#Topic（主题）" class="headerlink" title="Topic（主题）"></a>Topic（主题）</h3><ul>
<li>Topic主题由JMS Provider 管理，</li>
<li>主题由主题名识别</li>
<li>客户端可以通过JNDI 接口用主题名得到一个主题对象。</li>
<li>JMS没有给出主题的组织和层次结构的定义，由JMS Provider 自己定义</li>
</ul>
<h3 id="TemporaryTopic（临时主题）"><a href="#TemporaryTopic（临时主题）" class="headerlink" title="TemporaryTopic（临时主题）"></a>TemporaryTopic（临时主题）</h3><p>临时主题由TopicConnection创建，而且只能由创建它的TopicConnection使用。临时主题不能提供持久订阅功能。</p>
<h3 id="TopicConnectionFactory"><a href="#TopicConnectionFactory" class="headerlink" title="TopicConnectionFactory"></a>TopicConnectionFactory</h3><p>客户端用TopicConnectionFactory创建TopicConnection对象。</p>
<h3 id="TopicConnection"><a href="#TopicConnection" class="headerlink" title="TopicConnection"></a>TopicConnection</h3><p>TopicConnection是一个到JMS Pub/Sub provider的连接，客户端可以用TopicConnection创建TopicSession 来发布和订阅消息。</p>
<h3 id="TopicSession"><a href="#TopicSession" class="headerlink" title="TopicSession"></a>TopicSession</h3><p>TopicSession 提供一些方法创建TopicPublisher，TopicSubscriber，TemporaryTopic。它还提供unsubscribe方法取消消息的持久订阅。</p>
<h3 id="TopicPublisher"><a href="#TopicPublisher" class="headerlink" title="TopicPublisher"></a>TopicPublisher</h3><p>客户端用TopicPublisher 发布消息到主题。</p>
<h3 id="TopicSubscriber"><a href="#TopicSubscriber" class="headerlink" title="TopicSubscriber"></a>TopicSubscriber</h3><p>客户端用TopicSubscriber 接收发布到主题上的消息。可以在TopicSubscriber 中设置消息过滤功能，这样，不符合要求的消息不会被接收。</p>
<h3 id="Durable-TopicSubscriber"><a href="#Durable-TopicSubscriber" class="headerlink" title="Durable TopicSubscriber"></a>Durable TopicSubscriber</h3><p>如果一个客户端需要持久订阅消息，可以使用Durable TopicSubscriber，TopSession 提供一个方法createDurableSubscriber创建Durable TopicSubscriber 对象。</p>
<h3 id="Recovery-and-Redelivery（恢复和重新派送）"><a href="#Recovery-and-Redelivery（恢复和重新派送）" class="headerlink" title="Recovery and Redelivery（恢复和重新派送）"></a>Recovery and Redelivery（恢复和重新派送）</h3><p>恢复和重新派送非持久订阅状态下，不能恢复或重新派送一个未签收的消息。只有持久订阅才能恢复或重新派送一个未签收的消息</p>
<h3 id="TopicRequestor"><a href="#TopicRequestor" class="headerlink" title="TopicRequestor"></a>TopicRequestor</h3><ul>
<li>JMS 提供TopicRequestor 类简化消息的收发过程。</li>
<li>TopicRequestor的构造函数有两个参数:TopicSession和topic。</li>
<li>TopicRequestor 通过创建一个临时主题来完成最终的发布和接收消息请求。</li>
</ul>
<h3 id="Reliability（可靠性）"><a href="#Reliability（可靠性）" class="headerlink" title="Reliability（可靠性）"></a>Reliability（可靠性）</h3><ul>
<li>当所有的消息必须被接收，则用持久订阅模式。</li>
<li>当丢失消息能够被容忍，则用非持久订阅模式。</li>
</ul>
<hr>
<h1 id="JMS-Programming-Model（JMS编程模型）"><a href="#JMS-Programming-Model（JMS编程模型）" class="headerlink" title="JMS Programming Model（JMS编程模型）"></a>JMS Programming Model（JMS编程模型）</h1><p><img src="JMS_Programming_Model.png" alt="JMS Programming Model"></p>
<h2 id="ConnectionFactory（连接工厂）"><a href="#ConnectionFactory（连接工厂）" class="headerlink" title="ConnectionFactory（连接工厂）"></a>ConnectionFactory（连接工厂）</h2><p>它由服务器管理员创建，并绑定到JNDI树上，JMS客户端使用JNDI查找，定位连接工厂，然后利用连接工厂创建JMS连接。</p>
<h2 id="Connection（JMS连接）"><a href="#Connection（JMS连接）" class="headerlink" title="Connection（JMS连接）"></a>Connection（JMS连接）</h2><p>连接表示客户机和服务器之间的活动连接。JMS通过连接工厂创建连接。JMS是一个相当重要的对象。通常，每个客户机使用单独的连接，而每个连接则可以连接多个JMS目的。</p>
<h2 id="Session（JMS会话）"><a href="#Session（JMS会话）" class="headerlink" title="Session（JMS会话）"></a>Session（JMS会话）</h2><p>会话表示客户机与JMS服务器之间的通信状态。JMS会话建立在连接之上，表示JMS客户机与服务器之间的通信线程。会话定义了消息的顺序。JMS使用会话进行事务性的消息处理。</p>
<h2 id="Destination（JMS消息目的地）"><a href="#Destination（JMS消息目的地）" class="headerlink" title="Destination（JMS消息目的地）"></a>Destination（JMS消息目的地）</h2><p>Destination即消息生产者发送消息的目的地，也就是消息消费者获取消息的消息源。</p>
<h2 id="Message-Producer-（JMS消息生产者）"><a href="#Message-Producer-（JMS消息生产者）" class="headerlink" title="Message Producer （JMS消息生产者）"></a>Message Producer （JMS消息生产者）</h2><p>消息生产者负责创建消息并将消息发送到消息目的。</p>
<h2 id="Message-Consumer-（JMS消息消费者）"><a href="#Message-Consumer-（JMS消息消费者）" class="headerlink" title="Message Consumer （JMS消息消费者）"></a>Message Consumer （JMS消息消费者）</h2><p>消息消费者负责接收消息并读取消息内容。</p>
<h1 id="JMS消息的确认方式"><a href="#JMS消息的确认方式" class="headerlink" title="JMS消息的确认方式"></a>JMS消息的确认方式</h1><p>消息的确认是指消息接受者接到消息，并做出了对应的处理之后，它将回送一个确认消息。<br>对于 <strong>非事务性</strong> 会话，创建会话时应该指定确定方式，JMS定义了3种确认方式:</p>
<h2 id="Auto-ACKnowledge-自动通知"><a href="#Auto-ACKnowledge-自动通知" class="headerlink" title="Auto_ACKnowledge    自动通知"></a>Auto_ACKnowledge    自动通知</h2><p>对于同步消费者，Receive方法调用返回，且没有异常发生时，将自动对收到的消息予以确认。<br>对于异步消息，当onMessage方法返回，且没有异常发生时，即对收到的消息自动确认。  </p>
<h2 id="Client-AcKnowledge-客户端自行决定通知时机"><a href="#Client-AcKnowledge-客户端自行决定通知时机" class="headerlink" title="Client_AcKnowledge    客户端自行决定通知时机"></a>Client_AcKnowledge    客户端自行决定通知时机</h2><p>这种方式要求客户端使用javax。jms。Message。acknowledge()方法完成确认。  </p>
<h2 id="Dups-OK-ACKnowledge-延时-批量通知"><a href="#Dups-OK-ACKnowledge-延时-批量通知" class="headerlink" title="Dups_OK_ACKnowledge    延时/批量通知"></a>Dups_OK_ACKnowledge    延时/批量通知</h2><p>这种确认方式允许JMS不必急于确认收到的消息，允许在收到多个消息之后一次完成确认，<br>与Auto_AcKnowledge相比，这种确认方式在某些情况下可能更有效，因为没有确认，当系统崩溃或者网络出现故障的时候，消息可以被重新传递。 </p>
<hr>
<p>参考阅读<br><a href="http://docs.oracle.com/cd/E19148-01/820-0533/aeraq/index.html">Sun Java System Message Queue</a><br><a href="http://www.javatpoint.com/jms-tutorial">jms-tutorial</a>  </p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch集群部署</title>
    <url>/2016/07/22/Elasticsearch%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>Elasticsearch V2.3.4 集群部署记录：3个Node，6个Shard，2个Replica，能保证一台服务器宕机服务还能正常运行，且后期容易扩展到6个Node；</p>
<hr>
<a id="more"></a> 
<h1 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h1><p>sudo yum install java-1.8.0-openjdk.x86_64<br>Centos7自带openJdk8</p>
<h1 id="swap配置"><a href="#swap配置" class="headerlink" title="swap配置"></a>swap配置</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#_swapping_is_the_death_of_performance">swapping_is_the_death_of_performance</a>,<br>ElasticSearch建议将 /proc/sys/vm/swappiness 设置为 0。默认设置为30。<br>查看当前swap分区设置<code>cat /proc/sys/vm/swappiness</code><br>临时修改值：<code>sudo sysctl vm.swappiness=0</code> / <code>sudo swapoff -a</code><br>永久修改值：<code>vim /etc/sysctl.conf</code>，在最后加一行<code>vm.swappiness = 0</code></p>
<h1 id="修改hostname"><a href="#修改hostname" class="headerlink" title="修改hostname"></a>修改hostname</h1><p>设置hostname为v3es1，并查看修改结果<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">es1</span></span><br><span class="line">hostnamectl set-hostname es1</span><br><span class="line">hostnamectl set-hostname es1 --static</span><br><span class="line">hostnamectl status</span><br></pre></td></tr></table></figure></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">es2</span></span><br><span class="line">hostnamectl set-hostname es2</span><br><span class="line">hostnamectl set-hostname es2 --static</span><br><span class="line">hostnamectl status</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">es3</span></span><br><span class="line">hostnamectl set-hostname es3</span><br><span class="line">hostnamectl set-hostname es3 --static</span><br><span class="line">hostnamectl status</span><br></pre></td></tr></table></figure>
<p><code>vim  /etc/hosts</code><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> es节点配置</span></span><br><span class="line">193.168.201.213 es1.es.com es1</span><br><span class="line">193.168.201.85  es2.es.com es2</span><br><span class="line">193.168.201.117 es3.es.com es3</span><br></pre></td></tr></table></figure></p>
<h2 id="局域网hosts配置"><a href="#局域网hosts配置" class="headerlink" title="局域网hosts配置"></a>局域网hosts配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 局域网hosts配置es</span></span><br><span class="line">193.168.201.223 es1.es.com</span><br><span class="line">193.168.201.223 www.es1.es.com</span><br><span class="line">193.168.201.252  es2.es.com</span><br><span class="line">193.168.201.252  www.es2.es.com</span><br><span class="line">193.168.201.117  es3.es.com</span><br><span class="line">193.168.201.117  www.es3.es.com</span><br></pre></td></tr></table></figure>
<h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">停止firewall</span></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"><span class="meta">#</span><span class="bash">禁止firewall开机启动 </span></span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>
<h1 id="新增用户"><a href="#新增用户" class="headerlink" title="新增用户"></a>新增用户</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /data/elasticsearch/&#123;data,work,plugins,scripts&#125; </span><br><span class="line">useradd elasticsearch -s /bin/bash </span><br><span class="line"><span class="meta">#</span><span class="bash"> 1</span></span><br><span class="line">passwd elasticsearch</span><br><span class="line">vim /etc/sudoers	</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新增</span></span><br><span class="line">elasticsearch    ALL=(ALL)       ALL</span><br><span class="line"><span class="meta">#</span><span class="bash"> 授权</span></span><br><span class="line">mkdir /var/log/elasticsearch</span><br><span class="line">chown -R elasticsearch:elasticsearch /var/log/elasticsearch /data/elasticsearch</span><br></pre></td></tr></table></figure>
<h1 id="安装elasticsearch"><a href="#安装elasticsearch" class="headerlink" title="安装elasticsearch"></a>安装elasticsearch</h1><p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-centos-7">how-to-install-and-configure-elasticsearch-on-centos-7</a></p>
<h2 id="下载rpm包"><a href="#下载rpm包" class="headerlink" title="下载rpm包"></a>下载rpm包</h2><p>cd /mnt<br><code>wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.3.4/elasticsearch-2.3.4.rpm</code></p>
<h2 id="yum本地安装"><a href="#yum本地安装" class="headerlink" title="yum本地安装"></a>yum本地安装</h2><p><code>cd /mnt &amp;&amp; sudo yum localinstall elasticsearch-2.3.4.rpm</code> </p>
<h2 id="设置自启动"><a href="#设置自启动" class="headerlink" title="设置自启动"></a>设置自启动</h2><p><code>sudo systemctl daemon-reload</code><br><code>sudo systemctl enable elasticsearch.service</code></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p><code>vim /etc/elasticsearch/elasticsearch.yml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">cluster.name:</span> <span class="string">cloudx_web</span></span><br><span class="line"><span class="attr">node.name:</span> <span class="string">$&#123;HOSTNAME&#125;</span></span><br><span class="line"><span class="attr">node.master:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">node.data:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">index.number_of_shards:</span> <span class="number">6</span></span><br><span class="line"><span class="attr">index.number_of_replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">network.host:</span> <span class="string">$&#123;HOSTNAME&#125;</span></span><br><span class="line"><span class="attr">index.max_result_window:</span> <span class="number">10000000</span></span><br><span class="line"><span class="attr">discovery.zen.minimum_master_nodes:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">discovery.zen.ping.unicast.hosts:</span> <span class="string">[es1,es2,es3]</span></span><br><span class="line"><span class="attr">discovery.zen.ping.multicast.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">path.data:</span> <span class="string">/data/elasticsearch</span> </span><br><span class="line"><span class="attr">http.cors.allow-origin:</span> <span class="string">"*"</span></span><br><span class="line"><span class="attr">http.cors.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>复制到集群：<code>scp  /etc/elasticsearch/elasticsearch.yml root@es1:/etc/elasticsearch/</code></p>
<blockquote>
<p>理想状态下，3个Node，6个Shard，2个Replica，能保证一台服务器宕机服务还能正常运行，且后期容易扩展到6个Node；<br>但如果存储成本高，可改为1个Replica<br>另配置<code>discovery.zen.minimum_master_nodes=2</code>可保证不会出现脑裂问题；  </p>
</blockquote>
<p>3个节点正常运行<br><img src="es_cluster_shard1.png" alt="3个节点正常运行"><br>节点3挂了<br><img src="es_cluster_shard2.png" alt="节点3挂了"><br>replica自动复制迁移<br><img src="es_cluster_shard3.png" alt="replica自动复制迁移"><br>节点3恢复正常<br><img src="es_cluster_shard4.png" alt="节点3恢复正常"></p>
<h2 id="配置elasticsearch-heap大小"><a href="#配置elasticsearch-heap大小" class="headerlink" title="配置elasticsearch heap大小"></a>配置elasticsearch heap大小</h2><p><code>vim /etc/sysconfig/elasticsearch</code><br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ES_HEAP_SIZE=3G</span></span><br><span class="line"><span class="string">MAX_OPEN_FILES=65535</span></span><br></pre></td></tr></table></figure></p>
<h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>su elasticsearch<br><code>sudo systemctl start elasticsearch.service</code> </p>
<h2 id="查看运行状态"><a href="#查看运行状态" class="headerlink" title="查看运行状态"></a>查看运行状态</h2><p><code>service elasticsearch status</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">●</span> <span class="string">elasticsearch.service</span> <span class="bullet">-</span> <span class="string">Elasticsearch</span></span><br><span class="line">   <span class="attr">Loaded:</span> <span class="string">loaded</span> <span class="string">(/usr/lib/systemd/system/elasticsearch.service;</span> <span class="string">enabled;</span> <span class="attr">vendor preset:</span> <span class="string">disabled)</span></span><br><span class="line">   <span class="attr">Active:</span> <span class="string">active</span> <span class="string">(running)</span> <span class="string">since</span> <span class="string">日</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-24</span> <span class="number">19</span><span class="string">:56:07</span> <span class="string">CST;</span> <span class="string">8min</span> <span class="string">ago</span></span><br><span class="line">     <span class="attr">Docs:</span> <span class="string">http://www.elastic.co</span></span><br><span class="line">  <span class="attr">Process:</span> <span class="number">9370</span> <span class="string">ExecStartPre=/usr/share/elasticsearch/bin/elasticsearch-systemd-pre-exec</span> <span class="string">(code=exited,</span> <span class="string">status=0/SUCCESS)</span></span><br><span class="line"> <span class="attr">Main PID:</span> <span class="number">9374</span> <span class="string">(java)</span></span><br><span class="line">   <span class="attr">CGroup:</span> <span class="string">/system.slice/elasticsearch.service</span></span><br><span class="line">           <span class="string">└─9374</span> <span class="string">/bin/java</span> <span class="string">-Xms256m</span> <span class="string">-Xmx1g</span> <span class="string">-Djava.awt.headless=true</span> <span class="string">-XX:+UseParNewGC</span> <span class="string">-XX:+UseC...</span></span><br></pre></td></tr></table></figure>
<h2 id="测试是否成功"><a href="#测试是否成功" class="headerlink" title="测试是否成功"></a>测试是否成功</h2><p>curl -X GET ‘<a href="http://localhost:9200">http://localhost:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.250:9200">http://193.168.201.250:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.252:9200">http://193.168.201.252:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.117:9200">http://193.168.201.117:9200</a>‘</p>
<h2 id="插入测试"><a href="#插入测试" class="headerlink" title="插入测试"></a>插入测试</h2><p>curl -X POST ‘<a href="http://es1:9200/tutorial/helloworld/1">http://es1:9200/tutorial/helloworld/1</a>‘ -d ‘{ “message”: “Hello World!” }’<br>curl -X GET ‘<a href="http://es1:9200/tutorial/helloworld/1?pretty">http://es1:9200/tutorial/helloworld/1?pretty</a>‘</p>
<h2 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h2><p><code>tail -f  200 /var/log/elasticsearch/cloudx_web.log</code></p>
<h1 id="安装信息"><a href="#安装信息" class="headerlink" title="安装信息"></a>安装信息</h1><ul>
<li>安装目录：<code>/usr/share/elasticsearch/</code></li>
<li>配置目录：<code>/etc/elasticsearch</code></li>
<li>启动初始化脚本：<code>/etc/init.d/elasticsearch</code> </li>
<li>日志目录：<code>/var/log/elasticsearch</code></li>
<li>配置参数(<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html</a>)</li>
</ul>
<h1 id="删除elasticsearch"><a href="#删除elasticsearch" class="headerlink" title="删除elasticsearch"></a>删除elasticsearch</h1><p><code>yum remove  elasticsearch</code><br><code>find / -name &quot;elasticsearch&quot; -exec  rm -rf {} \;</code></p>
<h1 id="ElasticSearch插件"><a href="#ElasticSearch插件" class="headerlink" title="ElasticSearch插件"></a>ElasticSearch插件</h1><h2 id="Elastic-HQ"><a href="#Elastic-HQ" class="headerlink" title="Elastic-HQ"></a>Elastic-HQ</h2><blockquote>
<p>Monitoring, Management, and Querying Web Interface for ElasticSearch instances and clusters.<br>Benefits:</p>
<ul>
<li>Active real-time monitoring of ElasticSearch clusters and nodes.</li>
<li>Manage Indices, Mappings, Shards, Aliases, and Nodes.</li>
<li>Query UI for searching one or multiple Indices.</li>
<li>REST UI, eliminates the need for cURL and cumbersome JSON formats.</li>
<li>No software to install/download. 100% web browser-based.</li>
<li>Optimized to work on mobile phones, tablets, and other small screen devices.</li>
<li>Easy to use and attractive user interface.</li>
<li>Free (as in Beer)</li>
</ul>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install royrusso/elasticsearch-HQ</code>  </li>
<li>地址：<a href="http://es1.es.com9200/_plugin/hq/">http://es1.es.com9200/_plugin/hq/</a> </li>
</ul>
<h2 id="ElasticSearch-Kopf"><a href="#ElasticSearch-Kopf" class="headerlink" title="ElasticSearch-Kopf"></a>ElasticSearch-Kopf</h2><blockquote>
<p>Kopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install lmenezes/elasticsearch-kopf</code> </li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/kopf/">http://es1.es.com:9200/_plugin/kopf/</a></li>
</ul>
<h2 id="Elasticsearch-head"><a href="#Elasticsearch-head" class="headerlink" title="Elasticsearch-head"></a>Elasticsearch-head</h2><blockquote>
<p>A web front end for an Elasticsearch cluster，查看集群状态</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install mobz/elasticsearch-head</code>  </li>
</ul>
<h2 id="ElasticSearch-Paramedic"><a href="#ElasticSearch-Paramedic" class="headerlink" title="ElasticSearch-Paramedic"></a>ElasticSearch-Paramedic</h2><blockquote>
<p>Paramedic is a simple yet sexy tool to monitor and inspect ElasticSearch clusters.<br>It displays real-time statistics and information about your nodes and indices, as well as shard allocation within the cluster.<br>The application is written in JavaScript, using the Ember.js framework for sanity and the Cubism.js library for visuals. While the project is useful, the codebase, with most logic in controllers, lacking proper component separation and test suite, can’t be considered mature enough, yet.</p>
</blockquote>
<ul>
<li>安装：cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install karmi/elasticsearch-paramedic/</li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/paramedic">http://es1.es.com:9200/_plugin/paramedic</a></li>
</ul>
<h2 id="ElasticSearch-Whatson"><a href="#ElasticSearch-Whatson" class="headerlink" title="ElasticSearch-Whatson"></a>ElasticSearch-Whatson</h2><blockquote>
<p>Whatson is an elasticsearch plugin to visualize the state of a cluster. It’s inpired by other excellent plugins:<br>xyu/elasticsearch-whatson</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install xyu/elasticsearch-whatson</code>  </li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/whatson">http://es1.es.com:9200/_plugin/whatson</a></li>
</ul>
<h1 id="安装问题"><a href="#安装问题" class="headerlink" title="安装问题"></a>安装问题</h1><h2 id="服务启动问题-Failed-to-created-node-environment"><a href="#服务启动问题-Failed-to-created-node-environment" class="headerlink" title="服务启动问题-Failed to created node environment"></a>服务启动问题-Failed to created node environment</h2><p>启动权限问题，必须以elasticsearch用户启动服务，不能以root启动</p>
<h2 id="配置问题-discovery-zen-ping-unicast-hosts"><a href="#配置问题-discovery-zen-ping-unicast-hosts" class="headerlink" title="配置问题-discovery.zen.ping.unicast.hosts"></a>配置问题-discovery.zen.ping.unicast.hosts</h2><p>Likely root cause: java.net.UnknownHostException: v3es1: unknown error<br>hostname -f查看fqdn</p>
<h2 id="ElasticHQ安装问题"><a href="#ElasticHQ安装问题" class="headerlink" title="ElasticHQ安装问题"></a>ElasticHQ安装问题</h2><p>关闭防火墙，设置好fqdn，关闭VPN</p>
<h2 id="discovery-zen-ping-unicast-hosts中的hostname-ping不通"><a href="#discovery-zen-ping-unicast-hosts中的hostname-ping不通" class="headerlink" title="discovery.zen.ping.unicast.hosts中的hostname ping不通"></a>discovery.zen.ping.unicast.hosts中的hostname ping不通</h2><p>日志</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">discovery.zen.ping.unicast] [es1] failed to send ping to [&#123;#zen_unicast_3#&#125;&#123;193.168.201.117&#125;&#123;es3/193.168.201.117:9300&#125;]</span><br><span class="line">SendRequestTransportException[internal:discovery/zen/unicast]]; </span><br><span class="line">nested: NodeNotConnectedException[[][es3/<span class="number">193.168</span><span class="number">.201</span><span class="number">.117</span>:<span class="number">9300</span>] Node not connected];</span><br><span class="line">at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:<span class="number">340</span>)</span><br><span class="line">[action.admin.cluster.health] [es1] no known master node, scheduling a retry</span><br></pre></td></tr></table></figure>
<p>解决：hostname忘记设置了，(╯□╰)</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>实时计算系统Storm学习笔记</title>
    <url>/2016/09/13/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9FStorm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Storm简介"><a href="#Storm简介" class="headerlink" title="Storm简介"></a>Storm简介</h1><p>Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。<br>而且支持水平扩展，具有高容错性，保证每个消息都会得到处理。<br>Storm处理速度很快（在一个小集群中，每个结点每秒可以处理数以百万计的消息）。<br>Storm的部署和运维都很便捷，更为重要的是可以使用任意编程语言来开发应用。</p>
<p>目前国内一般采用阿里巴巴开源的JStorm版本；</p>
<hr>
<a id="more"></a>
<p><a href="http://os.51cto.com/art/201312/422708.htm">参考教程</a><br><a href="http://ifeve.com/getting-started-with-stom-index/">getting-started-with-stom-index</a></p>
<h1 id="Storm典型应用案例？"><a href="#Storm典型应用案例？" class="headerlink" title="Storm典型应用案例？"></a>Storm典型应用案例？</h1><ul>
<li>数据处理流；不像其它的流处理系统，Storm不需要中间队列。</li>
<li>连续计算：连续发送数据到客户端，使它们能够实时更新并显示结果，如网站指标。</li>
<li>分布式远程过程调用：频繁的CPU密集型操作并行化。</li>
</ul>
<h1 id="Storm组件"><a href="#Storm组件" class="headerlink" title="Storm组件"></a>Storm组件</h1><p>在Storm集群中，有两类节点：主节点master node和工作节点worker nodes。主节点运行着一个叫做Nimbus的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个Storm拓扑结构在不同的机器上运行着众多的工作节点。<br>因为Storm在Zookeeper或本地磁盘上维持所有的集群状态，守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康；</p>
<ul>
<li>NimBus: 责资源分配和任务调度</li>
<li>Supervisor:负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程</li>
<li>Work:运行具体处理组件逻辑的进程</li>
<li>Task: worker中每一个spout/bolt的线程称为一个task</li>
</ul>
<h2 id="0mq"><a href="#0mq" class="headerlink" title="0mq"></a>0mq</h2><p>在系统底层，Storm使用了zeromq(0mq)。这是一种先进的，可嵌入的网络通讯库，它提供的绝妙功能使Storm成为可能。<br>zeromq的特性：</p>
<ul>
<li>一个并发架构的Socket库</li>
<li>对于集群产品和超级计算，比TCP要快</li>
<li>可通过inproc（进程内）, IPC（进程间）, TCP和multicast(多播协议)通信</li>
<li>异步I / O的可扩展的多核消息传递应用程序</li>
<li>利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现N-N连接</li>
</ul>
<p><img src="storm_framework.jpg" alt="storm整体框架"></p>
<ul>
<li>客户端提交拓扑到nimbus。</li>
<li>Nimbus针对该拓扑建立本地的目录根据topology的配置计算task，分配task，在zookeeper上建立assignments节点存储task和supervisor机器节点中woker的对应关系；</li>
<li>在zookeeper上创建taskbeats节点来监控task的心跳；启动topology。</li>
<li>Supervisor去zookeeper上获取分配的tasks，启动多个woker进行，每个woker生成task，一个task一个线程；根据topology信息初始化建立task之间的连接;Task和Task之间是通过zeroMQ管理的；后整个拓扑运行起来。</li>
</ul>
<h1 id="Storm特点"><a href="#Storm特点" class="headerlink" title="Storm特点"></a>Storm特点</h1><p><a href="storm特性.pdf">storm特性</a><br>使用场景：如实时分析，在线机器学习，持续计算，分布式RPC，ETL等等。</p>
<p>Storm有如下特点：</p>
<h2 id="编程模型简单"><a href="#编程模型简单" class="headerlink" title="编程模型简单"></a>编程模型简单</h2><p>在大数据处理方面相信大家对hadoop已经耳熟能详，基于Google Map/Reduce来实现的Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单和优美。<br>同样，Storm也为大数据的实时计算提供了一些简单优美的原语，这大大降低了开发并行实时处理的任务的复杂性，帮助你快速、高效的开发应用。</p>
<h2 id="可扩展"><a href="#可扩展" class="headerlink" title="可扩展"></a>可扩展</h2><p>在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。<br>Storm集群中的每台机器上都可以运行多个工作进程，每个工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执行的。<br>因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。</p>
<h2 id="高可靠性"><a href="#高可靠性" class="headerlink" title="高可靠性"></a>高可靠性</h2><p>Storm可以保证spout发出的每条消息都能被“完全处理”，这也是直接区别于其他实时系统的地方，如S4。<br>请注意，spout发出的消息后续可能会触发产生成千上万条消息，可以形象的理解为一棵消息树，其中spout发出的消息为树根，Storm会跟踪这棵消息树的处理情况，只有当这棵消息树中的所有消息都被处理了，Storm才会认为spout发出的这个消息已经被“完全处理”。如果这棵消息树中的任何一个消息处理失败了，或者整棵消息树在限定的时间内没有“完全处理”，那么spout发出的消息就会重发。</p>
<p>考虑到尽可能减少对内存的消耗，Storm并不会跟踪消息树中的每个消息，而是采用了一些特殊的策略，它把消息树当作一个整体来跟踪，对消息树中所有消息的唯一id进行异或计算，通过是否为零来判定spout发出的消息是否被“完全处理”，这极大的节约了内存和简化了判定逻辑，后面会对这种机制进行详细介绍。</p>
<p>这种模式，每发送一个消息，都会同步发送一个ack/fail，对于网络的带宽会有一定的消耗，如果对于可靠性要求不高，可通过使用不同的emit接口关闭该模式。</p>
<p>上面所说的，Storm保证了每个消息至少被处理一次，但是对于有些计算场合，会严格要求每个消息只被处理一次，幸而Storm的0.7.0引入了事务性拓扑，解决了这个问题。</p>
<h2 id="高容错性"><a href="#高容错性" class="headerlink" title="高容错性"></a>高容错性</h2><p>如果在消息处理过程中出了一些异常，Storm会重新安排这个出问题的处理单元。Storm保证一个处理单元永远运行（除非你显式杀掉这个处理单元）。</p>
<p>当然，如果处理单元中存储了中间状态，那么当处理单元重新被Storm启动的时候，需要应用自己处理中间状态的恢复。</p>
<h2 id="支持多种编程语言"><a href="#支持多种编程语言" class="headerlink" title="支持多种编程语言"></a>支持多种编程语言</h2><p>除了用java实现spout和bolt，你还可以使用任何你熟悉的编程语言来完成这项工作，这一切得益于Storm所谓的多语言协议。多语言协议是Storm内部的一种特殊协议，允许spout或者bolt使用标准输入和标准输出来进行消息传递，传递的消息为单行文本或者是json编码的多行。</p>
<p>Storm支持多语言编程主要是通过ShellBolt, ShellSpout和ShellProcess这些类来实现的，这些类都实现了IBolt 和 ISpout接口，以及让shell通过java的ProcessBuilder类来执行脚本或者程序的协议。</p>
<p>可以看到，采用这种方式，每个tuple在处理的时候都需要进行json的编解码，因此在吞吐量上会有较大影响。</p>
<h2 id="支持本地模式"><a href="#支持本地模式" class="headerlink" title="支持本地模式"></a>支持本地模式</h2><p>Storm有一种“本地模式”，也就是在进程中模拟一个Storm集群的所有功能，以本地模式运行topology跟在集群上运行topology类似，这对于我们开发和测试来说非常有用。</p>
<h2 id="高效"><a href="#高效" class="headerlink" title="高效"></a>高效</h2><p>用ZeroMQ作为底层消息队列, 保证消息能快速被处理。</p>
<h1 id="Storm基本慨念"><a href="#Storm基本慨念" class="headerlink" title="Storm基本慨念"></a>Storm基本慨念</h1><p>Storm集群和Hadoop集群表面上看很类似。但是Hadoop上运行的是MapReduce jobs，而在Storm上运行的是拓扑（topology），这两者之间是非常不一样的。Topology的定义是一个Thrift结构，并且Nimbus就是一个Thrift服务， 你可以提交由任何语言创建的topology。</p>
<h2 id="Topologies"><a href="#Topologies" class="headerlink" title="Topologies"></a>Topologies</h2><p>一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来;<br>一个topology会一直运行直到你手动kill掉，Storm自动重新分配执行失败的任务， 并且Storm可以保证你不会有数据丢失（如果开启了高可靠性的话）。如果一些机器意外停机它上面的所有任务会被转移到其他机器上。<br>运行一个topology很简单。首先，把你所有的代码以及所依赖的jar打进一个jar包。然后运行类似下面的这个命令：<br>storm jar all-my-code.jar backtype.storm.MyTopology arg1 arg2<br>这个命令会运行主类: backtype.strom.MyTopology, 参数是arg1, arg2。这个类的main函数定义这个topology并且把它提交给Nimbus。storm jar负责连接到Nimbus并且上传jar包。</p>
<p>Topology的定义是一个Thrift结构，并且Nimbus就是一个Thrift服务， 你可以提交由任何语言创建的topology。上面的方面是用JVM-based语言提交的最简单的方法。</p>
<h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p>消息流stream是storm里的关键抽象。一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理。通过对stream中tuple序列中每个字段命名来定义stream。在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array。你也可以自定义类型（只要实现相应的序列化器）。</p>
<p>每个消息流在定义的时候会被分配给一个id，因为单向消息流使用的相当普遍， OutputFieldsDeclarer定义了一些方法让你可以定义一个stream而不用指定这个id。在这种情况下这个stream会分配个值为‘default’默认的id 。</p>
<p>Storm提供的最基本的处理stream的原语是spout和bolt。你可以实现spout和bolt提供的接口来处理你的业务逻辑。</p>
<h2 id="Nimbus"><a href="#Nimbus" class="headerlink" title="Nimbus"></a>Nimbus</h2><p>nimbus 雨云，主节点的守护进程，负责为工作节点分发任务。</p>
<h2 id="Spouts（消息源）"><a href="#Spouts（消息源）" class="headerlink" title="Spouts（消息源）"></a>Spouts（消息源）</h2><p><code>spout 龙卷，读取原始数据为bolt提供数据</code>；<br>消息源spout是Storm里面一个topology里面的消息生产者。一般来说消息源会从一个外部源读取数据（如MQ）并且向topology里面发出消息：tuple。Spout可以是可靠的也可以是不可靠的。如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了。</p>
<p>消息源可以发射多条消息流stream。使用OutputFieldsDeclarer.declareStream来定义多个stream，然后使用SpoutOutputCollector来发射指定的stream。</p>
<p>Spout类里面最重要的方法是nextTuple。要么发射一个新的tuple到topology里面或者简单的返回如果已经没有新的tuple。要注意的是nextTuple方法不能阻塞，因为storm在同一个线程上面调用所有消息源spout的方法。</p>
<p>另外两个比较重要的spout方法是ack和fail。storm在检测到一个tuple被整个topology成功处理的时候调用ack，否则调用fail。storm只对可靠的spout调用ack和fail。</p>
<h2 id="消息流中的Tuple"><a href="#消息流中的Tuple" class="headerlink" title="消息流中的Tuple"></a>消息流中的Tuple</h2><p>Tuple是一次消息传递的基本单元，tuple里的每个字段一个名字,并且不同tuple的对应字段的类型必须一样。<br>tuple的字段类型可以是： integer, long, short, byte, string, double, float, boolean和byte array；<br>还可以自定义类型 — 只要实现对应的序列化器。<br>每个消息流中包括若干个tuple。</p>
<h2 id="Bolts（消息处理者）"><a href="#Bolts（消息处理者）" class="headerlink" title="Bolts（消息处理者）"></a>Bolts（消息处理者）</h2><p><code>bolt 雷电，从spout或其它bolt接收数据，并处理数据，处理结果可作为其它bolt的数据源或最终结果</code>；<br>所有的消息处理逻辑被封装在bolts里面。Bolts可以做很多事情：过滤，聚合，查询数据库等等。</p>
<p>Bolts可以简单的做消息流的传递。复杂的消息流处理往往需要很多步骤，从而也就需要经过很多bolts。比如算出一堆图片里面被转发最多的图片就至少需要两步：第一步算出每个图片的转发数量。第二步找出转发最多的前10个图片。（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。<br>Bolts可以发射多条消息流， 使用OutputFieldsDeclarer.declareStream定义stream，使用OutputCollector.emit来选择要发射的stream。</p>
<p>Bolts的主要方法是execute, 它以一个tuple作为输入，bolts使用OutputCollector来发射tuple，bolts必须要为它处理的每一个tuple调用OutputCollector的ack方法，以通知Storm这个tuple被处理完成了，从而通知这个tuple的发射者spouts。 一般的流程是： bolts处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了。storm提供了一个IBasicBolt会自动调用ack。</p>
<h2 id="Stream-groupings（消息分发策略）"><a href="#Stream-groupings（消息分发策略）" class="headerlink" title="Stream groupings（消息分发策略）"></a>Stream groupings（消息分发策略）</h2><p>定义一个topology的其中一步是定义每个bolt接收什么样的流作为输入。stream grouping就是用来定义一个stream应该如何分配数据给bolts上面的多个tasks。</p>
<p>Storm里面有7种类型的stream grouping</p>
<pre><code>1. Shuffle Grouping: 随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同。
2. Fields Grouping：按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task。
3. All Grouping：广播发送，对于每一个tuple，所有的bolts都会收到。
4. Global Grouping：全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。
5. Non Grouping：不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。
6. Direct Grouping： 直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）。
7. Local or shuffle grouping：如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。
</code></pre><h2 id="Reliability"><a href="#Reliability" class="headerlink" title="Reliability"></a>Reliability</h2><p>Storm保证每个tuple会被topology完整的执行。Storm会追踪由每个spout tuple所产生的tuple树（一个bolt处理一个tuple之后可能会发射别的tuple从而形成树状结构），并且跟踪这棵tuple树什么时候成功处理完。每个topology都有一个消息超时的设置，如果storm在这个超时的时间内检测不到某个tuple树到底有没有执行成功， 那么topology会把这个tuple标记为执行失败，并且过一会儿重新发射这个tuple。</p>
<p>为了利用Storm的可靠性特性，在你发出一个新的tuple以及你完成处理一个tuple的时候你必须要通知storm。这一切是由OutputCollector来完成的。通过emit方法来通知一个新的tuple产生了，通过ack方法通知一个tuple处理完成了。</p>
<h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><p>每一个spout和bolt会被当作很多task在整个集群里执行。<br>每一个executor对应到一个线程，在这个线程上运行多个task，而stream grouping则是定义怎么从一堆task发射tuple到另外一堆task。<br>你可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）。</p>
<h2 id="Workers"><a href="#Workers" class="headerlink" title="Workers"></a>Workers</h2><p>一个topology可能会在一个或者多个worker（工作进程）里面执行，每个worker是一个物理JVM并且执行整个topology的一部分。<br>比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks。<br>Storm会尽量均匀的工作分配给所有的worker。</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p>Storm里面有一堆参数可以配置来调整Nimbus, Supervisor以及正在运行的topology的行为，一些配置是系统级别的，一些配置是topology级别的。<br>default.yaml里面有所有的默认配置。你可以通过定义个storm.yaml在你的classpath里来覆盖这些默认配置。并且你也可以在代码里面设置一些topology相关的配置信息（使用StormSubmitter）。</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title>随机森林学习笔记</title>
    <url>/2017/07/19/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>记录随机森林算法的基本概念（熵，分类器，候选特征，分裂特征），构建过程，优缺点</p>
<hr>
<a id="more"></a> 
<h2 id="随机森林学习笔记"><a href="#随机森林学习笔记" class="headerlink" title="随机森林学习笔记"></a>随机森林学习笔记</h2><h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>熵是对无序程度的衡量，熵越大越无序，熵越小越有序<br>首先，熵是一种不可逆性（热力学熵）。一件事（或一个过程），越不可逆，其熵越大。<br>热力学第二定理：温度可以自发从高向低传递，但不能反过来。虽然能量是守恒的，但你能使用的能量却在逐渐减少。这种不可逆性，即“覆水难收，人死不可复生。通常人们不喜欢不可逆。大部分人不能保证自己一次就能成功，所以希望有重新开始的机会<br>其次，熵反映了你对一件事的了解程度（信息熵）。你对一件事了解越少，其熵越大。<br>两个陌生人之间，就存在一个无比巨大的熵。在一起，双方自然会感觉不舒服。两人逐渐熟悉、逐渐了解的过程，本质是一个熵减的过程。当双方为知己时，相互的信息熵已趋近于0。两者相处起来，会轻松。沟通无障碍，不用去费劲解释。<br>最后，熵反映了你对一件东西的不确定性（构象熵）。当你越不确定，这件东西对你来说，熵就越大。</p>
<h2 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h2><p>分类器就是给定一个样本的数据，判定这个样本属于哪个类别的算法。例如在股票涨跌预测中，我们认为前一天的交易量和收盘价对于第二天的涨跌是有影响的，那么分类器就是通过样本的交易量和收盘价预测第二天的涨跌情况的算法。</p>
<h2 id="分裂"><a href="#分裂" class="headerlink" title="分裂"></a>分裂</h2><p>在决策树的训练过程中，需要一次次的将训练数据集分裂成两个子数据集，这个过程就叫做分裂。</p>
<h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><p>在分类问题中，输入到分类器中的数据叫做特征。以上面的股票涨跌预测问题为例，特征就是前一天的交易量和收盘价。</p>
<h2 id="待选特征"><a href="#待选特征" class="headerlink" title="待选特征"></a>待选特征</h2><p>在决策树的构建过程中，需要按照一定的次序从全部的特征中选取特征。待选特征就是在目前的步骤之前还没有被选择的特征的集合。例如，全部的特征是 ABCDE，第一步的时候，待选特征就是ABCDE，第一步选择了C，那么第二步的时候，待选特征就是ABDE。</p>
<h2 id="分裂特征"><a href="#分裂特征" class="headerlink" title="分裂特征"></a>分裂特征</h2><p>接待选特征的定义，每一次选取的特征就是分裂特征，例如，在上面的例子中，第一步的分裂特征就是C。因为选出的这些特征将数据集分成了一个个不相交的部分，所以叫它们分裂特征。</p>
<h1 id="如何选择分裂特征？"><a href="#如何选择分裂特征？" class="headerlink" title="如何选择分裂特征？"></a>如何选择分裂特征？</h1><p>用不同的准则衡量特征的贡献程度。主流准则的列举3个：</p>
<ul>
<li>ID3算法（J. Ross Quinlan于1986年提出），采用信息增益最大的特征；</li>
<li>C4.5算法（J. Ross Quinlan于1993年提出）采用信息增益比选择特征；</li>
<li>CART算法（Breiman等人于1984年提出）利用基尼指数最小化准则进行特征选择。</li>
</ul>
<h1 id="随机森林的构建过程"><a href="#随机森林的构建过程" class="headerlink" title="随机森林的构建过程"></a>随机森林的构建过程</h1><p>决策树相当于一个大师，通过自己在数据集中学到的知识对于新的数据进行分类。但是俗话说得好，一个诸葛亮，玩不过三个臭皮匠。随机森林就是希望构建多个臭皮匠，希望最终的分类效果能够超过单个大师的一种算法。</p>
<p>那随机森林具体如何构建呢？有两个方面：数据的随机性选取，以及待选特征的随机选取。</p>
<h2 id="数据的随机选取："><a href="#数据的随机选取：" class="headerlink" title="数据的随机选取："></a>数据的随机选取：</h2><p>首先，从原始的数据集中采取有放回的抽样，构造子数据集，子数据集的数据量是和原始数据集相同的。不同子数据集的元素可以重复，同一个子数据集中的元素也可以重复。<br>第二，利用子数据集来构建子决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。最后，如果有了新的数据需要通过随机森林得到分类结果，就可以通过对子决策树的判断结果的投票，得到随机森林的输出结果了。</p>
<p>如下图，假设随机森林中有3棵子决策树，2棵子树的分类结果是A类，1棵子树的分类结果是B类，那么随机森林的分类结果就是A类。<br><img src="数据的随机选取.png" alt="数据的随机选取"></p>
<h2 id="待选特征的随机选取："><a href="#待选特征的随机选取：" class="headerlink" title="待选特征的随机选取："></a>待选特征的随机选取：</h2><p>与数据集的随机选取类似，随机森林中的子树的每一个分裂过程并未用到所有的待选特征，而是从所有的待选特征中随机选取一定的特征，之后再在随机选取的特征中选取最优的特征。这样能够使得随机森林中的决策树都能够彼此不同，提升系统的多样性，从而提升分类性能。</p>
<p>下图中，蓝色的方块代表所有可以被选择的特征，也就是目前的待选特征。黄色的方块是分裂特征。<br>左边是一棵决策树的特征选取过程，通过在待选特征中选取最优的分裂特征（别忘了前文提到的ID3算法，C4.5算法，CART算法等等），完成分裂。<br>右边是一个随机森林中的子树的特征选取过程。<br><img src="Alt text.png" alt="Alt text"></p>
<h1 id="随机森林的优点与缺点"><a href="#随机森林的优点与缺点" class="headerlink" title="随机森林的优点与缺点"></a>随机森林的优点与缺点</h1><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><ol>
<li>随机森林算法能解决分类与回归两种类型的问题，并在这两个方面都有相当好的估计表现；</li>
<li>随机森林对于高维数据集的处理能力令人兴奋，它可以处理成千上万的输入变量，并确定最重要的变量，因此被认为是一个不错的降维方法。此外，该模型能够输出变量的重要性程度，这是一个非常便利的功能。</li>
<li>在对缺失数据进行估计时，随机森林是一个十分有效的方法。就算存在大量的数据缺失，随机森林也能较好地保持精确性。</li>
<li>当存在分类不平衡的情况时，随机森林能够提供平衡数据集误差的有效方法；（为什么？）</li>
<li>模型的上述性能可以被扩展运用到未标记的数据集中，用于引导无监督聚类、数据透视和异常检测；</li>
<li>随机森林算法中包含了对输入数据的重复自抽样过程，即所谓的bootstrap抽样。这样一来，数据集中大约三分之一将没有用于模型的训练而是用于测试，这样的数据被称为out of bag samples，通过这些样本估计的误差被称为out of bag error。<br>研究表明，这种out of bag方法的与测试集规模同训练集一致的估计方法有着相同的精确程度，因此在随机森林中我们无需再对测试集进行另外的设置。</li>
<li>训练速度快，容易做成并行化方法</li>
</ol>
<h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h2><p>1.随机森林在解决回归问题时并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续型的输出。当进行回归时，随机森林不能够作出超越训练集数据范围的预测，这可能导致在对某些还有特定噪声的数据进行建模时出现过度拟合。<br>2.对于许多统计建模者来说，随机森林给人的感觉像是一个黑盒子——你几乎无法控制模型内部的运行，只能在不同的参数和随机种子之间进行尝试。</p>
<p>机器学习中如何处理缺失数据？<br>目前有三类处理方法：</p>
<ol>
<li>用平均值、中值、分位数、众数、随机值等替代。效果一般，因为等于人为增加了噪声。</li>
<li>用其他变量做预测模型来算出缺失变量。效果比方法1略好。有一个根本缺陷，如果其他变量和缺失变量无关，则预测的结果无意义。如果预测结果相当准确，则又说明这个变量是没必要加入建模的。一般情况下，介于两者之间。</li>
<li>最精确的做法，把变量映射到高维空间。比如性别，有男、女、缺失三种情况，则映射成3个变量：是否男、是否女、是否缺失。连续型变量也可以这样处理。比如Google、百度的CTR预估模型，预处理时会把所有变量都这样处理，达到几亿维。这样做的好处是完整保留了原始数据的全部信息、不用考虑缺失值、不用考虑线性不可分之类的问题。缺点是计算量大大提升。而且只有在样本量非常大的时候效果才好，否则会因为过于稀疏，效果很差。</li>
</ol>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol>
<li><p>随机森林是一个十分有效的方法。就算存在大量的数据缺失，随机森林也能较好地保持精确性；<br>RF不需要做特征选择，不需要规范化数据，如何数据缺失，不用向量化进行矩阵运算吗？</p>
</li>
<li><p>随机森林在解决回归问题时并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续型的输出。当进行回归时，随机森林不能够作出超越训练集数据范围的预测，这可能导致在对某些还有特定噪声的数据进行建模时出现过度拟合。如何避免过拟合？</p>
</li>
</ol>
<p>样本选择是随机的，分裂特征选择也是随机的，</p>
<blockquote>
<p>random forest 确实是一个不易overfitting的模型。<br>主要依靠了其中三个随机过程，即产生决策树的样本是随机生成，构建决策树的特征值是随机选取，树产生过程中裂变的时候是选择N个最佳方向中的随机一个裂变的。</p>
</blockquote>
<p>当前的数据量过少，不足以对整个数据集进行分布估计，因此往往需要防止模型过拟合，提高模型泛化能力。<br>在对模型进行训练时，有可能遇到训练数据不够，即训练数据无法对整个数据的分布进行估计的时候，或者在对模型进行过度训练（overtraining）时，常常会导致模型的过拟合（overfitting）。如下图所示：<br><img src="Alt text.png" alt="Alt text"><br>  通过上图可以看出，随着模型训练的进行，模型的复杂度会增加，此时模型在训练数据集上的训练误差会逐渐减小，但是在模型的复杂度达到一定程度时，模型在验证集上的误差反而随着模型的复杂度增加而增大。此时便发生了过拟合，即模型的复杂度升高，但是该模型在除训练集之外的数据集上却不work。<br>  为了防止过拟合，我们需要用到一些方法，如：early stopping、数据集扩增（Data augmentation）、正则化（Regularization）、Dropout等。</p>
<ol>
<li>树的颗树，树的深度如何确定？<br>特征个数？</li>
</ol>
<blockquote>
<p>当随机森林产生的树的数目趋近无穷的时候，理论上根据大数定理可以证明训练误差与测试误差是收敛到一起的。 </p>
</blockquote>
<ol>
<li>RF训练集和测试集的比例确定？</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/morrislab/mlworkshop/blob/6eea6521958563aaf5856b013b6926c0f68fbb1d/supervised_learning/Random Forests.ipynb">可视化Random Forests.ipynb</a></p>
<p><a href="http://www.cnblogs.com/pinard/category/894692.html">刘建平Pinard 系列</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归-学习笔记</title>
    <url>/2017/08/12/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="逻辑回归-学习笔记"><a href="#逻辑回归-学习笔记" class="headerlink" title="逻辑回归-学习笔记"></a>逻辑回归-学习笔记</h1><p>学习任何东西都可以按照3W的框架进行，容器技术也是一样，先回答 What、Why 和 How 这三个问题。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="http://www.cnblogs.com/pinard/p/6029432.html">逻辑回归原理</a></li>
<li><a href="http://m.blog.csdn.net/pakko/article/details/37878837">逻辑回归</a></li>
<li><a href="https://gist.github.com/vietjtnguyen/6655020">Fun with Logistic Regression.ipynb</a></li>
</ul>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>辑回归是一个分类算法，它可以处理二元分类以及多元分类。<br>虽然它名字里面有“回归”两个字，却不是一个回归算法。<br>那为什么有“回归”这个误导性的词呢？<br>个人认为，虽然逻辑回归是分类模型，但是它的原理里面却残留着回归模型的影子，</p>
<h2 id="从线性回归到逻辑回归"><a href="#从线性回归到逻辑回归" class="headerlink" title="从线性回归到逻辑回归"></a>从线性回归到逻辑回归</h2><p>线性回归的模型是求出<code>输出特征向量Y</code>和<code>输入样本矩阵X</code>之间的<code>线性关系系数θ</code>，满足$Y=X     heta$。<br>此时我们的$Y$是连续的，所以是回归模型。<br>如果我们想要$Y$是离散的话，怎么办呢？我们对于Y再做一次函数转换，变为$g(Y)$。</p>
<blockquote>
<p>如果我们令$g(Y)$的值在某个实数区间的时候是类别A，在另一个实数区间的时候是类别B，以此类推，就得到了一个分类模型。如果结果的类别只有两种，那么就是一个二元分类模型了。<br>逻辑回归的出发点就是从这来的。</p>
</blockquote>
<h1 id="二元逻辑回归的模型"><a href="#二元逻辑回归的模型" class="headerlink" title="二元逻辑回归的模型"></a>二元逻辑回归的模型</h1><p>对线性回归的结果做一个在函数g上的转换，可以变化为逻辑回归。<br>这个函数g在逻辑回归中我们一般取为sigmoid函数，形式如下：</p>
<script type="math/tex; mode=display">g(z) = rac {1} {1+e^{-z}}</script><h3 id="模型性质"><a href="#模型性质" class="headerlink" title="模型性质"></a>模型性质</h3><ol>
<li>当z趋于正无穷时，g(z)趋于1；当z趋于负无穷时，g(z)趋于0（这非常适合分类概率模型）</li>
<li>对g(z)求导可得到：$g′(z)=g(z)(1−g(z))  $，如果令g(z)中的z为：$z=xθ$，这样就得到了二元逻辑回归模型的一般形式：<script type="math/tex; mode=display">h_{    heta}(x) = rac {1} {1+e^{-x    heta}}</script>其中$x$为样本输入，$h<em>    heta(x)$为模型输出，可以理解为某一分类的概率大小。而$θ$为分类模型的要求出的模型参数。<br>对于模型输出$h</em>    heta(x)$，我们让它和我们的二元样本输出$y$（假设为0和1）有这样的对应关系，<br>如果$h<em>    heta(x)&gt;0.5 $，即$x</em>    heta&gt;0$, 则$y$为1。<br>如果$h<em>    heta(x)&lt;0.5$，即$x</em>    heta&lt;0$, 则$y$为0。<br>$y=0.5$是临界情况，此时$x_    heta=0$， 从逻辑回归模型本身无法确定分类。</li>
</ol>
<blockquote>
<p>$h_    heta(x)$的值越小，而分类为0的的概率越高，反之，值越大的话分类为1的的概率越高。<br>如果靠近临界点，则分类准确率会下降。</p>
</blockquote>
<ol>
<li>模型的矩阵模式：<script type="math/tex; mode=display">h_{    heta}(X) = rac {1} {1+e^{-X    heta}}</script>其中$h_    heta(x)$为模型输出，为$m<em>1$的维度。$X$为样本特征矩阵，为$m</em>n$的维度。$    heta$为分类的模型系数，为$n*1$的向量。</li>
</ol>
<p>理解了二元分类回归的模型，就要看模型的损失函数，我们的目标是极小化损失函数来得到对应的模型系数$    heta$。</p>
<h1 id="二元逻辑回归的损失函数"><a href="#二元逻辑回归的损失函数" class="headerlink" title="二元逻辑回归的损失函数"></a>二元逻辑回归的损失函数</h1><p>由于线性回归是连续的，所以可以使用<code>模型误差的的平方和</code>来定义损失函数。<br>但是逻辑回归不是连续的，自然线性回归损失函数定义的经验就用不上了。<br>不过我们可以用<code>最大似然法</code>来推导出我们的损失函数。</p>
<p>按照二元逻辑回归的定义，假设我们的样本输出是0或者1两类。那么我们有：</p>
<script type="math/tex; mode=display">P(y=1|x,    heta ) = h_{    heta}(x)</script><script type="math/tex; mode=display">P(y=0|x,    heta ) = 1- h_{    heta}(x)</script><p>把这两个式子写成一个式子：<script type="math/tex">P(y|x,    heta ) = h_{    heta}(x)^y(1-h_{    heta}(x))^{1-y}</script><br>其中$y$的取值只能是0或者1。<br>用矩阵法表示，即为：<script type="math/tex">P(Y|X,    heta ) = h_{    heta}(X)^Y(E-h_{    heta}(X))^{1-Y}</script><br>其中$E$为单位矩阵。<br>得到了$y$的概率分布函数表达式，我们就可以用<code>似然函数最大化</code>来求解我们需要的模型系数$    heta$。<br>为了方便求解，这里我们用对数似然函数最大化，对数似然函数取反即为我们的损失函数$J(    heta)$。其中：<br>似然函数的代数表达式为：</p>
<script type="math/tex; mode=display">L(    heta) = \prod\limits_{i=1}^{m}(h_{    heta}(x^{(i)}))^{y^{(i)}}(1-h_{    heta}(x^{(i)}))^{1-y^{(i)}}</script><p>其中m为样本的个数。</p>
<p>对<code>似然函数对数化取反</code>的表达式，即损失函数表达式为：</p>
<script type="math/tex; mode=display">J(    heta) = -lnL(    heta) = -\sum\limits_{i=1}^{m}(y^{(i)}log(h_{    heta}(x^{(i)}))+ (1-y^{(i)})log(1-h_{    heta}(x^{(i)})))</script><p>损失函数用<code>矩阵法</code>表达更加简洁：</p>
<script type="math/tex; mode=display">J(    heta) = -Yullet log(h_{    heta}(X)) - (E-Y)ullet log(E-h_{    heta}(X))</script><p>其中E为单位矩阵$ullet$为内积。</p>
<h1 id="二元逻辑回归的损失函数的优化方法"><a href="#二元逻辑回归的损失函数的优化方法" class="headerlink" title="二元逻辑回归的损失函数的优化方法"></a>二元逻辑回归的损失函数的优化方法</h1><p>对于二元逻辑回归的损失函数极小化，有比较多的方法，最常见的有<code>梯度下降法</code>，<code>坐标轴下降法</code>，<code>等牛顿法</code>等。<br>这里推导出梯度下降法中$    heta$每次迭代的公式。<br>由于代数法推导比较的繁琐，我习惯于用<code>矩阵法</code>来做损失函数的优化过程，<br>这里给出<code>矩阵法推导二元逻辑回归梯度</code>的过程。</p>
<p>对于$J(    heta) = -Yullet log(h<em>{    heta}(X)) - (E-Y)ullet log(E-h</em>{    heta}(X))$，<br>我们用$J(    heta)$对$    heta$向量求导可得：</p>
<script type="math/tex; mode=display">rac{\partial}{\partial    heta}J(    heta) = -Y ullet X^Trac{1}{h_{    heta}(X)}h_{    heta}(X)(1-h_{    heta}(X)) + (E-Y)ullet X^Trac{1}{1-h_{    heta}(X)}h_{    heta}(X)(1-h_{    heta}(X)) = X^T(h_{    heta}(X) - Y )</script><p>这一步我们用到了矩阵求导的链式法则，和下面三个矩阵求导公式：</p>
<ul>
<li>$rac{\partial}{\partial X}logX = rac{1}{X}$</li>
<li>$rac{\partial}{\partial z}g(z) = g(z)(1-g(z))$，   (g(z)为sigmoid函数)</li>
<li>$rac{\partial}{\partial    heta}X    heta = X^T$</li>
</ul>
<p>从而在梯度下降法中每一步向量$    heta$的迭代公式如下：</p>
<script type="math/tex; mode=display">heta =     heta - lpha X^T(h_{    heta}(X) - Y )</script><p>其中，$lpha$为梯度下降法的步长。<br>实践中，我们一般不用操心优化方法，大部分机器学习库都内置了各种逻辑回归的优化方法，不过了解至少一种优化方法还是有必要的。
　　　　</p>
<h1 id="二元逻辑回归的正则化"><a href="#二元逻辑回归的正则化" class="headerlink" title="二元逻辑回归的正则化"></a>二元逻辑回归的正则化</h1><p>逻辑回归也会面临<code>过拟合问题</code>，所以我们也要考虑正则化。常见的有L1正则化和L2正则化。<br>逻辑回归的<code>L1正则化</code>的损失函数表达式如下，相比普通的逻辑回归损失函数，增加了L1的范数做作为惩罚，超参数$lpha$作为惩罚系数，调节惩罚项的大小。</p>
<p>二元逻辑回归的L1正则化损失函数表达式如下：</p>
<script type="math/tex; mode=display">J(    heta) = -Yullet logh_{    heta}(X) - (E-Y)ullet log(1-h_{    heta}(X)) + lpha||    heta||_1</script><p>其中$||    heta||_1$为$    heta$的<code>L1范数</code>。<br>逻辑回归的L1正则化损失函数的优化方法常用的有<code>坐标轴下降法</code>和<code>最小角回归法</code>。</p>
<p>二元逻辑回归的L2正则化损失函数表达式如下：</p>
<script type="math/tex; mode=display">J(    heta) = -Yullet logh_{    heta}(X) - (E-Y)ullet log(1-h_{    heta}(X)) + rac{1}{2}lpha||    heta||_2^2</script><p>其中$||    heta||_2$为$    heta$的<code>L2范数</code>。<br>逻辑回归的L2正则化损失函数的优化方法和普通的逻辑回归类似。</p>
<h1 id="二元逻辑回归的推广：多元逻辑回归"><a href="#二元逻辑回归的推广：多元逻辑回归" class="headerlink" title="二元逻辑回归的推广：多元逻辑回归"></a>二元逻辑回归的推广：多元逻辑回归</h1><p>二元逻辑回归的模型和损失函数很容易推广到多元逻辑回归。</p>
<ul>
<li>比如总是认为某种类型为正值，其余为0值，这种方法为最常用的是<code>one-vs-reset(OvR)</code>.</li>
<li><code>Many-vs-Many(MvM)</code>，它会选择一部分类别的样本和另一部分类别的样本来做逻辑回归二分类。</li>
<li>最常用的是<code>One-Vs-One（OvO）</code>。OvO是MvM的特例。</li>
</ul>
<p>我们选择两类样本来做二元逻辑回归，具体如下：<br>首先回顾下二元逻辑回归。</p>
<script type="math/tex; mode=display">P(y=1|x,    heta ) = h_{    heta}(x) =  rac{1}{1+e^{-x    heta}} = rac{e^{x    heta}}{1+e^{x    heta}}</script><script type="math/tex; mode=display">P(y=0|x,    heta ) = 1- h_{    heta}(x) = rac{1}{1+e^{x    heta}}</script><p>其中$y$只能取到0和1。则有：</p>
<script type="math/tex; mode=display">lnrac{P(y=1|x,    heta )}{P(y=0|x,    heta)} = x    heta</script><p>如果我们要推广到多元逻辑回归，则模型要稍微做下扩展。<br>我们假设是K元分类模型,即样本输出y的取值为1，2，。。。，K。<br>根据二元逻辑回归的经验，我们有：</p>
<script type="math/tex; mode=display">lnrac{P(y=1|x,    heta )}{P(y=K|x,    heta)} = x    heta</script><script type="math/tex; mode=display">lnrac{P(y=2|x,    heta )}{P(y=K|x,    heta)} = x    heta</script><script type="math/tex; mode=display">...</script><script type="math/tex; mode=display">lnrac{P(y=K-1|x,    heta )}{P(y=K|x,    heta)} = x    heta_{K-1}</script><p>上面有K-1个方程。<br>加上概率之和为1的方程如下：</p>
<script type="math/tex; mode=display">\sum\limits_{i=1}^{K}P(y=i|x,    heta ) = 1</script><p>从而得到K个方程，里面有K个逻辑回归的概率分布。<br>解出这个K元一次方程组，得到K元逻辑回归的概率分布如下：</p>
<script type="math/tex; mode=display">P(y=k|x,    heta ) =  e^{x    heta_k} igg/ 1+\sum\limits_{t=1}^{K-1}e^{x    heta_t},k = 1,2,...K-1</script><script type="math/tex; mode=display">P(y=K|x,    heta ) =  1 igg/ 1+\sum\limits_{t=1}^{K-1}e^{x    heta_t}</script><p>多元逻辑回归的损失函数推导以及优化方法和二元逻辑回归类似</p>
<h1 id="scikit-learn中的逻辑回归实践"><a href="#scikit-learn中的逻辑回归实践" class="headerlink" title="scikit-learn中的逻辑回归实践"></a>scikit-learn中的逻辑回归实践</h1><p><a href="http://www.cnblogs.com/pinard/p/6035872.html">http://www.cnblogs.com/pinard/p/6035872.html</a></p>
<h1 id="逻辑回归的优缺点"><a href="#逻辑回归的优缺点" class="headerlink" title="逻辑回归的优缺点"></a>逻辑回归的优缺点</h1><p>逻辑回归尤其是二元逻辑回归是非常常见的模型，训练速度很快，<br>虽然使用起来没有支持向量机（SVM）那么占主流，但是解决普通的分类问题是足够了，训练速度也比起SVM要快不少。<br>如果你要理解机器学习分类算法，那么第一个应该学习的分类算法个人觉得应该是逻辑回归。<br>理解了逻辑回归，其他的分类算法再学习起来应该没有那么难了。</p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低；</li>
<li>实现简单，广泛的应用于工业问题上；</li>
<li>分类时计算量非常小，速度很快，存储资源低；</li>
<li>便利的观测样本概率分数；</li>
<li>对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li><p>容易欠拟合，分类精度可能不高<br>why：数据问题？正负样本不均衡，特征不具代表性?</p>
</li>
<li><p>过拟合如何处理<br>方法一：尽量减少选取变量的数量<br>方法二：正则化</p>
</li>
</ul>
<h1 id="逻辑回归的应用"><a href="#逻辑回归的应用" class="headerlink" title="逻辑回归的应用"></a>逻辑回归的应用</h1>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>AVL</title>
    <url>/2017/10/10/AVL/</url>
    <content><![CDATA[<blockquote>
<p>The AVL tree is named after its two Soviet inventors, Georgy <code>A</code>delson-<code>V</code>elsky and Evgenii <code>L</code>andis, who published it in their 1962 paper “<code>An algorithm for the organization of information</code>“.</p>
<p>An AVL tree is a <code>self-balancing binary search tree</code>, and it was the <code>first</code> such data structure to be invented.<br>In an AVL tree, the heights of the two child subtrees of any node differ by at most one.<br>AVL trees are often compared with red-black trees because they support the same set of operations and because <code>red-black trees</code> also take <code>O(log n)</code> time for the basic operations. Because AVL trees are more <code>rigidly balanced</code>, they are <code>faster than red-black trees for lookup intensive applications</code>.<br>However, <code>red-black trees are faster for insertion and removal</code>.</p>
</blockquote>
<a id="more"></a> 
<h2 id="AVL-Tree的性质"><a href="#AVL-Tree的性质" class="headerlink" title="AVL Tree的性质"></a>AVL Tree的性质</h2><ul>
<li>任意一个结点的key，比它的lesserChild的key大，比它的greaterChild的key小；</li>
<li>任意结点的孩子结点之间高度差距最大为1；</li>
</ul>
<h2 id="平衡检测"><a href="#平衡检测" class="headerlink" title="平衡检测"></a>平衡检测</h2><p>对于一棵树来说，它的<code>高度(height)</code>定义如下：</p>
<blockquote>
<p>从根节点(root)开始到某一个叶子节点(leaf)的最长路径(path)上结点的个数</p>
</blockquote>
<p>根据AVL树的定义，我们可以为所有的结点定义一个<code>平衡因子(balanced factor)</code>：</p>
<blockquote>
<p>某个结点的平衡因子等于该节点的greaterHeight的高度减去lesserHeight的高度</p>
</blockquote>
<p>根据平衡树的定义，计算得到的平衡因为会出现两种情况：</p>
<ul>
<li>如果平衡因子是<code>0, 1, -1</code> 这三个数的话，可以认定该节点是符合平衡树的定义的；</li>
<li>否则，该结点不平衡，需要重新平衡；<br>对于一个BST来说，<code>每次插入的元素只可能放在叶子结点上。所以只能影响某个子树是否平衡，对其他子树不会有任何的影响。</code><br>在这种情况下，我们只需要根据搜索的路径，从孩子往祖先找，如果有不平衡的结点就可以被找到。如果一直到根结点都没有发现不平衡结点，则可以认为这次的插入操作没有造成树的不平衡。</li>
</ul>
<h2 id="AVL保持平衡操作"><a href="#AVL保持平衡操作" class="headerlink" title="AVL保持平衡操作"></a>AVL保持平衡操作</h2><p>如果发现了某个不平衡的结点，那么就需要对该结点进行重平衡。实现重平衡的方法，是对该节点的子树进行<code>旋转(rotation)</code>。<br>旋转有两种情况，如下图所示：</p>
<ul>
<li>一种称为左旋转(关于X结点的左旋转);</li>
<li>一种称为右旋转(关于Y结点的右旋转);<br>AVL树的旋转实际可以用4种情况表达：LL,RR,LR,RL。LL型时单向右旋，RR时单向左旋；LR,RL时双向旋转（先左后右、先右后左)。<br><img src="AVL树的旋转.png" alt="AVL树的旋转"></li>
</ul>
<h2 id="AVL的结构"><a href="#AVL的结构" class="headerlink" title="AVL的结构"></a>AVL的结构</h2><p>AVL树节点-父类<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; </span>&#123;</span><br><span class="line">       <span class="keyword">protected</span> T id = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; parent = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; lesser = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; greater = <span class="keyword">null</span>;</span><br><span class="line">       <span class="function"><span class="keyword">protected</span> <span class="title">Node</span><span class="params">(Node&lt;T&gt; parent, T id)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">this</span>.parent = parent;</span><br><span class="line">           <span class="keyword">this</span>.id = id;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<p>AVL树节点<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">AVLNode</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">int</span> height = <span class="number">1</span>;</span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="title">AVLNode</span><span class="params">(Node&lt;T&gt; parent, T value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>(parent, value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//是否叶子节点</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isLeaf</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> ((lesser == <span class="keyword">null</span>) &amp;&amp; (greater == <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//更新节点height</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">updateHeight</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> lesserHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (lesser != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; lesserAVLNode = (AVLNode&lt;T&gt;) lesser;</span><br><span class="line">                lesserHeight = lesserAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> greaterHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (greater != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; greaterAVLNode = (AVLNode&lt;T&gt;) greater;</span><br><span class="line">                greaterHeight = greaterAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (lesserHeight &gt; greaterHeight) &#123;</span><br><span class="line">                height = lesserHeight + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                height = greaterHeight + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> height;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *获取节点平衡因子</span></span><br><span class="line"><span class="comment">         * </span></span><br><span class="line"><span class="comment">         * <span class="doctag">@return</span> 左孩子比有孩子长时，平衡因子小于0</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">getBalanceFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> lesserHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (lesser != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; lesserAVLNode = (AVLNode&lt;T&gt;) lesser;</span><br><span class="line">                lesserHeight = lesserAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> greaterHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (greater != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; greaterAVLNode = (AVLNode&lt;T&gt;) greater;</span><br><span class="line">                greaterHeight = greaterAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> greaterHeight - lesserHeight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="AVL树的增删改查"><a href="#AVL树的增删改查" class="headerlink" title="AVL树的增删改查"></a>AVL树的增删改查</h2><h3 id="新增节点"><a href="#新增节点" class="headerlink" title="新增节点"></a>新增节点</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Node&lt;T&gt; <span class="title">addValue</span><span class="params">(T id)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//新增节点（lesser/greater）</span></span><br><span class="line">    Node&lt;T&gt; nodeToReturn = <span class="keyword">super</span>.addValue(id);</span><br><span class="line">    AVLNode&lt;T&gt; nodeAdded = (AVLNode&lt;T&gt;) nodeToReturn;</span><br><span class="line">    <span class="comment">//更新节点高度</span></span><br><span class="line">    nodeAdded.updateHeight();</span><br><span class="line">    <span class="comment">//平衡树</span></span><br><span class="line">    balanceAfterInsert(nodeAdded);</span><br><span class="line">true</span><br><span class="line">true<span class="comment">//从当前新增节点，自下而上遍历，更新节点height，对不平衡节点进行旋转操作，使树保存平衡</span></span><br><span class="line">    nodeAdded = (AVLNode&lt;T&gt;) nodeAdded.parent;</span><br><span class="line">    <span class="keyword">while</span> (nodeAdded != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> h1 = nodeAdded.height;</span><br><span class="line"></span><br><span class="line">        nodeAdded.updateHeight();</span><br><span class="line">        balanceAfterInsert(nodeAdded);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If height before and after balance is the same, stop going up the tree</span></span><br><span class="line">        <span class="keyword">int</span> h2 = nodeAdded.height;</span><br><span class="line">        <span class="keyword">if</span> (h1==h2)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        nodeAdded = (AVLNode&lt;T&gt;) nodeAdded.parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodeToReturn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="AVL树平衡"><a href="#AVL树平衡" class="headerlink" title="AVL树平衡"></a>AVL树平衡</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 插入node时，执行平衡AVL树</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node 子树的根节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">balanceAfterInsert</span><span class="params">(AVLNode&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">true<span class="comment">//获取平衡因子，如果不为-1,0,1，则需进行平衡处理</span></span><br><span class="line">    <span class="keyword">int</span> balanceFactor = node.getBalanceFactor();</span><br><span class="line">    <span class="keyword">if</span> (balanceFactor &gt; <span class="number">1</span> || balanceFactor &lt; -<span class="number">1</span>) &#123;</span><br><span class="line">        AVLNode&lt;T&gt; child = <span class="keyword">null</span>;</span><br><span class="line">        Balance balance = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//左孩子长</span></span><br><span class="line">        <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            child = (AVLNode&lt;T&gt;) node.lesser;</span><br><span class="line">            balanceFactor = child.getBalanceFactor();</span><br><span class="line">            <span class="comment">//左孩子长</span></span><br><span class="line">            <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>)</span><br><span class="line">                balance = Balance.LEFT_LEFT;</span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                balance = Balance.LEFT_RIGHT;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;<span class="comment">//右孩子长</span></span><br><span class="line">            child = (AVLNode&lt;T&gt;) node.greater;</span><br><span class="line">            balanceFactor = child.getBalanceFactor();</span><br><span class="line">            <span class="comment">//左孩子长</span></span><br><span class="line">            <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>)</span><br><span class="line">                balance = Balance.RIGHT_LEFT;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                balance = Balance.RIGHT_RIGHT;</span><br><span class="line">        &#125;</span><br><span class="line">truetrue<span class="comment">// 左孩子，右孩子长</span></span><br><span class="line">        <span class="keyword">if</span> (balance == Balance.LEFT_RIGHT) &#123;</span><br><span class="line">            <span class="comment">// Left-Right (Left rotation, right rotation)</span></span><br><span class="line">            rotateLeft(child);</span><br><span class="line">            rotateRight(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (balance == Balance.RIGHT_LEFT) &#123;</span><br><span class="line">            <span class="comment">// Right-Left (Right rotation, left rotation)</span></span><br><span class="line">            rotateRight(child);</span><br><span class="line">            rotateLeft(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (balance == Balance.LEFT_LEFT) &#123;</span><br><span class="line">            <span class="comment">// Left-Left (Right rotation)</span></span><br><span class="line">            rotateRight(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Right-Right (Left rotation)</span></span><br><span class="line">            rotateLeft(node);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        child.updateHeight();</span><br><span class="line">        node.updateHeight();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="旋转类型"><a href="#旋转类型" class="headerlink" title="旋转类型"></a>旋转类型</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">enum</span> Balance &#123;</span><br><span class="line">    <span class="comment">//（单右旋）</span></span><br><span class="line">    LEFT_LEFT, </span><br><span class="line">    <span class="comment">//（先右孩子左旋，再自身右旋）</span></span><br><span class="line">    LEFT_RIGHT, </span><br><span class="line">    <span class="comment">//（先左孩子右旋，再自身左旋）</span></span><br><span class="line">    RIGHT_LEFT, </span><br><span class="line">    <span class="comment">//（单左旋）</span></span><br><span class="line">    RIGHT_RIGHT</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="左旋"><a href="#左旋" class="headerlink" title="左旋"></a>左旋</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以node及其children为轴作左旋</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node Root of tree to rotate left.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">rotateLeft</span><span class="params">(Node&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">    Node&lt;T&gt; parent = node.parent;</span><br><span class="line">    Node&lt;T&gt; greater = node.greater;</span><br><span class="line">    Node&lt;T&gt; lesser = greater.lesser;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//节点的右孩子的左孩子=节点</span></span><br><span class="line">    greater.lesser = node;</span><br><span class="line">    <span class="comment">//节点的父节点=节点的右孩子</span></span><br><span class="line">    node.parent = greater;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的右孩子=节点的右孩子的左孩子</span></span><br><span class="line">    node.greater = lesser;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lesser != <span class="keyword">null</span>)</span><br><span class="line">        lesser.parent = node;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//非root节点</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node == parent.lesser) &#123;</span><br><span class="line">            <span class="comment">//当前节点是左孩子</span></span><br><span class="line">            parent.lesser = greater;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node == parent.greater) &#123;</span><br><span class="line">            <span class="comment">//当前节点是右孩子</span></span><br><span class="line">            parent.greater = greater;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Yikes! I'm not related to my parent. "</span> + node.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//旋转后的root节点指向旋转前的parent节点</span></span><br><span class="line">        greater.parent = parent;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        root = greater;</span><br><span class="line">        root.parent = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="右旋"><a href="#右旋" class="headerlink" title="右旋"></a>右旋</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以node及其children为轴作右旋</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node Root of tree to rotate right.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">rotateRight</span><span class="params">(Node&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">    Node&lt;T&gt; parent = node.parent;</span><br><span class="line">    Node&lt;T&gt; lesser = node.lesser;</span><br><span class="line">    Node&lt;T&gt; greater = lesser.greater;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的左孩子的右孩子=节点</span></span><br><span class="line">    lesser.greater = node;</span><br><span class="line">    <span class="comment">//节点的父节点=节点的左孩子</span></span><br><span class="line">    node.parent = lesser;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的左孩子=节点的左孩子的右孩子</span></span><br><span class="line">    node.lesser = greater;</span><br><span class="line">    <span class="comment">//若存在右孩子，节点的左孩子的右孩子的父节点=节点</span></span><br><span class="line">    <span class="keyword">if</span> (greater != <span class="keyword">null</span>)</span><br><span class="line">        greater.parent = node;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//非root节点</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node == parent.lesser) &#123;</span><br><span class="line">            <span class="comment">//当前节点是左孩子</span></span><br><span class="line">            parent.lesser = lesser;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node == parent.greater) &#123;</span><br><span class="line">            <span class="comment">//当前节点是右孩子</span></span><br><span class="line">            parent.greater = lesser;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Yikes! I'm not related to my parent. "</span> + node.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//旋转后的root节点指向旋转前的parent节点</span></span><br><span class="line">        lesser.parent = parent;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        root = lesser;</span><br><span class="line">        root.parent = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> Node&lt;T&gt; <span class="title">removeValue</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//找到待删除节点</span></span><br><span class="line">    Node&lt;T&gt; nodeToRemoved = <span class="keyword">this</span>.getNode(value);</span><br><span class="line">    <span class="keyword">if</span> (nodeToRemoved == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//找到替换节点（左子树最大/右子树最小/左子树/右子树）</span></span><br><span class="line">    Node&lt;T&gt; replacementNode = <span class="keyword">this</span>.getReplacementNode(nodeToRemoved);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 替换父节点处理</span></span><br><span class="line">    AVLNode&lt;T&gt; nodeToRefactor = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (replacementNode != <span class="keyword">null</span>)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) replacementNode.parent;</span><br><span class="line">    <span class="keyword">if</span> (nodeToRefactor == <span class="keyword">null</span>)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) nodeToRemoved.parent;</span><br><span class="line">    <span class="keyword">if</span> (nodeToRefactor != <span class="keyword">null</span> &amp;&amp; nodeToRefactor == nodeToRemoved)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) replacementNode;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//替换节点</span></span><br><span class="line">    replaceNodeWithNode(nodeToRemoved, replacementNode);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//遍历替换节点2度内的子节点进行重平衡处理</span></span><br><span class="line">    <span class="keyword">while</span> (nodeToRefactor != <span class="keyword">null</span>) &#123;</span><br><span class="line">        nodeToRefactor.updateHeight();</span><br><span class="line">        balanceAfterDelete(nodeToRefactor);</span><br><span class="line"></span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) nodeToRefactor.parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodeToRemoved;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="更新节点"><a href="#更新节点" class="headerlink" title="更新节点"></a>更新节点</h3><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>时间复杂度：O(log(n))<br>空间复杂度：O(n)    </p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>AVL是一种高度平衡的二叉树，所以通常的结果是，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。<br>当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL还是优于红黑的。</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>JMS消息中间件</title>
    <url>/2017/10/01/JMS%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</url>
    <content><![CDATA[<p>JMS即Java消息服务（Java Message Service）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。<br>Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。</p>
<blockquote>
<p>JMS (Java Message Service) is an API that provides the facility to create， send and read messages。<br>It provides loosely coupled（松耦合）， reliable（可靠） and asynchronous（异步） communication。</p>
</blockquote>
<a id="more"></a> 
<h1 id="JMS消息中间件"><a href="#JMS消息中间件" class="headerlink" title="JMS消息中间件"></a>JMS消息中间件</h1><p>JMS全称是Java Message Service。其是JavaEE技术规范中的一个重要组成部分，是一种企业消息处理的规范。它的作用就像一个智能交换机，负责路由分布式应用中各个组件所发出的消息；</p>
<ul>
<li>JMS提供了一组通用的Java API，开发者可以通过API来 创建，发送，接收，读取 、消息；</li>
<li>JMS是一种和具体实现厂商无关的API。它的作用类似于JDBC。不管底层采用何种消息服务器的实现，应用程序总是面向通用的JMS API编程；</li>
<li>常用的有apache的ActiveMQ，Jboss的HornetQ</li>
</ul>
<h1 id="JMS优势"><a href="#JMS优势" class="headerlink" title="JMS优势"></a>JMS优势</h1><p>1。 异步 Asynchronous: To receive the message， client is not required to send request。 Message will arrive automatically to the client。 消息采用异步处理机制，避免客户机等待。<br>2。 可靠 Reliable: It provides assurance that message is delivered。<br>JMS可以持久的保存消息，因而提高系统的可靠性。<br>3。 效率：JMS允许一条消息同时发给多个接受者，更具效率。</p>
<h1 id="JMS总体架构"><a href="#JMS总体架构" class="headerlink" title="JMS总体架构"></a>JMS总体架构</h1><p>JMS的架构总体架构分3部分：<br>1。 JMS服务器，路由消息的服务系统，广义上说就是服务器，比如JBOSS，GLASSFISH，WAS8；<br>2。 JMS生产者，负责创建并发送消息的程序组件；<br>3。 JMS消费者，负责读取并处理消息的程序组件。</p>
<h1 id="JMS的消息机制模型"><a href="#JMS的消息机制模型" class="headerlink" title="JMS的消息机制模型"></a>JMS的消息机制模型</h1><p>JMS的消息机制模型主要分2类:</p>
<h2 id="点对点PTP模型"><a href="#点对点PTP模型" class="headerlink" title="点对点PTP模型"></a>点对点PTP模型</h2><ul>
<li>PTP消息处理模型为应用中的各个逻辑处理单元提供可靠的通信支持；</li>
<li>在PTP通信中，JMS把每一个消息传递给一个消息消费者；</li>
<li>JMS系统保证消息传递给消费者，消息不会同时被多个消费者接受；</li>
<li>如果消息消费者不在连接范围内，JMS会自动保证消息不会丢失。直到消息消费者进入连接，消息将自动送达。因此JMS需要将消息保存到永久介质上如数据库；</li>
</ul>
<h2 id="发布-订阅Pub-Sub模型"><a href="#发布-订阅Pub-Sub模型" class="headerlink" title="发布/订阅Pub-Sub模型"></a>发布/订阅Pub-Sub模型</h2><ul>
<li>在这种模型中，每个消息被发送到一个消息主题，该主题可以拥有多个订阅者。</li>
<li>JMS系统负责将消息的副本传给该主题的每个订阅者。</li>
</ul>
<hr>
<h1 id="Point-to-Point-PTP-Messaging-Domain"><a href="#Point-to-Point-PTP-Messaging-Domain" class="headerlink" title="Point-to-Point (PTP) Messaging Domain"></a>Point-to-Point (PTP) Messaging Domain</h1><p>Point-to-Point (PTP) Messaging Domain(点对点通信模型)是基于队列(Queue)的，对于PTP消息模型而言，它的消息目的是一个消息队列(Queue)，消息生产者每次发送消息总是把消息送入消息队列中，消息消费者总是从消息队列中读取消息。先进队列的消息将先被消息消费者读取。<br><img src="JMS_PTP_Model.png" alt="JMS_PTP_Model"></p>
<blockquote>
<p>In PTP model， one message is delivered to one receiver only。 Here，<br>Queue is used as a message oriented middleware (MOM) 面向消息的中间件。<br>The Queue is responsible to hold the message until receiver is ready。（串行）<br>In PTP model， there is no timing dependency between sender and receiver。</p>
</blockquote>
<h2 id="PTP模型的对象的主要概念和方法"><a href="#PTP模型的对象的主要概念和方法" class="headerlink" title="PTP模型的对象的主要概念和方法"></a>PTP模型的对象的主要概念和方法</h2><h3 id="Queue（队列）"><a href="#Queue（队列）" class="headerlink" title="Queue（队列）"></a>Queue（队列）</h3><p>Queue由JMS Provider 管理，队列由队列名识别，客户端可以通过JNDI 接口用队列名得到一个队列对象。</p>
<h3 id="TemporaryQueue（临时队列）"><a href="#TemporaryQueue（临时队列）" class="headerlink" title="TemporaryQueue（临时队列）"></a>TemporaryQueue（临时队列）</h3><p>由QueueConnection 创建，而且只能由创建它的QueueConnection 使用。</p>
<h3 id="QueueConnectionFactory"><a href="#QueueConnectionFactory" class="headerlink" title="QueueConnectionFactory"></a>QueueConnectionFactory</h3><p>客户端用QueueConnectionFactory 创建QueueConnection 对象。</p>
<h3 id="QueueConnection"><a href="#QueueConnection" class="headerlink" title="QueueConnection"></a>QueueConnection</h3><p>一个到JMS PTP provider 的连接，客户端可以用QueueConnection 创建QueueSession 来发送和接收消息。</p>
<h3 id="QueueSession"><a href="#QueueSession" class="headerlink" title="QueueSession"></a>QueueSession</h3><p>QueueSession提供一些方法创建QueueReceiver，QueueSender，QueueBrowser 和TemporaryQueue。<br>如果在QueueSession 关闭时，有一些消息已经被收到，但还没有被签收(acknowledged)，那么，当接收者下次连接到相同的队列时，这些消息还会被再次接收。</p>
<h3 id="QueueReceiver"><a href="#QueueReceiver" class="headerlink" title="QueueReceiver"></a>QueueReceiver</h3><p>客户端用QueueReceiver 接收队列中的消息，如果用户在QueueReceiver中设定了消息选择条件，那么不符合条件的消息会留在队列中，不会被接收到。</p>
<h3 id="QueueSender"><a href="#QueueSender" class="headerlink" title="QueueSender"></a>QueueSender</h3><p>客户端用QueueSender 发送消息到队列</p>
<h3 id="QueueBrowser"><a href="#QueueBrowser" class="headerlink" title="QueueBrowser"></a>QueueBrowser</h3><p>客户端可以QueueBrowser 浏览队列中的消息，但不会收走消息。</p>
<h3 id="QueueRequestor"><a href="#QueueRequestor" class="headerlink" title="QueueRequestor"></a>QueueRequestor</h3><p>JMS 提供QueueRequestor 类简化消息的收发过程。<br>QueueRequestor 的构造函数有两个参数:QueueSession 和queue，QueueRequestor 通过创建一个临时队列来完成最终的收发消息请求。</p>
<h3 id="Reliability可靠性"><a href="#Reliability可靠性" class="headerlink" title="Reliability可靠性"></a>Reliability可靠性</h3><p>队列可以长久地保存消息直到接收者收到消息。<br>接收者不需要因为担心消息会丢失而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。</p>
<h1 id="Publisher-Subscriber-Pub-Sub-Messaging-Domain"><a href="#Publisher-Subscriber-Pub-Sub-Messaging-Domain" class="headerlink" title="Publisher/Subscriber (Pub/Sub) Messaging Domain"></a>Publisher/Subscriber (Pub/Sub) Messaging Domain</h1><p>JMS Publisher/Subscriber (Pub/Sub) Messaging Domain(出版者/订阅者模型)模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作主题(topic)。</p>
<ul>
<li>主题可以被认为是消息的传输中介；</li>
<li>发布者(publisher)发布消息到主题；</li>
<li>订阅者(subscribe) 从主题订阅消息；</li>
<li>主题使得消息订阅者和消息发布者保持互相独立，不需要接触即可保证消息的传送。<br><img src="JMS_Pub-Sub_Model..png" alt="JMS_Pub-Sub_Model."> </li>
</ul>
<blockquote>
<p>In Pub/Sub model， one message is delivered to all the subscribers。 It is like broadcasting。 Here，<br>Topic（主题） is used as a message oriented middleware that is responsible to hold and deliver messages。<br>In PTP model， there is timing dependency between publisher and subscriber。</p>
</blockquote>
<h2 id="JMS-Pub-Sub-模型中的主要概念和对象"><a href="#JMS-Pub-Sub-模型中的主要概念和对象" class="headerlink" title="JMS Pub/Sub 模型中的主要概念和对象"></a>JMS Pub/Sub 模型中的主要概念和对象</h2><h3 id="subscription（订阅）"><a href="#subscription（订阅）" class="headerlink" title="subscription（订阅）"></a>subscription（订阅）</h3><p>消息订阅分为非持久订阅(non-durable subscription)和持久订阅(durable subscrip-tion)：</p>
<ul>
<li>非持久订阅只有当客户端处于激活状态，也就是和JMS Provider 保持连接状态才能收到发送到某个主题的消息，而当客户端处于离线状态，这个时间段发到主题的消息将会丢失，永远不会收到。</li>
<li>持久订阅时，客户端向JMS 注册一个识别自己身份的ID，当这个客户端处于离线时，JMS Provider 会为这个ID 保存所有发送到主题的消息，当客户再次连接到JMS Provider时，会根据自己的ID 得到所有当自己处于离线时发送到主题的消息。</li>
</ul>
<h3 id="Topic（主题）"><a href="#Topic（主题）" class="headerlink" title="Topic（主题）"></a>Topic（主题）</h3><ul>
<li>Topic主题由JMS Provider 管理，</li>
<li>主题由主题名识别</li>
<li>客户端可以通过JNDI 接口用主题名得到一个主题对象。</li>
<li>JMS没有给出主题的组织和层次结构的定义，由JMS Provider 自己定义</li>
</ul>
<h3 id="TemporaryTopic（临时主题）"><a href="#TemporaryTopic（临时主题）" class="headerlink" title="TemporaryTopic（临时主题）"></a>TemporaryTopic（临时主题）</h3><p>临时主题由TopicConnection创建，而且只能由创建它的TopicConnection使用。临时主题不能提供持久订阅功能。</p>
<h3 id="TopicConnectionFactory"><a href="#TopicConnectionFactory" class="headerlink" title="TopicConnectionFactory"></a>TopicConnectionFactory</h3><p>客户端用TopicConnectionFactory创建TopicConnection对象。</p>
<h3 id="TopicConnection"><a href="#TopicConnection" class="headerlink" title="TopicConnection"></a>TopicConnection</h3><p>TopicConnection是一个到JMS Pub/Sub provider的连接，客户端可以用TopicConnection创建TopicSession 来发布和订阅消息。</p>
<h3 id="TopicSession"><a href="#TopicSession" class="headerlink" title="TopicSession"></a>TopicSession</h3><p>TopicSession 提供一些方法创建TopicPublisher，TopicSubscriber，TemporaryTopic。它还提供unsubscribe方法取消消息的持久订阅。</p>
<h3 id="TopicPublisher"><a href="#TopicPublisher" class="headerlink" title="TopicPublisher"></a>TopicPublisher</h3><p>客户端用TopicPublisher 发布消息到主题。</p>
<h3 id="TopicSubscriber"><a href="#TopicSubscriber" class="headerlink" title="TopicSubscriber"></a>TopicSubscriber</h3><p>客户端用TopicSubscriber 接收发布到主题上的消息。可以在TopicSubscriber 中设置消息过滤功能，这样，不符合要求的消息不会被接收。</p>
<h3 id="Durable-TopicSubscriber"><a href="#Durable-TopicSubscriber" class="headerlink" title="Durable TopicSubscriber"></a>Durable TopicSubscriber</h3><p>如果一个客户端需要持久订阅消息，可以使用Durable TopicSubscriber，TopSession 提供一个方法createDurableSubscriber创建Durable TopicSubscriber 对象。</p>
<h3 id="Recovery-and-Redelivery（恢复和重新派送）"><a href="#Recovery-and-Redelivery（恢复和重新派送）" class="headerlink" title="Recovery and Redelivery（恢复和重新派送）"></a>Recovery and Redelivery（恢复和重新派送）</h3><p>恢复和重新派送非持久订阅状态下，不能恢复或重新派送一个未签收的消息。只有持久订阅才能恢复或重新派送一个未签收的消息</p>
<h3 id="TopicRequestor"><a href="#TopicRequestor" class="headerlink" title="TopicRequestor"></a>TopicRequestor</h3><ul>
<li>JMS 提供TopicRequestor 类简化消息的收发过程。</li>
<li>TopicRequestor的构造函数有两个参数:TopicSession和topic。</li>
<li>TopicRequestor 通过创建一个临时主题来完成最终的发布和接收消息请求。</li>
</ul>
<h3 id="Reliability（可靠性）"><a href="#Reliability（可靠性）" class="headerlink" title="Reliability（可靠性）"></a>Reliability（可靠性）</h3><ul>
<li>当所有的消息必须被接收，则用持久订阅模式。</li>
<li>当丢失消息能够被容忍，则用非持久订阅模式。</li>
</ul>
<h1 id="JMS-Programming-Model（JMS编程模型）"><a href="#JMS-Programming-Model（JMS编程模型）" class="headerlink" title="JMS Programming Model（JMS编程模型）"></a>JMS Programming Model（JMS编程模型）</h1><p><img src="JMS Programming Model.png" alt="JMS Programming Model"></p>
<h2 id="ConnectionFactory（连接工厂）"><a href="#ConnectionFactory（连接工厂）" class="headerlink" title="ConnectionFactory（连接工厂）"></a>ConnectionFactory（连接工厂）</h2><p>它由服务器管理员创建，并绑定到JNDI树上，JMS客户端使用JNDI查找，定位连接工厂，然后利用连接工厂创建JMS连接。</p>
<h2 id="Connection（JMS连接）"><a href="#Connection（JMS连接）" class="headerlink" title="Connection（JMS连接）"></a>Connection（JMS连接）</h2><p>连接表示客户机和服务器之间的活动连接。JMS通过连接工厂创建连接。JMS是一个相当重要的对象。通常，每个客户机使用单独的连接，而每个连接则可以连接多个JMS目的。</p>
<h2 id="Session（JMS会话）"><a href="#Session（JMS会话）" class="headerlink" title="Session（JMS会话）"></a>Session（JMS会话）</h2><p>会话表示客户机与JMS服务器之间的通信状态。JMS会话建立在连接之上，表示JMS客户机与服务器之间的通信线程。会话定义了消息的顺序。JMS使用会话进行事务性的消息处理。</p>
<h2 id="Destination（JMS消息目的地）"><a href="#Destination（JMS消息目的地）" class="headerlink" title="Destination（JMS消息目的地）"></a>Destination（JMS消息目的地）</h2><p>Destination即消息生产者发送消息的目的地，也就是消息消费者获取消息的消息源。</p>
<h2 id="Message-Producer-（JMS消息生产者）"><a href="#Message-Producer-（JMS消息生产者）" class="headerlink" title="Message Producer （JMS消息生产者）"></a>Message Producer （JMS消息生产者）</h2><p>消息生产者负责创建消息并将消息发送到消息目的。</p>
<h2 id="Message-Consumer-（JMS消息消费者）"><a href="#Message-Consumer-（JMS消息消费者）" class="headerlink" title="Message Consumer （JMS消息消费者）"></a>Message Consumer （JMS消息消费者）</h2><p>消息消费者负责接收消息并读取消息内容。</p>
<h1 id="JMS消息的确认方式"><a href="#JMS消息的确认方式" class="headerlink" title="JMS消息的确认方式"></a>JMS消息的确认方式</h1><p>消息的确认是指消息接受者接到消息，并做出了对应的处理之后，它将回送一个确认消息。<br>对于 <strong>非事务性</strong> 会话，创建会话时应该指定确定方式，JMS定义了3种确认方式:</p>
<h2 id="Auto-ACKnowledge-自动通知"><a href="#Auto-ACKnowledge-自动通知" class="headerlink" title="Auto_ACKnowledge    自动通知"></a>Auto_ACKnowledge    自动通知</h2><p>对于同步消费者，Receive方法调用返回，且没有异常发生时，将自动对收到的消息予以确认。<br>对于异步消息，当onMessage方法返回，且没有异常发生时，即对收到的消息自动确认。  </p>
<h2 id="Client-AcKnowledge-客户端自行决定通知时机"><a href="#Client-AcKnowledge-客户端自行决定通知时机" class="headerlink" title="Client_AcKnowledge    客户端自行决定通知时机"></a>Client_AcKnowledge    客户端自行决定通知时机</h2><p>这种方式要求客户端使用javax。jms。Message。acknowledge()方法完成确认。  </p>
<h2 id="Dups-OK-ACKnowledge-延时-批量通知"><a href="#Dups-OK-ACKnowledge-延时-批量通知" class="headerlink" title="Dups_OK_ACKnowledge    延时/批量通知"></a>Dups_OK_ACKnowledge    延时/批量通知</h2><p>这种确认方式允许JMS不必急于确认收到的消息，允许在收到多个消息之后一次完成确认，<br>与Auto_AcKnowledge相比，这种确认方式在某些情况下可能更有效，因为没有确认，当系统崩溃或者网络出现故障的时候，消息可以被重新传递。 </p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://docs.oracle.com/cd/E19148-01/820-0533/aeraq/index.html">Sun Java System Message Queue</a><br><a href="http://www.javatpoint.com/jms-tutorial">jms-tutorial</a>  </p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka学习笔记</title>
    <url>/2017/10/08/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Kafka is used for building <code>real-time</code> data pipelines and streaming apps. It is <code>horizontally scalable</code>, <code>fault-tolerant</code>, <code>wicked fast</code>, and runs in production in thousands of companies.</p>
<hr>
<a id="more"></a> 
<h2 id="Kafka学习笔记"><a href="#Kafka学习笔记" class="headerlink" title="Kafka学习笔记"></a>Kafka学习笔记</h2><h1 id="关于消息中间件"><a href="#关于消息中间件" class="headerlink" title="关于消息中间件"></a>关于消息中间件</h1><blockquote>
<p>什么是消息中间件？</p>
</blockquote>
<p>举个生产者/消费者的例子，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋。</p>
<ul>
<li>假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。</li>
<li>再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，”鸡蛋“又丢失了，</li>
<li>这个时候我们放个篮子在它们中间，生产出来的鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里</li>
<li>而这个篮子就是”kafka“。鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的（就是tcp、http什么的），也称为报文，也叫“消息”。消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。<br>kafka是干什么的，它就是那个”篮子”。</li>
</ul>
<h1 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h1><p><img src="Alt text.png" alt="Alt text"><br>Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。<br>Kafka是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p>
<ul>
<li>快速：单个kafka服务每秒可以处理数以千计从客户端发来的几百兆字节的读取和写入。</li>
<li>可扩展性：kafka被设计为允许单个集群作为中央数据骨干大型组织。它可以弹性地，透明地扩展，无需停机。数据流被划分并分布在机器的集群中，允许数据流比任何单一机器的性能大，并让集群来协调消费者。</li>
<li>可靠性：消息被保存在磁盘上,并在集群中复制，防止数据丢失。每个代理可以处理TB级的消息，而不影响性能。</li>
<li>分布式设计：kafka使用现代化的集群为中心设计，并提供了强大的耐用性和容错性保证。</li>
</ul>
<h1 id="kafka名词解释"><a href="#kafka名词解释" class="headerlink" title="kafka名词解释"></a>kafka名词解释</h1><p>后面大家会看到一些关于kafka的名词，比如topic、producer、consumer、broker，我这边来简单说明一下。</p>
<ul>
<li><code>topic</code>：Kafka将消息种子(Feed)分门别类， 每一类的消息称之为话题(Topic)。例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发；</li>
<li><code>partion</code>：topic物理上的分组，一个topic可以分为多个partion，每个partion是一个有序的队列；</li>
<li><code>segment</code>：partion物理上由多个segment组成；</li>
<li><code>offset</code>：每个partion都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partion中。每个partion中的每个消息都由一个连续的序列化叫做offset，由于partion唯一标识一条消息；</li>
<li><code>producer</code>： 发布消息的对象称之为话题生产者(Kafka topic producer)；</li>
<li><code>consumer</code>：订阅消息并处理发布的消息的Feed的对象称之为话题消费者(consumers)消费者；</li>
<li><code>broker</code>： 消息中间件处理节点，一个Kafka节点就是一个Broker，多个Broker可以组成一个Kafka集群；</li>
</ul>
<p>Client和Server之间的通讯是通过一条简单、高能并且和开发语言无关的TCP协议。<br>除了Java Client外，还有非常多的其它编程语言的Client。</p>
<h1 id="Kafka的保证-Guarantees"><a href="#Kafka的保证-Guarantees" class="headerlink" title="Kafka的保证(Guarantees)"></a>Kafka的保证(Guarantees)</h1><p>生产者发送到一个特定的Topic的分区上的消息将会按照它们发送的顺序依次加入<br>消费者收到的消息也是此顺序<br>如果一个Topic配置了复制因子( replication facto)为N， 那么可以允许N-1服务器宕机而不丢失任何已经增加的消息</p>
<h1 id="Kafka的文件存储机制"><a href="#Kafka的文件存储机制" class="headerlink" title="Kafka的文件存储机制"></a>Kafka的文件存储机制</h1><p>一个商业化消息队列的好坏，其文件存储机制是衡量一个消息队列服务技术水平的最关键指标之一。</p>
<h2 id="topic中partion存储分布"><a href="#topic中partion存储分布" class="headerlink" title="topic中partion存储分布"></a>topic中partion存储分布</h2><p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，<br>partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>
<h2 id="partion中文件存储方式"><a href="#partion中文件存储方式" class="headerlink" title="partion中文件存储方式"></a>partion中文件存储方式</h2><ul>
<li>每个partion(目录)相当于一个巨型文件被平均分配到多个<code>大小相等segment</code>(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</li>
<li>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。<br>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。<h2 id="partion中segment文件存储结构"><a href="#partion中segment文件存储结构" class="headerlink" title="partion中segment文件存储结构"></a>partion中segment文件存储结构</h2></li>
<li>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</li>
<li>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</li>
<li>索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</li>
</ul>
<p>message物理结构参数说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">关键字</th>
<th style="text-align:left">解释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">8 byte offset</td>
<td style="text-align:left">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td style="text-align:left">4 byte message size</td>
<td style="text-align:left">message大小</td>
</tr>
<tr>
<td style="text-align:left">4 byte CRC32</td>
<td style="text-align:left">用crc32校验message</td>
</tr>
<tr>
<td style="text-align:left">1 byte “magic”</td>
<td style="text-align:left">表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td style="text-align:left">1 byte “attributes”</td>
<td style="text-align:left">表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td style="text-align:left">4 byte key length</td>
<td style="text-align:left">表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td style="text-align:left">K byte key</td>
<td style="text-align:left">可选</td>
</tr>
<tr>
<td style="text-align:left">value bytes payload</td>
<td style="text-align:left">表示实际消息数据</td>
</tr>
</tbody>
</table>
</div>
<h2 id="在partion中如何通过offset找到message"><a href="#在partion中如何通过offset找到message" class="headerlink" title="在partion中如何通过offset找到message"></a>在partion中如何通过offset找到message</h2><p><img src="Alt text.png" alt="Alt text"><br><img src="Alt text.png" alt="Alt text"><br>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<ul>
<li>第一步查找segment file，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。 当offset=368776时定位到00000000000000368769.index|log</li>
<li>第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</li>
</ul>
<p>从上图可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<h2 id="Kafka中读写message特点"><a href="#Kafka中读写message特点" class="headerlink" title="Kafka中读写message特点"></a>Kafka中读写message特点</h2><h3 id="写message"><a href="#写message" class="headerlink" title="写message"></a>写message</h3><ul>
<li>消息从java堆转入page cache(即物理内存)。</li>
<li>由异步线程刷盘,消息从page cache刷入磁盘。<h3 id="读message"><a href="#读message" class="headerlink" title="读message"></a>读message</h3></li>
<li>消息直接从page cache转入socket发送出去。</li>
<li>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁盘Load消息到page cache，然后直接从socket发出去；</li>
</ul>
<h2 id="Kafka高效文件存储设计特点"><a href="#Kafka高效文件存储设计特点" class="headerlink" title="Kafka高效文件存储设计特点"></a>Kafka高效文件存储设计特点</h2><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li>
</ul>
<h1 id="Kafka常见问题"><a href="#Kafka常见问题" class="headerlink" title="Kafka常见问题"></a>Kafka常见问题</h1><ul>
<li>kafka节点之间如何复制备份的？</li>
<li>kafka消息是否会丢失？为什么？</li>
<li>kafka最合理的配置是什么？</li>
<li>kafka的leader选举机制是什么？</li>
<li>kafka对硬件的配置有什么要求？</li>
<li>kafka的消息保证有几种方式？</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.orchome.com/kafka/index">kafka中文教程</a></li>
<li><a href="http://blog.csdn.net/suifeng3051/article/details/48053965">enter link description here</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark与Hadoop对比</title>
    <url>/2017/10/11/Spark%E4%B8%8EHadoop%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>整理Hadoop和Spark的设计理念，组成模块，集群架构，应用场景；<br>Spark生态齐全，从数据系统Lambda架构的角度，更具优势</p>
<hr>
<a id="more"></a>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><blockquote>
<p>Hadoop解决了什么问题？</p>
</blockquote>
<p>Hadoop解决了大数据（大到一台计算机无法进行存储，一台计算机无法在要求的时间内完成处理）的可靠存储和计算问题。</p>
<h2 id="Hadoop组件"><a href="#Hadoop组件" class="headerlink" title="Hadoop组件"></a>Hadoop组件</h2><p><img src="Hadoop-Ecosystem.png" alt="Hadoop-Ecosystem"></p>
<h2 id="HDFS（Hadoop-Distributed-File-System-）"><a href="#HDFS（Hadoop-Distributed-File-System-）" class="headerlink" title="HDFS（Hadoop Distributed File System ）"></a>HDFS（Hadoop Distributed File System ）</h2><p>Hadoop分布式文件系统HDFS被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。</p>
<ul>
<li>HDFS是一个高度容错性的系统，适合部署在廉价的机器上。</li>
<li>HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。</li>
<li>HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。</li>
<li>HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。</li>
<li>HDFS是Apache Hadoop Core项目的一部分。</li>
</ul>
<blockquote>
<p>在由普通PC组成的集群上提供高可靠的文件存储，通过将块保存多个副本的办法解决服务器或硬盘坏掉的问题。</p>
</blockquote>
<p><img src="HDFS.png" alt="HDFS"></p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>通过简单的<code>Mapper</code>和<code>Reducer</code>的抽象提供一个编程模型，可以在一个由几十台上百台的PC组成的不可靠集群上并发地，分布式地处理大量的数据集，而把并发、分布式（如机器间通信）和故障恢复等计算细节隐藏起来。<br>而Mapper和Reducer的抽象，又是各种各样的复杂数据处理都可以分解为的基本元素。<br>这样，复杂的数据处理可以分解为由多个Job（包含一个Mapper和一个Reducer）组成的有向无环图（DAG），然后每个Mapper和Reducer放到Hadoop集群上执行，就可以得出结果。</p>
<p>在MapReduce中，Shuffle是一个非常重要的过程，正是有了看不见的Shuffle过程，才可以使在MapReduce之上写数据处理的开发者完全感知不到分布式和并发的存在。<br><img src="MapReduce-Shuffle.png" alt="MapReduce-Shuffle"><br>广义的Shuffle是指图中在Map和Reuce之间的一系列过程。</p>
<h2 id="Hadoop的局限和不足"><a href="#Hadoop的局限和不足" class="headerlink" title="Hadoop的局限和不足"></a>Hadoop的局限和不足</h2><p>但是，MapRecue存在以下局限，使用起来比较困难。</p>
<ul>
<li>抽象层次低，需要手工编写代码来完成，使用上难以上手；</li>
<li>只提供两个操作，Map和Reduce，表达力欠缺；</li>
<li>一个Job只有Map和Reduce两个阶段（Phase），复杂的计算需要大量的Job完成，Job之间的依赖关系是由开发者自己管理的；</li>
<li>处理逻辑隐藏在代码细节中，没有整体逻辑；</li>
<li>中间结果也放在HDFS文件系统中；</li>
<li>ReduceTask需要等待所有MapTask都完成后才可以开始；</li>
<li>时延高，只适用Batch数据处理，对于交互式数据处理，实时数据处理的支持不够；</li>
<li>对于迭代式数据处理性能比较差；</li>
</ul>
<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p>Apache Spark是一个新兴的大数据处理的引擎，主要特点是提供了一个集群的分布式内存抽象，以支持需要工作集的应用。<br>这个抽象就是<code>RDD</code>（Resilient Distributed Dataset），RDD就是一个不可变的带分区的记录集合，RDD也是Spark中的编程模型。</p>
<h2 id="Spark组件"><a href="#Spark组件" class="headerlink" title="Spark组件"></a>Spark组件</h2><p><img src="Spark-Stack.png" alt="Spark-Stack"></p>
<h2 id="RDD（Resilient-Distributed-Datasets）"><a href="#RDD（Resilient-Distributed-Datasets）" class="headerlink" title="RDD（Resilient Distributed Datasets）"></a>RDD（Resilient Distributed Datasets）</h2><p>Spark提供了RDD上的两类操作，转换（transformation）和动作（action）。</p>
<ul>
<li>转换：用来定义一个新的RDD，包括map, flatMap, filter, union, sample, join, groupByKey, cogroup, ReduceByKey, cros, sortByKey, mapValues等，</li>
<li>动作：返回一个结果，包括collect, reduce, count, save, lookupKey。</li>
</ul>
<p>RDD就是一个分布式的数据集合（Collection），对这个集合的任何操作都可以像函数式编程中操作内存中的集合一样直观、简便，但集合操作的实现确是在后台分解成一系列Task发送到几十台上百台服务器组成的集群上完成的。</p>
<blockquote>
<p>RDD（弹性分布式数据集）如何理解？</p>
<p>如果说，<code>MapReduce</code>是公认的分布式数据处理的低层次抽象，类似逻辑门电路中的与门，或门和非门；<br>那么Spark的<code>RDD</code>就是分布式大数据处理的高层次抽象，类似逻辑电路中的编码器或译码器等。</p>
</blockquote>
<h2 id="DAG（Directed-Acyclic-Graph）"><a href="#DAG（Directed-Acyclic-Graph）" class="headerlink" title="DAG（Directed Acyclic Graph）"></a>DAG（Directed Acyclic Graph）</h2><p>在Spark中，所有RDD的转换都是是<code>Lazy（惰性）</code>求值的。<br>RDD的转换操作会生成新的RDD，新的RDD的数据依赖于原来的RDD的数据，每个RDD又包含多个分区。<br>那么一段程序实际上就构造了一个由相互依赖的多个RDD组成的有向无环图（DAG），并通过在RDD上执行动作将这个<code>有向无环图作为一个Job</code>提交给Spark执行。<br>Spark对于有向无环图Job进行调度，确定<code>阶段（Stage），分区（Partition），流水线（Pipeline），任务（Task）和缓存（Cache）</code>，进行优化，并在Spark集群上运行Job。<br>RDD之间的依赖分为<code>宽依赖</code>（依赖多个分区）和<code>窄依赖</code>（只依赖一个分区），在确定阶段时，需要根据宽依赖划分阶段。根据分区划分任务。<br><img src="Spark-DAG.png" alt="Spark-DAG"></p>
<blockquote>
<p>由RDD组成的有向无环图（DAG）的执行是调度程序将其生成物理计划并进行优化，然后在Spark集群上执行的。<br>Spark还提供了一个类似于MapReduce的执行引擎，该引擎更多地使用内存，而不是磁盘，得到了更好的执行性能。</p>
</blockquote>
<h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><p>Spark支持故障恢复的方式也不同，提供两种方式，</p>
<ul>
<li><code>Linage</code>，通过数据的血缘关系，再执行一遍前面的处理；</li>
<li><code>Checkpoint</code>，将数据集存储到持久存储中。</li>
</ul>
<p>Spark为迭代式数据处理提供更好的支持。每次迭代的数据可以保存在内存中，而不是写入文件。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>Spark的性能相比Hadoop有很大提升，2014年10月，Spark完成了一个Daytona Gray类别的Sort Benchmark测试，排序完全是在磁盘上进行的，与Hadoop之前的测试的对比结果如表格所示：<br><img src="Hadoop-Spark比较.png" alt="Hadoop-Spark比较"><br><a href="https://databricks.com/blog/2014/11/05/spark-officially-sets-a-new-record-in-large-scale-sorting.html"> Spark officially sets a new record in large-scale sorting</a><br>从表格中可以看出排序100TB的数据（1万亿条数据），Spark只用了Hadoop所用1/10的计算资源，耗时只有Hadoop的1/3。</p>
<h2 id="Spark的一站式解决方案"><a href="#Spark的一站式解决方案" class="headerlink" title="Spark的一站式解决方案"></a>Spark的一站式解决方案</h2><p>Spark的优势不仅体现在性能提升上的，Spark框架为批处理（Spark Core），交互式（Spark SQL），流式（Spark Streaming），机器学习（MLlib），图计算（GraphX）提供一个统一的数据处理平台，这相对于使用Hadoop有很大优势。</p>
<p>按照Databricks的连城的说法是<code>One Stack To Rule Them All</code><br>特别是在有些情况下，你需要进行一些ETL工作，然后训练一个机器学习的模型，最后进行一些查询，如果是使用Spark，你可以在一段程序中将这三部分的逻辑完成形成一个大的有向无环图（DAG），而且Spark会对大的有向无环图进行整体优化。</p>
<p>例如下面的程序：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//用Spark SQL 查寻出了一些点</span></span><br><span class="line"><span class="keyword">val</span> points = sqlContext.sql(<span class="string">"SELECT latitude, longitude FROM historic_tweets"</span>)  </span><br><span class="line"><span class="comment">//用MLlib中的K-means算法使用这些点训练了一个模型</span></span><br><span class="line"><span class="keyword">val</span> model = <span class="type">KMeans</span>.train(points, <span class="number">10</span>)</span><br><span class="line"><span class="comment">//用Spark Streaming处理流中的消息，使用了训练好的模型。</span></span><br><span class="line">sc.twitterStream(...).map(t =&gt; (model.closestCenter(t.location), <span class="number">1</span>))   .reduceByWindow(<span class="string">"5s"</span>, _ + _)</span><br></pre></td></tr></table></figure><br><a href="https://www.slideshare.net/Hadoop_Summit/building-a-unified-data-pipeline-in-apache-spark">building-a-unified-data-pipeline-in-apache-spark</a></p>
<h3 id="Lambda-Architecture"><a href="#Lambda-Architecture" class="headerlink" title="Lambda Architecture"></a>Lambda Architecture</h3><p>Lambda Architecture是一个大数据处理平台的参考模型，如下图所示：<br><img src="Spark Lambda Architecture.png" alt="Spark Lambda Architecture"><br><a href="https://mapr.com/developercentral/lambda-architecture/">Spark Lambda Architecture</a><br>其中包含3层，Batch Layer，Speed Layer和Serving Layer，由于Batch Layer和Speed Layer的数据处理逻辑是一致的，如果用Hadoop作为Batch Layer，而用Storm作为Speed Layer，你需要维护两份使用不同技术的代码。<br>而Spark可以作为Lambda Architecture一体化的解决方案,大致如下：</p>
<ul>
<li>Batch Layer批处理层，<code>HDFS+Spark Core</code>，将实时的增量数据追加到HDFS中，使用Spark Core批量处理全量数据，生成全量数据的视图；</li>
<li>Speed Layer实时处理层，<code>Spark Streaming</code>来处理实时的增量数据，以较低的时延生成实时数据的视图；</li>
<li>Serving Layer服务层，<code>HDFS+Spark SQL</code>（也许还有BlinkDB），存储Batch Layer和Speed Layer输出的视图，提供低时延的即席查询功能，将批量数据的视图与实时数据的视图合并；</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><blockquote>
<p>Spark解决了Hadoop的哪些问题呢？</p>
</blockquote>
<ol>
<li>抽象层次低，需要手工编写代码来完成，使用上难以上手。<br>=&gt;基于RDD的抽象，实数据处理逻辑的代码非常简短。。</li>
<li>只提供两个操作，Map和Reduce，表达力欠缺。<br>=&gt;提供很多转换和动作，很多基本操作如Join，GroupBy已经在RDD转换和动作中实现。</li>
<li>一个Job只有Map和Reduce两个阶段（Phase），复杂的计算需要大量的Job完成，Job之间的依赖关系是由开发者自己管理的。<br>=&gt;一个Job可以包含RDD的多个转换操作，在调度时可以生成多个阶段（Stage），而且如果多个map操作的RDD的分区不变，是可以放在同一个Task中进行。</li>
<li>处理逻辑隐藏在代码细节中，没有整体逻辑<br>=&gt;在Scala中，通过匿名函数和高阶函数，RDD的转换支持流式API，可以提供处理逻辑的整体视图。代码不包含具体操作的实现细节，逻辑更清晰。</li>
<li>中间结果也放在HDFS文件系统中<br>=&gt;中间结果放在内存中，内存放不下了会写入本地磁盘，而不是HDFS。</li>
<li>ReduceTask需要等待所有MapTask都完成后才可以开始<br>=&gt; 分区相同的转换构成流水线放在一个Task中运行，分区不同的转换需要Shuffle，被划分到不同的Stage中，需要等待前面的Stage完成后才可以开始。</li>
<li>时延高，只适用Batch数据处理，对于交互式数据处理，实时数据处理的支持不够<br>=&gt;通过将流拆成小的batch提供Discretized Stream处理流数据。</li>
<li>对于迭代式数据处理性能比较差<br>=&gt;通过在内存中缓存数据，提高迭代式计算的性能。</li>
</ol>
<p>so，Hadoop MapReduce会被新一代的大数据处理平台替代是技术发展的趋势，而在新一代的大数据处理平台中，Spark目前得到了最广泛的认可和支持。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://m.blog.csdn.net/lvsaixia/article/details/51778487">数据系统架构-Lambda architecture</a></li>
<li><a href="https://www.zhihu.com/question/26568496">知乎-与 Hadoop 对比，如何看待 Spark 技术？</a></li>
<li><a href="http://dongxicheng.org/framework-on-yarn/apache-spark-multi-threads-model/">Apache Spark探秘：多进程模型还是多线程模型？</a></li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之AVL树</title>
    <url>/2017/10/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BAVL%E6%A0%91/</url>
    <content><![CDATA[<p> An AVL tree is a <code>self-balancing binary search tree</code>, and it was the <code>first</code> such data structure to be invented.<br><a id="more"></a></p>
<h1 id="AVL"><a href="#AVL" class="headerlink" title="AVL"></a>AVL</h1><blockquote>
<p>The AVL tree is named after its two Soviet inventors, Georgy <code>A</code>delson-<code>V</code>elsky and Evgenii <code>L</code>andis, who published it in their 1962 paper “<code>An algorithm for the organization of information</code>“.</p>
<p>An AVL tree is a <code>self-balancing binary search tree</code>, and it was the <code>first</code> such data structure to be invented.<br>In an AVL tree, the heights of the two child subtrees of any node differ by at most one.<br>AVL trees are often compared with red-black trees because they support the same set of operations and because <code>red-black trees</code> also take <code>O(log n)</code> time for the basic operations. Because AVL trees are more <code>rigidly balanced</code>, they are <code>faster than red-black trees for lookup intensive applications</code>.<br>However, <code>red-black trees are faster for insertion and removal</code>.</p>
</blockquote>
<h2 id="AVL-Tree的性质"><a href="#AVL-Tree的性质" class="headerlink" title="AVL Tree的性质"></a>AVL Tree的性质</h2><ul>
<li>任意一个结点的key，比它的lesserChild的key大，比它的greaterChild的key小；</li>
<li>任意结点的孩子结点之间高度差距最大为1；</li>
</ul>
<h2 id="平衡检测"><a href="#平衡检测" class="headerlink" title="平衡检测"></a>平衡检测</h2><p>对于一棵树来说，它的<code>高度(height)</code>定义如下：</p>
<blockquote>
<p>从根节点(root)开始到某一个叶子节点(leaf)的最长路径(path)上结点的个数</p>
</blockquote>
<p>根据AVL树的定义，我们可以为所有的结点定义一个<code>平衡因子(balanced factor)</code>：</p>
<blockquote>
<p>某个结点的平衡因子等于该节点的greaterHeight的高度减去lesserHeight的高度</p>
</blockquote>
<p>根据平衡树的定义，计算得到的平衡因为会出现两种情况：</p>
<ul>
<li>如果平衡因子是<code>0, 1, -1</code> 这三个数的话，可以认定该节点是符合平衡树的定义的；</li>
<li>否则，该结点不平衡，需要重新平衡；<br>对于一个BST来说，<code>每次插入的元素只可能放在叶子结点上。所以只能影响某个子树是否平衡，对其他子树不会有任何的影响。</code><br>在这种情况下，我们只需要根据搜索的路径，从孩子往祖先找，如果有不平衡的结点就可以被找到。如果一直到根结点都没有发现不平衡结点，则可以认为这次的插入操作没有造成树的不平衡。</li>
</ul>
<h2 id="AVL保持平衡操作"><a href="#AVL保持平衡操作" class="headerlink" title="AVL保持平衡操作"></a>AVL保持平衡操作</h2><p>如果发现了某个不平衡的结点，那么就需要对该结点进行重平衡。实现重平衡的方法，是对该节点的子树进行<code>旋转(rotation)</code>。<br>旋转有两种情况，如下图所示：</p>
<ul>
<li>一种称为左旋转(关于X结点的左旋转);</li>
<li>一种称为右旋转(关于Y结点的右旋转);<br>AVL树的旋转实际可以用4种情况表达：LL,RR,LR,RL。LL型时单向右旋，RR时单向左旋；LR,RL时双向旋转（先左后右、先右后左)。<br><img src="AVL树的旋转.png" alt="AVL树的旋转"></li>
</ul>
<h2 id="AVL的结构"><a href="#AVL的结构" class="headerlink" title="AVL的结构"></a>AVL的结构</h2><p>AVL树节点-父类<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; </span>&#123;</span><br><span class="line">       <span class="keyword">protected</span> T id = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; parent = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; lesser = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">protected</span> Node&lt;T&gt; greater = <span class="keyword">null</span>;</span><br><span class="line">       <span class="function"><span class="keyword">protected</span> <span class="title">Node</span><span class="params">(Node&lt;T&gt; parent, T id)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">this</span>.parent = parent;</span><br><span class="line">           <span class="keyword">this</span>.id = id;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<p>AVL树节点<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">AVLNode</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">int</span> height = <span class="number">1</span>;</span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="title">AVLNode</span><span class="params">(Node&lt;T&gt; parent, T value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>(parent, value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//是否叶子节点</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isLeaf</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> ((lesser == <span class="keyword">null</span>) &amp;&amp; (greater == <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//更新节点height</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">updateHeight</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> lesserHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (lesser != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; lesserAVLNode = (AVLNode&lt;T&gt;) lesser;</span><br><span class="line">                lesserHeight = lesserAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> greaterHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (greater != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; greaterAVLNode = (AVLNode&lt;T&gt;) greater;</span><br><span class="line">                greaterHeight = greaterAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (lesserHeight &gt; greaterHeight) &#123;</span><br><span class="line">                height = lesserHeight + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                height = greaterHeight + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> height;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *获取节点平衡因子</span></span><br><span class="line"><span class="comment">         * </span></span><br><span class="line"><span class="comment">         * <span class="doctag">@return</span> 左孩子比有孩子长时，平衡因子小于0</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">getBalanceFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> lesserHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (lesser != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; lesserAVLNode = (AVLNode&lt;T&gt;) lesser;</span><br><span class="line">                lesserHeight = lesserAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> greaterHeight = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (greater != <span class="keyword">null</span>) &#123;</span><br><span class="line">                AVLNode&lt;T&gt; greaterAVLNode = (AVLNode&lt;T&gt;) greater;</span><br><span class="line">                greaterHeight = greaterAVLNode.height;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> greaterHeight - lesserHeight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="AVL树的增删改查"><a href="#AVL树的增删改查" class="headerlink" title="AVL树的增删改查"></a>AVL树的增删改查</h2><h3 id="新增节点"><a href="#新增节点" class="headerlink" title="新增节点"></a>新增节点</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Node&lt;T&gt; <span class="title">addValue</span><span class="params">(T id)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//新增节点（lesser/greater）</span></span><br><span class="line">    Node&lt;T&gt; nodeToReturn = <span class="keyword">super</span>.addValue(id);</span><br><span class="line">    AVLNode&lt;T&gt; nodeAdded = (AVLNode&lt;T&gt;) nodeToReturn;</span><br><span class="line">    <span class="comment">//更新节点高度</span></span><br><span class="line">    nodeAdded.updateHeight();</span><br><span class="line">    <span class="comment">//平衡树</span></span><br><span class="line">    balanceAfterInsert(nodeAdded);</span><br><span class="line">true</span><br><span class="line">true<span class="comment">//从当前新增节点，自下而上遍历，更新节点height，对不平衡节点进行旋转操作，使树保存平衡</span></span><br><span class="line">    nodeAdded = (AVLNode&lt;T&gt;) nodeAdded.parent;</span><br><span class="line">    <span class="keyword">while</span> (nodeAdded != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> h1 = nodeAdded.height;</span><br><span class="line"></span><br><span class="line">        nodeAdded.updateHeight();</span><br><span class="line">        balanceAfterInsert(nodeAdded);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If height before and after balance is the same, stop going up the tree</span></span><br><span class="line">        <span class="keyword">int</span> h2 = nodeAdded.height;</span><br><span class="line">        <span class="keyword">if</span> (h1==h2)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        nodeAdded = (AVLNode&lt;T&gt;) nodeAdded.parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodeToReturn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="AVL树平衡"><a href="#AVL树平衡" class="headerlink" title="AVL树平衡"></a>AVL树平衡</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 插入node时，执行平衡AVL树</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node 子树的根节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">balanceAfterInsert</span><span class="params">(AVLNode&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">true<span class="comment">//获取平衡因子，如果不为-1,0,1，则需进行平衡处理</span></span><br><span class="line">    <span class="keyword">int</span> balanceFactor = node.getBalanceFactor();</span><br><span class="line">    <span class="keyword">if</span> (balanceFactor &gt; <span class="number">1</span> || balanceFactor &lt; -<span class="number">1</span>) &#123;</span><br><span class="line">        AVLNode&lt;T&gt; child = <span class="keyword">null</span>;</span><br><span class="line">        Balance balance = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//左孩子长</span></span><br><span class="line">        <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            child = (AVLNode&lt;T&gt;) node.lesser;</span><br><span class="line">            balanceFactor = child.getBalanceFactor();</span><br><span class="line">            <span class="comment">//左孩子长</span></span><br><span class="line">            <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>)</span><br><span class="line">                balance = Balance.LEFT_LEFT;</span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                balance = Balance.LEFT_RIGHT;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;<span class="comment">//右孩子长</span></span><br><span class="line">            child = (AVLNode&lt;T&gt;) node.greater;</span><br><span class="line">            balanceFactor = child.getBalanceFactor();</span><br><span class="line">            <span class="comment">//左孩子长</span></span><br><span class="line">            <span class="keyword">if</span> (balanceFactor &lt; <span class="number">0</span>)</span><br><span class="line">                balance = Balance.RIGHT_LEFT;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                balance = Balance.RIGHT_RIGHT;</span><br><span class="line">        &#125;</span><br><span class="line">truetrue<span class="comment">// 左孩子，右孩子长</span></span><br><span class="line">        <span class="keyword">if</span> (balance == Balance.LEFT_RIGHT) &#123;</span><br><span class="line">            <span class="comment">// Left-Right (Left rotation, right rotation)</span></span><br><span class="line">            rotateLeft(child);</span><br><span class="line">            rotateRight(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (balance == Balance.RIGHT_LEFT) &#123;</span><br><span class="line">            <span class="comment">// Right-Left (Right rotation, left rotation)</span></span><br><span class="line">            rotateRight(child);</span><br><span class="line">            rotateLeft(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (balance == Balance.LEFT_LEFT) &#123;</span><br><span class="line">            <span class="comment">// Left-Left (Right rotation)</span></span><br><span class="line">            rotateRight(node);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Right-Right (Left rotation)</span></span><br><span class="line">            rotateLeft(node);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        child.updateHeight();</span><br><span class="line">        node.updateHeight();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="旋转类型"><a href="#旋转类型" class="headerlink" title="旋转类型"></a>旋转类型</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">enum</span> Balance &#123;</span><br><span class="line">    <span class="comment">//（单右旋）</span></span><br><span class="line">    LEFT_LEFT, </span><br><span class="line">    <span class="comment">//（先右孩子左旋，再自身右旋）</span></span><br><span class="line">    LEFT_RIGHT, </span><br><span class="line">    <span class="comment">//（先左孩子右旋，再自身左旋）</span></span><br><span class="line">    RIGHT_LEFT, </span><br><span class="line">    <span class="comment">//（单左旋）</span></span><br><span class="line">    RIGHT_RIGHT</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="左旋"><a href="#左旋" class="headerlink" title="左旋"></a>左旋</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以node及其children为轴作左旋</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node Root of tree to rotate left.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">rotateLeft</span><span class="params">(Node&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">    Node&lt;T&gt; parent = node.parent;</span><br><span class="line">    Node&lt;T&gt; greater = node.greater;</span><br><span class="line">    Node&lt;T&gt; lesser = greater.lesser;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//节点的右孩子的左孩子=节点</span></span><br><span class="line">    greater.lesser = node;</span><br><span class="line">    <span class="comment">//节点的父节点=节点的右孩子</span></span><br><span class="line">    node.parent = greater;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的右孩子=节点的右孩子的左孩子</span></span><br><span class="line">    node.greater = lesser;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lesser != <span class="keyword">null</span>)</span><br><span class="line">        lesser.parent = node;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//非root节点</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node == parent.lesser) &#123;</span><br><span class="line">            <span class="comment">//当前节点是左孩子</span></span><br><span class="line">            parent.lesser = greater;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node == parent.greater) &#123;</span><br><span class="line">            <span class="comment">//当前节点是右孩子</span></span><br><span class="line">            parent.greater = greater;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Yikes! I'm not related to my parent. "</span> + node.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//旋转后的root节点指向旋转前的parent节点</span></span><br><span class="line">        greater.parent = parent;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        root = greater;</span><br><span class="line">        root.parent = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="右旋"><a href="#右旋" class="headerlink" title="右旋"></a>右旋</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以node及其children为轴作右旋</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> node Root of tree to rotate right.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">rotateRight</span><span class="params">(Node&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">    Node&lt;T&gt; parent = node.parent;</span><br><span class="line">    Node&lt;T&gt; lesser = node.lesser;</span><br><span class="line">    Node&lt;T&gt; greater = lesser.greater;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的左孩子的右孩子=节点</span></span><br><span class="line">    lesser.greater = node;</span><br><span class="line">    <span class="comment">//节点的父节点=节点的左孩子</span></span><br><span class="line">    node.parent = lesser;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//节点的左孩子=节点的左孩子的右孩子</span></span><br><span class="line">    node.lesser = greater;</span><br><span class="line">    <span class="comment">//若存在右孩子，节点的左孩子的右孩子的父节点=节点</span></span><br><span class="line">    <span class="keyword">if</span> (greater != <span class="keyword">null</span>)</span><br><span class="line">        greater.parent = node;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//非root节点</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node == parent.lesser) &#123;</span><br><span class="line">            <span class="comment">//当前节点是左孩子</span></span><br><span class="line">            parent.lesser = lesser;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node == parent.greater) &#123;</span><br><span class="line">            <span class="comment">//当前节点是右孩子</span></span><br><span class="line">            parent.greater = lesser;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Yikes! I'm not related to my parent. "</span> + node.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//旋转后的root节点指向旋转前的parent节点</span></span><br><span class="line">        lesser.parent = parent;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        root = lesser;</span><br><span class="line">        root.parent = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> Node&lt;T&gt; <span class="title">removeValue</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//找到待删除节点</span></span><br><span class="line">    Node&lt;T&gt; nodeToRemoved = <span class="keyword">this</span>.getNode(value);</span><br><span class="line">    <span class="keyword">if</span> (nodeToRemoved == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//找到替换节点（左子树最大/右子树最小/左子树/右子树）</span></span><br><span class="line">    Node&lt;T&gt; replacementNode = <span class="keyword">this</span>.getReplacementNode(nodeToRemoved);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 替换父节点处理</span></span><br><span class="line">    AVLNode&lt;T&gt; nodeToRefactor = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (replacementNode != <span class="keyword">null</span>)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) replacementNode.parent;</span><br><span class="line">    <span class="keyword">if</span> (nodeToRefactor == <span class="keyword">null</span>)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) nodeToRemoved.parent;</span><br><span class="line">    <span class="keyword">if</span> (nodeToRefactor != <span class="keyword">null</span> &amp;&amp; nodeToRefactor == nodeToRemoved)</span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) replacementNode;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//替换节点</span></span><br><span class="line">    replaceNodeWithNode(nodeToRemoved, replacementNode);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//遍历替换节点2度内的子节点进行重平衡处理</span></span><br><span class="line">    <span class="keyword">while</span> (nodeToRefactor != <span class="keyword">null</span>) &#123;</span><br><span class="line">        nodeToRefactor.updateHeight();</span><br><span class="line">        balanceAfterDelete(nodeToRefactor);</span><br><span class="line"></span><br><span class="line">        nodeToRefactor = (AVLNode&lt;T&gt;) nodeToRefactor.parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodeToRemoved;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="更新节点"><a href="#更新节点" class="headerlink" title="更新节点"></a>更新节点</h3><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>时间复杂度：O(log(n))<br>空间复杂度：O(n)    </p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>AVL是一种高度平衡的二叉树，所以通常的结果是，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。<br>当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL还是优于红黑的。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1>]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>AVL</tag>
      </tags>
  </entry>
  <entry>
    <title>消息中间件之Kafka</title>
    <url>/2017/10/08/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%B9%8BKafka/</url>
    <content><![CDATA[<p>Kafka  is used for building <code>real-time</code> data pipelines and streaming apps. It is <code>horizontally scalable</code>, <code>fault-tolerant</code>, <code>wicked fast</code>, and runs in production in thousands of companies.</p>
<hr>
<a id="more"></a> 
<h2 id="消息中间件之Kafka"><a href="#消息中间件之Kafka" class="headerlink" title="消息中间件之Kafka"></a>消息中间件之Kafka</h2><h1 id="关于消息中间件"><a href="#关于消息中间件" class="headerlink" title="关于消息中间件"></a>关于消息中间件</h1><blockquote>
<p>什么是消息中间件？</p>
</blockquote>
<p>举个生产者/消费者的例子，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋。</p>
<ul>
<li>假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。</li>
<li>再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，”鸡蛋“又丢失了，</li>
<li>这个时候我们放个篮子在它们中间，生产出来的鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里</li>
<li>而这个篮子就是”kafka“。鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的（就是tcp、http什么的），也称为报文，也叫“消息”。消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。<br>kafka是干什么的，它就是那个”篮子”。</li>
</ul>
<h1 id="什么时候用消息中间件"><a href="#什么时候用消息中间件" class="headerlink" title="什么时候用消息中间件"></a>什么时候用消息中间件</h1><p>解决耦合问题：</p>
<ol>
<li>数据驱动的任务依赖</li>
<li>上游不关心多下游执行结果</li>
<li>异步返回执行时间长</li>
</ol>
<h1 id="消息中间件的不足"><a href="#消息中间件的不足" class="headerlink" title="消息中间件的不足"></a>消息中间件的不足</h1><ol>
<li>系统更复杂，多了一个MQ组件</li>
<li>消息传递路径更长，延时会增加</li>
<li>消息可靠性和重复性互为矛盾，消息不丢不重难以同时保证</li>
<li>上游无法知道下游的执行结果，这一点是很致命的</li>
</ol>
<h1 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h1><p><img src="Alt text.png" alt="Alt text"><br>Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。<br>Kafka是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p>
<ul>
<li>快速：单个kafka服务每秒可以处理数以千计从客户端发来的几百兆字节的读取和写入。</li>
<li>可扩展性：kafka被设计为允许单个集群作为中央数据骨干大型组织。它可以弹性地，透明地扩展，无需停机。数据流被划分并分布在机器的集群中，允许数据流比任何单一机器的性能大，并让集群来协调消费者。</li>
<li>可靠性：消息被保存在磁盘上,并在集群中复制，防止数据丢失。每个代理可以处理TB级的消息，而不影响性能。</li>
<li>分布式设计：kafka使用现代化的集群为中心设计，并提供了强大的耐用性和容错性保证。</li>
</ul>
<h1 id="kafka名词解释"><a href="#kafka名词解释" class="headerlink" title="kafka名词解释"></a>kafka名词解释</h1><p>后面大家会看到一些关于kafka的名词，比如topic、producer、consumer、broker，我这边来简单说明一下。</p>
<ul>
<li><code>topic</code>：Kafka将消息种子(Feed)分门别类， 每一类的消息称之为话题(Topic)。例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发；</li>
<li><code>partion</code>：topic物理上的分组，一个topic可以分为多个partion，每个partion是一个有序的队列；</li>
<li><code>segment</code>：partion物理上由多个segment组成；</li>
<li><code>offset</code>：每个partion都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partion中。每个partion中的每个消息都由一个连续的序列化叫做offset，由于partion唯一标识一条消息；</li>
<li><code>producer</code>： 发布消息的对象称之为话题生产者(Kafka topic producer)；</li>
<li><code>consumer</code>：订阅消息并处理发布的消息的Feed的对象称之为话题消费者(consumers)消费者；</li>
<li><code>broker</code>： 消息中间件处理节点，一个Kafka节点就是一个Broker，多个Broker可以组成一个Kafka集群；</li>
</ul>
<p>Client和Server之间的通讯是通过一条简单、高能并且和开发语言无关的TCP协议。<br>除了Java Client外，还有非常多的其它编程语言的Client。</p>
<h1 id="Kafka的保证-Guarantees"><a href="#Kafka的保证-Guarantees" class="headerlink" title="Kafka的保证(Guarantees)"></a>Kafka的保证(Guarantees)</h1><p>生产者发送到一个特定的Topic的分区上的消息将会按照它们发送的顺序依次加入<br>消费者收到的消息也是此顺序<br>如果一个Topic配置了复制因子( replication facto)为N， 那么可以允许N-1服务器宕机而不丢失任何已经增加的消息</p>
<h1 id="Kafka的文件存储机制"><a href="#Kafka的文件存储机制" class="headerlink" title="Kafka的文件存储机制"></a>Kafka的文件存储机制</h1><p>一个商业化消息队列的好坏，其文件存储机制是衡量一个消息队列服务技术水平的最关键指标之一。</p>
<h2 id="topic中partion存储分布"><a href="#topic中partion存储分布" class="headerlink" title="topic中partion存储分布"></a>topic中partion存储分布</h2><p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，<br>partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>
<h2 id="partion中文件存储方式"><a href="#partion中文件存储方式" class="headerlink" title="partion中文件存储方式"></a>partion中文件存储方式</h2><ul>
<li>每个partion(目录)相当于一个巨型文件被平均分配到多个<code>大小相等segment</code>(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</li>
<li>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。<br>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。<h2 id="partion中segment文件存储结构"><a href="#partion中segment文件存储结构" class="headerlink" title="partion中segment文件存储结构"></a>partion中segment文件存储结构</h2></li>
<li>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</li>
<li>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</li>
<li>索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</li>
</ul>
<p>message物理结构参数说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">关键字</th>
<th style="text-align:left">解释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">8 byte offset</td>
<td style="text-align:left">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td style="text-align:left">4 byte message size</td>
<td style="text-align:left">message大小</td>
</tr>
<tr>
<td style="text-align:left">4 byte CRC32</td>
<td style="text-align:left">用crc32校验message</td>
</tr>
<tr>
<td style="text-align:left">1 byte “magic”</td>
<td style="text-align:left">表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td style="text-align:left">1 byte “attributes”</td>
<td style="text-align:left">表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td style="text-align:left">4 byte key length</td>
<td style="text-align:left">表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td style="text-align:left">K byte key</td>
<td style="text-align:left">可选</td>
</tr>
<tr>
<td style="text-align:left">value bytes payload</td>
<td style="text-align:left">表示实际消息数据</td>
</tr>
</tbody>
</table>
</div>
<h2 id="在partion中如何通过offset找到message"><a href="#在partion中如何通过offset找到message" class="headerlink" title="在partion中如何通过offset找到message"></a>在partion中如何通过offset找到message</h2><p><img src="Alt text.png" alt="Alt text"><br><img src="Alt text.png" alt="Alt text"><br>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<ul>
<li>第一步查找segment file，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。 当offset=368776时定位到00000000000000368769.index|log</li>
<li>第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</li>
</ul>
<p>从上图可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<h2 id="Kafka中读写message特点"><a href="#Kafka中读写message特点" class="headerlink" title="Kafka中读写message特点"></a>Kafka中读写message特点</h2><h3 id="写message"><a href="#写message" class="headerlink" title="写message"></a>写message</h3><ul>
<li>消息从java堆转入page cache(即物理内存)。</li>
<li>由异步线程刷盘,消息从page cache刷入磁盘。<h3 id="读message"><a href="#读message" class="headerlink" title="读message"></a>读message</h3></li>
<li>消息直接从page cache转入socket发送出去。</li>
<li>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁盘Load消息到page cache，然后直接从socket发出去；</li>
</ul>
<h2 id="Kafka高效文件存储设计特点"><a href="#Kafka高效文件存储设计特点" class="headerlink" title="Kafka高效文件存储设计特点"></a>Kafka高效文件存储设计特点</h2><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li>
</ul>
<h1 id="Kafka常见问题"><a href="#Kafka常见问题" class="headerlink" title="Kafka常见问题"></a>Kafka常见问题</h1><ul>
<li>kafka节点之间如何复制备份的？</li>
<li>kafka消息是否会丢失？为什么？</li>
<li>kafka最合理的配置是什么？</li>
<li>kafka的leader选举机制是什么？</li>
<li>kafka对硬件的配置有什么要求？</li>
<li>kafka的消息保证有几种方式？</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.orchome.com/kafka/index">kafka中文教程</a></li>
<li><a href="http://blog.csdn.net/suifeng3051/article/details/48053965">enter link description here</a></li>
<li><a href="http://www.10tiao.com/html/249/201704/2651960012/1.html">到底什么时候该使用MQ？</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数据预处理工艺流程</title>
    <url>/2017/12/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%B7%A5%E8%89%BA%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>整理机器学习数据清洗与特征处理相关知识</p>
<hr>
<a id="more"></a>
<h1 id="机器学习数据预处理工艺流程"><a href="#机器学习数据预处理工艺流程" class="headerlink" title="机器学习数据预处理工艺流程"></a>机器学习数据预处理工艺流程</h1><h1 id="确定预测目标"><a href="#确定预测目标" class="headerlink" title="确定预测目标"></a>确定预测目标</h1><ul>
<li>确定问题域/预测目标：如根据用户的历史还款周期确定是否优质用户</li>
</ul>
<h1 id="确定特征获取方案"><a href="#确定特征获取方案" class="headerlink" title="确定特征获取方案"></a>确定特征获取方案</h1><h2 id="确定数据源"><a href="#确定数据源" class="headerlink" title="确定数据源"></a>确定数据源</h2><p>确定完成预测目标的数据来源：如用户多头借贷数据、设备数据、借贷行为数据、消费行为数据；</p>
<h2 id="确定数据获取方案"><a href="#确定数据获取方案" class="headerlink" title="确定数据获取方案"></a>确定数据获取方案</h2><h3 id="离线同步方案"><a href="#离线同步方案" class="headerlink" title="离线同步方案"></a>离线同步方案</h3><p>授权&amp;签订保密协议，以移动硬盘等外部存储设备同步数据</p>
<h3 id="实时-准实时（T-1）数据获取方案"><a href="#实时-准实时（T-1）数据获取方案" class="headerlink" title="实时/准实时（T+1）数据获取方案"></a>实时/准实时（T+1）数据获取方案</h3><p>打通内部网络，或开放数据接口，以CSV或Parquet进行同步，spark可直接读取parquet/csv数据生成hive table。</p>
<ul>
<li>数据安全性：敏感字段加密脱敏；</li>
<li>同步性能：以redis等k-v数据库存储，或Cassandra等读写性能高的列数据库进行存储；</li>
<li>增量更新：根据数据的生命周期，确定增量更新的数据</li>
</ul>
<h1 id="确定特征"><a href="#确定特征" class="headerlink" title="确定特征"></a>确定特征</h1><p>确定各数据源中能完成预测目标的特征</p>
<h2 id="梳理特征"><a href="#梳理特征" class="headerlink" title="梳理特征"></a>梳理特征</h2><p>采样以下方法：</p>
<ol>
<li>借鉴专家经验：同业务专家梳理业务流程，确定各业务流程中涉及的数据源和数据结构<ul>
<li>输出：Visio业务流程图、Excel数据字典</li>
</ul>
</li>
<li>数据分析：采用一些统计分析、可视化分析方法进行辅助特征选择<ol>
<li>看元数据，包括字段解释、数据来源、代码表等等一切描述数据的信息；</li>
<li>抽取一部分数据，使用人工查看方式，对数据本身有一个直观的了解，并且初步发现一些问题，为之后的清洗做准备。</li>
</ol>
</li>
</ol>
<h2 id="特征可用性分析"><a href="#特征可用性分析" class="headerlink" title="特征可用性分析"></a>特征可用性分析</h2><ol>
<li>数据获取难度：用户个人敏感信息，如个人4要素</li>
<li>数据的准确性：如业务系统未控制的，用户可随意填写的字段</li>
<li>数据的覆盖率：缺失情况</li>
</ol>
<h1 id="特征数据清洗"><a href="#特征数据清洗" class="headerlink" title="特征数据清洗"></a>特征数据清洗</h1><p>数据清洗， 是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。<br>在实际操作中，数据清洗通常会占据分析过程的50%—80%的时间。</p>
<h2 id="格式内容清洗"><a href="#格式内容清洗" class="headerlink" title="格式内容清洗"></a>格式内容清洗</h2><p>如果数据是由系统日志而来，那么通常在格式和内容方面，会与元数据的描述一致；而如果数据是由人工收集或用户填写而来，则有很大可能性在格式和内容上存在一些问题，格式内容问题有以下几类：</p>
<ol>
<li>时间、日期、数值、全半角等显示格式不一致；<br>这种问题通常与输入端有关，在整合多来源数据时也有可能遇到，将其处理成一致的某种格式即可。</li>
<li>内容中有不该存在的字符；<br>某些内容可能只包括一部分字符，比如身份证号是数字+字母，中国人姓名是汉字（赵C这种情况还是少数）。<br>最典型的就是头、尾、中间的空格，也可能出现姓名中存在数字符号、身份证号中出现汉字等问题。这种情况下，需要以半自动校验半人工方式来找出可能存在的问题，并去除不需要的字符。</li>
<li>内容与该字段应有内容不符；<br>姓名写了性别，身份证号写了手机号等等，均属这种问题。<br>此不能简单的以删除来处理，因为成因有可能是人工填写错误，也有可能是前端没有校验，还有可能是导入数据时部分或全部存在列没有对齐的问题，因此要详细识别问题类型进行逐个处理。</li>
</ol>
<h2 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h2><p>用逻辑推理发现问题数据，防止分析结果走偏。主要包含以下几个步骤：</p>
<h3 id="去除不合理值"><a href="#去除不合理值" class="headerlink" title="去除不合理值"></a>去除不合理值</h3><p>如年龄中存在负值等违背常识的数据</p>
<blockquote>
<p>可构建箱形图分析</p>
</blockquote>
<h3 id="修正矛盾内容"><a href="#修正矛盾内容" class="headerlink" title="修正矛盾内容"></a>修正矛盾内容</h3><p>有些字段是可以互相验证的，此时需要根据字段的数据来源，来判定哪个字段提供的信息更为可靠，去除或重构不可靠的字段。<br>如身份证号中包含出身年月、性别、年龄等元信息；</p>
<h2 id="重复值处理"><a href="#重复值处理" class="headerlink" title="重复值处理"></a>重复值处理</h2><ol>
<li>数据源问题：直接删除</li>
<li>数据交换问题：和数据源提供方确认后重取数据；</li>
</ol>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><h3 id="确定缺失值范围"><a href="#确定缺失值范围" class="headerlink" title="确定缺失值范围"></a>确定缺失值范围</h3><p>对每个字段都计算其缺失值比例，然后按照缺失比例和字段重要性，分别制定策略，可用下图表示：<br><img src="重要性-缺失率.png" alt="重要性-缺失率"></p>
<h3 id="删除不需要的字段"><a href="#删除不需要的字段" class="headerlink" title="删除不需要的字段"></a>删除不需要的字段</h3><h3 id="填充缺失内容"><a href="#填充缺失内容" class="headerlink" title="填充缺失内容"></a>填充缺失内容</h3><p>某些缺失值可以进行填充，方法有以下三种：</p>
<ul>
<li>以业务知识或经验推测填充缺失值；</li>
<li>以同一指标的计算结果（均值、中位数、众数等）填充缺失值；</li>
<li>以不同指标的计算结果填充缺失值，如年龄字段缺失，但是有屏蔽后六位的身份证号可以计算得出年龄；<h3 id="重新取数"><a href="#重新取数" class="headerlink" title="重新取数"></a>重新取数</h3>如果某些指标非常重要又缺失率高，那就需要和取数人员或业务人员了解，是否有其他渠道可以取到相关数据。</li>
</ul>
<h1 id="标注数据清洗"><a href="#标注数据清洗" class="headerlink" title="标注数据清洗"></a>标注数据清洗</h1><p>非平衡数据集的处理与建模，可从3个方面进行考虑：</p>
<ol>
<li>收集更多的数据；(╯﹏╰）</li>
<li>样本平衡，常见的方法，over-sample, under-sample，smote。</li>
<li>建模方法：可以采用对非平衡数据集不敏感的算法。<h2 id="样本均衡"><a href="#样本均衡" class="headerlink" title="样本均衡"></a>样本均衡</h2><h3 id="过采样（-over-sample）"><a href="#过采样（-over-sample）" class="headerlink" title="过采样（ over-sample）"></a>过采样（ over-sample）</h3><h4 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h4><h4 id="生成新数据SMOTE（Synthetic-Minority-Over-sampling-Technique）"><a href="#生成新数据SMOTE（Synthetic-Minority-Over-sampling-Technique）" class="headerlink" title="生成新数据SMOTE（Synthetic Minority Over-sampling Technique）"></a>生成新数据SMOTE（Synthetic Minority Over-sampling Technique）</h4><h3 id="欠采样（-under-sample）"><a href="#欠采样（-under-sample）" class="headerlink" title="欠采样（ under-sample）"></a>欠采样（ under-sample）</h3></li>
</ol>
<h2 id="样本过滤"><a href="#样本过滤" class="headerlink" title="样本过滤"></a>样本过滤</h2><h3 id="业务逻辑过滤"><a href="#业务逻辑过滤" class="headerlink" title="业务逻辑过滤"></a>业务逻辑过滤</h3><p>结合业务情况进行数据的过滤如去除crawler抓取，spam，作弊等数据。</p>
<h3 id="异常点检测"><a href="#异常点检测" class="headerlink" title="异常点检测"></a>异常点检测</h3><p>采用异常点检测算法对样本进行分析，常用的异常点检测算法：</p>
<ol>
<li>偏差检测，例如聚类，最近邻等。</li>
<li>基于统计的异常点检测算法<br>例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。</li>
<li>基于距离的异常点检测算法<br>主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。</li>
<li>基于密度的异常点检测算法<br>考察当前点周围密度，可以发现局部异常点，例如局部异常因子算法-Local Outlier Factor(LOF)</li>
</ol>
<h1 id="特征分类"><a href="#特征分类" class="headerlink" title="特征分类"></a>特征分类</h1><p>根据不同的分类方法，可以将特征分为</p>
<ul>
<li>Low level特征和High level特征；</li>
<li>稳定特征与动态特征；</li>
<li>二值特征、连续特征、枚举特征；</li>
<li>定性特征、定量特征 </li>
</ul>
<h1 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h1><h2 id="定性特征（category）"><a href="#定性特征（category）" class="headerlink" title="定性特征（category）"></a>定性特征（category）</h2><p>定性特征，表示某个数据点属于某一个类别，或具有某一种类的特性。一列定性特征，默认用自然数表示（可以用sklearn.preprocessing中的LabelEncoder将字符串转化为自然数）。如果一列定性特征里有K种不同类别，其取值范围是{0, 1, 2, 3, …, K-1}。<br>例：颜色、性别、地址、血型、国籍、省、市、邮政编码。</p>
<h3 id="onehot编码（One-hot-Encoding）"><a href="#onehot编码（One-hot-Encoding）" class="headerlink" title="onehot编码（One-hot Encoding）"></a>onehot编码（One-hot Encoding）</h3><p>对于每一个特征，如果它有m个可能值，那么经过独热编码后，就变成了m个二元特征。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。<br>好处：</p>
<ol>
<li>解决了分类器不好处理属性数据的问题；</li>
<li>在一定程度上也起到了扩充特征的作用；<h3 id="平均数编码（mean-encoding）"><a href="#平均数编码（mean-encoding）" class="headerlink" title="平均数编码（mean encoding）"></a>平均数编码（mean encoding）</h3><h3 id="聚类编码"><a href="#聚类编码" class="headerlink" title="聚类编码"></a>聚类编码</h3></li>
</ol>
<h2 id="定量特征（continous）"><a href="#定量特征（continous）" class="headerlink" title="定量特征（continous）"></a>定量特征（continous）</h2><p>定量特征（numerical feature），可以是连续的（continuous），也可以是离散的（discrete），一般表示为一个实数值。<br>例：年龄、价格、身高、体重、测量数据。</p>
<h3 id="归一化（Normalization）"><a href="#归一化（Normalization）" class="headerlink" title="归一化（Normalization）"></a>归一化（Normalization）</h3><p><strong>方法</strong></p>
<ol>
<li>把数变为（0，1）之间的小数主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速；</li>
<li>把有量纲表达式变为无量纲表达式，归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。<br>一般的方法是$ (x-min(x))/(max(x)-min(x))$ </li>
</ol>
<p><strong>特点</strong><br>对不同特征维度的伸缩变换的目的是使各个特征维度对目标函数的影响权重是一致的，即使得那些扁平分布的数据伸缩变换成类圆形。这也就<code>改变了原始数据的分布</code>。</p>
<p> <strong>好处</strong></p>
<ol>
<li>提高迭代求解的<code>收敛速度</code>；</li>
<li>提高迭代求解的精度；</li>
</ol>
<h3 id="标准化（Standardization）"><a href="#标准化（Standardization）" class="headerlink" title="标准化（Standardization）"></a>标准化（Standardization）</h3><p><strong>方法</strong><br>数据的标准化是将数据按比例缩放，使之落入一个小的特定区间。<br>常规标准化公式为：$(x-mean(x)/std(x)$  计算时对每个属性/每列分别进行。<br>将数据按期属性（按列进行）减去其均值，并除以其方差。得到的结果是，对于每个属性/每列来说所有数据都聚集在$0$附近，方差为$1$。</p>
<p><strong>特点</strong><br>对不同特征维度的伸缩变换的目的是使得不同度量之间的特征具有可比性。同时<code>不改变原始数据的分布</code>。</p>
<p><strong>好处</strong></p>
<ol>
<li>使得不同度量之间的特征具有<code>可比性</code>，对目标函数的影响体现在几何分布上，而不是数值上；</li>
<li>不改变原始数据的分布。</li>
</ol>
<h3 id="区间缩放（Scaling）"><a href="#区间缩放（Scaling）" class="headerlink" title="区间缩放（Scaling）"></a>区间缩放（Scaling）</h3><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ol>
<li>保存各阶段的中间数据结果；</li>
<li>记录各类预处理工具的操作脚本，并归纳整理成预处理工具集；</li>
<li></li>
</ol>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="归一化与标准化的区别"><a href="#归一化与标准化的区别" class="headerlink" title="归一化与标准化的区别"></a>归一化与标准化的区别</h2><p>归一化，一般的方法是$ (x-min(x))/(max(x)-min(x))$<br>标准化，一般方法是$(x-mean(x))/std(x) $<br>这两种方法都是属于线性转换，都是按比例缩放的<br>但是归一化还有其他方法（如对数Logistic模式），不一定是按比例缩放的。所以，他们之间不是子集和全集的关系。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/20571505">数据清洗的一些梳理</a></li>
<li><a href="http://www.zuozuovera.cn/archives/623/#directory089988462436209064">数据清洗与特征处理流程</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27627299">为什么要对数据进行归一化处理？</a></li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>特征工程</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN卷积神经网络</title>
    <url>/2018/01/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。</p>
<hr>
<a id="more"></a>
<h2 id="CNN卷积神经网络"><a href="#CNN卷积神经网络" class="headerlink" title="CNN卷积神经网络"></a>CNN卷积神经网络</h2><p><img src="mnist cnn卷积过程.png" alt="mnist cnn卷积过程"></p>
<h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><p>卷积网络是因为“卷积”操作而得名的。卷积的根本目的是从输入图片中提取特征。卷积用一个小方阵的数据学习图像特征，可以保留像素之间的空间关系。</p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p><img src="卷积.png" alt="卷积"><br>3x3矩阵也叫“滤波器”、“核”或“特征探测器”，在原图上滑动滤波器、点乘矩阵所得的矩阵称为“卷积特征”、“激励映射”或“特征映射”。<br>这里的重点就是，理解滤波器对于原输入图片来说，是个特征探测器。<br>对于同一张照片，不同的滤波器将会产生不同的特征映射。</p>
<h2 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h2><p>在实践当中，卷积神经网络在训练过程中学习滤波器的值，当然我们还是要在训练之前需要指定一些参数：滤波器的个数，滤波器尺寸、网络架构等等。滤波器越多，从图像中提取的特征就越多，模式识别能力就越强。<br><img src="卷积核.png" alt="卷积核"><br>特征映射的尺寸由三个参数控制，我们需要在卷积步骤之前就设定好：</p>
<h3 id="深度-Depth"><a href="#深度-Depth" class="headerlink" title="深度(Depth)"></a>深度(Depth)</h3><p> 深度就是卷积操作中用到的滤波器个数。如图7所示，我们对原始的船图用了三个不同的滤波器，从而产生了三个特征映射。你可以认为这三个特征映射也是堆叠的2d矩阵，所以这里特征映射的“深度”就是3</p>
<h3 id="步幅-Stride"><a href="#步幅-Stride" class="headerlink" title="步幅(Stride)"></a>步幅(Stride)</h3><p>步幅是每次滑过的像素数。当Stride=1的时候就是逐个像素地滑动。当Stride=2的时候每次就会滑过2个像素。步幅越大，特征映射越小。</p>
<h3 id="补零-Zero-padding"><a href="#补零-Zero-padding" class="headerlink" title="补零(Zero-padding)"></a>补零(Zero-padding)</h3><p>有时候在输入矩阵的边缘填补一圈0会很方便，这样我们就可以对图像矩阵的边缘像素也施加滤波器。补零的好处是让我们可以控制特征映射的尺寸。补零也叫宽卷积，不补零就叫窄卷积。</p>
<h3 id="卷积层输出计算公式"><a href="#卷积层输出计算公式" class="headerlink" title="卷积层输出计算公式"></a>卷积层输出计算公式</h3><p>对于任何给定的卷积层输出大小的计算公式</p>
<script type="math/tex; mode=display">N = (W - F + 2P )/S+1</script><p>参数</p>
<ul>
<li>输入图片大小 $W$</li>
<li>卷积核大小 $F$</li>
<li>步长 $S$</li>
<li>padding的像素数 $P$</li>
<li>输出图片大小 $N$</li>
</ul>
<hr>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>非线性化<br>每个卷积操作之后，都有一个叫ReLU的附加操作。ReLU的全称是纠正线性单元(Rectified Linear Unit)，是一种非线性操作，其输出如下：</p>
<p>ReLU是以像素为单位生效的，其将所有负值像素替换为0。ReLU的目的是向卷积网络中引入非线性，因为真实世界里大多数需要学习的问题都是非线性的（单纯的卷积操作时线性的——矩阵相乘、相加，所以才需要额外的计算引入非线性）。<br><img src="relu特征映射.png" alt="relu特征映射"><br>输出的新特征映射也叫“纠正”特征映射。（黑色被抹成了灰色）</p>
<p>其他非线性方程比如tanh或sigmoid也可以替代ReLU，但多数情况下ReLU的表现更好。</p>
<h1 id="PoolingLayer-池化层"><a href="#PoolingLayer-池化层" class="headerlink" title="PoolingLayer 池化层"></a>PoolingLayer 池化层</h1><p>空间池化（也叫亚采样或下采样）降低了每个特征映射的维度，但是保留了最重要的信息。空间池化可以有很多种形式：<code>最大(Max)，平均(Average)，求和(Sum)</code>等等。<br>以最大池化为例，我们定义了空间上的邻域（2x2的窗）并且从纠正特征映射中取出窗里最大的元素。除了取最大值以额外，我们也可以取平均值（平均池化）或者把窗里所有元素加起来。实际上，最大池化已经显示了最好的成效。<br><img src="池化层.png" alt="池化层"><br>图中显示了对纠正特征映射的最大池化操作（在卷积+ReLU之后），使用的是2x2的窗。<br>以2格的步幅(Stride)滑动2x2的窗，并且取每个区域的最大值。图中同样显示了池化可以减少特征映射的维度。</p>
<h2 id="池化的功能"><a href="#池化的功能" class="headerlink" title="池化的功能"></a>池化的功能</h2><p>池化的功能室逐步减少输入表征的空间尺寸。特别地，池化</p>
<ul>
<li>使输入表征（特征维度）更小而易操作</li>
<li>减少网络中的参数与计算数量，从而遏制过拟合</li>
<li>增强网络对输入图像中的小变形、扭曲、平移的鲁棒性（输入里的微小扭曲不会改变池化输出——因为我们在局部邻域已经取了最大值/平均值）。</li>
<li>帮助我们获得不因尺寸而改变的等效图片表征。这非常有用，因为这样我们就可以探测到图片里的物体，不论那个物体在哪。</li>
</ul>
<h1 id="DropOut稀疏层"><a href="#DropOut稀疏层" class="headerlink" title="DropOut稀疏层"></a>DropOut稀疏层</h1><p>这是一个比较新的也非常好用的防止过拟合的方法<br>完全随机选取经过神经网络流一半的数据来训练，在每次训练过程中用0来替代被丢掉的激活值，其它激活值合理缩放<br>为了减少过拟合，我们在输出层之前加入dropout。一般用一个 placeholder 来代表一个神经元在dropout中被保留的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。</p>
<h1 id="Fully-Connected-Layer，FC，全连接层"><a href="#Fully-Connected-Layer，FC，全连接层" class="headerlink" title="Fully Connected Layer，FC，全连接层"></a>Fully Connected Layer，FC，全连接层</h1><p>连接层(Fully Connected layer)就是使用了softmax激励函数作为输出层的多层感知机(Multi-Layer Perceptron)，其他很多分类器如支持向量机也使用了softmax。<br>“全连接”表示上一层的每一个神经元，都和下一层的每一个神经元是相互连接的。</p>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>卷积层和池化层的输出代表了输入图像的高级特征，全连接层的目的就是用这些特征进行<code>分类</code>，类别基于训练集。<br>比如下图所示的图像分类任务，有四种可能的类别。（注意，图中没有显示出所有的神经元节点）<br><img src="全连接层.png" alt="全连接层"></p>
<h2 id="非线性组合"><a href="#非线性组合" class="headerlink" title="非线性组合"></a>非线性组合</h2><p>除了分类以外，加入全连接层也是学习特征之间<code>非线性组合</code>的有效办法。卷积层和池化层提取出来的特征很好，但是如果考虑这些特征之间的组合，就更好了。</p>
<h2 id="Softmax概率输出"><a href="#Softmax概率输出" class="headerlink" title="Softmax概率输出"></a>Softmax概率输出</h2><p>全连接层的输出概率之和为1，这是由激励函数Softmax保证的。Softmax函数把任意实值的向量转变成元素取之0-1且和为1的向量。</p>
<blockquote>
<p>FC在整个卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的<code>分布式特征表示映射到样本标记空间</code>的作用。</p>
</blockquote>
<h1 id="CNN卷积神经网络构建过程"><a href="#CNN卷积神经网络构建过程" class="headerlink" title="CNN卷积神经网络构建过程"></a>CNN卷积神经网络构建过程</h1><h2 id="CNN训练"><a href="#CNN训练" class="headerlink" title="CNN训练"></a>CNN训练</h2><p>卷积网络的训练过程可以概括如下：</p>
<ul>
<li>Step 1: 用随机数初始化所有的滤波器和参数/权重</li>
<li>Step 2: 网络将训练图片作为输入，执行前向步骤（卷积，ReLU，池化以及全连接层的前向传播）并计算每个类别的对应输出概率。<ul>
<li>假设船图的输出概率是[0.2, 0.4, 0.1, 0.3]</li>
<li>因为第一个训练样本的权重都是随机的，所以这个输出概率也跟随机的差不多</li>
</ul>
</li>
<li>Step 3: 计算输出层的总误差（4类别之和）<ul>
<li>总误差=$总误差=∑rac{1}{2}(目标概率−输出概率)^2$</li>
</ul>
</li>
<li>Step 4: 反向传播算法计算误差相对于所有权重的梯度，并用梯度下降法更新所有的滤波器/权重和参数的值，以使输出误差最小化。<ul>
<li>权重的调整程度与其对总误差的贡献成正比。</li>
<li>当同一图像再次被输入，这次的输出概率可能是[0.1, 0.1, 0.7, 0.1]，与目标[0, 0, 1, 0]更接近了。</li>
<li>这说明我们的神经网络已经学习着分类特定图片了，学习的方式是调整权重/滤波器以降低输出误差。</li>
<li>如滤波器个数、滤波器尺寸、网络架构这些参数，是在Step 1之前就已经固定的，且不会在训练过程中改变——只有滤波矩阵和神经元突触权重会更新。</li>
</ul>
</li>
</ul>
<p>以上步骤训练了卷积网络——本质上就是优化所有的权重和参数，使其能够正确地分类训练集里的图片。</p>
<h2 id="CNN预测"><a href="#CNN预测" class="headerlink" title="CNN预测"></a>CNN预测</h2><p>当一个新的（前所未见的）的图片输入至卷积网络，网络会执行<code>前向传播</code>步骤并输出每个类别的概率（对于新图像，输出概率用的也是训练过的权重值）。<br>如果我们的训练集足够大，网络就有望正确分类新图片，获得良好的泛化(generalization)能力。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://jizhi.im/blog/post/intuitive_explanation_cnn">卷积：如何成为一个很厉害的神经网络</a><br><a href="http://scs.ryerson.ca/~aharley/vis/conv/">mnist写字卷积过程3D可视化</a><br><a href="http://yangguang2009.github.io/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/">keras实现mmmnist识别</a><br><a href="http://blog.csdn.net/qiaofangjie/article/details/16826849">LeNet-5卷积参数</a><br><a href="https://github.com/CSCfi/machine-learning-scripts/tree/master/notebooks">mimnistinear/mlp/cnn/rnn的keras实现</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>RiceQuant开源框架RQAlpha阅读笔记</title>
    <url>/2018/01/25/RiceQuant%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6RQAlpha%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>从RQAlpha开源量化投资框架的<code>代码结构</code>、<code>技术选型</code>、<code>回测流程</code>、<code>撮合机制</code>等多个方面分析。</p>
<a id="more"></a>
<p><img src="rqalpha.jpg" alt="rqalpha"></p>
<h1 id="RQAlpha框架代码结构"><a href="#RQAlpha框架代码结构" class="headerlink" title="RQAlpha框架代码结构"></a>RQAlpha框架代码结构</h1><p><img src="RQAlpha框架代码结构.png" alt="RQAlpha框架代码结构"> </p>
<h1 id="RQAlpha技术选型"><a href="#RQAlpha技术选型" class="headerlink" title="RQAlpha技术选型"></a>RQAlpha技术选型</h1><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>bcolz：列式压缩存储，本地磁盘；<br>ricequant远程数据以七牛云存储，需手动更新到本地；</p>
<h2 id="策略因子"><a href="#策略因子" class="headerlink" title="策略因子"></a>策略因子</h2><p>TA-LIB：金融市场数据的技术因子分析</p>
<h2 id="实盘交易"><a href="#实盘交易" class="headerlink" title="实盘交易"></a>实盘交易</h2><p>VN.py，开源量化交易程序开发框架，交易API接口（vnpy.api）基本覆盖了国内外所有常规交易品种（股票、期货、期权、外汇、外盘、比特币）。<br>RQAlpha 对接 vnpy 的扩展 Mod（qalpha-mod-vnpy）。可通过启用该 Mod 来实现期货策略的实盘交易。</p>
<h2 id="报表输出"><a href="#报表输出" class="headerlink" title="报表输出"></a>报表输出</h2><p>图表：matplotlib<br>报表：XlsxWriter</p>
<h2 id="辅助工具"><a href="#辅助工具" class="headerlink" title="辅助工具"></a>辅助工具</h2><p>命令行工具：click</p>
<h1 id="回测流程"><a href="#回测流程" class="headerlink" title="回测流程"></a>回测流程</h1><h2 id="回测系统流程图"><a href="#回测系统流程图" class="headerlink" title="回测系统流程图"></a>回测系统流程图</h2><p><img src="RQAlpha回测系统.png" alt="RQAlpha回测系统"></p>
<h2 id="策略运行方式"><a href="#策略运行方式" class="headerlink" title="策略运行方式"></a>策略运行方式</h2><p><img src="Alt text.png" alt="Alt text"></p>
<h2 id="日回测流程图"><a href="#日回测流程图" class="headerlink" title="日回测流程图"></a>日回测流程图</h2><p><img src="日回测流程时序图.png" alt="日回测流程时序图"></p>
<h1 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h1><p><img src="数据源.png" alt="数据源"></p>
<h1 id="事件机制"><a href="#事件机制" class="headerlink" title="事件机制"></a>事件机制</h1><h2 id="事件源"><a href="#事件源" class="headerlink" title="事件源"></a>事件源</h2><ol>
<li>获取回测时间段内的交易日；</li>
<li>遍历交易日获取日线/分钟线/tick的行情数据，发布事件到事件总线；</li>
</ol>
<ul>
<li>EVENT.TICK <code>tick数据更新事件</code><ul>
<li>PRE_TICK</li>
<li>HANDLE_TICK</li>
<li>POST_TICK</li>
</ul>
</li>
<li>EVENT.BAR  <code>bar数据更新事件</code><ul>
<li>PRE_BAR</li>
<li>HANDLE_BAR</li>
<li>POST_BAR</li>
</ul>
</li>
<li>EVENT.BEFORE_TRADING  <code>交易发生前事件</code><ul>
<li>PRE_BEFORE_TRADING</li>
<li>HANDLE_BEFORE_TRADING</li>
<li>POST_BEFORE_TRADING</li>
</ul>
</li>
<li>EVENT.AFTER_TRADING <code>交易成交后事件</code><ul>
<li>PRE_AFTER_TRADING</li>
<li>HANDLE_AFTER_TRADING</li>
<li>POST_AFTER_TRADING</li>
</ul>
</li>
<li>EVENT.SETTLEMENT  <code>结算事件</code><ul>
<li>PRE_SETTLEMENT</li>
<li>HANDLE_SETTLEMENT</li>
<li>POST_SETTLEMENT</li>
</ul>
</li>
</ul>
<h2 id="回测事件驱动模型"><a href="#回测事件驱动模型" class="headerlink" title="回测事件驱动模型"></a>回测事件驱动模型</h2><p><img src="事件驱动模型.png" alt="事件驱动模型"></p>
<p>RQAlpha 大部分的组件是以 <code>add_listener</code> 的方式进行事件的注册。<br>以策略执行为例：</p>
<ol>
<li>当Bar数据生成时，触发 <code>EVENT.BAR</code> 事件，那么用户的 <code>handle_bar</code> 相关的代码注册了该事件则会立即执行。</li>
<li>当订单下单时，触发 <code>EVENT.ORDER_PENDING_NEW</code> 事件，前端风控模块注册了该事件，则可以立即对该订单进行审核，如果不满足风控要求，则直接指定执行 <code>order._cancel(reason)</code> 来保证有问题的订单不会进入实际下单环节。</li>
<li>当订单成交时，触发 <code>EVENT.TRADE</code> 事件，那么系统的账户模块因为注册了该事件，就可以立即计算成交以后的收益和资金变化。</li>
</ol>
<blockquote>
<p>程序化交易中很多操作，都是通过注册事件的方式插入到 RQAlpha 中进行扩展的。</p>
</blockquote>
<h2 id="事件分类"><a href="#事件分类" class="headerlink" title="事件分类"></a>事件分类</h2><ul>
<li><strong>SystemEvent: 系统事件源</strong><ul>
<li>POST_SYSTEM_INIT: 系统初始化后触发</li>
<li>POST_USER_INIT: 策略的 <code>init</code> 函数执行后触发</li>
<li>POST_SYSTEM_RESTORED: 在实盘时，你可能需要在此事件后根据其他信息源对系统状态进行调整</li>
</ul>
</li>
<li><strong>MarketEvent: 市场及数据事件源</strong><ul>
<li>POST_UNIVERSE_CHANGED: 策略证券池发生变化后触发</li>
<li>PRE_BEFORE_TRADING: 执行 <code>before_trading</code> 函数前触发</li>
<li>BEFORE_TRADING: 该事件会触发策略的 <code>before_trading</code> 函数</li>
<li>POST_BEFORE_TRADING: 执行 <code>before_trading</code> 函数后触发</li>
<li>PRE_BAR: 执行 <code>handle_bar</code> 函数前触发</li>
<li>BAR: 该事件会触发策略的 <code>handle_bar</code> 函数</li>
<li>POST_BAR: 执行 <code>handle_bar</code> 函数后触发</li>
<li>PRE_TICK: 执行 <code>handle_tick</code> 前触发</li>
<li>TICK: 该事件会触发策略的 <code>handle_tick</code> 函数</li>
<li>POST_TICK: 执行 <code>handle_tick</code> 后触发</li>
<li>PRE_SCHEDULED: 在 <code>scheduler</code> 执行前触发</li>
<li>POST_SCHEDULED: 在 <code>scheduler</code> 执行后触发</li>
<li>PRE_AFTER_TRADING: 执行 <code>after_trading</code> 函数前触发</li>
<li>AFTER_TRADING: 该事件会触发策略的 <code>after_trading</code> 函数</li>
<li>POST_AFTER_TRADING: 执行 <code>after_trading</code> 函数后触发</li>
<li>PRE_SETTLEMENT: 结算前触发该事件</li>
<li>SETTLEMENT: 触发结算事件</li>
<li>POST_SETTLEMENT: 结算后触发该事件</li>
</ul>
</li>
<li><strong>OrderEvent: 交易事件源</strong><ul>
<li>ORDER_PENDING_NEW: 创建订单</li>
<li>ORDER_CREATION_PASS: 创建订单成功</li>
<li>ORDER_CREATION_REJECT: 创建订单失败</li>
<li>ORDER_PENDING_CANCEL: 创建撤单</li>
<li>ORDER_CANCELLATION_PASS: 撤销订单成功</li>
<li>ORDER_CANCELLATION_REJECT: 撤销订单失败</li>
<li>ORDER_UNSOLICITED_UPDATE: 订单状态更新</li>
<li>TRADE: 成交</li>
</ul>
</li>
</ul>
<h1 id="撮合机制"><a href="#撮合机制" class="headerlink" title="撮合机制"></a>撮合机制</h1><p>在回测时，订单撮合过程在运行结束 `handle_bar函数之后，是以历史实时行情进行的虚拟撮合。</p>
<p>由于是对真实场景的模拟，订单并不会立刻以某个价格成交，而是通过和实时行情的具体价格（结合股息、手续费、滑点、税率等计算）和具体成交量（不超过总成交量的0.25）进行比对，从而断定成交价格和成交时间。</p>
<h2 id="撮合方式"><a href="#撮合方式" class="headerlink" title="撮合方式"></a>撮合方式</h2><p>RQAlpha提供的撮合方式有两种：</p>
<ol>
<li>当前收盘价。即当前bar发单，以当前bar收盘价作为参考价撮合。</li>
<li>下一开盘价。即当前bar发单，以下一bar开盘价作为参考价撮合。</li>
</ol>
<p>对于不同订单类型，成交条件如下：</p>
<h2 id="限价单（LimitOrder）"><a href="#限价单（LimitOrder）" class="headerlink" title="限价单（LimitOrder）"></a>限价单（LimitOrder）</h2><p>如果买单价格&gt;=参考价，或卖单价格&lt;=参考价，以参考价加入滑点影响成交（买得更高，卖得更低）。<br>限价单会一直在订单队列中等待下一个bar数据撮合成交，直到当日收盘。当日收盘后，所有未成交限价单都将被系统自动撤单。</p>
<h2 id="市价单（MarketOrder）"><a href="#市价单（MarketOrder）" class="headerlink" title="市价单（MarketOrder）"></a>市价单（MarketOrder）</h2><p>直接以以参考价加入滑点影响成交。<strong>成交数量都不超过当前bar成交量的25%。</strong>一旦超过，市价单会在部分成交之后被自动撤单；</p>
<p>不满足订单撮合条件的订单，会标记为拒绝，具体情况可能有：</p>
<ul>
<li>portfolio内可用资金不足</li>
<li>下单数量不足一手（股票为100股）</li>
<li>下单价格超过当日涨跌停板限制</li>
<li>当前可卖（可平）仓位不足</li>
<li>股票当日停牌</li>
<li>合约已经退市（到期）或尚未上市</li>
</ul>
<p>当日收盘后，所有未成交订单都将被系统自动撤单。</p>
<blockquote>
<p>注意：如果当时市场处于涨停或跌停这种单边市情况，买单（对应涨停），卖单（对应跌停）是无法成交的。尽管bar数据中可能成交量不为0。判断逻辑：当前bar数据的收盘价等于涨停价，则当前市场处于涨停状态。跌停也是类似处理。</p>
</blockquote>
<h2 id="日线级别回测"><a href="#日线级别回测" class="headerlink" title="日线级别回测"></a>日线级别回测</h2><p>在一个<code>handelbar</code>内下单，下单时立刻撮合成交（成交价取决于撮合机制以及滑点设置）。<br>撮合方式遵循“<strong>先卖后买，开盘价撮合</strong>”原则，即先处理卖出订单，后处理买入订单，卖出订单产生的现金，会参与买入订单的交易。<br>由于下单是在当天开盘前，订单撮合会与当天开盘价进行比较，如果满足条件，就会撮合成交，如果不满足条件，则继续挂单，等待下一次撮合尝试。</p>
<h2 id="分钟线级别回测"><a href="#分钟线级别回测" class="headerlink" title="分钟线级别回测"></a>分钟线级别回测</h2><p>在一个<code>handle_bar</code>内下单，在该<code>handle_bar</code>结束时统一撮合成交（成交价取决于撮合机制以及滑点设置）。<br>撮合方式遵循“<strong>先下单先处理，开盘价撮合</strong>”原则，即先下单的订单会先进行撮合尝试。<br>订单撮合会与下一分钟K线的开盘价进行比较，如果满足条件，就会撮合成交，如果不满足条件，则继续挂单，等待下一次撮合尝试。</p>
<blockquote>
<p>注意：在分钟回测以及实盘模拟中handle_bar内发单之后立刻通过cancel_order对该订单进行撤单操作，是一定会撤单成功的。但在日回测中则很可能撤单失败，因为日回测中下单之后立刻撮合成交。</p>
</blockquote>
<h1 id="资产组合"><a href="#资产组合" class="headerlink" title="资产组合"></a>资产组合</h1><p>资产组合<br><img src="资产组合.png" alt="资产组合"></p>
<p>资产组合详情<br><img src="资产组合详情.png" alt="资产组合详情"></p>
<h1 id="回测结果分析指标"><a href="#回测结果分析指标" class="headerlink" title="回测结果分析指标"></a>回测结果分析指标</h1><h2 id="年化收益率（Annualized-Returns）"><a href="#年化收益率（Annualized-Returns）" class="headerlink" title="年化收益率（Annualized Returns）"></a>年化收益率（Annualized Returns）</h2><script type="math/tex; mode=display">p_r = \left (\frac{p_{end}}{p_{start}}\right)^{\left (250/n  \right)}-1</script><script type="math/tex; mode=display">p_{end} = 策略最终总资产，p_{start} = 策略初始总资产，n = 回测交易日数量</script><h2 id="阿尔法（Alpha）"><a href="#阿尔法（Alpha）" class="headerlink" title="阿尔法（Alpha）"></a>阿尔法（Alpha）</h2><p> CAPM模型表达式中的残余项。表示策略所持有投资组合的收益中和市场整体收益无关的部分，是策略选股能力的度量。<br> 当策略所选股票的总体表现优于市场基准组合成分股时，阿尔法取正值；反之取负值。</p>
<script type="math/tex; mode=display">\alpha = p_r - r_f - eta(B_r - r_f)</script><script type="math/tex; mode=display">p_r = 策略年化收益率，r_f = 无风险收益率，B_r = 基准年化收益率</script><p>Alpha是投资者获得与市场波动无关的回报，一般用来度量投资者的投资技艺。<br>比如投资者获得了12%的回报，其基准获得了10%的回报，那么Alpha或者价值增值的部分就是2%。<br><img src="Alpha示例.png" alt="Alpha示例"><br>该值越大越好。</p>
<h2 id="贝塔（Beta）"><a href="#贝塔（Beta）" class="headerlink" title="贝塔（Beta）"></a>贝塔（Beta）</h2><p>表示投资的系统性风险，反映了策略对大盘变化的敏感性。例如，一个策略的Beta为1.3，则大盘涨1%的时候，策略可能涨1.3%，反之亦然；如果一个策略的Beta为-1.3，说明大盘涨1%的时候，策略可能跌1.3%，反之亦然。 </p>
<script type="math/tex; mode=display">Beta = rac{Cov(p_n,B_n)}{\sigma_m^2}</script><script type="math/tex; mode=display">p_n = 策略每日收益率，B_n = 基准每日收益率，\sigma_m^2 = 基准每日收益方差，Cov(p_n,B_n) = 策略和基准每日收益率的协方差</script><p>该值越小越好。</p>
<h2 id="夏普比率（Sharpe-Ratio）"><a href="#夏普比率（Sharpe-Ratio）" class="headerlink" title="夏普比率（Sharpe Ratio）"></a>夏普比率（Sharpe Ratio）</h2><p>表示每承受一单位总风险，会产生多少的超额报酬，可以同时对策略的收益与风险进行综合考虑。<br>sharp是衡量策略最重要的一个指标，该指标的计算不仅考虑收益率，还考虑了风险，因此比较具有参考价值，可以理解为经过风险调整后的收益率。</p>
<script type="math/tex; mode=display">SharpRatio = rac{p_r - r_f}{\sigma_p}</script><script type="math/tex; mode=display">p_r = 策略年化收益率，r_f = 无风险收益率，\sigma_p = 策略收益率波动率</script><h2 id="收益波动率（Volatility）"><a href="#收益波动率（Volatility）" class="headerlink" title="收益波动率（Volatility）"></a>收益波动率（Volatility）</h2><p>用来测量资产的风险性，波动越大代表策略风险越高。 </p>
<script type="math/tex; mode=display">\sigma_p = \sqrt{rac{250}{n-1}\sum_{i=1}^{n}(p_t-\overline{p_t})^2}</script><script type="math/tex; mode=display">n = 回测交易日数量，p_t = 策略每日收益率，\overline{p_t} = 策略每日平均收益率 = rac{1}{n}\sum_{i=1}^{n}p_n</script><h2 id="信息比率（Information-Ratio）"><a href="#信息比率（Information-Ratio）" class="headerlink" title="信息比率（Information Ratio）"></a>信息比率（Information Ratio）</h2><p>衡量单位超额风险带来的<strong>超额收益</strong>。信息比率越大，说明该策略单位跟踪误差所获得的超额收益越高，</p>
<p>因此，信息比率较大的策略的表现要优于信息比率较低的。 </p>
<script type="math/tex; mode=display">InformationRatio = rac{p_r-B_r}{\sigma_t}</script><script type="math/tex; mode=display">p_r = 策略年化收益率，B_r = 基准年化收益率，\sigma_t = 策略与基准每日收益差值的年化标准差</script><p>合理的投资目标应该是在承担适度风险下，尽可能追求高信息比率。</p>
<h2 id="最大回撤（Max-Drawdown）"><a href="#最大回撤（Max-Drawdown）" class="headerlink" title="最大回撤（Max Drawdown）"></a>最大回撤（Max Drawdown）</h2><p>策略在整个时间段上亏损最严重的时候相比净值最高值下跌的百分比。描述策略可能出现的最糟糕的情况。</p>
<script type="math/tex; mode=display">MaxDrawDown=max(1-rac {p_x}{p_y})</script><script type="math/tex; mode=display">p_x=策略当日价值， p_y=当日之前虚拟账户最高价值</script><p>例如一个账户的净值是100,200,50,<code>300</code>,150,<code>100</code>, 200，那最大的亏损就是从300那个点开始一直亏到100。$MaxDrawDown=1-(100/300)=0.67$<br>最大回撤是策略评估时非常关键的一个指标，通常与<strong>风险承受能力</strong>相关。</p>
<h2 id="换手率（Turnover-Rate）"><a href="#换手率（Turnover-Rate）" class="headerlink" title="换手率（Turnover Rate）"></a>换手率（Turnover Rate）</h2><p>换手率也称周转率，指在一定时间内市场中股票转手<code>买卖的频率</code>，是反映股票<code>流通性强弱</code>的指标之一。<br>换手率描述了策略变化的频率以及持有某只股票平均时间的长短。　</p>
<script type="math/tex; mode=display">TurnOverRate＝rac{p_x}{p_y}</script><script type="math/tex; mode=display">p_x=某一段时期内的成交量，p_y=发行总股数</script><p>一般而言，交收期越短，换手率越高。</p>
<p>换手率的高低往往意味着这样几种情况：</p>
<ol>
<li>股票的换手率越高，意味着该只股票的交投越活跃，人们购买该只股票的意愿越高，属于热门股；反之，股票的换手率越低，则表明该只股票少人关注，属于冷门股。</li>
<li>换手率高一般意味着股票流通性好。然而值得注意的是，换手率较高的股票，往往也是短线资金追逐的对象，投机性较强，股价起伏较大，风险也相对较大。</li>
<li>将换手率与股价走势相结合，可以对未来的股价做出一定的预测和判断。某只股票的换手率突然上升，成交量放大，可能意味着有投资者在大量买进，股价可能会随之上扬。如果某只股票持续上涨了一个时期后，换手率又迅速上升，则可能意昧着一些获利者要套现，股价可能会下跌。</li>
</ol>
<p>例如，某只股票在一个月内成交了2000万股，而该股票的总股本为l亿股，则该股票在这个月的换手率为20%。</p>
]]></content>
      <categories>
        <category>量化投资</category>
      </categories>
      <tags>
        <tag>量化投资</tag>
      </tags>
  </entry>
  <entry>
    <title>量化投资策略</title>
    <url>/2018/01/20/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<p>量化投资学习笔记-量化策略<br><a id="more"></a></p>
<h1 id="选股策略"><a href="#选股策略" class="headerlink" title="选股策略"></a>选股策略</h1><h1 id="交易策略"><a href="#交易策略" class="headerlink" title="交易策略"></a>交易策略</h1><h2 id="GoldenCross策略"><a href="#GoldenCross策略" class="headerlink" title="GoldenCross策略"></a>GoldenCross策略</h2><h3 id="移动平均线"><a href="#移动平均线" class="headerlink" title="移动平均线"></a>移动平均线</h3><ul>
<li>移动平均线是利用统计学上的原理,通过平均数的原理将每天的股价予以平均,剔除数列中的不规则波动,显示出该种数列的真正动向并用以判断股价未来的走势。</li>
<li>移动平均线的计算方法通常有算术平均法（EMA）、加权平均法（WMA）和指数平滑移动法（EMA）三种。</li>
<li>移动平均线是一种平滑工具,通过计算价格数据的平均值,可以求得一条起伏较为平缓的曲线。</li>
<li>移动平均线的变化滞后于市场行情的变化。但是,借助于较为平缓的移动平均线,可以大大简化探究潜在趋势的工作。</li>
<li>移动平均线实质上是一种追踪趋势的工具,其目的在于识别和显示旧趋势已经终结或反转、新趋势正在萌生的关键契机。<h4 id="移动平均线的用途"><a href="#移动平均线的用途" class="headerlink" title="移动平均线的用途"></a>移动平均线的用途</h4></li>
</ul>
<ol>
<li>揭示股价平均成本。</li>
<li>显示股价变动的基本趋势。</li>
<li>股价支撑线和阻挡线。</li>
<li>自动发出买卖讯号。<h4 id="SMA"><a href="#SMA" class="headerlink" title="SMA"></a>SMA</h4>简单移动平均值<h4 id="WMA"><a href="#WMA" class="headerlink" title="WMA"></a>WMA</h4>加权移动平均值<h4 id="EMA"><a href="#EMA" class="headerlink" title="EMA"></a>EMA</h4>指数移动平均值(EMA)是比简单移动平均值SMA更优的趋势跟踪指标。它赋予近期数据更高的权重，所以比SMA值反应更快。同时，EMA不会对即将淘汰的数据做出剧烈反应。</li>
</ol>
<h3 id="GoldenCross算法"><a href="#GoldenCross算法" class="headerlink" title="GoldenCross算法"></a>GoldenCross算法</h3><p>短均线平均值低于长均线平均值，清仓<br>短均线平均值高于长均线平均值，开仓</p>
<p>SMA简单移动均线计算<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果短均线从上往下跌破长均线，也就是在目前的bar短线平均值低于长线平均值，而上一个bar的短线平均值高于长线平均值</span></span><br><span class="line">    <span class="keyword">if</span> short_avg[<span class="number">-1</span>] &lt; long_avg[<span class="number">-1</span>]  <span class="keyword">and</span> short_avg[<span class="number">-2</span>] &gt; long_avg[<span class="number">-2</span>] <span class="keyword">and</span> cur_position &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 进行清仓</span></span><br><span class="line">        order_target_value(context.s1, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果短均线从下往上突破长均线，为入场信号</span></span><br><span class="line">    <span class="keyword">if</span> short_avg[<span class="number">-1</span>] &gt; long_avg[<span class="number">-1</span>] <span class="keyword">and</span> short_avg[<span class="number">-2</span>] &lt; long_avg[<span class="number">-2</span>]:</span><br><span class="line">        <span class="comment"># 满仓入股</span></span><br><span class="line">        order_shares(context.s1, shares)</span><br></pre></td></tr></table></figure></p>
<h1 id="单股票MACD算法"><a href="#单股票MACD算法" class="headerlink" title="单股票MACD算法"></a>单股票MACD算法</h1><p>MACD是一种中长线的研判指标。当股市强烈震荡或股价变化巨大（如送配股拆细等）时，可能会给出错误的信号。所以在决定股票操作时，应该谨慎参考其他指标，以及市场状况，不能完全信任差离值的单一研判，避免造成损失。</p>
<h2 id="MACD指标"><a href="#MACD指标" class="headerlink" title="MACD指标"></a>MACD指标</h2><p><a href="https://zh.wikipedia.org/wiki/MACD">MACD</a>，移动平滑异同平均线(Moving Average Convergence Divergence)策略。MACD是查拉尔ï¿½阿佩尔(Geral Appel)于1979年提出的，由一快及一慢指数移动平均值（EMA）之间的差计算出来。“快”指短时期的EMA，而“慢”则指长时期的EMA，最常用的是12及26日EMA。<br>MACD指标运用快速（短期）和慢速（长期）移动平均线及其聚合与分离的征兆，加以双重平滑运算，是一种<code>趋向类指标</code>。<br>根据移动平均线原理发展出来的MACD，一则去除了移动平均线频繁发出假信号的缺陷，二则保留了移动平均线的效果，因此，MACD指标具有均线趋势性、稳重性、安定性等特点，是用来研判买卖股票的时机，预测股票价格涨跌的技术分析指标 。</p>
<h3 id="MACD图形的计算方法"><a href="#MACD图形的计算方法" class="headerlink" title="MACD图形的计算方法"></a>MACD图形的计算方法</h3><h4 id="差离值（DIF值）"><a href="#差离值（DIF值）" class="headerlink" title="差离值（DIF值）"></a>差离值（DIF值）</h4><p>先利用收盘价的指数移动平均值（<code>12</code>日／<code>26</code>日）计算出差离值。</p>
<script type="math/tex; mode=display">DIF=EMA_12-EMA_26</script><h4 id="讯号线（DEM值，又称MACD值）"><a href="#讯号线（DEM值，又称MACD值）" class="headerlink" title="讯号线（DEM值，又称MACD值）"></a>讯号线（DEM值，又称MACD值）</h4><p>计算出DIF后，会再画一条「讯号线」，通常是DIF的<code>9</code>日指数移动平均值。</p>
<script type="math/tex; mode=display">DEM=EMA_9</script><h4 id="柱形图或棒形图（histogram-bar-graph）"><a href="#柱形图或棒形图（histogram-bar-graph）" class="headerlink" title="柱形图或棒形图（histogram / bar graph）"></a>柱形图或棒形图（histogram / bar graph）</h4><p>接着，将DIF与DEM的差画成柱形图（MACD bar / OSC）。</p>
<p>收市价图表（OHLC chart）<br><img src="Alt text.png" alt="Alt text"></p>
<p>表的绿线是差离值（DIF），红线是讯号线（DEM），白色区块柱形图（MACD bar / OSC）是两者的差（ DM）。</p>
<h2 id="MACD买卖原则"><a href="#MACD买卖原则" class="headerlink" title="MACD买卖原则"></a>MACD买卖原则</h2><ol>
<li>DIF、DEA均为正，DIF向上突破DEA，买入信号参考。</li>
<li>DIF、DEA均为负，DIF向下突破DEA，卖出信号参考。</li>
</ol>
<h1 id="多股票RSI算法"><a href="#多股票RSI算法" class="headerlink" title="多股票RSI算法"></a>多股票RSI算法</h1><p>相对强弱指数（Relative Strength Index，RSI），一借比较价格升降运动以表达<code>价格强度</code>的技术分析工具。<br>RSI在1978年6月由美国机械工程师威列斯ï¿½威尔德提出的技术分析方法。相比起其他分析工具，RSI是其中一种较容易向大众传译的计量工具。<br>根据威尔德的测量结果，当n=14时，指数最具代表性。</p>
<ul>
<li>当某证券的RSI升至70时，代表该证券已被超买（<code>Overbought</code>），投资者应考虑出售该证券。相反，</li>
<li>当证券RSI跌至30时，代表证券被超卖（<code>Oversold</code>），投资者应购入该证券。</li>
<li>当某证券的价格变动倾向（上升或下跌）越趋极端，价格变动逆转的可能性将越大。</li>
</ul>
<blockquote>
<p>在证券市场中，大幅波动对RSI有相当程度的影响，但这可能是错误的买卖讯号，投资者应配合其他技术分析指标以发挥相对强弱指数的功用。</p>
</blockquote>
<h1 id="海龟交易系统（期货）"><a href="#海龟交易系统（期货）" class="headerlink" title="海龟交易系统（期货）"></a>海龟交易系统（期货）</h1><h2 id="ATR-真实波动幅度均值"><a href="#ATR-真实波动幅度均值" class="headerlink" title="ATR 真实波动幅度均值"></a>ATR 真实波动幅度均值</h2><p>真实波动幅度均值（Average True Range，ATR）是由美国威尔德所发展出来的技术分析指标，以N天的指数移动平均数平均后的交易波动幅度。<br>某日的简单交易幅度是当日之最高价H_t−最低价L_t。而真实波动幅度（True Range，TR）则包含前一日的收盘价c_t-1，是以H_t、L_t、C_t-1三个价格做比较，求出当日股价波动的最大幅度。<br>波动幅度的概念表示可以显示出交易者的期望和热情。大幅的或增加中的波动幅度表示交易者在当天可能准备持续买进或卖出股票。波动幅度的减少则表示交易者对股市没有太大的兴趣。</p>
<h2 id="海龟交易系统"><a href="#海龟交易系统" class="headerlink" title="海龟交易系统"></a>海龟交易系统</h2><p>天然的海龟是一个比较成熟而完整的交易系统。<br>构建交易系统的目的就是避免交易员自己做出主观的决策。这样才能真正的让概率发挥作用。<br>海龟的主要目标是捕捉趋势。其采用突破法（唐奇安通道 ）来确定趋势，当价格突破时认为有买入的信号，而随着价格离当初突破的价格越来越远，我们认为趋势成立的概率就越来越高，加仓！</p>
<h2 id="海龟交易系统的组成"><a href="#海龟交易系统的组成" class="headerlink" title="海龟交易系统的组成"></a>海龟交易系统的组成</h2><p>完整的海龟交易系统包含以下内容：</p>
<h3 id="市场"><a href="#市场" class="headerlink" title="市场"></a>市场</h3><p>原版海龟选择交易纽约和芝加哥的场内期货。筛选标准则是<code>高流动性</code>，我大A股市场当然也符合这个标准啦。</p>
<h3 id="仓位"><a href="#仓位" class="headerlink" title="仓位"></a>仓位</h3><p>仓位管理这可以说是海龟交易系统最核心的部分。Richard Dennis期望通过<code>市场的波动性水平</code>来管理仓位。其构建了<code>指数N</code>来衡量波动性水平。指数的构建为以下四步：</p>
<h4 id="True-Range-波动量"><a href="#True-Range-波动量" class="headerlink" title="True Range 波动量"></a>True Range 波动量</h4><script type="math/tex; mode=display">TR=Max(H−L,H−PDC,PDC−L)</script><p>公式中，<br><code>TR</code>表示一天内的波动量，<br><code>H</code> 为当日日内最高价，<br><code>L</code> 为当日日内最低价，<br><code>PDC</code> 为前一日收盘价。</p>
<h4 id="N指数"><a href="#N指数" class="headerlink" title="N指数"></a>N指数</h4><script type="math/tex; mode=display">N=19∗PDN+TR_{20}</script><p>公式中，<br><code>TR</code>为True Range，即一天内波动量，<br><code>PDN</code>为前一日的N值。<br>此公式的真是含义为计算之前20天（包括今天在内）的N的平均值</p>
<h4 id="Dollar-Volatility"><a href="#Dollar-Volatility" class="headerlink" title="Dollar Volatility"></a>Dollar Volatility</h4><script type="math/tex; mode=display">DollarVolatility=N∗DollarsPerPoint</script><p>公式中，<br><code>Dollar Volatility</code>指的是波动的价格，<br><code>Dollars per Point</code>指的是标的股票每波动一个最小单位，1手股票的总价格变化量。<br>在国内最小变化量是0.01元，1手是100股。所以<code>Dollars per Point</code>就是0.01ï¿½100=1</p>
<h4 id="Unit"><a href="#Unit" class="headerlink" title="Unit"></a>Unit</h4><script type="math/tex; mode=display">Unit= rac {1 \% of Account} {Market Dollar Volatility}</script><p>公式中，Unit即为我们买卖的单位，<br><code>1% of Account</code>是总资产的1%，<br><code>Market Dollar Volatility</code>就是我们之前算出的<code>Dollar Volatility</code>，<br>通过此公式计算出的Unit就是我们要买入的单位数量。<br>此公式的意义是在一般情况下（市场波动率不大的时候），如果买入1Unit单位的资产，当天震幅使得总资产的变化不超过1%</p>
<h3 id="入市"><a href="#入市" class="headerlink" title="入市"></a>入市</h3><p>海龟将所有资金分为两部分，一部分资金按系统一执行，一部分资金按系统二执行</p>
<h4 id="系统一"><a href="#系统一" class="headerlink" title="系统一"></a>系统一</h4><ol>
<li>若当前价格高于过去20日的最高价，则买入一个Unit（注意是分钟回测）</li>
<li>加仓：若股价在上一次买入（或加仓）的基础上上涨了0.5N，则加仓一个Unit<h4 id="系统二"><a href="#系统二" class="headerlink" title="系统二"></a>系统二</h4>与系统一相一致，但当如破55日最高价时才购买</li>
<li>若当前价格高于过去55日的最高价，则买入一个Unit（注意是分钟回测）</li>
<li>加仓：若股价在上一次买入（或加仓）的基础上上涨了0.5N，则加仓一个Unit</li>
</ol>
<blockquote>
<p>eg：若某只股票A的N为2，20日最高价为100<br>则当股价突破100时买入一个Unit，当股价突破100+0.5ï¿½2=101时加仓一个Unit，当股价突破101+0.5ï¿½2=102时加仓一个Unit。</p>
</blockquote>
<h3 id="止损"><a href="#止损" class="headerlink" title="止损"></a>止损</h3><p>止损即损失达到多少时就一定要卖出现有仓位。<br>海龟交易系统规定，当价格比最后一次买入价格下跌2N时，则卖出全部头寸止损（也就是，在一般情况下，损失不会超过2%）。</p>
<h3 id="止盈"><a href="#止盈" class="headerlink" title="止盈"></a>止盈</h3><h4 id="系统一-1"><a href="#系统一-1" class="headerlink" title="系统一"></a>系统一</h4><p>当股价跌破10日内最低价时（10日唐奇安通道下沿），清空头寸结束本次交易</p>
<h4 id="系统二-1"><a href="#系统二-1" class="headerlink" title="系统二"></a>系统二</h4><p>当股价跌破20日内最低价时（20日唐奇安通道下沿），清空头寸结束本次交易</p>
<h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><p>资金的调整。开始时设定两个比例：<code>Loss</code>和<code>Adjust</code>。<br>若交易结束后损失的资金占总资金比例大于Loss，则今后只用现有投资资金的Adjust比例。</p>
<blockquote>
<p>eg：若初始资金为100万，设定Loss=80%，Adjust=90%。则当总资产低于100ï¿½80%=80万时，进行一次资金调整，以后只使用80ï¿½90%=72万的资金用于投资行为</p>
</blockquote>
<h1 id="商品期货跨品种配对交易"><a href="#商品期货跨品种配对交易" class="headerlink" title="商品期货跨品种配对交易"></a>商品期货跨品种配对交易</h1><h2 id="布林带（Bollinger-Bands）"><a href="#布林带（Bollinger-Bands）" class="headerlink" title="布林带（Bollinger Bands）"></a>布林带（Bollinger Bands）</h2><p>布林带（Bollinger Bands，BBands）也称为布林通道、包宁杰带状、保力加通道或布历加通道，是由约翰ï¿½包宁杰（John Bollinger）在1980年代发明的技术分析工具。<br>应用上结合了移动平均和标准差的概念，其基本的型态是由三条轨道线组成的带状通道（中轨和上、下轨各一条）。中轨为股价的平均成本，上轨和下轨可分别视为股价的压力线和支撑线。</p>
<h3 id="布林带的定义"><a href="#布林带的定义" class="headerlink" title="布林带的定义"></a>布林带的定义</h3><ul>
<li>中轨= N时间段的简单移动平均线</li>
<li>上轨=中轨+ K ï¿½ N时间段的标准差</li>
<li>下轨=中轨− K ï¿½ N时间段的标准差</li>
</ul>
<p>一般情况下，设定<code>N=20</code>和<code>K=2</code>，这两个数值也是在布林带当中使用最多的。<br>在日线图里，N=20其实就是「月均线」（MA20）。<br>依照正态分布规则，约有95%的数值会分布在距离平均值有正负2个标准差的范围内。</p>
<h3 id="两大指标"><a href="#两大指标" class="headerlink" title="两大指标"></a>两大指标</h3><p>由布林带衍生出两项颇为实用的指标：%b指标、带宽指标，以辅助布林带的判读和运用。</p>
<h4 id="b指标"><a href="#b指标" class="headerlink" title="%b指标"></a>%b指标</h4><p>$\%b$ 指标（Percent b，PB），以数字形式呈现收盘价在布林带中的位置，做为交易决策时的关键指标。例如：当%b值为0.5（或以百分比表示50%），代表收盘价处于布林带的中间位置。</p>
<p>计算公式：<code>%b值 = (收盘价−布林带下轨值) ï¿½ (布林带上轨值−布林带下轨值)</code></p>
<p>由于收盘价会在上、下轨道震荡游走，幅度甚至大于轨道范围（0~1），因此%b值没有上下限。</p>
<ul>
<li>当走势向上突破，收盘价落于上轨上方时，%b值&gt; 1；</li>
<li>当走趋向下突破，收盘价落在下轨下方时，%b值&lt; 0。</li>
</ul>
<p>功能：通过观察分析「%b指标」可以提供投资时的参考，依据指标的强弱走势，作出买卖决策。</p>
<h4 id="带宽指标"><a href="#带宽指标" class="headerlink" title="带宽指标"></a>带宽指标</h4><p>带宽指标（Bandwidth，BW），是由布林带中轨及上、下轨衍生出的指标，利用<code>股价波动范围</code>以判断<code>趋势的强度与转折</code>。</p>
<p>计算公式：<code>带宽指标值 = (布林带上轨值−布林带下轨值) ï¿½布林带中轨值</code><br>布林带中轨为股价的移动平均值（平均成本），所以带宽指标值可视为<code>通道上、下轨幅度与股价平均成本的比率</code>（例如：当带宽指标值为0.3，代表通道上、下轨幅度为股价平均成本的30%）。</p>
<ul>
<li>带宽指标值越高，代表幅度相对平均成本比率越大；</li>
<li>带宽指标值越低，代表幅度相对平均成本比率越小。</li>
</ul>
<p>功能：带宽指标，最常用于限定收敛状态，一种基于<code>波动率</code>的交易机会；</p>
<h2 id="对冲比率-套期保值比率"><a href="#对冲比率-套期保值比率" class="headerlink" title="对冲比率/套期保值比率"></a>对冲比率/套期保值比率</h2><p>套期保值比率是指为规避固定收益债券现货市场风险，套期保值者在建立交易头寸时所确定的<code>期货合约的总价值</code>与所保值的<code>现货合同总价值</code>之间的比率。<br>确定合适的套期保值比率是减少交叉套期保值风险，达到最佳套期保值效果的关键。</p>
<h1 id="KDJ指标（随机指标）"><a href="#KDJ指标（随机指标）" class="headerlink" title="KDJ指标（随机指标）"></a>KDJ指标（随机指标）</h1><p>随机指标（KDJ）由George C．Lane创制。它综合了<code>动量观念</code>、<code>强弱指标</code>及<code>移动平均线</code>的优点，用来度量股价脱离价格正常范围的变异程度。<br>KDJ指标考虑的不仅是<code>收盘价</code>，而且有近期的<code>最高价</code>和<code>最低价</code>，这避免了仅考虑收盘价而忽视真正波动幅度的弱点。</p>
<h2 id="KDJ的原理"><a href="#KDJ的原理" class="headerlink" title="KDJ的原理"></a>KDJ的原理</h2><ul>
<li>随机指标(KDJ)一般是根据统计学的原理，通过一个特定的周期（常为9日、9周等）内出现过的最高价、最低价及最后一个计算周期的收盘价及这三者之间的比例关系，来计算最后一个计算周期的未成熟随机值 <code>RSV</code>，然后根据平滑移动平均线的方法来计算K值、D值与J值，并绘成曲线图来研判<code>股票走势</code>。</li>
<li>随机指标(KDJ)是以最高价、最低价及收盘价为基本数据进行计算，得出的K值、D值和J值分别在指标的坐标上形成的一个点，连接无数个这样的点位，就形成一个完整的、能反映价格波动趋势的KDJ指标。它主要是利用价格波动的真实波幅来反映价格走势的强弱和超买超卖现象，在价格尚未上升或下降之前发出买卖信号的一种技术工具。它在设计过程中主要是研究最高价、最低价和收盘价之间的关系，同时也融合了动量观念、强弱指标和移动平均线的一些优点，因此，能够比较迅速、快捷、直观地研判行情。</li>
<li>随机指标(KDJ)最早是以<code>KD</code>指标的形式出现，而KD指标是在<code>威廉指标</code>的基础上发展起来的。不过威廉指标只判断股票的超买超卖的现象，在KDJ指标中则融合了移动平均线速度上的观念，形成比较准确的买卖信号依据。在实践中，K线与D线配合J线组成KDJ指标来使用。由于KDJ线本质上是一个随机波动的观念，故其对于掌握<code>中短期</code>行情走势比较准确。</li>
</ul>
<h2 id="RSV"><a href="#RSV" class="headerlink" title="RSV"></a>RSV</h2><h2 id="KD指标"><a href="#KD指标" class="headerlink" title="KD指标"></a>KD指标</h2><h2 id="威廉指标"><a href="#威廉指标" class="headerlink" title="威廉指标"></a>威廉指标</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://rqalpha.readthedocs.io/zh_CN/latest/intro/examples.html">ricequant 策略示例</a><br><a href="https://uqer.io/help">优矿帮助文档</a></p>
]]></content>
      <categories>
        <category>量化投资</category>
      </categories>
      <tags>
        <tag>量化投资</tag>
      </tags>
  </entry>
  <entry>
    <title>BinaryHeap的实现原理</title>
    <url>/2019/10/20/BinaryHeap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>前段时间折腾RabbitMQ踩了个坑，</p>
<ul>
<li>队列中对每个消息设置TTL时，如果队头有消息阻塞会导致TTL已过期的消息不能准时送达，优先队列也同样适用；</li>
<li>由于存储方式的原因，RabbitMQ中PriorityQueue一但定义了就不能更改队列的类型；</li>
</ul>
<p>其中关于<code>PriorityQueue</code>的机制不太清楚，于是有了这篇关于二叉堆的文章，下一步研究下JDK中PriorityQueue的源码如何实现；</p>
<blockquote>
<p>关键点：二叉堆基于<code>一维数组</code>构建完全二叉树结构,，<code>heapify</code>复杂度为<code>O(n)</code>，其<code>add</code>和<code>pop</code>复杂度为<code>O(log(n))</code>，<code>peek</code>的复杂度为<code>O(1)</code>，适用于优先队列场景；</p>
</blockquote>
<a id="more"></a> 
<h1 id="数据结构中的堆栈"><a href="#数据结构中的堆栈" class="headerlink" title="数据结构中的堆栈"></a>数据结构中的堆栈</h1><h2 id="Stack栈"><a href="#Stack栈" class="headerlink" title="Stack栈"></a>Stack栈</h2><blockquote>
<p>栈就像装数据的桶或箱子</p>
<ul>
<li>栈它是一种具有后进先出(LIFO)性质的数据结构，也就是说后存放的先取，先存放的后取。</li>
<li>如同我们要取出放在箱子里面底下的东西（放入的比较早的物体），我们首先要移开压在它上面的物体（放入的比较晚的物体）。</li>
</ul>
</blockquote>
<h2 id="Heap堆"><a href="#Heap堆" class="headerlink" title="Heap堆"></a>Heap堆</h2><blockquote>
<p>堆像一棵倒过来的树</p>
<ul>
<li>堆是一种经过排序的树形数据结构，每个结点都有一个值。通常我们所说的堆的数据结构，是指二叉堆。</li>
<li>堆的特点是根结点的值最小（或最大），且根结点的两个子树也是一个堆。</li>
<li>由于堆的这个特性，常用来实现优先队列;</li>
<li>堆的存取是随意，这就如同我们在图书馆的书架上取书，虽然书的摆放是有顺序的，但是我们想取任意一本时不必像栈一样，先取出前面所有的书，书架这种机制不同于箱子，我们可以直接取出我们想要的书。</li>
</ul>
</blockquote>
<h1 id="内存分配中的堆栈"><a href="#内存分配中的堆栈" class="headerlink" title="内存分配中的堆栈"></a>内存分配中的堆栈</h1><ul>
<li>内存中的<code>Stack区</code>中分配局部变量空间，</li>
<li>内存中的<code>Heap区</code>是用于分配程序员申请的内存空间。</li>
<li>另外还有<code>静态区</code>是分配静态变量/全局变量空间的；<code>只读区</code>是分配常量和程序代码空间的；以及其他一些分区。</li>
</ul>
<blockquote>
<ul>
<li>数据结构中的堆栈，是一种<code>逻辑结构</code>，是一种<code>抽象</code>的概念，如线性表；</li>
<li>内存分配中的堆栈，是一种<code>存储结构</code>，是一种<code>具体/物理</code>的概念，是一块具体的内存空间；</li>
</ul>
<p>下文中的堆是指数据结构中的Heap</p>
</blockquote>
<h1 id="堆（Heap）"><a href="#堆（Heap）" class="headerlink" title="堆（Heap）"></a>堆（Heap）</h1><p>堆是计算机科学中的一种特别的树状数据结构。<br>若是满足以下特性，即可称为堆：</p>
<ul>
<li>给定堆中任意节点 P和C，</li>
<li>若P是C的母节点，那么P的值会小于等于（或大于等于）C的值。</li>
<li>若母节点的值恒小于等于子节点的值，此堆积称为最小堆（min heap）；</li>
<li>反之，若母节点的值恒大于等于子节点的值，此堆积称为最大堆（max heap）。</li>
<li>在堆中最顶端的那一个节点，称作根节点（root node），根节点本身没有母节点（parent node）。</li>
</ul>
<p>堆始于<code>JWJ Williams</code>在1964年发表的<code>堆排序</code>（<code>heap sort</code>），当时他提出了二元堆积树作为此演算法的资料结构。堆在<code>Dijkstra</code>算法中亦为重要的关键。</p>
<h2 id="堆的应用"><a href="#堆的应用" class="headerlink" title="堆的应用"></a>堆的应用</h2><p>在<code>队列</code>中，调度程序反复<code>提取队列中第一个作业并运行</code>，实际会有这样的情况</p>
<ul>
<li>某些<code>耗时较短</code>的任务<code>等待很长时间</code>才被处理，</li>
<li>某些<code>耗时不短</code>，但<code>重要性</code>较高的任务，应当具有<code>优先权</code>：优先队列  </li>
</ul>
<p>堆即为解决此类问题设计的一种数据结构。</p>
<h1 id="二叉堆-binary-heap"><a href="#二叉堆-binary-heap" class="headerlink" title="二叉堆(binary heap)"></a>二叉堆(binary heap)</h1><p>二叉堆是一种特殊的堆，</p>
<ul>
<li>二叉堆具有<code>堆</code>的性质：父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值；</li>
<li>二叉堆又具有<code>二叉树</code>的性质：二叉堆是<code>完全二叉树</code>或者是近似完全二叉树）；</li>
<li>当父节点的键值大于或等于它的每一个子节点的键值时我们称它为最大堆；</li>
<li>当父节点的键值小于或等于它的每一个子节点的键值时我们称它为最小堆；</li>
</ul>
<p><img src="https://raw.githubusercontent.com/geosmart/geosmart.io/master/blog/img/heap.gif" alt="heap"></p>
<h2 id="二叉堆的性能"><a href="#二叉堆的性能" class="headerlink" title="二叉堆的性能"></a>二叉堆的性能</h2><ul>
<li>pop和insert：<code>O(log(n))</code></li>
<li>peek：<code>O(1)</code></li>
</ul>
<h2 id="二叉堆的节点类型"><a href="#二叉堆的节点类型" class="headerlink" title="二叉堆的节点类型"></a>二叉堆的节点类型</h2><p>设堆大小为N，则以下节点的数组Index为：</p>
<ul>
<li>父节点：P</li>
<li>左孩子：L=2P+1</li>
<li>右孩子：R=2P+2</li>
<li>最后一个父节点：(N/2)-1</li>
</ul>
<h2 id="二叉堆的操作类型"><a href="#二叉堆的操作类型" class="headerlink" title="二叉堆的操作类型"></a>二叉堆的操作类型</h2><ul>
<li>pop：提取堆顶元素</li>
<li>insert：插入节点</li>
<li>peek：查询堆顶</li>
</ul>
<h2 id="构建二叉堆（heapify）"><a href="#构建二叉堆（heapify）" class="headerlink" title="构建二叉堆（heapify）"></a>构建二叉堆（heapify）</h2><ul>
<li>将一个未排序的数组构建成二叉堆（升序/降序）；</li>
<li>将数组假定为一个二叉堆，然后<code>从最后一个父节点</code>开始<code>向上遍历</code>，对每个父节点执行<code>下沉</code>操作，直到根节点；<blockquote>
<p><code>Heapify</code>后只能保证趋势顺序，<code>HeapSort</code>保证绝对顺序</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>siftDown</p>
</blockquote>
<p><img src="heapify.gif" alt="heapify"></p>
<h2 id="插入节点-add"><a href="#插入节点-add" class="headerlink" title="插入节点(add)"></a>插入节点(add)</h2><ul>
<li>在<code>堆尾</code>新增元素,数组大小不足时需要扩容；</li>
<li>从最后一个父节点开始执行<code>上浮</code>；</li>
<li>直到父节点的值小于或等于该节点，或到达根节点时，才停止上浮，即插入结束。</li>
</ul>
<blockquote>
<p>siftUp</p>
</blockquote>
<h2 id="提取最大-小节点-pop"><a href="#提取最大-小节点-pop" class="headerlink" title="提取最大/小节点(pop)"></a>提取最大/小节点(pop)</h2><p>删除后需要要保持堆的完全二叉树特性；</p>
<ul>
<li>将<code>堆尾</code>元素替换到<code>堆顶</code>位置；</li>
<li>抽取<code>堆顶</code>元素；</li>
<li>以新的<code>堆顶</code>元素作为父节点，执行<code>下沉</code>；</li>
<li>直到子节点小于或等于改节点，才停止下沉；</li>
<li>返回抽取的堆顶元素，即pop结束;</li>
</ul>
<blockquote>
<p>siftDown</p>
</blockquote>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><p>可以利于堆的特性(顶总是最值)来处理排序问题；重复从堆顶获取最值来完成数组排序；</p>
<ol>
<li>对未排序的数组执行heapify，构建一个最大堆;</li>
<li>重复pop堆顶元素操作（下沉调整），直到堆元素为1；</li>
<li>pop出的元素组成的数组即为排序后结果;</li>
</ol>
<p><img src="heapsort.gif" alt="heapsort"></p>
<blockquote>
<p>时间复杂度：O(n) + O(n<em>log(n)) = O(n</em>log(n))</p>
</blockquote>
<h1 id="二叉堆的Java实现"><a href="#二叉堆的Java实现" class="headerlink" title="二叉堆的Java实现"></a>二叉堆的Java实现</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 二叉堆</span></span><br><span class="line"><span class="comment"> * 示例日志：https://gist.github.com/geosmart/c31fe452f0b536ea12fbda72c1385553</span></span><br><span class="line"><span class="comment"> * 完整源码地址：https://github.com/geosmart/me.demo.algorithm/blob/master/src/main/java/me/demo/algorithm/heap/PriorityHeap.java</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 二叉堆</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PriorityHeap</span> </span>&#123;</span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 堆数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Object[] heap;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 堆大小</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PriorityHeap</span><span class="params">(Object[] array)</span> </span>&#123;</span><br><span class="line">        heap = array;</span><br><span class="line">        size = heap.length;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 将数组调整为满足parent&gt;(left,right)的堆结构</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">heapify</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"orgin heap."</span>);</span><br><span class="line">        printHeap();</span><br><span class="line">        <span class="comment">//从最后一个父节点开始下沉</span></span><br><span class="line">        <span class="keyword">int</span> i = (size &gt;&gt; <span class="number">1</span>) - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(String.format(<span class="string">"heapify,parent[%s] siftdown"</span>, i));</span><br><span class="line">            siftDown(i, (<span class="keyword">int</span>) heap[i]);</span><br><span class="line">            i--;</span><br><span class="line">            printHeap();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 插入节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> node 节点值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> node)</span> </span>&#123;</span><br><span class="line">        heap = Arrays.copyOf(heap, size + <span class="number">1</span>);</span><br><span class="line">        size = size + <span class="number">1</span>;</span><br><span class="line">        heap[size - <span class="number">1</span>] = node;</span><br><span class="line">        <span class="comment">//从最后一个节点开始,逐父节点单线遍历上浮</span></span><br><span class="line">        siftUp(size - <span class="number">1</span>, (<span class="keyword">int</span>) heap[size - <span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 弹出节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 堆顶节点值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(<span class="string">"heap is empty"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//弹出节点</span></span><br><span class="line">        Object node = heap[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//堆尾节点移动到堆顶节点</span></span><br><span class="line">        heap[<span class="number">0</span>] = heap[heap.length - <span class="number">1</span>];</span><br><span class="line">        <span class="comment">//数组</span></span><br><span class="line">        heap = Arrays.copyOf(heap, size - <span class="number">1</span>);</span><br><span class="line">        size -= <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (size &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">//顶点下沉</span></span><br><span class="line">            System.out.println(String.format(<span class="string">"parent[%s] siftdown"</span>, <span class="number">0</span>));</span><br><span class="line">            siftDown(<span class="number">0</span>, (<span class="keyword">int</span>) heap[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 获取堆顶节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 堆顶节点值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">peak</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(<span class="string">"heap is empty"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> heap[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 节点下沉</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> parent 父节点index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value 父节点值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDown</span><span class="params">(<span class="keyword">int</span> parent, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//当parent还有子节点时进行循环swap</span></span><br><span class="line">        <span class="keyword">while</span> (parent &lt; (size / <span class="number">2</span>)) &#123;</span><br><span class="line">            <span class="comment">//假设left最小</span></span><br><span class="line">            <span class="keyword">int</span> left = (parent &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> right = left + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (right &lt; size &amp;&amp; (<span class="keyword">int</span>) heap[right] &lt; (<span class="keyword">int</span>) heap[left]) &#123;</span><br><span class="line">                <span class="comment">//right最小</span></span><br><span class="line">                left = right;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//parent最小</span></span><br><span class="line">            <span class="keyword">if</span> (value &lt; (<span class="keyword">int</span>) heap[left]) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//交换parent与最小值</span></span><br><span class="line">            heap[parent] = heap[left];</span><br><span class="line">            parent = left;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//将原始parent放到最终交换后的位置</span></span><br><span class="line">        heap[parent] = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 节点上浮</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> child 节点index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value 节点值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUp</span><span class="params">(<span class="keyword">int</span> child, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//从最后一个节点开始,逐父节点单线遍历上浮</span></span><br><span class="line">        <span class="keyword">while</span> (child &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(String.format(<span class="string">"node[%s] siftup"</span>, child));</span><br><span class="line">            <span class="keyword">int</span> parent = (child - <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">            <span class="comment">//父节点大，则交换上浮</span></span><br><span class="line">            <span class="keyword">if</span> ((<span class="keyword">int</span>) heap[child] &lt; (<span class="keyword">int</span>) heap[parent]) &#123;</span><br><span class="line">                heap[child] = heap[parent];</span><br><span class="line">                heap[parent] = value;</span><br><span class="line">                child = parent;</span><br><span class="line">                printHeap();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 堆排序</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] heapSort() &#123;</span><br><span class="line">        <span class="comment">//构建堆</span></span><br><span class="line">        heapify();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] sortArray = <span class="keyword">new</span> <span class="keyword">int</span>[heap.length];</span><br><span class="line">        <span class="comment">//逐个弹出堆顶最值即可完成排序</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sortArray.length; i++) &#123;</span><br><span class="line">            System.out.println(String.format(<span class="string">"pop[%s]"</span>, i));</span><br><span class="line">            sortArray[i] = (<span class="keyword">int</span>) pop();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sortArray;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printHeap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(JSON.toJSONString(getHeap()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Object[] getHeap() &#123;</span><br><span class="line">        <span class="keyword">return</span> heap;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/geosmart/geosmart.io/blob/master/blog/编程基础/BinaryTree基础知识.md">BinaryTree基础知识</a></li>
<li><a href="https://medium.com/@parulbaweja8/a-closer-look-at-heapsort-c83b331f8353">A Closer Look at Heapsort</a></li>
</ul>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Heap</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ系统架构</title>
    <url>/2019/11/05/RabbitMQ%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>rabbitmq采用什么系统架构，有哪些常规使用模式？</p>
<a id="more"></a> 
<h1 id="RabbitMQ的物理架构"><a href="#RabbitMQ的物理架构" class="headerlink" title="RabbitMQ的物理架构"></a>RabbitMQ的物理架构</h1><ul>
<li>架构1：普通架构<br><img src="rabbitmq_physical2.png" alt="rabbitmq物理架构2"><blockquote>
<p>First node is the master of cluster – two other nodes will join him.<br>We use container management to enable an UI administration console for each node.<br>Every node has default connection and UI management ports exposed.<br>Important thing is to link rabbit2 and rabbit3 constainers to rabbit1, which is necessary while joining to cluster mastering by rabbit1.  </p>
</blockquote>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rabbit1 --name rabbit1 -e RABBITMQ_ERLANG_COOKIE=<span class="string">'rabbitcluster'</span> -p 30000:5672 -p 30001:15672 rabbitmq:management</span><br><span class="line"></span><br><span class="line">rabbit2 --name rabbit2 --link rabbit1:rabbit1 -e RABBITMQ_ERLANG_COOKIE=<span class="string">'rabbitcluster'</span> -p 30002:5672 -p 30003:15672 rabbitmq:management</span><br><span class="line"></span><br><span class="line">rabbit3 --name rabbit3 --link rabbit1:rabbit1 -e RABBITMQ_ERLANG_COOKIE=<span class="string">'rabbitcluster'</span> -p 30004:5672 -p 30005:15672 rabbitmq:management</span><br></pre></td></tr></table></figure>
<ul>
<li>架构2：加入集群权限管理和节点自注册<br><img src="rabbitmq_physical1.png" alt="rabbitmq物理架构1"><blockquote>
<p>We use Vault as a credentials manager when applications try to authenticate against RabbitMQ node or user tries to login to RabbitMQ web admin console.<br>Each RabbitMQ node registers itself after startup in Consul and retrieves list of nodes running inside a cluster.<br>Vault is integrated with RabbitMQ using dedicated secrets engine.   </p>
</blockquote>
</li>
</ul>
<h2 id="RabbitMQ的结点类型"><a href="#RabbitMQ的结点类型" class="headerlink" title="RabbitMQ的结点类型"></a>RabbitMQ的结点类型</h2><p>rabbitmq节点类型有内存节点（ram node）和磁盘节点(disk node)。</p>
<ul>
<li><code>RAM node</code>:内存节点将所有的队列、交换机、绑定、用户、权限和vhost的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等操作更加的快速。</li>
<li><code>Disk node</code>:将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启RabbitMQ的时候，丢失系统的配置信息。</li>
</ul>
<p>RabbitMQ要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。</p>
<blockquote>
<p>问题说明：如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作（增删改查），直到节点恢复。<br>解决方案：设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改。</p>
</blockquote>
<h2 id="RabbitMQ的集群模式"><a href="#RabbitMQ的集群模式" class="headerlink" title="RabbitMQ的集群模式"></a>RabbitMQ的集群模式</h2><p>RabbitMQ的Cluster集群模式分为2种，普通模式和镜像模式。</p>
<h3 id="普通模式-default"><a href="#普通模式-default" class="headerlink" title="普通模式(default)"></a>普通模式(default)</h3><ul>
<li>默认的集群模式，对于Queue来说，<code>消息实体只存在于其中一个节点</code>，对于<code>集群上的所有节点仅有相同的元数据</code>，即队列的结构。</li>
<li>当消息进入集群中某个节点的Queue后，consumer从另外一个节点消费时，比如node1、node2两个节，RabbitMQ会临时在node1、node2间进行消息传输，把A中的消息实体取出并经过B发送给consumer。</li>
<li>所以<code>consumer应尽量连接每一个节点</code>，从中取消息。即对于<code>同一个逻辑队列，要在多个节点建立物理Queue</code>。否则无论consumer连或node1还是node2，出口总在node1，会产生瓶颈。</li>
<li>当node1节点故障后，node2节点无法取到node1节点中还未消费的消息实体。如果做了消息持久化，那么得等node1节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。</li>
</ul>
<h3 id="镜像模式"><a href="#镜像模式" class="headerlink" title="镜像模式"></a>镜像模式</h3><p>将需要消费的队列变为镜像队列，存在于多个节点（至少3个），这样就可以实现RabbitMQ的<code>HA高可用性</code>。<br>作用就是<code>消息实体</code>会主动在镜像节点之间实现<code>同步</code>，而不是像普通模式那样，在consumer消费数据时临时读取。缺点是集群内部的同步通讯会占用大量的网络带宽。<br><img src="rabbitmq_mirror.png" alt="rabbitmq镜像模式"><br>镜像队列实现了RabbitMQ的高可用性（HA），具体的实现策略如下：</p>
<ul>
<li><code>all</code>：镜像队列将会在整个集群中复制。当一个新的节点加入后，也会在这个节点上复制一份。</li>
<li><code>exactly（count）</code>：镜像队列将会在集群上复制count份。如果集群数量少于count时候，队列会复制到所有节点上。如果大于Count集群，有一个节点crash后，新进入节点也不会做新的镜像。</li>
<li><code>nodes（node name）</code>： 镜像队列会在node name中复制。如果这个名称不是集群中的一个，这不会触发错误。如果在这个node list中没有一个节点在线，那么这个queue会被声明在client连接的节点。</li>
</ul>
<blockquote>
<p>一般互联网大厂都会构建这种镜像集群模式;<br>实际生产环境：一般客户端是通过HAProxy这类<code>负载均衡</code>对MQ进行访问；</p>
</blockquote>
<h3 id="双活模式"><a href="#双活模式" class="headerlink" title="双活模式"></a>双活模式</h3><ul>
<li>实现异地集群的都是采用这种<code>双活</code>或者<code>多活</code>模型来实现的。这种模式需要依赖 rabbitMQ 的<code>federation</code>插件，可以实现持续的，可靠的 AMQP 数据通信，多活模式在实际配置与应用非常的简单。    </li>
<li>rabbitMQ 部署架构采用双中心模式(多中心)，那么在两套(或多套)数据中心各部署一套 rabbitMQ 集群，各中心的rabbitMQ 服务除了需要为业务提供正常的消息服务外，中心之间还需要实现部分队列消息共享。</li>
</ul>
<h1 id="RabbitMQ的逻辑架构"><a href="#RabbitMQ的逻辑架构" class="headerlink" title="RabbitMQ的逻辑架构"></a>RabbitMQ的逻辑架构</h1><p><img src="rabbitmq_logic1.png" alt="rabbitmq逻辑架构"></p>
<ul>
<li>发布者（producer）是发布消息的应用程序。</li>
<li>队列（queue）用于消息存储的缓冲。</li>
<li>消费者（consumer）是接收消息的应用程序。</li>
<li>消息代理（message broker）：消息代理（message brokers）从生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。</li>
</ul>
<blockquote>
<p>由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理可以存在于不同的设备上。</p>
<p><code>AMQP</code>，即<code>Advanced Message Queuing Protocol</code>,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。</p>
<p>基于此协议的<code>客户端</code>与<code>消息中间件</code>可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erla</p>
</blockquote>
<h1 id="RabbitMQ消息模型的核心理念"><a href="#RabbitMQ消息模型的核心理念" class="headerlink" title="RabbitMQ消息模型的核心理念"></a>RabbitMQ消息模型的核心理念</h1><ul>
<li>producer：消息生产者，不会直接发送任何消息给队列，事实上，发布者（producer）甚至不知道消息是否已经被投递到队列，发布者（producer）只需要把消息发送给一个交换机（exchange）</li>
<li>consumer：消息消费者</li>
<li>virtual host：虚拟主机，在RabbitMQ中，用户只能在虚拟主机的层面上进行一些权限设置，比如我可以访问哪些队列，我可以处理哪些请求等等；</li>
<li>broker：消息转发者，也就是我们RabbitMQ服务端充当的功能了，那么消息是按照什么规则进行转发的呢？需要用到下面几个概念；</li>
<li>exchange：交换机，一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息，这些规则是通过交换机类型（exchange type）来定义的；</li>
<li>routing key(路由键)，每个消息都有这个键，我们也可以自己设定，其实就是一字符串；</li>
<li>queue：消息队列，用于存放消息，他接收exchange路由过来的消息，我们可以对队列内容进行持久化操作，</li>
<li>binding key(绑定键)：queue到底接收哪个exchange路由的消息？这个时候就要用到binding key(绑定键)了，绑定键会将队列和exchange进行绑定，至于绑定方式，RabbitMQ提供了多种方式（direct,topic,fanout,header）；</li>
</ul>
<h1 id="交换机（Exchange）"><a href="#交换机（Exchange）" class="headerlink" title="交换机（Exchange）"></a>交换机（Exchange）</h1><p><img src="rabbitmq_exchange.png" alt="rabbitmq_exchange"></p>
<h2 id="交换机的属性"><a href="#交换机的属性" class="headerlink" title="交换机的属性"></a>交换机的属性</h2><p>除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是：</p>
<ul>
<li>Name</li>
<li>Durability （消息代理重启后，交换机是否还存在）</li>
<li>Auto-delete （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它）</li>
<li>Arguments（依赖代理本身）</li>
</ul>
<p>Exchange可以有两个状态：<code>持久态（durable）</code>、<code>瞬态（transient）</code>。<br>持久化的Exchange会在消息代理（broker）重启后依旧存在，而瞬态的Exchange则不会（它们需要在broker再次上线后重新被声明）。</p>
<blockquote>
<p>然而并不是所有的应用场景都需要持久化的Exchange。</p>
</blockquote>
<h2 id="交换机的类型"><a href="#交换机的类型" class="headerlink" title="交换机的类型"></a>交换机的类型</h2><h3 id="直连交换机-amq-direct"><a href="#直连交换机-amq-direct" class="headerlink" title="直连交换机(amq.direct)"></a>直连交换机(<code>amq.direct</code>)</h3><p>定义：将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行比较，如果相等，则发送到该Binding对应的Queue中。</p>
<p><img src="rabbitmq_direct.png" alt="rabbitmq_direct"></p>
<h3 id="主题交换机-amq-topic"><a href="#主题交换机-amq-topic" class="headerlink" title="主题交换机(amq.topic)"></a>主题交换机(<code>amq.topic</code>)</h3><p>定义：将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行规则对比，如果匹配上了，则发送到该Binding对应的Queue中。</p>
<p>主题交换机是很强大的，它可以表现出跟其他交换机类似的行为当一个队列的绑定键为 “#”（井号） 的时候，这个队列将会无视消息的路由键，接收所有的消息。当 * (星号) 和 # (井号) 这两个特殊字符都未在绑定键中出现的时候，此时主题交换机就拥有的直连交换机的行为。</p>
<p><img src="rabbitmq_topic.png" alt="rabbitmq_direct"></p>
<pre><code>&gt; 示例中，我们发送的所有消息都是用来描述小动物的。发送的消息所携带的路由键是由三个单词所组成的，这三个单词被两个.分割开。
路由键里的第一个单词描述的是动物的手脚的利索程度，第二个单词是动物的颜色，第三个是动物的种类。所以它看起来是这样的： `&lt;celerity&gt;.&lt;colour&gt;.&lt;species&gt;`。
我们创建了三个绑定：Q1的绑定键为 `*.orange.*`，Q2的绑定键为 `*.*.rabbit` 和` lazy.#` 。
这三个绑定键被可以总结为：
&gt;* Q1 对所有的桔黄色动物都感兴趣。
&gt;* Q2 则是对所有的兔子和所有懒惰的动物感兴趣。
</code></pre><h3 id="扇型交换机-amq-fanout"><a href="#扇型交换机-amq-fanout" class="headerlink" title="扇型交换机(amq.fanout)"></a>扇型交换机(<code>amq.fanout</code>)</h3><p>定义：直接将消息转发到所有binding的对应queue中，这种exchange在路由转发的时候，忽略Routing key。</p>
<p><img src="rabbitmq_fanout.png" alt="rabbitmq_fanout"></p>
<blockquote>
<p>把消息发送给所有绑定的队列，没有足够的灵活性，它能做的仅仅是广播。</p>
<h3 id="头交换机-amq-headers"><a href="#头交换机-amq-headers" class="headerlink" title="头交换机(amq.headers)"></a>头交换机(<code>amq.headers</code>)</h3><p>定义：将消息中的<code>headers</code>与该Exchange相关联的所有Binging中的参数进行匹配，如果匹配上了，则发送到该Binding对应的Queue中。</p>
</blockquote>
<p><img src="rabbitmq_header.png" alt="rabbitmq_header"></p>
<blockquote>
<p>header exchange(头交换机)和主题交换机有点相似，但是不同于主题交换机的路由是基于路由键，<br>头交换机的路由值基于消息的header数据。 主题交换机路由键只能是字符串,而头交换机可以是<code>整型</code>和<code>哈希值</code> </p>
</blockquote>
<h3 id="默认交换机"><a href="#默认交换机" class="headerlink" title="默认交换机"></a>默认交换机</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.basic_publish(exchange=<span class="string">''</span>,</span><br><span class="line">                      routing_key=<span class="string">'hello'</span>,</span><br><span class="line">                      body=message)</span><br></pre></td></tr></table></figure>
<p>默认交换机（default exchange）实际上是一个由消息代理预先声明好的没有名字（名字为空字符串）的直连交换机（direct exchange）。<br>它有一个特殊的属性使得它对于简单应用特别有用处：那就是每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。</p>
<blockquote>
<p>The default exchange is a direct exchange with no name (empty string) pre-declared by the broker. It has one special property that makes it very useful for simple applications:<br>every queue that is created is automatically bound to it with a routing key which is the same as the queue name.</p>
</blockquote>
<h1 id="路由-Routing"><a href="#路由-Routing" class="headerlink" title="路由(Routing)"></a>路由(Routing)</h1><ul>
<li>功能：用于订阅消息的一个字集</li>
<li>应用场景：日志消息系统中，我们只需要把严重的错误日志信息写入日志文件（存储到磁盘），但同时仍然把所有的日志信息输出到控制台中；发送消息到一个exchange(direct类型)，把日志级别作为RoutingKey。这样接收日志的脚本(consumer)就可以根据logLevel来选择它想要处理的日志。</li>
</ul>
<p><img src="rabbitmq_routing.png" alt="rabbitmq_routing"></p>
<ul>
<li>注意：绑定RoutingKey的意义取决于交换机（exchange）的类型。扇型交换机（fanout exchanges）会忽略这个值。</li>
</ul>
<h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>AMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。<br>队列跟交换机共享某些属性，但是队列也有一些另外的属性。</p>
<ul>
<li>NameDurable（消息代理重启后，队列依旧存在）</li>
<li>Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除）</li>
<li>Auto-delete（当最后一个消费者退订后即被删除）</li>
<li>Arguments（一些消息代理用他来完成类似与TTL的某些额外功能）队列在声明（declare）后才能被使用。</li>
</ul>
<p>队列声明</p>
<ul>
<li>如果一个队列尚不存在，声明一个队列会创建它。</li>
<li>如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。</li>
<li>如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出。</li>
</ul>
<h1 id="RabbitMQ实现的RPC"><a href="#RabbitMQ实现的RPC" class="headerlink" title="RabbitMQ实现的RPC"></a>RabbitMQ实现的RPC</h1><p><img src="rabbitmq_rpc.png" alt="rabbitmq_rpc"></p>
<p>RPC工作流程:</p>
<ol>
<li>当客户端启动的时候，它创建一个匿名独享的回调队列。</li>
<li>在RPC请求中，客户端发送带有两个属性的消息：一个是设置回调队列的<code>reply_to</code>属性，另一个是设置唯一值的<code>correlation_id</code>属性。</li>
<li>将请求发送到一个rpc_queue队列中。</li>
<li>RPCServer等待请求发送到这个队列中来。当请求出现的时候，它执行他的工作并且将带有执行结果的消息发送给reply_to字段指定的队列。</li>
<li>客户端等待回调队列里的数据。当有消息出现的时候，它会检查correlation_id属性。如果此属性的值与请求匹配，将它返回给应用。</li>
</ol>
<h1 id="使用问题记录"><a href="#使用问题记录" class="headerlink" title="使用问题记录"></a>使用问题记录</h1><h2 id="basicQos控制消费者接收的消息数量"><a href="#basicQos控制消费者接收的消息数量" class="headerlink" title="basicQos控制消费者接收的消息数量"></a>basicQos控制消费者接收的消息数量</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Channel channel = ...;</span><br><span class="line">Consumer consumer = ...;</span><br><span class="line">channel.basicQos(<span class="number">10</span>); <span class="comment">// Per consumer limit</span></span><br><span class="line">channel.basicConsume(<span class="string">"my-queue"</span>, <span class="keyword">false</span>, consumer);</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://dzone.com/articles/rabbitmq-in-cluster">Using RabbitMQ in Cluster</a></li>
<li><a href="https://piotrminkowski.wordpress.com/2018/12/27/rabbitmq-cluster-with-consul-and-vault/">RabbitMQ Cluster with Consul and Vault</a></li>
<li><a href="https://www.jianshu.com/p/cd81afa8ade1">RabbitMQ博客列表</a></li>
<li><a href="http://sadwxqezc.github.io/HuangHuanBlog/middleware/2018/11/25/RabbitMq.html">rabbitmq-诞生于金融行业的消息队列</a></li>
<li><a href="https://geewu.gitbooks.io/rabbitmq-quick/">rabbitmq快速手册</a></li>
<li><a href="https://kknews.cc/code/423365x.html">RabbitMQ的4种集群架构—主备、远程、镜像模式、多活模式</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次内存泄漏排查</title>
    <url>/2019/12/07/%E8%AE%B0%E4%B8%80%E6%AC%A1JVM%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>OOM了怎么办？<br>常见的内存泄漏情况有哪些？<br>如何定位解决内存泄漏问题？<br><a id="more"></a> </p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ul>
<li>一个hbase的rpc_server程序，运行后tcp长连接接收rpc client端的请求操作hbase数据库；</li>
<li>程序运行一段时间（3小时）后抛出java.lang.OutOfMemoryError:Java heap space；</li>
</ul>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote>
<p>先定位进程，再定位线程.</p>
</blockquote>
<ul>
<li><code>jps</code>命令定位程序进程：<code>jps -lvm | grep rpc</code>找到程序pid</li>
<li>服务端启动<code>jstatd</code>远程监控服务</li>
<li>客户端以<code>jvisualvm</code>工具连接jstatd端口，根据pid查看服务的运行情况；</li>
<li><code>jvisualvm</code>中安装visual gc插件，发现eden区每次回收后都有很多的survivor，survivor的1和2区交换几次满了后就都到old gen老年代去了，<br>导致每次回收后内存使用量一直在增长，内存使用曲线呈现45度锯齿状；</li>
</ul>
<p><img src="内存使用曲线.png" alt="内存使用曲线"><br><img src="GC可视化.png" alt="GC可视化"><br>毫无疑问是内存泄漏了！！！</p>
<ul>
<li>程序添加OOM时输出日dump志，java程序启动命令新增：<code>-XX:+HeapDumpOnOutOfMemoryError</code>  -XX:HeapDumpPath=/home/users/developer/service/log/mlp</li>
<li>下一次OOM发生后将生成的dump文件导入jvisualvm中分析；</li>
<li>dump分析发现最多的是char[]，类实例中大多是insert语句语句中涉及的参数：清楚明白了，是数据库连接未释放</li>
<li>数据库连接是本地连接池管理的，所以基本不释放，但dao中生成的preparestatement和resultset需要手动释放；</li>
<li>在finally中添加statement.close方法释放资源；</li>
<li>重新运行程序，世界一片美好，回复了正常的非倾斜的锯齿状内存占用曲线；</li>
</ul>
<h2 id="关于内存泄漏"><a href="#关于内存泄漏" class="headerlink" title="关于内存泄漏"></a>关于内存泄漏</h2><p>上面的内存泄漏问题问题是解决了，深入拓展开：</p>
<ul>
<li>什么是内存泄漏？JVM内存管理、JVM垃圾回收方式；</li>
<li>内存泄漏的常见原因是什么？内存分配不足；代码bug；</li>
<li>不同情况的内存泄漏有什么表现特征？各种OOM情况；</li>
<li>如何定位解决内存泄漏问题？代码定位、工具定位；</li>
</ul>
<h3 id="什么是内存泄漏？"><a href="#什么是内存泄漏？" class="headerlink" title="什么是内存泄漏？"></a>什么是内存泄漏？</h3><ul>
<li>Java使用new为对象分配内存，而这些内存空间都在堆（Heap）上;</li>
<li>一个对象是否是垃圾的依据：<code>引用计数法</code>，<code>可达性算法</code>实现;</li>
<li>Java内存回收采用<code>分代回收算法</code>实现；</li>
<li>Java的一个重要特性就是通过垃圾收集器(GC)自动管理内存的回收，而不需要程序员自己来释放内存。理论上Java中所有不会再被利用的对象所占用的内存，都可以被GC回收，但是Java也存在内存泄露，但它的表现与C++不同。<h3 id="Java中的内存管理"><a href="#Java中的内存管理" class="headerlink" title="Java中的内存管理"></a>Java中的内存管理</h3>内存的释放，也即清理那些不可达的对象，是由GC决定和执行的，所以GC会监控每一个对象的状态，包括申请、引用、被引用和赋值等。<code>释放对象的根本原则就是对象不会再被使用</code>：</li>
<li>给对象赋予了空值null，之后再没有调用过。</li>
<li>另一个是给对象赋予了新值，这样重新分配了内存空间。</li>
</ul>
<p>通常，会认为在堆上分配对象的代价比较大，但是GC却优化了这一操作：C++中，在堆上分配一块内存，会查找一块适用的内存加以分配，如果对象销毁，这块内存就可以重用；而Java中，就像一条长的带子，每分配一个新的对象，Java的<code>堆指针</code>就向后移动到尚未分配的区域。所以，Java分配内存的效率，可与C++媲美。</p>
<p>但是这种工作方式有一个问题：如果频繁的申请内存，资源将会耗尽。这时GC就介入了进来，它会回收空间，并使堆中的对象排列更紧凑。这样，就始终会有足够大的内存空间可以分配。</p>
<ul>
<li>gc清理时的引用计数方式：当引用连接至新对象时，引用计数+1；当某个引用离开作用域或被设置为null时，引用计数-1，GC发现这个计数为0时，就回收其占用的内存。这个开销会在引用程序的整个生命周期发生，并且不能处理<code>循环引用</code>的情况。所以这种方式只是用来说明GC的工作方式，而不会被任何一种Java虚拟机应用。</li>
<li>多数GC采用一种自适应的清理方式（加上其他附加的用于提升速度的技术），主要依据是找出任何“活”的对象，然后采用<code>自适应的、分代的、停止-复制、标记-清理</code>式的垃圾回收器。</li>
</ul>
<h2 id="内存泄漏的常见原因是什么？"><a href="#内存泄漏的常见原因是什么？" class="headerlink" title="内存泄漏的常见原因是什么？"></a>内存泄漏的常见原因是什么？</h2><p>Java中的内存泄露，广义并通俗的说，就是：<code>不再会被使用的对象的内存不能被回收，就是内存泄露</code>。<br>Java中的内存泄露与C++中的表现有所不同。</p>
<ul>
<li>在C++中，所有被分配了内存的对象，不再使用后，都必须程序员手动的释放他们。所以，每个类，都会含有一个<code>析构函数</code>，作用就是完成清理工作，如果我们忘记了某些对象的释放，就会造成内存泄露。</li>
<li>但是在Java中，我们不用自己释放内存，无用的对象由GC自动清理，这也极大的简化了我们的编程工作。但，实际有时候一些不再会被使用的对象，在GC看来不能被释放，就会造成内存泄露。<blockquote>
<p>对象都是有生命周期的，有的长，有的短，<code>如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露</code>。</p>
</blockquote>
</li>
</ul>
<h2 id="常见的内存泄漏情况"><a href="#常见的内存泄漏情况" class="headerlink" title="常见的内存泄漏情况"></a>常见的内存泄漏情况</h2><h3 id="监听器"><a href="#监听器" class="headerlink" title="监听器"></a>监听器</h3><p>在释放对象的时候却没有去删除这些监听器，增加了内存泄漏的机会。</p>
<h3 id="静态集合类"><a href="#静态集合类" class="headerlink" title="静态集合类"></a>静态集合类</h3><ul>
<li>如<code>HashMap、ArrayList</code>，静态容器中保有着其他无用对象的引用，会导致无用对象无法被回收，而<code>静态的容器的生命周期是与进程生命周期一致</code>的。</li>
<li>容器如HashSet中修改了其中的值，因为HashSet内部是封装了HashMap的，所以当对HashSet中的元素进行修改时，会改变该元素的HashCode，也就是说会改变该元素在HashMap中的存放位置，但是由于没有改变在HashSet中的存放位置，因此使用remove()方法都无法进行移除，这就会造成内存泄漏。（这里需要对HashCode和Equal方法进行重写）</li>
</ul>
<h3 id="各种连接-提供了close-方法的对象"><a href="#各种连接-提供了close-方法的对象" class="headerlink" title="各种连接(提供了close()方法的对象)"></a><code>各种连接</code>(提供了close()方法的对象)</h3><ul>
<li>数据库连接（dataSourse.getConnection()），网络连接(socket)和io连接，除非其显式的调用了其close())方法将其连接关闭，否则是不会自动被GC回收的。</li>
<li>JDBC中对于Resultset 和Statement 对象可以不进行显式回收，但Connection 一定要显式回收，因为Connection 在任何时候都无法自动回收，而Connection一旦回收，Resultset 和Statement 对象就会立即为NULL。</li>
<li>如果使用连接池，除了要显式地关闭连接，还必须显式地关闭Resultset和Statement 对象（关闭其中一个，另外一个也会关闭），否则就会造成大量的Statement 对象无法释放，从而引起内存泄漏。这种情况下一般都会在try里面去的连接，在finally里面释放连接。</li>
</ul>
<h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><p>不正确使用单例模式是引起内存泄漏的一个常见问题，单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有<code>外部的引用</code>，那么这个对象将不能被JVM正常回收，导致内存泄漏。</p>
<h3 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h3><p>私有内部类（匿名的私有内部类也算）中会有一个外部类的引用，那么当内部类对象没有被销毁，外部类也不会被销毁，这一点很容易忽略从而造成内存泄漏.</p>
<h3 id="外部模块的引用"><a href="#外部模块的引用" class="headerlink" title="外部模块的引用"></a>外部模块的引用</h3><p>要小心外部模块不经意的引用</p>
<ul>
<li>例如程序员A负责A模块，调用了B模块的一个方法如： public void registerMsg(Object b); 这种调用就要非常小心了，传入了一个对象，很可能模块B就保持了对该对象的引用，这时候就需要注意模块B是否提供相应的操作去除引用。</li>
</ul>
<h2 id="如何定位解决内存泄漏问题？"><a href="#如何定位解决内存泄漏问题？" class="headerlink" title="如何定位解决内存泄漏问题？"></a>如何定位解决内存泄漏问题？</h2><h3 id="排查工具"><a href="#排查工具" class="headerlink" title="排查工具"></a>排查工具</h3><p>内存泄漏排查过程中涉及到的工具：</p>
<ul>
<li><code>jps</code>：查询进程</li>
<li><code>jvisualvm</code>、；综合监控：cpu、线程、内存、可视化gc</li>
<li><code>jstat</code>：jstat -gcutil查看jvm gc情况：jstat -gcutil 12743 1000 100</li>
<li><code>jmap</code>：导出堆转储文件：jmap -dump:live,format=b,file=20190803.dump pid</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://my.oschina.net/ydsakyclguozi/blog/404389">强引用、弱引用、软引用、虚引用</a></p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis持久化</title>
    <url>/2020/01/03/Redis%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<blockquote>
<p>持久化是Redis HA的一种，主要实现数据备份，与<code>主从复制</code>相比强调的是由<code>内存到硬盘</code>的备份。</p>
</blockquote>
<p>本文总结Redis的持久化策略(RDB和AOF)，各自的<code>文件格式</code>、<code>控制参数</code>、<code>触发机制</code>、<code>实现方式</code>、<code>实现原理</code>、<code>执行流程</code>、<code>优缺点</code>。</p>
<a id="more"></a>
<h1 id="RDB快照"><a href="#RDB快照" class="headerlink" title="RDB快照"></a>RDB快照</h1><h2 id="RDB文件格式"><a href="#RDB文件格式" class="headerlink" title="RDB文件格式"></a>RDB文件格式</h2><ul>
<li>REDIS：常量，保存着”REDIS”5个字符。</li>
<li>db_version：RDB文件的版本号，注意不是Redis的版本号。</li>
<li>SELECTDB 0 pairs：<ul>
<li>SELECTDB是一个常量</li>
<li>0：0号数据库</li>
<li>pairs：存储了具体的键值对信息</li>
</ul>
</li>
<li>EOF：常量，标志RDB文件正文内容结束。</li>
<li>check_sum：前面所有内容的校验和</li>
</ul>
<h2 id="RDB控制参数"><a href="#RDB控制参数" class="headerlink" title="RDB控制参数"></a>RDB控制参数</h2><ul>
<li><code>rdbcompression</code>:是否开启RDB文件压缩</li>
<li><code>rdbchecksum</code>:是否开启RDB文件的校验，在写入文件和读取文件时都起作用。关闭checksum在写入文件和启动文件时大约能带来10%的性能提升， 但是数据损坏时无法发现</li>
<li><code>save m n</code>：m秒内写n次则触发快照,bgsave自动触发的条件</li>
<li><code>stop-writes-on-bgsave-error yes</code><ul>
<li>yes:则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；</li>
<li>no:Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no</li>
</ul>
</li>
</ul>
<h2 id="RDB触发机制"><a href="#RDB触发机制" class="headerlink" title="RDB触发机制"></a>RDB触发机制</h2><h3 id="save的默认触发条件"><a href="#save的默认触发条件" class="headerlink" title="save的默认触发条件"></a>save的默认触发条件</h3><ul>
<li>1分钟写1万次</li>
<li>5分钟写10次</li>
<li>15分钟写1次</li>
</ul>
<h3 id="从节点同步时"><a href="#从节点同步时" class="headerlink" title="从节点同步时"></a>从节点同步时</h3><p>在主从复制场景下，如果从节点执行全量复制操作， 则主节点会执行bgsave命令，并将rdb文件发送给从节点</p>
<h3 id="shutdown时"><a href="#shutdown时" class="headerlink" title="shutdown时"></a>shutdown时</h3><p>执行shutdown命令时，自动执行rdb持久化</p>
<blockquote>
<p>最佳实践<br>BGSAVE 对于IO的性能影响比较大， 如何解决保证数据持久化同时解决性能问题？<br>通常的设计思路就是利用「Replication」机制来解决： </p>
<ul>
<li>master不开启RDB日志和AOF日志，来保证master的读写性能。 </li>
<li>slave则开启rdb和aof来进行持久化，保证数据的持久性，</li>
</ul>
</blockquote>
<h2 id="RDB实现方式"><a href="#RDB实现方式" class="headerlink" title="RDB实现方式"></a>RDB实现方式</h2><h3 id="save命令"><a href="#save命令" class="headerlink" title="save命令"></a>save命令</h3><ul>
<li>阻塞创建快照</li>
<li>线上环境要杜绝save的使用</li>
</ul>
<h3 id="bgsave命令"><a href="#bgsave命令" class="headerlink" title="bgsave命令"></a>bgsave命令</h3><ul>
<li>异步创建快照:只有fork子进程时会阻塞服务器</li>
</ul>
<blockquote>
<p>10GB内fork进程一般不超过百毫秒级</p>
</blockquote>
<h2 id="RDB实现原理"><a href="#RDB实现原理" class="headerlink" title="RDB实现原理"></a>RDB实现原理</h2><p>Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。</p>
<ul>
<li>serverCron周期性操作函数</li>
<li>dirty计数器：服务器状态进行了多少次增删改，bgsave后清零</li>
<li>lastsave时间戳：上一次成功执行save/bgsave的时间</li>
</ul>
<p>save m n的原理如下：<br>每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。<br>对于每一个save m n条件，只有下面两条同时满足时才算满足：</p>
<ol>
<li>当前时间-lastsave &gt; m</li>
<li>dirty &gt;= n</li>
</ol>
<h2 id="RDB执行流程"><a href="#RDB执行流程" class="headerlink" title="RDB执行流程"></a>RDB执行流程</h2><p><img src="rdb_snapshot.png" alt="rdb_snapshot"></p>
<ol>
<li><p>Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。</p>
<blockquote>
<p>bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。</p>
</blockquote>
</li>
<li><p>父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令</p>
</li>
<li>父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令</li>
<li>子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换</li>
<li>子进程发送信号给父进程表示完成，父进程更新统计信息</li>
</ol>
<h2 id="RDB优缺点"><a href="#RDB优缺点" class="headerlink" title="RDB优缺点"></a>RDB优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>可配置不同的备份周期来满足灵活的备份需求</li>
<li>fork子进程备份，最大化redis性能</li>
<li>便于大规模数据备份恢复</li>
<li>与AOF相比，重启时数据内存恢复更快</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>fork子进程备份，内存数据量大时候性能受影响</li>
<li>备份时宕机，会导致数据丢失</li>
</ul>
<h1 id="AOF日志"><a href="#AOF日志" class="headerlink" title="AOF日志"></a>AOF日志</h1><h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><p>日志内容和redis命令一致，可读性强</p>
<blockquote>
<p>select db默认写入</p>
</blockquote>
<h2 id="控制参数"><a href="#控制参数" class="headerlink" title="控制参数"></a>控制参数</h2><ul>
<li><code>appendonly</code>：是否开启，yes/no</li>
<li><code>appendfilename &quot;appendonly.aof&quot;</code> :aof备份文件名</li>
<li><code>appendfsync everysec</code> 文件缓冲同步到磁盘的频率<ul>
<li>always 每执行一个命令保存一次</li>
<li>everyseconds 每一秒钟保存一次</li>
<li>no 不保存</li>
</ul>
</li>
</ul>
<blockquote>
<p>重写rewrite参数</p>
</blockquote>
<ul>
<li><code>no-appendfsync-on-rewrite no</code>: AOF重写期间是否禁止fsync</li>
<li><code>auto-aof-rewrite-percentage 100</code> :自动重写百分比, 0禁用rewrite</li>
<li><code>auto-aof-rewrite-min-size 64mb</code>：自动重写最小文件</li>
</ul>
<blockquote>
<p>aof加载</p>
</blockquote>
<ul>
<li><code>aof-load-truncated yes</code>: 如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件<ul>
<li>yes: 自动修复aof尾部异常</li>
<li>no: redis-check-aof -fix 手动修复aof文件</li>
</ul>
</li>
<li><code>aof-use-rdb-preamble yes</code> :结合rdb加载aof</li>
</ul>
<h2 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h2><h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h2 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h2><h3 id="命令追加-append"><a href="#命令追加-append" class="headerlink" title="命令追加(append)"></a>命令追加(append)</h3><p>将Redis的写命令追加到缓冲区aof_buf</p>
<h3 id="文件写入-write-和文件同步-sync"><a href="#文件写入-write-和文件同步-sync" class="headerlink" title="文件写入(write)和文件同步(sync)"></a>文件写入(write)和文件同步(sync)</h3><p>根据不同的同步策略将aof_buf中的内容同步到硬盘；<br>AOF缓存区的同步文件策略由参数<code>appendfsync</code>控制</p>
<ul>
<li><strong>no</strong>:命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步； 同步由操作系统负责，通常同步周期为30秒。<ul>
<li>存在问题:这种情况下，文件同步的时间不可控， 且缓冲区中堆积的数据会很多，数据安全性无法保证。</li>
</ul>
</li>
<li><strong>always</strong>:命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。 这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，<ul>
<li>存在问题:Redis只能支持大约几百TPS写入，严重降低了Redis的性能； 即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令， 而且会大大降低SSD的寿命。</li>
</ul>
</li>
<li><strong>everysec</strong>:命令写入aof_buf后调用系统write操作，write完成后线程返回； fsync同步文件操作由专门的线程每秒调用一次。 <ul>
<li>everysec是前述两种策略的折中，是性能和数据安全性的平衡， 因此是Redis的默认配置，也是我们推荐的配置。</li>
</ul>
</li>
</ul>
<h4 id="everysec刷盘机制"><a href="#everysec刷盘机制" class="headerlink" title="everysec刷盘机制"></a>everysec刷盘机制</h4><blockquote>
<p>存在问题</p>
<ol>
<li>如果硬盘负载过高，那么fsync操作可能会超过1s； </li>
<li>如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快 </li>
<li>如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。</li>
</ol>
<p>处理策略</p>
<ol>
<li>主线程每次进行AOF会对比上次fsync成功的时间； </li>
<li>如果距上次不到2s，主线程直接返回； </li>
<li>如果超过2s，则主线程阻塞直到fsync同步完成。</li>
</ol>
<p>AOF追加阻塞问题定位的方法</p>
<ol>
<li>监控info Persistence中的<code>aof_delayed_fsync</code>：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。</li>
<li>AOF阻塞时的Redis日志：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</li>
<li>如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等，如果是存储介质瓶颈可以考虑更换IO速度更快的硬盘。</li>
</ol>
<p>处理结果<br>如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；<br>使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。</p>
</blockquote>
<h3 id="文件重写-rewrite"><a href="#文件重写-rewrite" class="headerlink" title="文件重写(rewrite)"></a>文件重写(rewrite)</h3><h4 id="rewrite出现的背景"><a href="#rewrite出现的背景" class="headerlink" title="rewrite出现的背景"></a>rewrite出现的背景</h4><p>随着时间流逝，Redis服务器执行的写命令越来越多，AOF文件也会越来越大；<br>过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。</p>
<h4 id="rwrite的作用"><a href="#rwrite的作用" class="headerlink" title="rwrite的作用"></a>rwrite的作用</h4><ul>
<li>减少文件占用的空间</li>
<li>加快恢复速度</li>
</ul>
<h4 id="rewrite为什么能压缩aof日志"><a href="#rewrite为什么能压缩aof日志" class="headerlink" title="rewrite为什么能压缩aof日志"></a>rewrite为什么能压缩aof日志</h4><ul>
<li>过期的数据不再写入文件</li>
<li>无效的命令不再写入文件<ul>
<li>有些数据被重复设值(set mykey v1, set mykey v2)</li>
<li>有些数据被删除了(sadd myset v1, del myset)</li>
</ul>
</li>
<li>多条命令可以合并为一个<ul>
<li>如sadd myset v1, sadd myset v2, sadd myset v3 可以合并为sadd myset v1 v2 v3,不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令； 而是以某个常量为界将命令拆分为多条。</li>
<li>这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改， 3.0版本中值是64。</li>
</ul>
</li>
</ul>
<h4 id="rewrite注意事项"><a href="#rewrite注意事项" class="headerlink" title="rewrite注意事项"></a>rewrite注意事项</h4><ul>
<li>AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作!</li>
<li>对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；</li>
<li>在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。</li>
</ul>
<h4 id="rewrite的触发"><a href="#rewrite的触发" class="headerlink" title="rewrite的触发"></a>rewrite的触发</h4><ul>
<li>手动触发：bgrewriteaof</li>
<li>自动触发<ul>
<li>根据<code>auto-aof-rewrite-min-size</code>和<code>auto-aof-rewrite-percentage</code>参数， 以及<code>aof_current_size</code>和<code>aof_base_size</code>状态确定触发时机。</li>
<li>auto-aof-rewrite-min-size 执行AOF重写时，文件的最小体积默认值为64MB</li>
<li>auto-aof-rewrite-percentage 执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值，默认值为100。</li>
</ul>
</li>
</ul>
<h4 id="rewrite重写流程"><a href="#rewrite重写流程" class="headerlink" title="rewrite重写流程"></a>rewrite重写流程</h4><p><img src="aof_rewrite.png" alt="aof_rewrite"></p>
<ol>
<li>Redis父进程首先判断当前是否存在正在执行<code>bgsave</code>/<code>bgrewriteaof</code>的子进程，<ul>
<li>如果存在则<code>bgrewriteaof</code>命令直接返回，</li>
<li>如果存在<code>bgsave</code>命令则等bgsave执行完成后再执行。这个主要是基于性能方面的考虑。</li>
</ul>
</li>
<li>父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。</li>
<li>父进程fork后，bgrewriteaof命令返回”Background append only file rewrite started”信息并不再阻塞父进程，并可以响应其他命令,Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确(3.1)。<ul>
<li>由于fork操作使用<code>写时复制</code>技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用<code>AOF重写缓冲区</code>(图中的<code>aof_rewrite_buf</code>)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到<code>aof_buf</code>和<code>aof_rewirte_buf</code>两个缓冲区(3.2)。</li>
</ul>
</li>
<li>子进程根据内存快照，按照命令合并规则写入到新的AOF文件。</li>
<li>子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过<code>info persistence</code>查看(5.1)。</li>
<li>父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致(5.2)。</li>
<li>使用新的AOF文件替换老文件，完成AOF重写(5.3)。</li>
</ol>
<blockquote>
<p>注意</p>
<ul>
<li>重写由父进程fork子进程进行</li>
<li>重写期间Redis执行的写命令，需要追加到新的AOF文件中， 为此Redis引入了<code>aof_rewrite_buf</code>缓存</li>
</ul>
</blockquote>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>更安全的持久化， 更多样化的fsync策略</li>
<li>appendOnlyLog保证日志数据的安全性， 且能修复尾部异常的日志数据</li>
<li>自带日志重写机制，日志文件过大时， 会根据当前数据重写生成一个更小的日志文件</li>
<li>日志内容和redis命令一致，可读性强， 特殊情况可修改后再恢复数据</li>
</ul>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>AOF文件比RDB文件更占用磁盘空间</li>
<li>AOF的sync策略为everyseconds或always时性能比RDB差</li>
<li>没有RDB稳健</li>
</ul>
<h1 id="关闭持久化"><a href="#关闭持久化" class="headerlink" title="关闭持久化"></a>关闭持久化</h1><p>save “”<br>appendonly no</p>
<h1 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h1><h2 id="关闭持久化-1"><a href="#关闭持久化-1" class="headerlink" title="关闭持久化"></a>关闭持久化</h2><ul>
<li>Redis中的数据完全丢弃也没有关系</li>
<li>如Redis完全用作DB层数据的cache</li>
</ul>
<h2 id="使用RDB"><a href="#使用RDB" class="headerlink" title="使用RDB"></a>使用RDB</h2><ul>
<li>单机环境下，可以接受十几分钟或更多的数据丢失</li>
<li>允许服务器宕机时一段时间内的数据丢失</li>
</ul>
<h2 id="使用AOF"><a href="#使用AOF" class="headerlink" title="使用AOF"></a>使用AOF</h2><ul>
<li>只能接受秒级别的数据丢失</li>
</ul>
<h2 id="同时开启RDB和AOF持久化"><a href="#同时开启RDB和AOF持久化" class="headerlink" title="同时开启RDB和AOF持久化"></a>同时开启RDB和AOF持久化</h2><blockquote>
<p>redis表示未来可能会合并RDB和AOF</p>
</blockquote>
<h3 id="master节点"><a href="#master节点" class="headerlink" title="master节点"></a>master节点</h3><p>完全关闭持久化</p>
<h3 id="slave节点"><a href="#slave节点" class="headerlink" title="slave节点"></a>slave节点</h3><ul>
<li><p>功能</p>
<ul>
<li>实现数据的热备</li>
<li>读写分离分担Redis读请求</li>
<li>master宕掉后继续提供服务</li>
</ul>
</li>
<li><p>关闭RDB，开启AOF</p>
</li>
<li>定时对AOF文件进行备份</li>
<li>关闭AOF的自动重写， 添加定时任务，在每天Redis闲时（如凌晨12点）调用<code>bgrewriteaof</code>。</li>
</ul>
<h1 id="异地灾备"><a href="#异地灾备" class="headerlink" title="异地灾备"></a>异地灾备</h1><h2 id="主从集群灾备"><a href="#主从集群灾备" class="headerlink" title="主从集群灾备"></a>主从集群灾备</h2><ul>
<li>rdb：可以定时在master上执行<code>bgsave</code>， 然后将RDB文件通过scp拷贝到远程机器，一般来说，由于RDB文件文件小、恢复快，因此<code>灾难恢复</code>常用RDB文件；</li>
<li>aof：在slave上执行<code>bgrewriteaof</code>重写AOF文件后，将AOF文件拷贝到远程机器上。</li>
</ul>
<h2 id="单机灾备"><a href="#单机灾备" class="headerlink" title="单机灾备"></a>单机灾备</h2><p>可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等</p>
<h2 id="备份频率"><a href="#备份频率" class="headerlink" title="备份频率"></a>备份频率</h2><p>异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于<code>一天一次</code>。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.cnblogs.com/kismetv/p/9137897.html">深入学习Redis（2）：持久化</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中的IO模型</title>
    <url>/2020/03/21/Java%E4%B8%AD%E7%9A%843%E7%A7%8DIO%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>学Netty之前，得先了解Unix的5种IO模型，Java的3种IO模型；本文主要介绍Java中的3种IO模型（BIO,NIO,AIO）；</p>
<ul>
<li>BIO的优化版（线程池实现异步）适用于1000以内的并发场景；</li>
<li>NIO多路复用适用于高并发网络场景（Netty基于NIO实现）；</li>
<li>AIO暂时用的较少；</li>
</ul>
<a id="more"></a>  
<h1 id="Java中的IO模型"><a href="#Java中的IO模型" class="headerlink" title="Java中的IO模型"></a>Java中的IO模型</h1><p>Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对<code>操作系统</code>的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。</p>
<p>在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。</p>
<h2 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h2><p>关于同步和异步的概念解读困扰着很多程序员，大部分的解读都会带有自己的一点偏见。<br>参考Stackoverflow<a href="https://stackoverflow.com/questions/748175/asynchronous-vs-synchronous-execution-what-does-it-really-mean">Asynchronous vs synchronous execution, what does it really mean? </a>：</p>
<blockquote>
<p>When you execute something synchronously, you wait for it to finish before moving on to another task.<br>当你同步执行某项任务时，你需要等待其完成才能继续执行其他任务。<br>When you execute something asynchronously, you can move on to another task before it finishes.<br>当你异步执行某些操作时，你可以在完成另一个任务之前继续进行。</p>
</blockquote>
<ul>
<li><strong>同步</strong>：两个同步任务相互依赖，并且一个任务必须以依赖于另一任务的某种方式执行。 <ul>
<li>比如在A-&gt;B事件模型中，你需要先完成 A 才能执行B。 再换句话说，同步调用种被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。</li>
</ul>
</li>
<li><strong>异步</strong>： 两个异步的任务完全独立的，一方的执行不需要等待另外一方的执行。再换句话说，异步调用中，调用后就返回结果不需要等待处理结果返回，当处理结果返回的时候通过<code>回调函数</code>或者其他方式拿着结果再做相关事情;</li>
</ul>
<h2 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h2><ul>
<li><strong>阻塞</strong>： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。</li>
<li><strong>非阻塞</strong>： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。</li>
</ul>
<h2 id="如何区分同步-异步和阻塞-非阻塞？"><a href="#如何区分同步-异步和阻塞-非阻塞？" class="headerlink" title="如何区分同步/异步和阻塞/非阻塞？"></a>如何区分<code>同步/异步</code>和<code>阻塞/非阻塞</code>？</h2><ul>
<li>同步/异步是从<code>行为角度</code>描述事物的;</li>
<li>阻塞和非阻塞描述的<code>当前事物的状态</code>（等待调用结果时的状态）</li>
</ul>
<h1 id="BIO-Blocking-I-O"><a href="#BIO-Blocking-I-O" class="headerlink" title="BIO (Blocking I/O)"></a>BIO (Blocking I/O)</h1><p><img src="BIO.png" alt="BIO"><br>BIO通信（一请求一应答）模型：<code>Each handler may be started in its own thread</code></p>
<p>采用 BIO 通信模型 的服务端，通常由一个独立的<code>Acceptor</code>线程负责监听客户端的连接。<br>我们一般通过在<code>while(true)</code>循环中服务端会调用<code>accept()</code>方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字（Scoket），在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成，不过可以<code>通过多线程来支持多个客户端的连接</code>，如上图所示。</p>
<h2 id="BIO如何实现并发？"><a href="#BIO如何实现并发？" class="headerlink" title="BIO如何实现并发？"></a>BIO如何实现并发？</h2><p><strong>利用多线程实现并发处理</strong><br>如果要让 BIO 通信模型能够同时处理多个客户端请求，就必须使用多线程（主要原因是socket.accept()、socket.read()、socket.write() 涉及的三个主要函数都是同步阻塞的），<br>也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。<br>这就是典型的一请求一应答通信模型 。</p>
<p><strong>线程的使用成本高</strong><br>在 Java 虚拟机中，线程是宝贵的资源，<code>线程的创建、切换、销毁成本很高。
尤其在 Linux 这样的操作系统中，线程本质上就是一个进程，</code>创建和销毁线程都是重量级的系统函数<code>。
如果并发访问量增加会导致</code>线程数急剧膨胀<code>可能会导致线程</code>堆栈溢出<code>、创建新线程失败等问题，最终导致</code>进程宕机<code>或者</code>僵死`，不能对外提供服务。</p>
<p> <strong>利用线程池实现并发控制</strong><br>为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化，<br>后端通过一个线程池来处理多个客户端的请求接入，通过线程池可以灵活地调配线程资源，让线程的创建和回收成本相对较低，可设置线程的最大值，防止由于海量并发接入导致线程耗尽。</p>
<blockquote>
<p>如使用<code>FixedThreadPool</code>可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，</p>
<p>实现了N(客户端请求数量):M(处理客户端请求的线程数量)的<code>伪异步I/O模型</code>（N 可以远远大于 M）；</p>
</blockquote>
<p>采用线程池和任务队列可以实现一种叫做<code>伪异步的 I/O 通信框架</code>；<br><img src="BIO_async.png" alt="BIO"></p>
<ul>
<li>当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个<code>消息队列</code>和 N 个活跃线程，对消息队列中的任务进行处理。</li>
<li>由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。</li>
</ul>
<p>伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的<code>线程资源耗尽</code>问题。<br>不过因为它的底层仍然是同步阻塞的BIO模型，因此无法从根本上解决问题。</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><blockquote>
<p>伪异步I/O通信框架适用于并发数小于1000的情况。</p>
</blockquote>
<p>在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且<code>编程模型简单</code>，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。<br>但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。</p>
<h1 id="NIO-New-I-O"><a href="#NIO-New-I-O" class="headerlink" title="NIO (New I/O)"></a>NIO (New I/O)</h1><p>NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。<br><img src="nio.png" alt="NIO"></p>
<ul>
<li>NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法；</li>
<li>NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式；</li>
<li>阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反；</li>
<li>对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；</li>
<li>对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发；</li>
</ul>
<h2 id="NIO的问题"><a href="#NIO的问题" class="headerlink" title="NIO的问题"></a>NIO的问题</h2><p>为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：</p>
<ul>
<li><p>JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的<code>空轮询 bug</code>会导致 cpu 飙升 100%；</p>
</li>
<li><p>项目庞大之后，自行实现的 NIO 很容易出现各类 bug，<code>维护成本较高</code>；</p>
<p>Netty 的出现很大程度上改善了 JDK 原生 NIO 所存在的一些让人难以忍受的问题。</p>
</li>
</ul>
<h1 id="AIO-Asynchronous-I-O"><a href="#AIO-Asynchronous-I-O" class="headerlink" title="AIO (Asynchronous I/O)"></a>AIO (Asynchronous I/O)</h1><p><img src="aio.png" alt="aio"><br>在 JDK1.7中引入了 NIO 的改进版 NIO2，也就是AIO（异步IO），它是异步非阻塞的IO模型。<br>异步 IO 是<code>基于事件和回调机制实现</code>的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。</p>
<ul>
<li>虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的；</li>
<li>除了 AIO 其他的 IO 类型都是同步的；</li>
<li>目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md">BIO-NIO-AIO</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM中类的加载过程</title>
    <url>/2020/03/10/JVM%E4%B8%AD%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p> 在搞清楚JVM运行时数据区里面的堆/栈/GC这些原理之前，得先搞清楚JVM是如何把class文件加载到内存中的，这是一切开始的原点。</p>
<p>本文就主要说明JVM如何把<code>Bytecode</code>加载到<code>Method Area</code>的全过程。</p>
<a id="more"></a>
<h1 id="类的加载过程"><a href="#类的加载过程" class="headerlink" title="类的加载过程"></a>类的加载过程</h1><p><img src="类加载过程.png" alt="类加载过程"></p>
<h2 id="加载-Loading"><a href="#加载-Loading" class="headerlink" title="加载 Loading"></a>加载 Loading</h2><p>什么时候开始类的<code>加载阶段</code>，Java虚拟机规范中没有强制约束，交给虚拟机的具体实现去自由把握。</p>
<h3 id="非数组类的加载"><a href="#非数组类的加载" class="headerlink" title="非数组类的加载"></a>非数组类的加载</h3><p>在加载阶段，JVM需要完成3件事情：</p>
<ol>
<li>通过一个<code>类的全限定名</code>来获取此类的二进制字节流；</li>
<li>通过这个字节流所代表的<code>静态存储结构</code>转化为<code>方法区的运行时数据结构</code>；</li>
<li>在内存中生成一个代表这个类的<code>java.lang.Class</code>对象，作为方法区这个类的各种数据的访问入口；</li>
</ol>
<p>加载阶段可以采用BootstrapClassLoader，也可以采用自定义类加载器来控制字节流的获取方式，重写loadClass()方法；</p>
<h3 id="数组类的加载"><a href="#数组类的加载" class="headerlink" title="数组类的加载"></a>数组类的加载</h3><p>数组类的加载与普通类的加载情况有所不同：数组类本身不通过类加载器创建，而是通过JVM直接创建，但数组类的元素类型最终也要靠类加载器去创建。</p>
<p>数组类的创建遵循已下规则：</p>
<ul>
<li>如果数组的类型是<code>引用类型</code>，需要递归采用非数组类的加载过程去加载；</li>
<li>如果数组的类型<code>不是引用类型</code>（如int[]），JVM会将数组标记为与BootstrapClassLoader关联；</li>
<li>数组类的<code>可见性</code>与它的元素类型的可见性是一致的，如果元素类型不是引用类型，那数组类型的可见性将默认是public；???</li>
</ul>
<p>加载阶段与连接阶段的部分内容（如字节码文件格式的验证）是交叉进行的；<br>加载尚未完成，连接阶段可能就已经开始了。</p>
<h2 id="连接-Linking"><a href="#连接-Linking" class="headerlink" title="连接 Linking"></a>连接 Linking</h2><h3 id="校验-Verification"><a href="#校验-Verification" class="headerlink" title="校验 Verification"></a>校验 Verification</h3><p>Class文件是JVM规范定义的，并不一定要求用Java源码编译而来，可以使用任何途径产生。<br>所以为了保护虚拟机自身安全，防止恶意代码的攻击，验证阶段需要拦截对自身有害的字节流避免导致系统崩溃；</p>
<ul>
<li>如果校验不通过，会抛出异常：<code>java.lang.VerifyError</code>，</li>
<li>如果代码被反复验证过了，可以提供<code>-Xverify:none</code>来关闭校验以缩短类加载的时间；</li>
</ul>
<p>验证阶段包含4个校验动作（文件格式、元数据、字节码、符号引用校验），</p>
<h4 id="文件格式校验"><a href="#文件格式校验" class="headerlink" title="文件格式校验"></a>文件格式校验</h4><p>验证字节流是否符合 Class 文件格式的规范，并且能被当前版本的虚拟机处理。<br>验证内容：</p>
<ul>
<li>是否以魔数 0xCAFEBABE 开头。</li>
<li>主、次版本号是否在当前虚拟机处理范围之内。</li>
<li>常量池的常量中是否有不被支持的常量类型。</li>
</ul>
<p>该阶段的验证是基于<code>字节流</code>进行的，只有验证通过了，字节流才会进入内存的方法区中进行存储。<br>所以后面 3 个验证阶段都是基于<code>方法区的存储结构</code>进行的。</p>
<h4 id="元数据校验"><a href="#元数据校验" class="headerlink" title="元数据校验"></a>元数据校验</h4><p>对字节码描述的信息进行<code>语义分析</code>，以保证其描述的信息符合 Java 语言规范的要求。<br>验证内容：</p>
<ul>
<li><p>这个类是否有父类（除 java.lang.Object 外，所有类都应当有父类）。</p>
</li>
<li><p>这个类的父类是否继承了不允许被继承的类（被 final 修饰的类）。</p>
</li>
<li><p>如果这个类不是抽象类，是否实现了其父类或接口中要求实现的所有方法。</p>
</li>
<li><p>类中的字段、方法是否与父类发生矛盾；</p>
</li>
</ul>
<p>主要目的是对类的元数据信息进行语义校验，保证不存在不符合 Java 语言规范的元数据信息。</p>
<h4 id="字节码验证"><a href="#字节码验证" class="headerlink" title="字节码验证"></a>字节码验证</h4><p>对类的<code>方法体</code>进行检验分析，保证类的方法在运行时不会做出危害虚拟机安全的事件。<br>验证内容：</p>
<ul>
<li>保证任意时刻<code>操作数栈的数据类型</code>与<code>指令代码序列</code>都能配合工作。</li>
<li>保证跳转指令不会跳转到方法体以外的字节码指令上。<br>保证方法体中的类型转换是有效的。<br>主要目的是通过<code>数据流</code>和<code>控制流</code>分析，确定<code>程序语义</code>是合法的、符合逻辑的。</li>
</ul>
<h4 id="符号引用验证"><a href="#符号引用验证" class="headerlink" title="符号引用验证"></a>符号引用验证</h4><p>对类自身以外（常量池中的各种符合引用）的信息进行匹配性校验。<br>这一阶段发生在虚拟机将<code>符号引用</code>转化为<code>直接引用</code>时（解析阶段发生）。</p>
<p>验证内容：</p>
<ul>
<li>类名称：符号引用中通过字符串描述的<code>全限定名</code>是否能找到对应的类。</li>
<li>方法和字段：在指定类中是否存在符合方法的字段描述符，以及简单名称所描述的<code>方法</code>和<code>字段</code>。</li>
<li>访问权限：符号引用中的类、字段、方法的访问性是否可被当前类访问。</li>
</ul>
<p>主要目的是<code>确保解析动作能正常执行</code>。</p>
<h3 id="准备-Preparation"><a href="#准备-Preparation" class="headerlink" title="准备 Preparation"></a>准备 Preparation</h3><p>准备阶段是正式为类变量分配内存并<code>设置变量初始值</code>的阶段。</p>
<p>注意点：</p>
<ul>
<li>进行内存分配的仅包括<code>类变量</code>，而不包括实例变量（实例变量为null）。</li>
<li>初始值通常是数据类型的零值。</li>
<li>会指定常量的值（final）；</li>
</ul>
<h3 id="解析-Resolution"><a href="#解析-Resolution" class="headerlink" title="解析 Resolution"></a>解析 Resolution</h3><p>解析阶段是虚拟机将常量池内的<code>符号引用</code>替换为<code>直接引用</code>的过程。</p>
<ul>
<li>符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。</li>
<li>直接引用：可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。</li>
</ul>
<p>解析动作主要针对以下7 类符号引用（常量类型）进行</p>
<ul>
<li><code>类或接口（CONSTANT_Class_info）</code></li>
<li><code>字段（CONSTANT_Fieldref_info）</code></li>
<li><code>类方法（CONSTANT_Methodref_info）</code></li>
<li><code>接口方法（CONSTANT_InterfaceMethodref_info）</code></li>
<li><code>方法类型（CONSTANT_MethodType_info）</code></li>
<li><code>方法句柄（CONSTANT_MethodHandle_info ）</code></li>
<li><code>调用点限定符（CONSTANT_InvokeDynamic_info ）</code> </li>
</ul>
<h2 id="初始化-Initialization"><a href="#初始化-Initialization" class="headerlink" title="初始化 Initialization"></a>初始化 Initialization</h2><p>在准备阶段，变量赋默认值，在初始化阶段根据程序员的主观计划去<code>初始化类变量</code>和其他资源的阶段。</p>
<p>到了初始化阶段，才真正开始执行类中定义的 Java 程序代码（或者说字节码），或者从另一个角度表达，初始化阶段是执行类构造器 cinit() 方法的过程。</p>
<h3 id="类构造器-cinit-方法的过程"><a href="#类构造器-cinit-方法的过程" class="headerlink" title="类构造器 cinit() 方法的过程"></a>类构造器 cinit() 方法的过程</h3><p>cinit() 方法执行过程中的可能会影响程序运行行为的特点和细节：</p>
<ul>
<li>cinit() 方法是有编译器自动收集类中的所有<code>类变量的赋值动作</code>和<code>静态语句块中的语句</code>合并产生的；</li>
<li><code>父类</code>的cinit() 方法一定是优先于子类执行的；</li>
<li>cinit() 方法也不是必须的，如果一个类或者接口中没有静态变量语句块，也没有对静态变量的赋值操作，那么编译器可以不为这个类生成cinit() 方法；</li>
<li>虚拟机保证一个类的cinit() 方法在<code>多线程中被正确的加锁，同步</code>。如果多线程去初始化这个类，其它线程都需要阻塞等待，直到活动线程cinit() 方法完毕；</li>
</ul>
<p>对于<code>初始化阶段</code>，虚拟机规范严格规定了有且只有5种情况（<code>主动引用</code>），如果没有进行过初始化，需要触发类的初始化；</p>
<h3 id="5种主动引用触发初始化"><a href="#5种主动引用触发初始化" class="headerlink" title="5种主动引用触发初始化"></a>5种主动引用触发初始化</h3><ol>
<li>遇到以下4条字节码指令时：<ol>
<li>new（实例化对象）；</li>
<li>getstatic（读取类的静态字段）；</li>
<li>putstatic（设置类的静态字段）；</li>
<li>invokestatic（调用类的静态方法）；</li>
</ol>
</li>
<li>使用<code>java.lang.reflect</code>进行反射调用时；</li>
<li>当初始化一个类时，如果发现父类没有初始化，需先初始化父类；</li>
<li>JVM启动时，需指定一个执行的主类（包含main方法的那个类），JVM会先初始化这个主类；</li>
<li>JDK1.7动态语言支持时，如果一个<code>java.lang.invke.MethodHandle</code>实例最后的解析结果REF_getstatic、REF_putstatic、REF_invokestatic的方法句柄；???</li>
</ol>
<p>除此之外，所有引用类的方式都不会触发初始化</p>
<h3 id="被动引用不会触发初始化"><a href="#被动引用不会触发初始化" class="headerlink" title="被动引用不会触发初始化"></a>被动引用不会触发初始化</h3><ol>
<li>通过子类引用父类的静态字段，不会触发子类的初始化；</li>
<li>通过数组定义的引用类，不会触发此类的初始化；</li>
<li>引用类的常量不会触发初始化，因为在编译阶段常量会存入调用类的常量池中（常量传播优化），本质上没有直接引用到定义常量的类；</li>
<li>接口的初始化时，不会要求其父类全部都完成初始化，只有在真正使用到父接口时（如引用接口定义的常量）才会初始化；</li>
</ol>
<h2 id="使用-Using"><a href="#使用-Using" class="headerlink" title="使用 Using"></a>使用 Using</h2><h2 id="卸载-Unloading"><a href="#卸载-Unloading" class="headerlink" title="卸载 Unloading"></a>卸载 Unloading</h2><h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><blockquote>
<p>什么是类加载器？</p>
</blockquote>
<p>虚拟机设计团队把类加载阶段中的<code>通过一个类的全限定名来获取描述此类的二进制字节流</code>这个动作放到 Java 虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为<code>类加载器</code>。</p>
<h2 id="类与类加载器"><a href="#类与类加载器" class="headerlink" title="类与类加载器"></a>类与类加载器</h2><p>对于任意一个类，都需要由加载它的<code>类加载器</code>和这个<code>类本身</code>一同确立其在 Java 虚拟机的<code>唯一性</code>，每个类加载器都拥有一个独立的类名称空间。</p>
<p>也就是说：比较两个类是否<code>相等(equals,isInstance)</code>，只要在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p>
<p>从 Java 虚拟机的角度来讲，只存在两种不同的类加载器：</p>
<ol>
<li>启动类加载器（Bootstrap ClassLoader），这个类加载器使用<code>C++ 实现</code>，是虚拟机自身的一部分；</li>
<li>所有其他的类加载器，这些类加载器都由<code>Java实现</code>，独立于虚拟机外部，并且全都继承自抽象类 <code>java.lang.ClassLoader</code>。</li>
</ol>
<p>从 Java 开发者的角度来看，类加载器可以划分为：</p>
<ul>
<li><strong>启动类加载器（Bootstrap ClassLoader）</strong>：这个类加载器负责将存放在<code>\lib 目录</code>中的类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，那直接使用 null 代替即可；</li>
<li><strong>扩展类加载器（Extension ClassLoader）</strong>：这个类加载器由 <code>sun.misc.Launcher$ExtClassLoader</code> 实现，它负责加载<code>\lib\ext</code>目录中，或者被<code>java.ext.dirs</code> 系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器；</li>
<li><strong>应用程序类加载器（Application ClassLoader）</strong>：这个类加载器由 <code>sun.misc.Launcher$App-ClassLoader</code> 实现。<code>getSystemClassLoader()</code> 方法返回的就是这个类加载器，因此也被称为<code>系统类加载器</code>。它负责加载<code>用户类路径</code>（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中<code>默认的类加载器</code>。</li>
</ul>
<p>我们的应用程序都是由这 3 种类加载器互相配合进行加载的，在必要时还可以自己定义类加载器。</p>
<h2 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h2><p><img src="双亲委派模型.png" alt="双亲委派模型"><br>类加载器所呈现出的这种层次关系，称为类加载器的<code>双亲委派模型</code>（Parents Delegation Model）。<br>双亲委派模型要求除了顶层的启动类加载器以外，其余的类加载器都应当有自己的父类加载器。</p>
<h3 id="双亲委派模型的工作过程"><a href="#双亲委派模型的工作过程" class="headerlink" title="双亲委派模型的工作过程"></a>双亲委派模型的工作过程</h3><p>如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，<br>只有当父类加载器反馈自己无法完成这个类加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。<br>这样做的好处就是 Java 类随着它的类加载器一起具备了一种带有优先级的层次关系。</p>
<h3 id="双亲委派模型的功能"><a href="#双亲委派模型的功能" class="headerlink" title="双亲委派模型的功能"></a>双亲委派模型的功能</h3><p>双亲委派模型对于保证 Java 程序运行的·稳定性·很重要。</p>
<p>例如<code>java.lang.Object</code>它放在 <code>rt.jar</code> 中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型顶端的启动类加载器来加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。<br>相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为 <code>java.lang.Object</code>的类，并放在程序的<code>ClassPath</code>中，那系统中将会出现多个不同的 Object 类，<code>java 类型体系中最基本的行为</code>就无法保证了。</p>
<h3 id="双亲委派模型的实现"><a href="#双亲委派模型的实现" class="headerlink" title="双亲委派模型的实现"></a>双亲委派模型的实现</h3><p>实现双亲委派模型的代码都集中在<code>java.lang.ClassLoader</code>的<code>loadClass()</code>方法中：</p>
<ul>
<li>子类先委托父类加载；</li>
<li>父类加载器有自己的<strong>加载范围</strong>，范围内没有找到，则不加载，并返回给子类；</li>
<li>子类在收到父类无法加载的时候，才会自己去加载；<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> Class&lt;?&gt; loadClass(String name, <span class="keyword">boolean</span> resolve)</span><br><span class="line">        <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line">    <span class="comment">// 首先，检查请求的类是不是已经被加载过</span></span><br><span class="line">    Class&lt;?&gt; c = findLoadedClass(name);</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">                c = parent.loadClass(name, <span class="keyword">false</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                c = findBootstrapClassOrNull(name);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">            <span class="comment">// 如果父类抛出 ClassNotFoundException 说明父类加载器无法完成加载</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 如果父类加载器无法加载，则调用自己的 findClass 方法来进行类加载</span></span><br><span class="line">            c = findClass(name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (resolve) &#123;</span><br><span class="line">        resolveClass(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="破坏双亲委派模型"><a href="#破坏双亲委派模型" class="headerlink" title="破坏双亲委派模型"></a>破坏双亲委派模型</h2><blockquote>
<p>为什么需要破坏双亲委派模型？</p>
</blockquote>
<p>因为在某些情况下父类加载器需要委托子类加载器去加载class文件，但受到加载范围的限制，父类加载器无法加载到需要的文件，比如<code>JDBC加载外部数据库驱动</code>就是破坏了双亲委派的典型示例。</p>
<p>以<code>java.sql.Driver</code>接口为例，由于Driver接口定义在JDK当中的，而其实现由各个数据库的服务商来提供，比如MySQL的就写了<code>MySQL Connector</code>，那么问题就来了，<code>java.sql.DriverManager</code>（也由JDK提供）要加载各个实现了Driver接口的实现类，然后进行管理，但是<code>DriverManager</code>由<code>BootstrapClassLoader</code>加载，但只能加载JAVA_HOME的lib下文件，而其实现是由服务商提供的，由<code>ApplicationClassLoader</code>加载，这个时候就需要<code>BootstrapClassLoader</code>来委托子类来加载Driver实现。</p>
<p>在<code>sun.misc.Launcher</code>中，Launcher初始化的时候，会获取<code>ApplicationClassLoader</code>，然后将其设置为上下文类加载器（<code>Thread.currentThread().setContextClassLoader(this.loader)</code>），所以<strong>线程上下文类加载器默认情况下就是系统加载器</strong>。</p>
<p>破坏双亲委派模型的应用：JDBC、JNDI、JAXB、JCE、JBI；</p>
<p>其他程序动态性的追求：代码热替换、模块热部署；</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="">《深入理解Java虚拟机-JVM高级特性与最佳实践》</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty的IO模型</title>
    <url>/2020/03/23/Netty%E7%9A%84IO%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>要学Netty，得先从IO模型入手，一点点来。从Unix系统的5个IO模型，JDK的3种IO模型，Reactor模式的3种实现，最后到Netty事件模型的3种实现。</p>
<p>补完课，终于到Netty的IO模型这一章，(╥﹏╥)，这一章主要从大颗粒度的了解下Netty的IO模型，Netty包含的组件，以及用Netty手写一个简单的RPC协议；</p>
<a id="more"></a>  
<h1 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h1><p><img src="Netty.png" alt="Netty"><br>Netty官方的介绍</p>
<blockquote>
<p>Netty is a <code>NIO</code> client server framework which enables quick and easy development of <code>network applications</code> such as <code>protocol servers and clients</code>.<br>It greatly simplifies and streamlines network programming such as <code>TCP and UDP socket server</code>.<br>‘Quick and easy’ doesn’t mean that a resulting application will suffer from a maintainability or a performance issue.<br>Netty has been designed carefully with the experiences earned from the implementation of a lot of protocols such as <code>FTP, SMTP, HTTP</code>, and various binary and <code>text-based legacy protocols</code>.<br>As a result, Netty has succeeded to find a way to achieve ease of <code>development, performance, stability, and flexibility</code> without a compromise.<br>关键点：基于NIO实现的客户端-服务端间的网络通信框架，支持多协议，高性能，灵活，稳定，安全，易用；</p>
</blockquote>
<h1 id="Netty的IO模型"><a href="#Netty的IO模型" class="headerlink" title="Netty的IO模型"></a>Netty的IO模型</h1><p><img src="netty_io.jpg" alt="netty_io"><br>Netty的io模型是基于Java NIO实现的，参考Reactor模式的主从Reactor多线程版本，思想是分而治之+池化处理；</p>
<ol>
<li>Netty抽象出2组reactor线程池：BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络的读写；</li>
<li>BossGroup和WorkGroup的类型都是NioEventLoopGroup；</li>
<li>NioEventLoopGroup相当于一个时间循环组，这个组中含有多个事件循环，每个事件循环是NioEventLoop；</li>
<li>NioEventLoop表示一个不断循环处理任务的线程，每个NioEventLoop都有一个selector，用于监听绑定在其上的网络通信（Channel）；</li>
<li>每个Boss NioEventLoop执行的步骤有3步；<ol>
<li>轮询accep事件；</li>
<li>处理accept事件，与client建立连接，生成NioSocketChannel，并将其注册到worker NioEventLoop上的selector；</li>
<li>处理任务队列的任务，即runAllTasks；</li>
</ol>
</li>
<li>每个Worker NioEventLoop执行的步骤<ol>
<li>轮询read,write事件；</li>
<li>处理I/O事件，即在对应的NioScoketChannel中处理read、write事件，</li>
<li>处理任务队列的任务，即runAllTasks；</li>
</ol>
</li>
<li>每个Worker NioEventLoop处理业务时，会使用pipeline(管道)，pipeline中包含了channel，通过pipeline可以获取到对应的通道，另外管道中维护了很多的handler；</li>
</ol>
<h1 id="Netty的组件"><a href="#Netty的组件" class="headerlink" title="Netty的组件"></a>Netty的组件</h1><p>Nettty 有如下几个核心组件：</p>
<ul>
<li>Channel：通道，网络操作抽象类；</li>
<li>EventLoop：事件轮询器，为Channel 处理I/O 操作</li>
<li>ChannelFuture：I/O异步处理结果对象</li>
<li>ChannelHandler：事件处理器</li>
<li>ChannelPipeline：事件处理顺序管理</li>
</ul>
<h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><p>Channel 是 Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 之外，还包括了 Netty 框架相关的一些功能，如获取该 Channe l的 EventLoop。<br>相对于原生 NIO 的 Channel，Netty 的 Channel 具有如下优势：</p>
<ul>
<li>在 Channel 接口层，采用 <code>Facade</code> 模式进行统一封装，将网络 I/O 操作、网络 I/O 相关联的其他操作封装起来，统一对外提供。</li>
<li>Channel 接口的定义尽量大而全，为 SocketChannel 和 ServerSocketChannel 提供统一的视图，由不同子类实现不同的功能，公共功能在抽象父类中实现，最大程度地实现功能和接口的<code>重用</code>。</li>
<li>具体实现采用<code>聚合</code>而非包含的方式，将相关的功能类聚合在 Channel 中，有 Channel 统一负责和调度，功能实现更加灵活。</li>
</ul>
<p>Channel的产生是为了降低网络传输变成的复杂性，它是传入传出数据的载体，可以打开或者关闭，连接或断开。可以当做它是Socket的升级，大大降低了直接与 <code>Socket</code>进行操作的复杂性。</p>
<ul>
<li>EmbeddedChannel：Embedded传输，一般用于测试ChannelHandller</li>
<li>LocalServerChannel：Local传输，在VM内部通过管道进行通信的本地传输</li>
<li>NioDatagramChannel：UDP协议NIO传输</li>
<li>NioSctpChannel：SCTP协议NIO传输(基于Session)</li>
<li>NioSocketChanne：TCP协议NIO传输，使用Java提供的NIO作为基础，基于选择器的方式（重点）</li>
</ul>
<h1 id="EventLoop"><a href="#EventLoop" class="headerlink" title="EventLoop"></a>EventLoop</h1><p>Netty 基于事件驱动模型，使用不同的事件来通知我们状态的改变或者操作状态的改变。它定义了在整个连接的生命周期里当有事件发生的时候处理的核心抽象。<br>Channel 为Netty 网络操作抽象类，EventLoop 主要是为Channel 处理I/O 操作，两者配合参与 I/O 操作。<br>下图是Channel、EventLoop、Thread、EventLoopGroup之间的关系（摘自《Netty In Action》）：<br><img src="Channel-EventLoop-EventLoopGroup.jpg" alt="Channel-EventLoop-EventLoopGroup"><br>Netty提供的EventLoop结合了JDK的并发编程和Channel的事件，能够帮助用户实现<code>周期性任务调度任务</code>，类层次如下<br><img src="EventLoop.jpg" alt="EventLoop"></p>
<p>当一个连接到达时，Netty 就会注册一个 Channel，然后从 EventLoopGroup 中分配一个 EventLoop 绑定到这个Channel上，在该Channel的整个生命周期中都是有这个绑定的 EventLoop 来服务的。<br>所以有如下约定的关系:</p>
<ul>
<li>一个EventLoopGroup包含一个或多个EventLoop</li>
<li>一个EventLoop在其生命周期内只能和一个Thread绑定</li>
<li>由EventLoop处理的I/O事件都由它绑定的Thread处理</li>
<li>一个Channel在其生命周期内，只能注册于一个EventLoop</li>
<li>一个EventLoop可能被分配处理多个Channel。也就是EventLoop与Channel是1:n的关系</li>
<li>一个Channel上的所有ChannelHandler的事件由绑定的EventLoop中的I/O线程处理</li>
<li>不要阻塞Channel的I/O线程，可能会影响该EventLoop中其他Channel事件处理</li>
</ul>
<h1 id="ChannelFuture"><a href="#ChannelFuture" class="headerlink" title="ChannelFuture"></a>ChannelFuture</h1><p>Netty中所有的I/O操作都是异步的，该异步操作可能无法立即得到返回。<br>Netty提供<code>addListener()</code>方法注册回调函数<code>ChannelFutureListener</code>，当操作执行成功或者失败时，监听就会自动触发返回结果。</p>
<ol>
<li>可以将ChannelFuture看作是将来要执行的操作的结果占位符，什么时候被执行，不知道。但肯定会被执行</li>
<li>属于同一个Channel的操作(回调函数)都被保证将按照注册的顺序执行。</li>
</ol>
<h1 id="ChannelHandler"><a href="#ChannelHandler" class="headerlink" title="ChannelHandler"></a>ChannelHandler</h1><p>ChannelHandler 为 Netty 中最核心的组件，它充当了所有处理入站和出站数据的应用程序逻辑的容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。<br><img src="ChannelHandler.jpg" alt="ChannelHandler"><br>ChannelHandler 有两个核心子类：</p>
<ul>
<li>ChannelInboundHandler(入站):：处理输入数据和Channel状态类型改变；<ul>
<li>适配器: ChannelInboundHandlerAdapter（适配器设计模式）</li>
<li>常用的: SimpleChannelInboundHandler，继承于ChannelInboundHandlerAdapter，对没有外界引用的资源进行一定的清理</li>
</ul>
</li>
<li><p>ChannelOutboundHandler(出站): 处理输出数据</p>
<ul>
<li>适配器: ChannelOutboundHandlerAdapter</li>
</ul>
</li>
<li><p>ChannelHandler的<code>适配器模式</code></p>
<ul>
<li>为了避免子类需要实现ChannelInboundHandler和ChannelOutboundHandler两个接口中的所有方法，所以设计了ChannelInboundHandlerAdapter和ChannelOutboundHandlerAdapter适配器去实现两个接口，重载它的所有方法；</li>
<li>当外部需要自定义Handler时，只需要继承Adapter接口，就无须重载上面2个接口的所有方法了；</li>
</ul>
</li>
</ul>
<h1 id="ChannelPipeline"><a href="#ChannelPipeline" class="headerlink" title="ChannelPipeline"></a>ChannelPipeline</h1><p><img src="ChannelPipeline.png" alt="ChannelPipeline"></p>
<ul>
<li>ChannelPipeline类是ChannelHandler实例对象的链表，用于处理或截获Channel的接收和发送数据。它提供了一种高级的截取过滤模式（类似serverlet中的filter功能），让用户可以在ChannelPipeline中完全控制一个事件以及如何处理ChannelHandler与ChannelPipeline的交互；</li>
<li>对于每个新的通道Channel，都会创建一个新的ChannelPipeline，并将器pipeline附加到channel中；</li>
<li>一个数据或者事件可能会被多个 Handler 处理，在这个过程中，数据或者事件经流 ChannelPipeline，由 ChannelHandler 处理。在这个处理过程中，一个 ChannelHandler 接收数据后处理完成后交给下一个 ChannelHandler，或者什么都不做直接交给下一个 ChannelHandler；</li>
<li>ChannelPipeline并不是直接管理ChannelHandler，而是通过<code>ChannelHandlerContext</code>来间接管理；</li>
</ul>
<h1 id="Netty实现RPC服务"><a href="#Netty实现RPC服务" class="headerlink" title="Netty实现RPC服务"></a>Netty实现RPC服务</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">《Scalable IO in Java》-Doug Lea</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中的NIO模型</title>
    <url>/2020/03/22/Java%E4%B8%AD%E7%9A%84NIO%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>一个使用传统阻塞I/O的系统，如果使用一个请求对应一个线程这种模式，一旦有<code>高并发</code>的大量请求，就会有如下问题： </p>
<ol>
<li>线程不够用, 就算使用了<code>线程池</code>复用线程也无济于事; </li>
<li>阻塞I/O模式下,会有大量的线程被阻塞，一直在等待数据,这个时候的线程被挂起，只能干等，<code>CPU利用率很低</code>，换句话说，系统的<code>吞吐量低</code>; </li>
<li>如果<code>网络I/O堵塞</code>或者有网络抖动或者网络故障等，线程的阻塞时间可能很长，整个系统也变的不可靠;</li>
</ol>
<p>怎么办？<code>NIO</code>闪亮登场！<br><a id="more"></a>  </p>
<h1 id="关于NIO"><a href="#关于NIO" class="headerlink" title="关于NIO"></a>关于NIO</h1><p>java.nio全称java non-blocking IO（实际上是new io），是指JDK 1.4 及以上版本里提供的新api（New IO） ，为所有的原始类型（boolean类型除外）提供缓存支持的数据容器，使用它可以提供<code>非阻塞式的高伸缩性网络</code>。</p>
<p>HTTP2.0使用了<code>多路复用</code>的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。</p>
<h1 id="IO和NIO的区别"><a href="#IO和NIO的区别" class="headerlink" title="IO和NIO的区别"></a>IO和NIO的区别</h1><p>原始的IO是面向流的、阻塞的；<br>NIO是面向缓冲区的、非阻塞的；</p>
<h2 id="阻塞I-O模型"><a href="#阻塞I-O模型" class="headerlink" title="阻塞I/O模型"></a>阻塞I/O模型</h2><ul>
<li>jdk1.4以前的IO模型，一连接对一个线程。</li>
<li>原始的IO是<code>面向流</code>的，不存在缓存的概念。Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区；</li>
<li>原始的IO的各种流是<code>阻塞</code>的，这意味着当一个线程调用<code>read</code>或<code>write</code>方法时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。</li>
</ul>
<h2 id="非阻塞I-O模型"><a href="#非阻塞I-O模型" class="headerlink" title="非阻塞I/O模型"></a>非阻塞I/O模型</h2><ul>
<li>NIO是<code>面向缓冲区</code>的：数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。</li>
<li>NIO的非阻塞模式<ul>
<li>非阻塞读：一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 </li>
<li>非阻塞写：一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。</li>
</ul>
</li>
<li>NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来,根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个。</li>
</ul>
<h1 id="NIO网络通信的3个核心"><a href="#NIO网络通信的3个核心" class="headerlink" title="NIO网络通信的3个核心"></a>NIO网络通信的3个核心</h1><ul>
<li>Channel通道：负责连接；</li>
<li>Buffer缓冲区：负责数据的存取；</li>
<li>Selector选择器：是SelectableChannel的多路复用器，用于监控SelectableChannel的IO状况；</li>
</ul>
<h1 id="Buffer缓冲区"><a href="#Buffer缓冲区" class="headerlink" title="Buffer缓冲区"></a>Buffer缓冲区</h1><ul>
<li>缓冲区：在NIO中负责<code>数据的存取</code>；</li>
<li>缓冲区就是字节数组，存储不同类型的数据，根据数据类型不同（Boolean除外），提供相应类型的缓冲区<ul>
<li>ByteBuffer</li>
<li>CharBuffer</li>
<li>ShortBuffer</li>
<li>InteBuffer</li>
<li>LongBuffer</li>
<li>FloatBuffer</li>
<li>DoubleBuffer</li>
</ul>
</li>
</ul>
<p><img src="Buffer_class.jpg" alt="Buffer_class"></p>
<h2 id="Buffer核心操作方法"><a href="#Buffer核心操作方法" class="headerlink" title="Buffer核心操作方法"></a>Buffer核心操作方法</h2><ul>
<li>allocate(capacity)：获取缓冲区，分配内存</li>
<li>put(bytes)：存入数据</li>
<li>get(dst,offset,len) ：获取数据</li>
</ul>
<h2 id="Buffer核心属性"><a href="#Buffer核心属性" class="headerlink" title="Buffer核心属性"></a>Buffer核心属性</h2><p><img src="Buffer_model.png" alt="Buffer_model"></p>
<ul>
<li>capacity,容量，表示缓冲区中最大存储数据的容量；</li>
<li>limit,界限：表示缓冲区可以操作数据的大小；<ul>
<li>在写模式下，缓冲区的limit表示你最多能往Buffer里写多少数据；</li>
<li>在读模式下，limit等于Buffer的capacity，意味着你还能从缓冲区获取多少数据。</li>
</ul>
</li>
<li>position,位置：表示缓存区中正在操作数据的位置；<ul>
<li>当写数据到缓冲时，position表示当前待写入的位置，position最大可为capacity – 1；</li>
<li>当从缓冲读取数据时，position表示从当前位置读取。</li>
</ul>
</li>
<li>mark,标记：记录当前position的位置，可以通过reset()恢复到mark的位置；</li>
</ul>
<blockquote>
<p>0&lt;=mark&lt;=position&lt;=limit&lt;=capacity</p>
</blockquote>
<h2 id="直接缓冲区和非直接缓冲区"><a href="#直接缓冲区和非直接缓冲区" class="headerlink" title="直接缓冲区和非直接缓冲区"></a>直接缓冲区和非直接缓冲区</h2><h3 id="非直接缓冲区"><a href="#非直接缓冲区" class="headerlink" title="非直接缓冲区"></a>非直接缓冲区</h3><p><img src="NonDirectBuffer.jpg" alt="NonDirectBuffer"></p>
<ul>
<li>NIO通过通道连接磁盘文件与应用程序，通过缓冲区存取数据进行双向的数据传输。</li>
<li>物理磁盘的存取是操作系统进行管理的，与物理磁盘的数据操作需要经过内核地址空间；而我们的Java应用程序是通过JVM分配的缓冲空间。</li>
<li>数据需要在<code>内核地址空间</code>和<code>用户地址空间</code>，在<code>操作系统</code>和<code>JVM</code>之间进行数据的来回<code>拷贝</code>，无形中增加的中间环节使得效率与后面要提的直接缓冲区相比偏低。</li>
<li>非直接缓冲区通过<code>allocate()</code>方法分配缓冲区，将缓冲区分配在JVM内存的<code>byte[]</code>中；</li>
</ul>
<h3 id="直接缓冲区"><a href="#直接缓冲区" class="headerlink" title="直接缓冲区"></a>直接缓冲区</h3><p><img src="DirectBuffer.jpg" alt="DirectBuffer"></p>
<ul>
<li>直接缓冲区则不再通过<code>内核地址空间</code>和<code>用户地址空间</code>的缓存数据的<code>复制传递</code>，而是在<code>物理内存</code>中申请了一块空间，这块空间<code>映射</code>到内核地址空间和用户地址空间；</li>
<li>应用程序与磁盘之间的数据存取之间通过这块直接申请的物理内存进行；</li>
<li>直接缓冲区通过<code>allocateDirect()</code>方法分配直接缓冲区，将缓冲区建立在操作系统内存中（<code>通过Unsafe.allocateMemory(size)</code>分配内存），即<code>直接内存</code>;</li>
</ul>
<h4 id="直接缓冲区的优点"><a href="#直接缓冲区的优点" class="headerlink" title="直接缓冲区的优点"></a>直接缓冲区的优点</h4><p>性能更高、效率更快。<br>直接缓冲区可以通过FileChannel的map()方法将文件区域直接映射到内存中来创建，避免了在操作系统IO缓冲区和JVM的IO缓冲区之间的双向copy的成本；</p>
<h4 id="直接缓冲区的缺点"><a href="#直接缓冲区的缺点" class="headerlink" title="直接缓冲区的缺点"></a>直接缓冲区的缺点</h4><ol>
<li>不安全；</li>
<li>消耗更多，因为它不是在JVM中直接开辟空间。这部分内存的回收只能依赖于垃圾回收机制，垃圾什么时候回收不受我们控制；</li>
<li>数据写入物理内存缓冲区中，程序就失去了对这些数据的管理，即什么时候这些数据被最终写入从磁盘只能由操作系统来决定，应用程序无法再干涉。</li>
</ol>
<blockquote>
<p>直接缓冲区适合与数据长时间存在于内存，或者大数据量的操作时更加适合。</p>
</blockquote>
<h2 id="Buffer的选择"><a href="#Buffer的选择" class="headerlink" title="Buffer的选择"></a>Buffer的选择</h2><p>通常情况下，操作系统的一次写操作分为两步： </p>
<ol>
<li>将数据从用户空间拷贝到系统空间。 </li>
<li>从系统空间往网卡写。</li>
</ol>
<p>同理，读操作也分为两步： </p>
<ol>
<li>将数据从网卡拷贝到系统空间； </li>
<li>将数据从系统空间拷贝到用户空间。</li>
</ol>
<p>对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。</p>
<ul>
<li>如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。</li>
<li>如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。</li>
</ul>
<h1 id="Channel通道"><a href="#Channel通道" class="headerlink" title="Channel通道"></a>Channel通道</h1><ul>
<li>Channel由java.nio.channels包定义；</li>
<li>Channel表示<code>IO源</code>与<code>目标</code>打开的<code>连接</code>，在Java NIO中负责缓冲区中<code>数据的传输</code>，类似于传统IO的<code>流</code>；</li>
<li>Channel不能直接访问数据，只能<code>与Buffer进行交互</code>；</li>
</ul>
<h2 id="Channel的主要实现类"><a href="#Channel的主要实现类" class="headerlink" title="Channel的主要实现类"></a>Channel的主要实现类</h2><p>java.io.channels.Channels接口，常用的有</p>
<ul>
<li>FileChannel：文件通道（阻塞模式），用于对文件进行读写；</li>
<li>SocketChannel：TCP通道，用户TCP数据传输；</li>
<li>ServerSocketChannel：用于服务端监听外部过来的TCP请求；</li>
<li>DatagramChannel：UDP通道，用于监听UDP请求和发送UDP请求；</li>
</ul>
<p><img src="Channel_class.jpg" alt="Channel_class"></p>
<h2 id="获取通道的方法"><a href="#获取通道的方法" class="headerlink" title="获取通道的方法"></a>获取通道的方法</h2><ol>
<li><p>针对支持通道的类提供了<code>getChannel()</code>方法</p>
<ul>
<li><p>本地IO操作</p>
<ul>
<li>FileInputStream/FileOutputStream；</li>
<li>RandomAccessFile</li>
</ul>
</li>
<li><p>网络IO操作</p>
<ul>
<li>Socket</li>
<li>ServerSocket</li>
<li>DatagramSocket</li>
</ul>
</li>
</ul>
</li>
<li>JDK1.7中的NIO.2针对各个通道提供了一个<code>open()</code>方法获取通道；</li>
<li>JDK1.7中的NIO.2的<code>Files#newByteChannel()</code>获取通道；</li>
</ol>
<h2 id="通道的读写操作"><a href="#通道的读写操作" class="headerlink" title="通道的读写操作"></a>通道的读写操作</h2><ul>
<li>读操作：将数据从Channel读取到Buffer中，进行后续处理，方法：<code>channel.read(buffer)</code>；</li>
<li>写操作：将数据从Buffer写入到Channel中，方法：<code>channel.write(buffer)</code>;</li>
</ul>
<h2 id="通道之间的数据传输"><a href="#通道之间的数据传输" class="headerlink" title="通道之间的数据传输"></a>通道之间的数据传输</h2><ol>
<li>非直接缓冲区：读取<code>Channel</code>进行复制（速度和缓冲区大小相关）；</li>
<li>利用直接缓冲区复制文件：以<code>MappedByteBuffer</code>进行复制；</li>
<li>通道之间的数据传输：Channel的<code>transferTo</code>或<code>transferFrom</code>进行复制；</li>
<li>File工具类：<code>Files.copy(src,tar,opt)</code>调用操作系统接口进行复制（性能最优）；</li>
</ol>
<p>具体实现代码见文件复制的单元测试代码<a href="">TestChannel.java</a></p>
<h2 id="分散（Scatter）与聚集（Gather）"><a href="#分散（Scatter）与聚集（Gather）" class="headerlink" title="分散（Scatter）与聚集（Gather）"></a>分散（Scatter）与聚集（Gather）</h2><ul>
<li>分散读取（Scatter Reads）：将通道中的数据分散到多个缓冲区中；</li>
<li>聚集写入（Gather Writes）：将多个缓冲区中的数据聚集到通道中；</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">test_scatter_read_and_gather_write</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    RandomAccessFile raf1 = <span class="keyword">new</span> RandomAccessFile(<span class="string">"d:/tmp/1.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line">    <span class="comment">//1.获取通道</span></span><br><span class="line">    FileChannel channel1 = raf1.getChannel();</span><br><span class="line">    <span class="comment">//2,分配指定大小的缓冲区</span></span><br><span class="line">    ByteBuffer buf1 = ByteBuffer.allocate(<span class="number">100</span>);</span><br><span class="line">    ByteBuffer buf2 = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    <span class="comment">//3.分散读取</span></span><br><span class="line">    ByteBuffer[] buffers = &#123;buf1, buf2&#125;;</span><br><span class="line">    channel1.read(buffers);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (ByteBuffer byteBuffer : buffers) &#123;</span><br><span class="line">        byteBuffer.flip();</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="keyword">new</span> String(buffers[<span class="number">0</span>].array(), <span class="number">0</span>, buffers[<span class="number">0</span>].limit()));</span><br><span class="line">    System.out.println(<span class="keyword">new</span> String(buffers[<span class="number">1</span>].array(), <span class="number">0</span>, buffers[<span class="number">1</span>].limit()));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4. 聚集写入</span></span><br><span class="line">    RandomAccessFile raf2 = <span class="keyword">new</span> RandomAccessFile(<span class="string">"d:/tmp/2.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line">    FileChannel channel2 = raf2.getChannel();</span><br><span class="line">    channel2.write(buffers);</span><br><span class="line"></span><br><span class="line">    SortedMap&lt;String, Charset&gt; stringCharsetSortedMap = Charset.availableCharsets();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry s : stringCharsetSortedMap.entrySet()) &#123;</span><br><span class="line">        System.out.println(s.getKey() + <span class="string">"="</span> + s.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="字符集（Charset）"><a href="#字符集（Charset）" class="headerlink" title="字符集（Charset）"></a>字符集（Charset）</h2><ul>
<li>编码：字符串2字符数组</li>
<li>解码：字符数组2字符串</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">test_encoder_decoder</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Charset cs1 = Charset.forName(<span class="string">"GBK"</span>);</span><br><span class="line">    <span class="comment">//1.获取编码器</span></span><br><span class="line">    CharsetEncoder ce = cs1.newEncoder();</span><br><span class="line">    <span class="comment">//2.获取解码器</span></span><br><span class="line">    CharsetDecoder cd = cs1.newDecoder();</span><br><span class="line"></span><br><span class="line">    CharBuffer charBuffer = CharBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    charBuffer.put(<span class="string">"武汉加油！"</span>);</span><br><span class="line">    charBuffer.flip();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.encoder编码</span></span><br><span class="line">    ByteBuffer eBuffer = ce.encode(charBuffer);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        System.out.println(eBuffer.get());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//4.decoder解码</span></span><br><span class="line">    eBuffer.flip();</span><br><span class="line">    CharBuffer dBuffer = cd.decode(eBuffer);</span><br><span class="line">    System.out.println(dBuffer.toString());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Charset直接解码</span></span><br><span class="line">    Charset cs2 = Charset.forName(<span class="string">"GBK"</span>);</span><br><span class="line">    eBuffer.flip();</span><br><span class="line">    CharBuffer decode = cs2.decode(eBuffer);</span><br><span class="line">    System.out.println(decode.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Selector选择器"><a href="#Selector选择器" class="headerlink" title="Selector选择器"></a>Selector选择器</h1><p>Selector建立在非阻塞的基础之上，经常说的的<code>多路复用</code>在java中指的就是selector，用于实现一个线程管理多个Channel。</p>
<h2 id="选择器-Selector"><a href="#选择器-Selector" class="headerlink" title="选择器(Selector)"></a>选择器(Selector)</h2><p>将通道注册到选择器上,并指定监听事件</p>
<ul>
<li>Selector.open()：开启Selector；</li>
<li>channel.configureBlocking(false)：将通道设置为非阻塞模式，因为默认都是阻塞模式的；</li>
<li>channel.register(selector,SelectionKeys)：注册方法返回值是 SelectionKey 实例，它包含了 Channel 和 Selector 信息，也包括了一个叫做<code>Interest Set</code> 的信息，即我们设置的我们感兴趣的正在监听的事件集合；</li>
<li>selector.select()：调用 select() 方法获取通道信息。用于判断是否有我们感兴趣的事件已经发生了。</li>
</ul>
<h2 id="选择键-SelectionKey"><a href="#选择键-SelectionKey" class="headerlink" title="选择键(SelectionKey)"></a>选择键(SelectionKey)</h2><ul>
<li>OP_ACCEPT：对应 00010000，接受 TCP 连接；</li>
<li>OP_READ：对应 00000001，通道中有数据可以进行读取；</li>
<li>OP_WRITE：对应 00000100，可以往通道中写入数据；</li>
<li>OP_CONNECT：对应 00001000，成功建立 TCP 连接；</li>
</ul>
<p>可以同时监听一个 Channel 中的发生的多个事件，比如我们要监听 ACCEPT 和 READ 事件，那么指定参数为二进制的 00010001 即十进制数值 17 即可。</p>
<h2 id="Selector示例"><a href="#Selector示例" class="headerlink" title="Selector示例"></a>Selector示例</h2><p>服务端选择器绑定通道，根据选择键区分处理逻辑示例<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 服务端</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@Test</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">server</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="comment">//1.获取通道</span></span><br><span class="line">      ServerSocketChannel ssChannel = ServerSocketChannel.open();</span><br><span class="line">      <span class="comment">//2.切换非阻塞模式</span></span><br><span class="line">      ssChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">      <span class="comment">//3.绑定连接</span></span><br><span class="line">      ssChannel.bind(<span class="keyword">new</span> InetSocketAddress(host, port));</span><br><span class="line">      <span class="comment">//4.获取选择器</span></span><br><span class="line">      Selector selector = Selector.open();</span><br><span class="line">      <span class="comment">//5.将通道注册到选择器上,并指定监听事件</span></span><br><span class="line">      ssChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//6.轮询式的获取选择器上已经准备就绪的事件</span></span><br><span class="line">      <span class="keyword">while</span> (selector.select() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">//7.获取当前选择器中所有注册的选择键（已就绪的监听事件）</span></span><br><span class="line">          Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</span><br><span class="line">          Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();</span><br><span class="line">          <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">              SelectionKey selectionKey = iterator.next();</span><br><span class="line">              <span class="comment">//8.获取准备就绪的事件</span></span><br><span class="line">              <span class="keyword">if</span> (selectionKey.isAcceptable()) &#123;</span><br><span class="line">                  <span class="comment">//9.若接收就绪，获取客户端连接</span></span><br><span class="line">                  SocketChannel sChannel = ssChannel.accept();</span><br><span class="line">                  <span class="comment">//10.切换非阻塞模式</span></span><br><span class="line">                  sChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">                  <span class="comment">//11.将该通道注册到选择器上</span></span><br><span class="line">                  sChannel.register(selector, SelectionKey.OP_READ);</span><br><span class="line">              &#125; <span class="keyword">else</span> <span class="keyword">if</span> (selectionKey.isReadable()) &#123;</span><br><span class="line">                  <span class="comment">//获取当前选择器上读就绪状态的通道</span></span><br><span class="line">                  SocketChannel schannel = (SocketChannel) selectionKey.channel();</span><br><span class="line">                  ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                  <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">                  <span class="keyword">while</span> ((len = schannel.read(buf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">                      buf.flip();</span><br><span class="line">                      System.out.println(<span class="keyword">new</span> String(buf.array(), <span class="number">0</span>, len));</span><br><span class="line">                      buf.clear();</span><br><span class="line">                  &#125;</span><br><span class="line">                  schannel.close();</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="comment">//取消选择键SelectionKey</span></span><br><span class="line">              iterator.remove();</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><ul>
<li>使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。</li>
<li>NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。</li>
<li>推荐使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://tech.meituan.com/2016/11/04/nio.html">Java NIO浅析</a></li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>Unix中的5种IO模型</title>
    <url>/2020/03/20/Unix%E4%B8%AD%E7%9A%845%E7%A7%8DIO%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>学Netty之前，得先了解Uinux中的5种I/O模型，Java的3种I/O模型；</p>
<p>本文主要介绍《UNIX网络编程.卷1#6.2节》一书中提到的Unix中的5种IO模型：</p>
<ol>
<li>阻塞式I/O（blocking I/O）</li>
<li>非阻塞式I/O（non-blocking I/O）</li>
<li>I/O复用（I/O multiplexing）</li>
<li>信号驱动式I/O（signal driven I/O）</li>
<li>异步I/O（asynchronous I/O）</li>
</ol>
<p>通常一个 socket 上的输入操作包含2个阶段：</p>
<ol>
<li>等待数据准备好：通常涉及等待数据从网络中到达，当所等待分组到达时，它被复制到内核中的某个缓冲区；</li>
<li>从内核向进程复制数据：数据从内核缓冲区复制到应用进程缓冲区。</li>
</ol>
<p>上述5种IO模型就是在这2个阶段上各有不同的情况。</p>
<p>通过本文，搞清楚什么是同步I/O，异步I/O，阻塞I/O，非阻塞I/O，他们之间有什么区别和联系？</p>
<a id="more"></a>  
<h1 id="I-O"><a href="#I-O" class="headerlink" title="I/O"></a>I/O</h1><p>我们常说的IO，指的是文件的输入和输出，但是在操作系统层面是如何定义I/O的呢？到底什么样的过程可以叫做是一次I/O呢？</p>
<p>拿一次磁盘文件读取为例，我们要读取的文件是存储在磁盘上的，我们的目的是把它读取到内存中。</p>
<p>可以把这个步骤简化成把数据从硬件（硬盘）中读取到用户空间中。</p>
<blockquote>
<p><strong>用钓鱼来解释I/O</strong><br>钓鱼的时候，刚开始鱼是在鱼塘里面的，我们的钓鱼动作的最终结束标志是鱼从鱼塘中被我们钓上来，放入鱼篓中。一次完整的<strong>钓鱼</strong>操作，是<strong>鱼</strong>从<strong>鱼塘</strong>中<strong>转移</strong>到<strong>鱼篓</strong>的过程。<br>I/O映射成钓鱼的示例说明：</p>
<ul>
<li>钓鱼：I/O</li>
<li>鱼：文件</li>
<li>鱼塘：硬盘</li>
<li>鱼钩：内核空间</li>
<li>转移：copy</li>
<li>鱼篓：用户空间</li>
</ul>
</blockquote>
<h1 id="阻塞式I-O（blocking-I-O）"><a href="#阻塞式I-O（blocking-I-O）" class="headerlink" title="阻塞式I/O（blocking I/O）"></a>阻塞式I/O（blocking I/O）</h1><p> <img src="阻塞式IO模型.jpg" alt="阻塞式IO模型"></p>
<ul>
<li>上图为UDP示例（UDP与TCP相比，数据准备好读取的概念比较简单，要么整个数据报已经收到，要么还没有）</li>
<li>进程调用<code>recvfrom</code>，其系统调用直到数据报到达且被复制到应用进程的缓冲区中或者发生错误才返回，最常见的错误是系统调用被信号中断；</li>
<li><code>recvfrom</code>成功返回后，应用进程开始处理数据报；</li>
</ul>
<p><strong>阻塞式IO的特点就是在I/O执行的两个阶段都被阻塞了：阻塞等待数据，阻塞复制数据；</strong></p>
<blockquote>
<p><strong>用钓鱼来解释IO</strong>：1根竹制鱼竿，静坐等待鱼儿上钩。</p>
</blockquote>
<h1 id="非阻塞式I-O（non-blocking-I-O）"><a href="#非阻塞式I-O（non-blocking-I-O）" class="headerlink" title="非阻塞式I/O（non-blocking I/O）"></a>非阻塞式I/O（non-blocking I/O）</h1><p> <img src="非阻塞式IO模型.jpg" alt="非阻塞式IO模型"></p>
<ul>
<li>当对一个非阻塞 socket 执行读操作时，如果内核中的数据还没有准备好，那么它并不会阻塞用户进程，而是立刻返回一个<code>EWOULDBLOCK</code>错误；</li>
<li>如果内核中有数据准备好了，它会立即将数据拷贝到用户内存，并成功返回。</li>
<li>由于非阻塞I/O在没有数据时会立即返回，故用户进程通常需要循环调用<code>recvfrom</code>，不断地主动询问内核数据是否ready，这称之为轮询（polling）。</li>
</ul>
<p><strong>非阻塞式IO的特点是在I/O执行的第一个阶段不会阻塞线程，但在第二阶段会阻塞</strong>。</p>
<p>轮询的缺点是<code>耗费大量CPU时间</code>，不过这种模型偶尔也会用到，通常是在专门提供某一种功能的系统中才有；</p>
<blockquote>
<p><strong>用钓鱼来解释</strong>：1根竹制鱼竿，时不时来看看是否有鱼儿上钩。</p>
</blockquote>
<h1 id="I-O复用（IO-multiplexing）"><a href="#I-O复用（IO-multiplexing）" class="headerlink" title="I/O复用（IO multiplexing）"></a>I/O复用（IO multiplexing）</h1><p> <img src="IO复用模型.jpg" alt="IO复用模型"></p>
<p><code>I/O复用</code>(I/O multiplexing)，也称<code>事件驱动IO</code>(event-driven I/O)，就是在单个线程里同时监控多个socket，通过<code>select</code>或 <code>poll</code>轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。</p>
<ul>
<li>I/O多路复用多了一个select函数，多个进程的IO可以注册到同一个<code>select</code>上，当用户进程调用该select，select会监听所有注册好的I/O，如果所有被监听的I/O需要的数据都没有准备好时，select调用进程会<code>阻塞</code>。</li>
<li>当任意一个I/O所需的数据准备好之后，<code>select</code>调用就会返回，然后进程在通过<code>recvfrom</code>来进行数据拷贝，此时进程<code>阻塞</code>在I/O执行的第二个阶段。</li>
</ul>
<p>如上图整个用户进程其实是一直被阻塞的，但I/O复用的优势在于可以等待多个描述符就绪（并发）。</p>
<p>所以，<strong>I/O复用的特点是进行了二次系统调用，进程先阻塞在<code>select/poll</code>上，再阻塞在读操作的第二个阶段上</strong>。</p>
<p>I/O复模型支持并发，可以提高效率，机制类似多线程版本的阻塞I/O；</p>
<blockquote>
<p><strong>用钓鱼来解释</strong>：多根竹制鱼竿，时不时来看看哪根鱼竿有鱼儿上钩。</p>
</blockquote>
<h1 id="信号驱动式I-O（signal-driven-I-O）"><a href="#信号驱动式I-O（signal-driven-I-O）" class="headerlink" title="信号驱动式I/O（signal driven I/O）"></a>信号驱动式I/O（signal driven I/O）</h1><p> <img src="信号驱动式IO模型.jpg" alt="信号驱动式IO模型"><br>信号驱动式I/O(signal-driven I/O)，就是让内核在描述符就绪时发送<code>SIGIO</code>信号通知用户进程。</p>
<ul>
<li>开启 socket 的信号驱动式I/O功能，然后通过<code>sigaction</code>系统调用注册<code>SIGIO</code>信号处理函数 ，该系统调用会立即返回，不会阻塞用户进程。</li>
<li>当数据准备好时，内核会为该进程产生一个<code>SIGIO</code>信号，这时就可以在信号处理函数中调用 <code>recvfrom</code>读取数据了。</li>
</ul>
<p>所以，<strong>信号驱动式I/O的特点就是在<code>等待数据ready期间进程不被阻塞</code>，当收到信号通知时再<code>阻塞并复制数据</code>。</strong></p>
<blockquote>
<p><strong>用钓鱼来解释</strong>：1根鱼儿上钩会自动提醒的鱼竿，不用人看着鱼竿来确认是否有鱼儿上钩。</p>
</blockquote>
<h1 id="异步I-O（asynchronous-I-O）"><a href="#异步I-O（asynchronous-I-O）" class="headerlink" title="异步I/O（asynchronous I/O）"></a>异步I/O（asynchronous I/O）</h1><p> <img src="异步IO模型.jpg" alt="异步IO模型"></p>
<p>异步I/O(asynchronous IO)其实用得很少，在Linux 2.5 版本的内核中首次出现，在 2.6 版本的内核中才成为标准特性。</p>
<ul>
<li>用户进程在发起<code>aio_read</code>操作后，该系统调用立即返回，然后内核会自己等待数据ready，并自动将数据拷贝到用户内存。</li>
<li>整个过程完成以后，内核会给用户进程发送一个信号，通知I/O操作已完成。</li>
</ul>
<p>异步I/O与信号驱动式IO的主要区别是：信号驱动式I/O是由内核通知我们何时启动一个I/O操作，而异步I/O是由内核通知我们I/O操作何时完成。</p>
<p>所以，<strong>异步I/O的特点是I/O执行的两个阶段都由内核去完成，用户进程无需干预，也不会被阻塞</strong>。</p>
<blockquote>
<p><strong>用钓鱼来解释</strong>：高科技钓鱼设备，自动感应鱼儿上钩，自动收线，自动继续垂钓。</p>
</blockquote>
<h1 id="各种I-O模型的比较"><a href="#各种I-O模型的比较" class="headerlink" title="各种I/O模型的比较"></a>各种I/O模型的比较</h1><p> <img src="5种IO模型比较.jpg" alt="5种IO模型比较"></p>
<p>可以看出，前4种模型的主要区别在于第一阶段，因为它们的第二阶段是一样的：都是阻塞于<code>recvfrom</code>调用，将数据从内核复制到用户进程缓冲区。相反，异步I/O模型在这2个阶段都要处理，从而不同于其他4种模型；</p>
<h2 id="同步I-O和异步I-O对比"><a href="#同步I-O和异步I-O对比" class="headerlink" title="同步I/O和异步I/O对比"></a>同步I/O和异步I/O对比</h2><p>POSIX是这样定义的：</p>
<ul>
<li><strong>同步I/O操作</strong>：A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes. 同步IO操作导致请求进程阻塞，直到IO操作完成。</li>
<li><strong>异同步I/O操作</strong>：An asynchronous I/O operation does not cause the requesting process to be blocked.  异步IO操作不导致请求进程阻塞。</li>
</ul>
<h2 id="阻塞I-O和非阻塞I-O"><a href="#阻塞I-O和非阻塞I-O" class="headerlink" title="阻塞I/O和非阻塞I/O"></a>阻塞I/O和非阻塞I/O</h2><p>上面介绍阻塞式IO模型、非阻塞式IO模型时已经说明了两者的区别：</p>
<ul>
<li>阻塞I/O会一直阻塞用户进程直到操作完成；</li>
<li>非阻塞I/O在内核的数据还没准备好的情况下会立即返回；</li>
</ul>
<blockquote>
<p>回到一开始问题：同步I/O，异步I/O，阻塞I/O，非阻塞I/O，他们之间有什么区别和联系？</p>
</blockquote>
<p>上面定义中的<code>I/O operation</code>是指真正的I/O系统调用，比如<code>recvfrom</code>，</p>
<p>所以阻塞式I/O模型、非阻塞式I/O模型、I/O复用模型、信号驱动式I/O模型都属于<strong>同步I/O</strong>，只有异步I/O模型是属于POSIX定义的<strong>异步I/O</strong>；</p>
<h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><ul>
<li><code>POSIX</code>（Portable Operating System Interface）可移植操作系统接口，是IEEE为要在各种UNIX操作系统上运行软件，而定义API的一系列互相关联的标准的总称；</li>
<li><code>recvfrom</code>函数：本函数用于从（已连接）<a href="https://baike.baidu.com/item/套接口/10058888">套接口</a>上接收数据，并捕获数据发送源的地址。</li>
<li><code>select</code>函数：本函数允许进程指示内核等待多个事件中的任何一个发生，并只在有一个或多个事件发生或经历一段指定的时间后才唤醒它；</li>
<li><code>aio_read</code>函数：</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://juejin.im/post/5b94e93b5188255c672e901e">漫话：如何给女朋友解释什么是Linux的五种IO模型？</a></li>
<li><a href="[https://github.com/lancetw/ebook-1/blob/master/01_programming/UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71%EF%BC%9A%E5%A5%97%E6%8E%A5%E5%AD%97%E8%81%94%E7%BD%91API%EF%BC%88%E7%AC%AC3%E7%89%88%EF%BC%89.pdf](https://github.com/lancetw/ebook-1/blob/master/01_programming/UNIX网络编程卷1：套接字联网API（第3版）.pdf">《UNIX网络编程.卷1》</a>)</li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>重学设计模式（一）</title>
    <url>/2020/03/18/%E9%87%8D%E5%AD%A6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>GOF的设计模式，大话设计模式，Head First设计模式3本书之前都看过，但一聊起来总觉得描述不成体系，归根到底就是没彻底搞明白，书本上的看了只是当时明白，不实践，或是实践了但没回头和书本上的理论对照总结，那终归不是自己的知识；</p>
<p>模式就是方法论/工具 ，一定要牢记在心，工具箱里有各种趁手的武器，设计时才能有比较和选择，站在巨人的肩膀上，可以看的更远；</p>
<p>这次我再重新学一遍，不仅是要知道每个设计模式的分类/定义，更要结合JDK和开源框架中的应用来深入理解。本篇是第一篇，列举所有模式和应用场景，后续会对每个模式写一篇，包含的模式的概念，解决问题，适用场景，实现类图和示例代码；</p>
<a id="more"></a>
<h1 id="什么是设计模式？"><a href="#什么是设计模式？" class="headerlink" title="什么是设计模式？"></a>什么是设计模式？</h1><p>什么是模式？<strong>在某些场景下，针对某类问题的某种通用的解决方案</strong></p>
<ul>
<li>场景：项目所在的环境；</li>
<li>问题：约束条件，项目目标等；</li>
<li>解决方案：通用、可复用的设计，解决约束达到目标；</li>
</ul>
<p>在软件工程中，设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。这个术语是由埃里希·伽玛（Erich Gamma）等人在1990年代从建筑设计领域引入到计算机科学的。</p>
<p>设计模式并不直接用来完成代码的编写，而是描述在各种不同情况下，要怎么解决问题的一种方案。</p>
<p><code>面向对象设计模式</code>通常以<code>类别</code>或<code>对象</code>来描述其中的<code>关系</code>和<code>相互作用</code>，但不涉及用来完成应用程序的特定类别或对象。</p>
<p>设计模式能使不稳定依赖于相对稳定、具体依赖于相对抽象，避免会引起麻烦的紧耦合，以增强软件设计面对并适应<code>变化</code>的能力。</p>
<blockquote>
<p>备注：文中没有内聚性的描述一个模式的所有内容，而是对同一个模式在概念/JDK应用/实际应用中分开描述，是为了自己在阅读时脑子里能回忆上下文达到强化记忆的效果，看模式的应用时不懂模式是啥意思了强迫自己再回头看看概念；</p>
</blockquote>
<h1 id="有哪些设计模式？"><a href="#有哪些设计模式？" class="headerlink" title="有哪些设计模式？"></a>有哪些设计模式？</h1><p>设计模式分创建型、结构型和行为型3种</p>
<p><img src="设计模式列表.png" alt="设计模式列表"></p>
<h2 id="创建型（Creational）"><a href="#创建型（Creational）" class="headerlink" title="创建型（Creational）"></a>创建型（<strong>Creational</strong>）</h2><ul>
<li>单例模式（Singleton）：确保一个类只有1个实例，而且自行实例化并向整个系统提供这个实例；</li>
<li>抽象工厂模式（Abstract Factory）：为创建一组相关或相互依赖的对象提供一个接口，而且无需指定它们的具体类；</li>
<li>工厂方法（Factory Method）：定义一个用户创建对象的接口，让子类决定初始化哪一个类，工厂方法使一个类的实例化延迟到子类；</li>
<li>生成器模式（Builder）：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以构建不同的表示；</li>
<li>原型模式（Prototype）：用原型实例指定创建对象的种类，并且通过拷贝这些对象的原型创建新的对象</li>
</ul>
<h2 id="结构型（Structural）"><a href="#结构型（Structural）" class="headerlink" title="结构型（Structural）"></a>结构型（Structural）</h2><ul>
<li>适配器模式（Adapter）：将一个类的接口变换成客户端所期待的另一种接口，从而使原本因不匹配而无法在一起工作的两个类能够在一起工作；</li>
<li>装饰器模式（Decorator）：动态的将一个对象添加一些额外的规则，就增强功能来说，它比生成子类更为灵活；</li>
<li>桥接模式（Bridge）：将抽象和实现解耦，使得两者可以独立的变化；</li>
<li>组合模式（Composite）：将对象组合成树形结构以表示<code>部分-整体</code>的层次结构，使得用户对单个对象和组合对象的使用具有一致性；</li>
<li>外观模式（Facade）：要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行，门面模式是提供一个更高层次的接口，使得子系统更易于使用；</li>
<li>代理模式（Proxy）：为其他对象提供一种代理以控制对这个对象的访问；</li>
<li>享元模式（Flyweight）：使用共享对象可有效地支持大佬的细粒度对象；</li>
</ul>
<h2 id="行为型（Behavioral）"><a href="#行为型（Behavioral）" class="headerlink" title="行为型（Behavioral）"></a>行为型（Behavioral）</h2><ul>
<li>命令模式（Command）：把一个请求或者操作封装在命令对象中。命令模式允许系统使用不同的请求把客户参数化，对请求排队或者基类请求日志，可以提供命令的撤销和恢复功能；</li>
<li>状态模式（State）：当一个对象内在状态改变时允许其改变行为，这个对象看起来看起来像是改变了其类；</li>
<li>模板方法模式（Template Method）：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤；</li>
<li>策略模式（Strategy）：定义一组算法，将每个算法封装起来，并且使他们之间可以互换；</li>
<li>迭代器模式（Iterator）：提供一种方法访问一个容器对象中各个元素，而又不需暴露该对象的内部细节；</li>
<li>解释器模式（Interceptor）：给定一种语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子；</li>
<li>观察者模式（Observer）：定义对象间一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并自动更新。</li>
<li>中介者（Mediator）：用一个中介的对象封装一系列的对象交互，中介者使各个对象不需要显式的相互作用，从而使其耦合松散，并且可以独立的改变它们之间的交互；</li>
<li>访问者模式（Visitor）：封装一些作用于某个数据结构中的各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作；</li>
<li>责任链模式（Chain of Responsibility）：使多个对象都有机会处理请求，从而避免了请求的发送者和接受者之间的耦合关系。将这些对象练成一条链，并沿着这条链条传递该请求直到有对象处理它为止。</li>
<li>备忘录模式（Memento）：在不破坏封装性的前提下，捕获一个对象的内部状态，这样以后就可将该对象恢复到原先保存的状态；</li>
</ul>
<h1 id="设计模式在JDK中的应用"><a href="#设计模式在JDK中的应用" class="headerlink" title="设计模式在JDK中的应用"></a>设计模式在JDK中的应用</h1><h2 id="创建型（Creational）-1"><a href="#创建型（Creational）-1" class="headerlink" title="创建型（Creational）"></a>创建型（<strong>Creational</strong>）</h2><ul>
<li><strong>单例模式（Singleton）</strong>：只允许一个实例。在 Effective Java中建议使用Enum.<ul>
<li>java.lang.Runtime#getRuntime()</li>
<li>java.awt.Toolkit#getDefaultToolkit()</li>
<li>java.awt.GraphicsEnvironment#getLocalGraphicsEnvironment()</li>
<li>java.awt.Desktop#getDesktop()</li>
</ul>
</li>
<li><strong>抽象工厂模式（Abstract Factory）</strong>：创建一组有关联的对象实例。这个模式在JDK中也是相当的常见，还有很多的framework（如Spring）。我们很容易找到这样的实例。<ul>
<li>java.util.Calendar#getInstance()</li>
<li>java.util.Arrays#asList()</li>
<li>java.util.ResourceBundle#getBundle()</li>
<li>java.sql.DriverManager#getConnection()</li>
<li>java.sql.Connection#createStatement()</li>
<li>java.sql.Statement#executeQuery()</li>
<li>java.text.NumberFormat#getInstance()</li>
<li>javax.xml.transform.TransformerFactory#newInstance()</li>
</ul>
</li>
<li><strong>工厂方法（Factory Method）</strong>：简单来说，按照需求返回一个类型的实例。<ul>
<li>java.lang.Proxy#newProxyInstance()</li>
<li>java.lang.Object#toString()</li>
<li>java.lang.Class#newInstance()</li>
<li>java.lang.reflect.Array#newInstance()</li>
<li>java.lang.reflect.Constructor#newInstance()</li>
<li>java.lang.Boolean#valueOf(String)</li>
<li>java.lang.Class#forName()</li>
</ul>
</li>
<li><strong>生成器模式（Builder）</strong>：主要用来简化一个复杂的对象的创建。这个模式也可以用来实现一个 <a href="http://en.wikipedia.org/wiki/Fluent_interface">Fluent Interface</a>。<ul>
<li>java.lang.StringBuilder#append()</li>
<li>java.lang.StringBuffer#append()</li>
<li>java.sql.PreparedStatement</li>
<li>javax.swing.GroupLayout.Group#addComponent()</li>
</ul>
</li>
<li><strong>原型模式（Prototype）</strong>：使用自己的实例创建另一个实例。有时候，创建一个实例然后再把已有实例的值拷贝过去，是一个很复杂的动作。所以，使用这个模式可以避免这样的复杂性。<ul>
<li>java.lang.Object#clone()</li>
<li>java.lang.Cloneable</li>
</ul>
</li>
</ul>
<h2 id="结构型（Structural）-1"><a href="#结构型（Structural）-1" class="headerlink" title="结构型（Structural）"></a>结构型（Structural）</h2><ul>
<li><strong>适配器模式（Adapter）</strong>：把一个接口或是类变成另外一种。<ul>
<li>java.util.Arrays#asList()</li>
<li>javax.swing.JTable(TableModel)</li>
<li>java.io.InputStreamReader(InputStream)</li>
<li>java.io.OutputStreamWriter(OutputStream)</li>
<li>javax.xml.bind.annotation.adapters.XmlAdapter#marshal()</li>
<li>javax.xml.bind.annotation.adapters.XmlAdapter#unmarshal()</li>
</ul>
</li>
<li><strong>装饰器模式（Decorator）</strong>：为一个对象动态的加上一系列的动作，而不需要因为这些动作的不同而产生大量的继承类。这个模式在JDK中几乎无处不在，所以，下面的列表只是一些典型的。<ul>
<li>java.io.BufferedInputStream(InputStream)</li>
<li>java.io.DataInputStream(InputStream)</li>
<li>java.io.BufferedOutputStream(OutputStream)</li>
<li>java.util.zip.ZipOutputStream(OutputStream)</li>
<li>java.util.Collections#checked<a href="">List|Map|Set|SortedSet|SortedMap</a></li>
</ul>
</li>
<li><strong>桥接模式（Bridge）</strong>：把抽象和实现解藕，于是接口和实现可在完全独立开来。<ul>
<li>AWT (提供了抽象层映射于实际的操作系统)</li>
<li>JDBC</li>
</ul>
</li>
<li><strong>组合模式（Composite）</strong>：让使用者把单独的对象和组合对象混用。<ul>
<li>javax.swing.JComponent#add(Component)</li>
<li>java.awt.Container#add(Component)</li>
<li>java.util.Map#putAll(Map)</li>
<li>java.util.List#addAll(Collection)</li>
<li>java.util.Set#addAll(Collection)</li>
</ul>
</li>
<li><strong>外观模式（Facade）</strong>：用一个简单的接口包状一组组件，接口，抽象或是子系统。<ul>
<li>java.lang.Class</li>
<li>javax.faces.webapp.FacesServlet</li>
</ul>
</li>
<li><strong>代理模式（Proxy）</strong>：用一个简单的对象来代替一个复杂的对象。<ul>
<li>java.lang.reflect.Proxy</li>
<li>RMI</li>
</ul>
</li>
<li><strong>享元模式（Flyweight）</strong>：有效率地存储大量的小的对象。<ul>
<li>java.lang.Integer#valueOf(int)</li>
<li>java.lang.Boolean#valueOf(boolean)</li>
<li>java.lang.Byte#valueOf(byte)</li>
<li>java.lang.Character#valueOf(char)</li>
</ul>
</li>
</ul>
<h2 id="行为型（Behavioral）-1"><a href="#行为型（Behavioral）-1" class="headerlink" title="行为型（Behavioral）"></a>行为型（Behavioral）</h2><ul>
<li><strong>命令模式（Command）</strong>：把一个或一些命令封装到一个对象中。<ul>
<li>java.lang.Runnable</li>
<li>javax.swing.Action</li>
</ul>
</li>
<li><strong>状态模式（State）</strong>：当一个对象内在状态改变时允许其改变行为，这个对象看起来看起来像是改变了其类；</li>
<li><strong>模板方法模式（Template Method）</strong>：允许子类重载部分父类而不需要完全重写。<ul>
<li>java.util.Collections#sort()</li>
<li>java.io.InputStream#skip()</li>
<li>java.io.InputStream#read()</li>
<li>java.util.AbstractList#indexOf()</li>
</ul>
</li>
<li><strong>策略模式（Strategy）</strong>：定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。<ul>
<li>java.util.Comparator#compare()</li>
<li>javax.servlet.http.HttpServlet</li>
<li>javax.servlet.Filter#doFilter()</li>
</ul>
</li>
<li><strong>迭代器模式（Iterator）</strong>：提供一种一致的方法来顺序遍历一个容器中的所有元素。<ul>
<li>java.util.Iterator</li>
<li>java.util.Enumeration</li>
</ul>
</li>
<li><strong>解释器模式（Interceptor）</strong>：一个语法解释器的模式。<ul>
<li>java.util.Pattern</li>
<li>java.text.Normalizer</li>
<li>java.text.Format</li>
</ul>
</li>
<li><strong>观察者模式（Observer）</strong>：允许一个对象向所有的侦听的对象广播自己的消息或事件。<ul>
<li>java.util.EventListener</li>
<li>javax.servlet.http.HttpSessionBindingListener</li>
<li>javax.servlet.http.HttpSessionAttributeListener</li>
<li>javax.faces.event.PhaseListener</li>
</ul>
</li>
<li><strong>中介者（Mediator）</strong>：用来减少对象单的直接通讯的依赖关系。使用一个中间类来管理消息的方向。<ul>
<li>java.util.Timer</li>
<li>java.util.concurrent.Executor#execute()</li>
<li>java.util.concurrent.ExecutorService#submit()</li>
<li>java.lang.reflect.Method#invoke()</li>
</ul>
</li>
<li><strong>访问者模式（Visitor）</strong>：作用于某个对象群中各个对象的操作. 它可以使你在不改变这些对象本身的情况下,定义作用于这些对象的新操作.<ul>
<li>javax.lang.model.element.Element 和javax.lang.model.element.ElementVisitor</li>
<li>javax.lang.model.type.TypeMirror 和javax.lang.model.type.TypeVisitor</li>
</ul>
</li>
<li><strong>责任链模式（Chain of Responsibility）</strong>：把一个对象在一个链接传递直到被处理。在这个链上的所有的对象有相同的接口（抽象类）但却有不同的实现。<ul>
<li>java.util.logging.Logger#log()</li>
<li>javax.servlet.Filter#doFilter()</li>
</ul>
</li>
<li><strong>备忘录模式（Memento）</strong>：给一个对象的状态做一个快照。Date类在内部使用了一个long型来做这个快照。<ul>
<li>java.util.Date</li>
<li>java.io.Serializable</li>
</ul>
</li>
</ul>
<h1 id="设计模式的实际编码应用"><a href="#设计模式的实际编码应用" class="headerlink" title="设计模式的实际编码应用"></a>设计模式的实际编码应用</h1><blockquote>
<p>todo 需持续完善</p>
</blockquote>
<h2 id="创建型（Creational）-2"><a href="#创建型（Creational）-2" class="headerlink" title="创建型（Creational）"></a>创建型（<strong>Creational</strong>）</h2><ul>
<li><strong>单例模式（Singleton）</strong>：<ul>
<li>Spring的bean，默认就是单例级别的</li>
</ul>
</li>
<li><strong>抽象工厂模式（Abstract Factory）</strong>：</li>
<li><strong>工厂方法（Factory Method）</strong>：</li>
<li><strong>生成器模式（Builder）</strong>：</li>
<li><strong>原型模式（Prototype）</strong>：</li>
</ul>
<h2 id="结构型（Structural）-2"><a href="#结构型（Structural）-2" class="headerlink" title="结构型（Structural）"></a>结构型（Structural）</h2><ul>
<li><strong>适配器模式（Adapter）</strong><ul>
<li>新旧接口的版本兼容</li>
</ul>
</li>
<li><strong>装饰器模式（Decorator）</strong>：</li>
<li><strong>桥接模式（Bridge）</strong>：面向接口编程思想</li>
<li><strong>组合模式（Composite）</strong>：<ul>
<li>级联操作</li>
</ul>
</li>
<li><strong>外观模式（Facade）</strong>：<ul>
<li>SLF4J框架</li>
</ul>
</li>
<li><strong>代理模式（Proxy）</strong>：AOP思想（动态代理）</li>
<li><strong>享元模式（Flyweight）</strong>：缓存思想</li>
</ul>
<h2 id="行为型（Behavioral）-2"><a href="#行为型（Behavioral）-2" class="headerlink" title="行为型（Behavioral）"></a>行为型（Behavioral）</h2><ul>
<li><strong>命令模式（Command）</strong>：</li>
<li><strong>状态模式（State）</strong>：<ul>
<li>订单状态</li>
</ul>
</li>
<li><strong>模板方法模式（Template Method）</strong>：抽象类实现公共逻辑，子类实现差异化</li>
<li><strong>策略模式（Strategy）</strong>：<ul>
<li>if-else逻辑</li>
</ul>
</li>
<li><strong>迭代器模式（Iterator）</strong>：</li>
<li><strong>解释器模式（Interceptor）</strong>：</li>
<li><strong>观察者模式（Observer）</strong>：<ul>
<li>zookeeper/etcd等配置中心的watch机制/服务发现机制</li>
</ul>
</li>
<li><strong>中介者（Mediator）</strong>：</li>
<li><strong>访问者模式（Visitor）</strong>：</li>
<li><strong>责任链模式（Chain of Responsibility）</strong>：<ul>
<li>凡是带有<code>Filter</code>关键词的，基本都在用这个设计模式</li>
</ul>
</li>
<li><strong>备忘录模式（Memento）</strong>：</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://coolshell.cn/articles/3320.html">JDK中的设计模式</a></li>
</ul>
]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubeadm安装K8S集群</title>
    <url>/2020/04/08/Kubeadm%E5%AE%89%E8%A3%85K8S%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>记录如何用kubernetes官方提供的kubeadm工具安装k8s集群<br><a id="more"></a></p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul>
<li>host配置</li>
<li>SSH免密登录配置</li>
<li>清理已有安装：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl drain geolab.master --ignore-daemonsets</span><br><span class="line">kubectl delete node geolab.master</span><br><span class="line">kubeadm reset</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="重新安装"><a href="#重新安装" class="headerlink" title="重新安装"></a>重新安装</h1><h2 id="设置国内阿里云镜像"><a href="#设置国内阿里云镜像" class="headerlink" title="设置国内阿里云镜像"></a>设置国内阿里云镜像</h2><p>添加阿里云源,安装kubelet,kubeadm,kubectl<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-<span class="string">'EOF'</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [<span class="string">"https://wx3i03p1.mirror.aliyuncs.com"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set SELinux in permissive mode (effectively disabling it)</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line"><span class="comment"># 开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure></p>
<h1 id="master安装"><a href="#master安装" class="headerlink" title="master安装"></a>master安装</h1><h2 id="准备k8s依赖的镜像"><a href="#准备k8s依赖的镜像" class="headerlink" title="准备k8s依赖的镜像"></a>准备k8s依赖的镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `kubeadm config images list`; <span class="keyword">do</span> </span><br><span class="line">  imageName=<span class="variable">$&#123;i#k8s.gcr.io/&#125;</span></span><br><span class="line">  docker pull registry.aliyuncs.com/google_containers/<span class="variable">$imageName</span></span><br><span class="line">  docker tag registry.aliyuncs.com/google_containers/<span class="variable">$imageName</span> k8s.gcr.io/<span class="variable">$imageName</span></span><br><span class="line">  docker rmi registry.aliyuncs.com/google_containers/<span class="variable">$imageName</span></span><br><span class="line"><span class="keyword">done</span>;</span><br></pre></td></tr></table></figure>
<h2 id="安装k8s"><a href="#安装k8s" class="headerlink" title="安装k8s"></a>安装k8s</h2><p>kubeadm init  —kubernetes-version=v1.18.1 —apiserver-advertise-address=192.168.135.3 —pod-network-cidr=10.10.0.0/16   —ignore-preflight-errors=Swap<br>输出<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@geolab ~]<span class="comment"># kubeadm init  --kubernetes-version=v1.18.1 --apiserver-advertise-address=192.168.135.3 --pod-network-cidr=10.10.0.0/16   --ignore-preflight-errors=Swap</span></span><br><span class="line">W0411 16:32:29.608282   40905 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.1</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [geolab.master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.135.3]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/server"</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [geolab.master localhost] and IPs [192.168.135.3 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/peer"</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [geolab.master localhost] and IPs [192.168.135.3 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/healthcheck-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-etcd-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">W0411 16:32:34.260249   40905 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">W0411 16:32:34.261367   40905 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 19.002848 seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">"kubelet-config-1.18"</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node geolab.master as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node geolab.master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 2rmc0j.ef90k3cxqzuo15df</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[kubelet-finalize] Updating <span class="string">"/etc/kubernetes/kubelet.conf"</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br></pre></td></tr></table></figure></p>
<p>kubectl apply -f <a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a></p>
<h2 id="master安装dashboard"><a href="#master安装dashboard" class="headerlink" title="master安装dashboard"></a>master安装dashboard</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 卸载已有</span><br><span class="line"># kubectl delete ns kubernetes-dashboard</span><br><span class="line"># 安装</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;dashboard&#x2F;v2.0.0-rc7&#x2F;aio&#x2F;deploy&#x2F;recommended.yaml</span><br><span class="line"># 启动proxy</span><br><span class="line">kubectl proxy --address&#x3D;&#39;0.0.0.0&#39; --port&#x3D;9090 --accept-hosts&#x3D;&#39;^*$&#39; </span><br><span class="line"></span><br><span class="line"># 查看token</span><br><span class="line">kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#39;&#123;print $1&#125;&#39;) </span><br><span class="line"># 登陆</span><br><span class="line">http:&#x2F;&#x2F;192.168.135.3:9090&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kubernetes-dashboard&#x2F;services&#x2F;https:kubernetes-dashboard:&#x2F;proxy&#x2F;#&#x2F;login</span><br></pre></td></tr></table></figure>
<h1 id="woker加入master"><a href="#woker加入master" class="headerlink" title="woker加入master"></a>woker加入master</h1><p>kubeadm token create —print-join-command</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建token</span></span><br><span class="line">kubeadm token create</span><br><span class="line"><span class="comment"># 列出创建的token</span></span><br><span class="line">kubeadm token list		</span><br><span class="line"><span class="comment"># 查到discovery-token-ca-cert-hash</span></span><br><span class="line">openssl x509 -pubkey -<span class="keyword">in</span> /etc/kubernetes/pki/ca.crt |openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex |sed <span class="string">'s/^.* //'</span></span><br><span class="line"><span class="comment">#加入节点</span></span><br><span class="line">kubeadm join 192.168.135.3:6443  \</span><br><span class="line">--token 1ialrj.w5hb23c97wmwclcy  \</span><br><span class="line">–-discovery-token-unsafe-skip-ca-verification  \</span><br><span class="line">--discovery-token-ca-cert-hash  \</span><br><span class="line">sha256:0d347e9a2dd9e45724bd2c9d264525813f5bd7a51ead73e1b87348ff1c7e5672  \</span><br><span class="line">-v=10</span><br></pre></td></tr></table></figure>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="worker在joins时couldn’t-validate-the-identity-of-the-API-Server"><a href="#worker在joins时couldn’t-validate-the-identity-of-the-API-Server" class="headerlink" title="worker在joins时couldn’t validate the identity of the API Server"></a>worker在joins时couldn’t validate the identity of the API Server</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@geolab ~]<span class="comment"># kubeadm join 192.168.135.3:6443 --token gcwq0r.2da1200lrzpurxro     --discovery-token-ca-cert-hash sha256:0d347e9a2dd9e45724bd2c9d264525813f5bd7a51ead73e1b87348ff1c7e5672 </span></span><br><span class="line">W0411 08:27:49.560351   11398 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not <span class="built_in">set</span>.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">error execution phase preflight: couldn<span class="string">'t validate the identity of the API Server: Get https://192.168.135.3:6443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s: x509: certificate has expired or is not yet valid</span></span><br><span class="line"><span class="string">To see the stack trace of this error execute with --v=5 or higher</span></span><br></pre></td></tr></table></figure>
<p>—v5后显示的错误<br>curl <a href="https://192.168.135.3:6443/api/v1/nodes/geolab.worker?timeout=10s">https://192.168.135.3:6443/api/v1/nodes/geolab.worker?timeout=10s</a><br>  “message”: “nodes \”geolab.worker\” is forbidden: User \”system:anonymous\” cannot get resource \”nodes\” in API group \”\” at the cluster scope”,<br>解决：还么解决。。。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm/">kubeadm</a></li>
<li><a href="https://blog.csdn.net/qq_34348168/article/details/84137311">阿里云镜像安装k8s</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1525487">基于kubeadm的国内镜像源安装</a></li>
<li><a href="https://segmentfault.com/a/1190000021209788">kubeadm安装k8s完整教程</a></li>
</ul>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Kubernetes</tag>
        <tag>Kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title>DataSphereStudio的自动化部署</title>
    <url>/2020/11/21/DataSphereStudio%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>DSS(DataSphereStudio)的实现强依赖于Linkis计算中间件，dss包含6个，而底层linkis需要部署18个服务，所以一般基于dss二次开发，关键就是对linkis的hadoop集群做适配，以及超多的微服务导致部署的问题(工作量大，服务间存在依赖，容易出错)。</p>
<p>本文主要的关注点是如何将dss应用于生产环境并采用<code>gerrit + jenkins + ansible + docker</code>实施<code>cicd</code>，实现对linkis和dss的自动化部署，封装每个微服务在不同运行环境的配置和启动脚本。</p>
<a id="more"></a>  
<h1 id="关于DSS"><a href="#关于DSS" class="headerlink" title="关于DSS"></a>关于DSS</h1><p>DSS(DataSphereStudio)是一个一站式数据应用开发管理门户，基于插拔式的集成框架设计，基于计算中间件<code>Linkis</code>实现。</p>
<h1 id="Linkis部署结构"><a href="#Linkis部署结构" class="headerlink" title="Linkis部署结构"></a>Linkis部署结构</h1><p><img src="dss_deploy.png" alt="DataSphereStudio部署图"></p>
<p>linkis总共18个微服务</p>
<h2 id="Linkis服务列表"><a href="#Linkis服务列表" class="headerlink" title="Linkis服务列表"></a>Linkis服务列表</h2><ul>
<li>eureka：注册中心</li>
<li>linkis-gateway：网关</li>
<li>linkis-resourcemanager：资源管理服务</li>
<li>linkis-dsm-server：数据源服务</li>
<li>linkis-mdm-server：元数据管理服务</li>
<li>linkis-metadata：元数据服务</li>
<li>linkis-bml：物料库</li>
<li>linkis-cs-server：统一上下文服务</li>
<li>linkis-publicservice：公共服务（variable,database,udf,workspace等）</li>
</ul>
<blockquote>
<p>ujes 统一作业执行引擎</p>
</blockquote>
<ul>
<li>linkis-ujes-hive-enginemanager</li>
<li>linkis-ujes-hive-entrance</li>
<li>linkis-ujes-jdbc-entrance</li>
<li>linkis-ujes-python-enginemanager</li>
<li>linkis-ujes-python-entrance</li>
<li>linkis-ujes-shell-enginemanager</li>
<li>linkis-ujes-shell-entrance</li>
<li>linkis-ujes-spark-enginemanager</li>
<li>linkis-ujes-spark-entrance</li>
</ul>
<h2 id="Linkis部署包组成"><a href="#Linkis部署包组成" class="headerlink" title="Linkis部署包组成"></a>Linkis部署包组成</h2><p>每个服务的目录结构都一致，ujes部分会多一些引擎相关的配置：</p>
<ul>
<li>bin：服务启动/停止脚本<ul>
<li>pid文件：linkis.pid</li>
<li>用户切换脚本：rootScript.sh</li>
<li>启动服务：start-${SERVICE_NAME}.sh</li>
<li>停止服务：stop-${SERVICE_NAME}.sh</li>
</ul>
</li>
<li>config：服务配置文件<ul>
<li>log4j2.xml：log4j日志配置</li>
<li>log4j.properties：日志变量</li>
<li>application.yml：spring boot配置</li>
<li>linkis.properties：linkis服务配置</li>
<li>linkis-engine.properties：linkis ujes引擎配置</li>
<li>log4j2-engine.xml：ujes引擎log4j日志配置</li>
</ul>
</li>
<li>lib：依赖jar包</li>
<li>logs：日志文件<ul>
<li>linkis.log：log4j日志，按天/大小回滚</li>
<li>linkis.out：jvm启动日志，每次启动覆盖</li>
<li>linkis-gc.log：jvm gc日志，每次启动覆盖</li>
</ul>
</li>
</ul>
<h1 id="DSS部署结构"><a href="#DSS部署结构" class="headerlink" title="DSS部署结构"></a>DSS部署结构</h1><ul>
<li>dss-web：前端服务（可包含visualis-web）</li>
<li>dss-server：dss后端服务</li>
<li>dss-flow-execution-entrance：工作流执行入口</li>
<li>linkis-appjoint-entrance：linkis任务提交入口</li>
<li>dss-init-db：仅用于第一次初始化数据库</li>
</ul>
<p>由于linkis和dss都是微众开源的，dss部署包的目录结构和linkis类似；</p>
<h1 id="DSS部署资源规划"><a href="#DSS部署资源规划" class="headerlink" title="DSS部署资源规划"></a>DSS部署资源规划</h1><p>安装linkis+dss服务测试环境，采用4核8G*6台虚机：</p>
<ul>
<li>Server1：linkis-gateway、linkis-publicservice、linkis-cs-server、linkis-dsm-server、linkis-bml、linkis-metadata、linkis-mdm-server</li>
<li>Server2：enginemanager（spark、python）、entrance（spark、python）</li>
<li>Server3：enginemanager（hive、shell）、entrance（hive、shell）、jdbc-entrance</li>
<li>Server4：eureke、linkis-resourcemanager</li>
<li>Server5：dss-server、linkis-appjoint-entrance、dss-flow-execution-entrance</li>
<li>Server6：qualitis-server、azkaban、visualis-server</li>
</ul>
<blockquote>
<p>测试采用简化部署结构，生产eureke，linkis-resourcemanager需要HA部署;<br>每个服务的堆大小默认设置为1G;<br>服务间存在依赖关系，需按顺序启动：比如需先启动eureka，gateway，resoucemanager等基础服务,再启动其他应用层服务；</p>
</blockquote>
<p>单机资源够的情况下，测试时可以将ujes都部署在一台服务器；<br>实际生产环境，根据服务使用人数，具体可参考官方的文档<a href="https://github.com/WeBankFinTech/Linkis/wiki/Linkis生产部署参考指南">Linkis生产部署参考指南</a>做容量规划。</p>
<h1 id="DSS的CICD流程"><a href="#DSS的CICD流程" class="headerlink" title="DSS的CICD流程"></a>DSS的CICD流程</h1><p>主体CICD流程：代码提交到gerrit，review成功后，自动mvn打包，并通过ansible在测试环境发布重启docker容器，同时生成生产环境的部署包；</p>
<h2 id="Linkis自定义编译"><a href="#Linkis自定义编译" class="headerlink" title="Linkis自定义编译"></a>Linkis自定义编译</h2><p>自定义hadoop版本，修改linkis根目录和linkis-ujes-spark-engine项目的pom.xml文件<br>比如修改hadoop到2.6<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.6.5<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">hive.version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">hive.version</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">spark.version</span>&gt;</span>2.3.0<span class="tag">&lt;/<span class="name">spark.version</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>编译问题</p>
<ul>
<li>shell-enginemanager存在jackson包冲突会导致启动失败，保留<code>2.10.0</code>，其他版本exclude即可;</li>
<li>遇到<code>Assembly is incorrectly configured</code>问题，将<code>useStrictFiltering</code>属性改成false即可;</li>
<li>eureke需设置<code>instance-id</code>、<code>prefer-ip-address</code>和<code>ip-address</code>，不然显示的是docker内部ip，且服务间不能正常通信（使用的默认是docker内部ip）；</li>
</ul>
</blockquote>
<h2 id="DSS的部署包准备"><a href="#DSS的部署包准备" class="headerlink" title="DSS的部署包准备"></a>DSS的部署包准备</h2><ul>
<li><code>mvn -N install</code></li>
<li><code>mvn -Pspark2.3 clean install</code></li>
<li>将assembly/target/wedatasphere-linkis-{version}-dist.tar.gz解压后挂载到docker中</li>
</ul>
<p>上述流程可通过</p>
<ul>
<li><code>JJB(jenkins job builder)</code>实现<code>devops as code</code>，以yaml编写ci流程，ci流程更新后自动触发jenkins任务更新；</li>
<li>Jenkins中配置在<code>gerrit trigger</code>，配置不同的hook，让代码更新后自动触发对应的job构建；</li>
</ul>
<h2 id="DSS的多环境自动部署"><a href="#DSS的多环境自动部署" class="headerlink" title="DSS的多环境自动部署"></a>DSS的多环境自动部署</h2><p>在官方的config目录下添加dev、test、prod等配置，按不同部署环境的环境变量配置config.sh和db.sh，并通过docker挂载到容器内；</p>
<p>linkis和dss的目录结构比较规范，做容器化时，只需要参考install.sh中的脚本，拆分成多个entrypoint即可。</p>
<blockquote>
<p>注意</p>
<ul>
<li>官方的脚本针对的是一键部署，ansible集成时，所有的remote操作都可以简化为local操作</li>
</ul>
</blockquote>
<h2 id="DSS的运行日志"><a href="#DSS的运行日志" class="headerlink" title="DSS的运行日志"></a>DSS的运行日志</h2><ul>
<li>在<code>bin/start-{SERVICE_NAME}.sh</code>脚本然后将<code>SERVER_LOG_PATH</code>改为<code>/var/log/{SERVICE_NAME}</code>，<code>SERVER_LOG_PATH</code>并挂载到docker中，以便在容器重启后能够保持日志;</li>
<li>将官方<code>log4j.properties</code>中的<code>logs/linkis.log</code>改为${env:SERVER_LOG_PATH}/linkis.log；</li>
<li>gc和jvm日志也可参考log4j日志路径修改;</li>
</ul>
<h1 id="DSS的Docker镜像"><a href="#DSS的Docker镜像" class="headerlink" title="DSS的Docker镜像"></a>DSS的Docker镜像</h1><ul>
<li>CDH环境配置：参考CDH Agent机器配置即可，配置好后需设置HADOOP_HOME，SPARK_HOME，HIVE_HOME等环境变量</li>
<li>根据不同的运行环境，挂载不同的hadoop/yarn的核心site.xml文件;</li>
<li>确保terminal能正常使用hdfs,spark-sql,hive,kinit等服务；</li>
</ul>
<h2 id="DSS的Docker服务"><a href="#DSS的Docker服务" class="headerlink" title="DSS的Docker服务"></a>DSS的Docker服务</h2><p>实现<code>startup.sh ${SERVICE_NAME}</code>,通过SERVICE_NAME参数实现启动指定的微服务；<br>每个微服务的entrypoint脚本主要实现几个步骤：</p>
<ul>
<li>复制公共模块包;</li>
<li>复制服务压缩包；</li>
<li>删除当前部署目录；</li>
<li>解压服务压缩包；</li>
<li>读取config中的变量，用sed替换spring和log4j等配置文件；</li>
<li>调用服务压缩包<code>bin/start-{SERVICE_NAME}.sh</code>启动服务；</li>
<li>检查服务是否启动成功并打印启动日志；</li>
</ul>
<blockquote>
<p>docker容器的entrypoint示例:startup.sh</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load config and init</span></span><br><span class="line">RUN_ENV=<span class="variable">$&#123;DSS_RUN_ENV:=dev&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># eg. /opt/dss/dss-dist</span></span><br><span class="line">shellDir=<span class="variable">$&#123;DSS_INSTALL_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"shellDir:<span class="variable">$&#123;shellDir&#125;</span>"</span></span><br><span class="line"><span class="comment"># tar package path</span></span><br><span class="line">workDir=$(</span><br><span class="line">  <span class="built_in">cd</span> <span class="variable">$&#123;shellDir&#125;</span>/..</span><br><span class="line">  <span class="built_in">pwd</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">export</span> workDir=<span class="variable">$workDir</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'workDir'</span> <span class="variable">$&#123;workDir&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># eg. /opt/dss/dss-run</span></span><br><span class="line">DSS_WORK_HOME=<span class="variable">$&#123;DSS_WORK_HOME:=$&#123;workDir&#125;</span>&#125;</span><br><span class="line"><span class="built_in">export</span> DSS_WORK_HOME=<span class="variable">$DSS_WORK_HOME</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'DSS_WORK_HOME'</span> <span class="variable">$&#123;DSS_WORK_HOME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># init directories and log dir</span></span><br><span class="line"><span class="built_in">export</span> LOG_DIR=/var/<span class="built_in">log</span>/<span class="variable">$1</span></span><br><span class="line">mkdir -p <span class="variable">$&#123;LOG_DIR&#125;</span></span><br><span class="line">touch <span class="variable">$LOG_DIR</span>/linkis.out</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"LOGDIR:<span class="variable">$&#123;LOG_DIR&#125;</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> <span class="variable">$&#123;workDir&#125;</span>/bin/common.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> entrypoint/<span class="variable">$1</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"tail begin"</span></span><br><span class="line"><span class="built_in">exec</span> bash -c <span class="string">"tail -n 1 -f <span class="variable">$LOG_DIR</span>/linkis.out"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>linkis-gateway的entrypoint示例:linkis-gateway.sh</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> <span class="variable">$&#123;workDir&#125;</span>/bin/entrypoint/functions.sh</span><br><span class="line">EUREKA_URL=http://<span class="variable">$EUREKA_INSTALL_IP</span>:<span class="variable">$EUREKA_PORT</span>/eureka/</span><br><span class="line"></span><br><span class="line"><span class="comment">##GateWay Install</span></span><br><span class="line">PACKAGE_DIR=springcloud/gateway</span><br><span class="line">APP_PREFIX=<span class="string">"linkis-"</span></span><br><span class="line">SERVER_NAME=<span class="string">"gateway"</span></span><br><span class="line">SERVER_PATH=<span class="variable">$&#123;APP_PREFIX&#125;</span><span class="variable">$&#123;SERVER_NAME&#125;</span></span><br><span class="line">SERVER_IP=<span class="variable">$GATEWAY_INSTALL_IP</span></span><br><span class="line">SERVER_PORT=<span class="variable">$GATEWAY_PORT</span></span><br><span class="line">SERVER_HOME=<span class="variable">$LINKIS_WORK_HOME</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###install dir</span></span><br><span class="line">installPackage</span><br><span class="line"></span><br><span class="line"><span class="comment">###update linkis.properties</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$SERVER_PATH</span>-update linkis conf"</span></span><br><span class="line">SERVER_CONF_PATH=<span class="variable">$SERVER_HOME</span>/<span class="variable">$SERVER_PATH</span>/conf/linkis.properties</span><br><span class="line">executeCMD <span class="variable">$SERVER_IP</span> <span class="string">"sed -i \"s#wds.linkis.ldap.proxy.url.*#wds.linkis.ldap.proxy.url=<span class="variable">$LDAP_URL</span>#g\" <span class="variable">$SERVER_CONF_PATH</span>"</span></span><br><span class="line">executeCMD <span class="variable">$SERVER_IP</span> <span class="string">"sed -i \"s#wds.linkis.ldap.proxy.baseDN.*#wds.linkis.ldap.proxy.baseDN=<span class="variable">$LDAP_BASEDN</span>#g\" <span class="variable">$SERVER_CONF_PATH</span>"</span></span><br><span class="line">executeCMD <span class="variable">$SERVER_IP</span> <span class="string">"sed -i \"s#wds.linkis.gateway.admin.user.*#wds.linkis.gateway.admin.user=<span class="variable">$deployUser</span>#g\" <span class="variable">$SERVER_CONF_PATH</span>"</span></span><br><span class="line">isSuccess <span class="string">"subsitution linkis.properties of <span class="variable">$SERVER_PATH</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"&lt;----------------<span class="variable">$SERVER_PATH</span>:end-------------------&gt;"</span></span><br><span class="line"><span class="comment">##GateWay Install end</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># start and check</span></span><br><span class="line">startApp</span><br><span class="line">sleep 10</span><br><span class="line">checkServer</span><br></pre></td></tr></table></figure>
<h1 id="DSS的CICD建议"><a href="#DSS的CICD建议" class="headerlink" title="DSS的CICD建议"></a>DSS的CICD建议</h1><blockquote>
<p>原则是尽量统一行为规范，便于实施约定由于配置，实现运维自动化。</p>
</blockquote>
<ul>
<li>install脚本可以按微服务隔离成多个sh脚本，隔离关注点，方便容器化部署，方便社区参与&amp;维护；</li>
<li>项目命名规则不统一：有的驼峰有的全小写（contextservice，resourceManager），改版时可以统一风格；</li>
<li>eureka，dss-web和其他服务的install脚本不太一致，比如前缀，命名大小写把所有远程安装的脚本都删除，修改为本地操作即可；</li>
<li>dss-web可以添加frontend-maven-plugin插件，不依赖node环境完成前端自动化打包；</li>
<li>可以加入flyway等数据库ddl的版本控制，不然后面数据结构的迭代升级会比较痛苦；</li>
</ul>
<h1 id="DSS相关术语"><a href="#DSS相关术语" class="headerlink" title="DSS相关术语"></a>DSS相关术语</h1><ul>
<li>wds：WebDataSphere，套件名称，包含dss</li>
<li>dss：DataSphereStudio，数据平台</li>
<li>ujes，Unified Job Execution Services，通用作业执行服务</li>
<li>bml：Material Library ，物料库</li>
<li>dwc：DataWorkerCloud</li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>任务调度系统之DolphinScheduler</title>
    <url>/2020/08/03/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E4%B9%8BDolphinScheduler/</url>
    <content><![CDATA[<p>airflow要投入生产，定制成本太高，国产apache dolphinScheduler真香，只是可惜airflow使用python代码对dag进行版本控制的思路没有采用，得自己实现版本控制。<br><a id="more"></a>  </p>
<h1 id="DolphinScheduler核心概念"><a href="#DolphinScheduler核心概念" class="headerlink" title="DolphinScheduler核心概念"></a>DolphinScheduler核心概念</h1><ul>
<li>dag：任务关系依赖</li>
<li>cron：任务时间依赖</li>
<li>alert group：任务异常告警分组设置用户</li>
<li>worker group：任务执行环境隔离</li>
</ul>
<h1 id="DolphinScheduler架构"><a href="#DolphinScheduler架构" class="headerlink" title="DolphinScheduler架构"></a>DolphinScheduler架构</h1><p>DolphinScheduler的去中心化是Master/Worker注册到Zookeeper中，实现Master集群和Worker集群无中心，并使用Zookeeper分布式锁来选举其中的一台Master或Worker为“管理者”来执行任务。</p>
<ul>
<li><p><strong>MasterServer</strong>：MasterServer采用分布式无中心设计理念，MasterServer主要负责 DAG 任务切分、任务提交监控，并同时监听其它MasterServer和WorkerServer的健康状态。 MasterServer服务启动时向Zookeeper注册临时节点，通过监听Zookeeper临时节点变化来进行容错处理。<br>该服务内主要包含:</p>
<ul>
<li>Distributed Quartz分布式调度组件，主要负责定时任务的启停操作，当quartz调起任务后，Master内部会有线程池具体负责处理任务的后续操作;</li>
<li>MasterSchedulerThread是一个扫描线程，定时扫描数据库中的 command 表，根据不同的命令类型进行不同的业务操作</li>
<li>MasterExecThread主要是负责DAG任务切分、任务提交监控、各种不同命令类型的逻辑处理</li>
<li>MasterTaskExecThread主要负责任务的持久化</li>
</ul>
</li>
<li><p><strong>WorkerServer</strong>：WorkerServer也采用分布式无中心设计理念，WorkerServer主要负责任务的执行和提供日志服务。WorkerServer服务启动时向Zookeeper注册临时节点，并维持心跳。<br>该服务包含：</p>
<ul>
<li>FetchTaskThread主要负责不断从Task Queue中领取任务，并根据不同任务类型调用TaskScheduleThread对应执行器。</li>
<li>LoggerServer是一个RPC服务，提供日志分片查看、刷新和下载等功能</li>
</ul>
</li>
<li><p><strong>ZooKeeper</strong>：ZooKeeper服务，系统中的MasterServer和WorkerServer节点都通过ZooKeeper来进行集群管理和容错。另外系统还基于ZooKeeper进行事件监听和分布式锁。 </p>
</li>
<li><strong>Alert</strong>：提供告警相关接口，接口主要包括告警两种类型的告警数据的存储、查询和通知功能。其中通知功能又有邮件通知和<strong>SNMP(暂未实现)</strong>两种。</li>
<li><strong>API</strong>：API接口层，主要负责处理前端UI层的请求。该服务统一提供RESTful api向外部提供请求服务。 接口包括工作流的创建、定义、查询、修改、发布、下线、手工启动、停止、暂停、恢复、从该节点开始执行等等。</li>
<li><strong>UI</strong>：系统的前端页面，提供系统的各种可视化操作界面，详见系统使用手册部分。</li>
</ul>
<h1 id="选型DolphinScheduler的考虑"><a href="#选型DolphinScheduler的考虑" class="headerlink" title="选型DolphinScheduler的考虑"></a>选型DolphinScheduler的考虑</h1><blockquote>
<p><strong>pros</strong></p>
<ul>
<li>去中心化设计（netty+zookeeper），scheduler和worker都实现了高可用；</li>
<li>可视化拖拽设计dag流程，友好的task参数配置；</li>
<li>java工程化技术栈(springboot+mybatis+vue)，学习和维护成本低；</li>
<li>源码有完整的单元测试用例</li>
<li>告警/通知机制，提供dingtalk/email等集成；</li>
</ul>
<p><strong>cons</strong></p>
<ul>
<li>具体任务类型依赖的库耦合在同一个项目未做插件化；</li>
<li>自定义任务类型实现必须侵入性修改源码，插件化task类型的pr在开发中；</li>
<li>不支持数据血缘采集；</li>
<li>不支持sentry告警集成；</li>
<li>不支持ldap认证；</li>
</ul>
</blockquote>
<h1 id="DolphinScheduler的Process-Task状态"><a href="#DolphinScheduler的Process-Task状态" class="headerlink" title="DolphinScheduler的Process/Task状态"></a>DolphinScheduler的Process/Task状态</h1><p>对应<code>task_instance</code>表的state字段</p>
<ul>
<li>submit_success：提交成功</li>
<li>running：正在运行</li>
<li>ready_pause：准备暂停</li>
<li>pause：暂停</li>
<li>ready_stop：准备停止</li>
<li>stop：停止</li>
<li>failure：失败</li>
<li>success：成功</li>
<li>need_fault_tolerance：需要容错，worker节点宕机，任务标记为需要容错，然后被master接管后重新分派给其他worker处理</li>
<li>kill：中止</li>
<li>waiting_thread：等待线程</li>
<li>waiting_depend_node_complete：等待依赖完成</li>
</ul>
<blockquote>
<p>调度器处理的状态： submit_success, ready_pause, ready_stop, need_fault_tolerance，waiting_thread，waiting_depend_node_complete<br>任务运行状态：pause，running<br>任务终止状态：stop，success，kill，failure</p>
</blockquote>
<h1 id="DolphinScheduler的异常处理机制"><a href="#DolphinScheduler的异常处理机制" class="headerlink" title="DolphinScheduler的异常处理机制"></a>DolphinScheduler的异常处理机制</h1><ul>
<li>Master节点容错：依赖于ZooKeeper的Watcher机制实现（<code>EPHEMERAL_SEQUENTIAL</code>），watch到master节点remove时，会将host为当前节点且任务状态in[<code>正在运行，准备暂停，准备停止</code>]的任务的host设置为null，并重新生成新的command；</li>
<li>Worker节点容错：依赖于ZooKeeper的Watcher机制实现（<code>EPHEMERAL_SEQUENTIAL</code>），watch到worker节点remove时，会将host为当前节点且任务状态in[正在运行]的任务kill掉，然后状态改为<code>需要容错</code>;</li>
<li>任务失败重试：是任务级别的，是调度系统自动进行的，比如一个Shell任务设置重试次数为3次，那么在Shell任务运行失败后会自己再最多尝试运行3次；</li>
<li>流程失败恢复：是流程级别的，是手动进行的，恢复是从只能从失败的节点开始执行或从当前节点开始执行；</li>
<li>流程失败重跑：是流程级别的，是手动进行的，重跑是从开始节点进行；</li>
</ul>
<h1 id="调度规则"><a href="#调度规则" class="headerlink" title="调度规则"></a>调度规则</h1><ul>
<li>定时调度：cron表达式，提供可视化生成cron；</li>
<li>事件触发：从当前节点开始执行、从失败节点开始执行、补数、重跑、暂停/恢复暂停、停止；</li>
<li>调度实现：基于<code>quartz</code>分布式调度器</li>
</ul>
<h1 id="DolphinScheduler的表结构"><a href="#DolphinScheduler的表结构" class="headerlink" title="DolphinScheduler的表结构"></a>DolphinScheduler的表结构</h1><p><a href="dolphinscheduler.jdl">DolphinScheduler的ERD(JDL)</a></p>
<p><img src="dolphinscheduler.png" alt="dolphinescheduler-erd"></p>
<blockquote>
<p>表前缀：<code>t_ds_</code></p>
</blockquote>
<p>DolphinScheduler的表可分为用户，资源，用户资源授权，调度表（quartz），调度记录表，运维6类</p>
<h2 id="用户表"><a href="#用户表" class="headerlink" title="用户表"></a>用户表</h2><ul>
<li>tenant：租户</li>
<li>user：用户</li>
<li>access_token：访问ds后端的token</li>
<li>session：用户登陆session</li>
</ul>
<h2 id="资源表"><a href="#资源表" class="headerlink" title="资源表"></a>资源表</h2><ul>
<li>queue：队列</li>
<li>resources：资源文件</li>
<li>udfs：UDF资源</li>
<li>datasource：数据源</li>
<li>project：项目</li>
<li>process_definition：流程定义，存储dag定义数据；</li>
</ul>
<h2 id="用户资源授权表"><a href="#用户资源授权表" class="headerlink" title="用户资源授权表"></a>用户资源授权表</h2><ul>
<li>relation_project_user：用户关联的项目</li>
<li>relation_datasource_user：用户关联的数据源</li>
<li>relation_udfs_user：用户关联的UDF函数</li>
<li>relation_resources_user：用户关联的资源</li>
</ul>
<h2 id="调度记录表"><a href="#调度记录表" class="headerlink" title="调度记录表"></a>调度记录表</h2><ul>
<li>schedules：流程定时调度，存储process_definition的时间调度配置；</li>
<li>process_instance：流程实例</li>
<li>relation_process_instance：子流程，用于处理流程定义中含有子流程的情况；</li>
<li>task_instance：任务实例</li>
<li>command：任务执行命令</li>
<li>error_command：任务执行错误命令</li>
</ul>
<h2 id="运维表"><a href="#运维表" class="headerlink" title="运维表"></a>运维表</h2><ul>
<li>alert：告警信息</li>
<li>alertgroup：告警组</li>
<li>relation_user_alertgroup：用户关联告警组</li>
<li>version_ds：版本信息</li>
</ul>
<h2 id="quartz调度表"><a href="#quartz调度表" class="headerlink" title="quartz调度表"></a>quartz调度表</h2><blockquote>
<p>分布式quartz：保证了同一时刻有且只有一个服务器在调用定时器任务<br><img src="distributed-quartz.jpg" alt="distributed-quartz"></p>
</blockquote>
<ul>
<li>qrtz_triggers：存储定义的trigger；</li>
<li>qrtz_cron_triggers：存储 Cron Trigger，包括 Cron 表达式和时区信息；</li>
<li>qrtz_fired_triggers：存储与已触发的 Trigger 相关的状态信息，以及相联 Job 的执行信息；</li>
<li>qrtz_blob_triggers：以 Blob 类型存储Quartz的Calendar信息；</li>
<li>qrtz_simple_triggers：存储SimpleTrigger，包括重复次数，间隔，以及已触的次数；</li>
<li>qrtz_simprop_triggers：存储简单的存储CalendarIntervalTrigger和DailyTimeIntervalTrigger两种类型的触发器；</li>
<li>qrtz_paused_trigger_grps：存储已暂停的 Trigger 组的信息；</li>
<li>qrtz_calendars：自定义时间段，可以控制触发器在这个时间段内触发/不触发；</li>
<li>qrtz_scheduler_state：存储一个集群中其他调度器 (Scheduler) 的状态；</li>
<li>qrtz_job_details：存储每一个已配置的 Job 的详细信息(jobDetail)；</li>
<li>qrtz_locks：存储程序的悲观锁的信息（行锁实现同一个任务不会被多次调度）；</li>
</ul>
<h1 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h1><p>依赖</p>
<ul>
<li>dolphinscheduler-service：核心service层，包含log，queue，zk，quartz.cron等逻辑；</li>
<li>dolphinscheduler-dao：mybatis元数据库的数据访问层、外部数据源配置；</li>
<li>dolphinscheduler-common：枚举定义、不同任务类型的参数定义、辅助工具类；</li>
<li>dolphinscheduler-plugin-api：Alert插件api；</li>
<li>dolphinscheduler-remote：基于netty实现的rpc框架；</li>
<li>dolphinscheduler-dist：协议、部署；</li>
</ul>
<p>部署服务</p>
<ul>
<li>dolphinscheduler-ui：ds前端网站；</li>
<li>dolphinscheduler-api：rest服务；</li>
<li>dolphinscheduler-server：Master和Worker；</li>
<li>dolphinscheduler-alert：告警服务AlertServer；</li>
</ul>
<h1 id="如何定制"><a href="#如何定制" class="headerlink" title="如何定制"></a>如何定制</h1><ul>
<li><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1></li>
</ul>
<ul>
<li><a href="https://dolphinscheduler.apache.org/zh-cn/docs/development/architecture-design.html">Apache DolphinScheduler系统架构设计</a></li>
<li><a href="https://www.slidestalk.com/DolphinScheduler/ApacheDolphinScheduler81906">Apache DolphinScheduler-分布式易扩展的可视化DAG工作流调度系统</a></li>
<li><a href="https://www.slidestalk.com/DolphinScheduler/Distributed_Job_Management_Platform">Apache DolphinScheduler-让作业提交变得更简单</a></li>
</ul>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink配置参数说明</title>
    <url>/2021/01/29/Flink%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<p>flink-1.10.2的fink-conf.yaml配置文件说明<br><a id="more"></a>  </p>
<h1 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h1><p>常规配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The external address of the host on which the JobManager runs and can be</span></span><br><span class="line"><span class="comment"># reached by the TaskManagers and any clients which want to connect. This setting</span></span><br><span class="line"><span class="comment"># is only used in Standalone mode and may be overwritten on the JobManager side</span></span><br><span class="line"><span class="comment"># by specifying the --host &lt;hostname&gt; parameter of the bin/jobmanager.sh executable.</span></span><br><span class="line"><span class="comment"># In high availability mode, if you use the bin/start-cluster.sh script and setup</span></span><br><span class="line"><span class="comment"># the conf/masters file, this will be taken care of automatically. Yarn/Mesos</span></span><br><span class="line"><span class="comment"># automatically configure the host name based on the hostname of the node where the</span></span><br><span class="line"><span class="comment"># JobManager runs.</span></span><br><span class="line"></span><br><span class="line">jobmanager.rpc.address: localhost</span><br><span class="line"></span><br><span class="line"><span class="comment"># The RPC port where the JobManager is reachable.</span></span><br><span class="line"></span><br><span class="line">jobmanager.rpc.port: 6123</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The heap size for the JobManager JVM</span></span><br><span class="line"></span><br><span class="line">jobmanager.heap.size: 1024m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The total process memory size for the TaskManager.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Note this accounts for all memory usage within the TaskManager process, including JVM metaspace and other overhead.</span></span><br><span class="line"></span><br><span class="line">taskmanager.memory.process.size: 1728m</span><br><span class="line"></span><br><span class="line"><span class="comment"># To exclude JVM metaspace and overhead, please, use total Flink memory size instead of 'taskmanager.memory.process.size'.</span></span><br><span class="line"><span class="comment"># It is not recommended to set both 'taskmanager.memory.process.size' and Flink memory.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># taskmanager.memory.flink.size: 1280m</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.</span></span><br><span class="line"></span><br><span class="line">taskmanager.numberOfTaskSlots: 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># The parallelism used for programs that did not specify and other parallelism.</span></span><br><span class="line"></span><br><span class="line">parallelism.default: 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># The default file system scheme and authority.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># By default file paths without scheme are interpreted relative to the local</span></span><br><span class="line"><span class="comment"># root file system 'file:///'. Use this to override the default and interpret</span></span><br><span class="line"><span class="comment"># relative paths relative to a different file system,</span></span><br><span class="line"><span class="comment"># for example 'hdfs://mynamenode:12345'</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># fs.default-scheme</span></span><br></pre></td></tr></table></figure></p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>高可用配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The high-availability mode. Possible options are 'NONE' or 'zookeeper'.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># high-availability: zookeeper</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The path where metadata for master recovery is persisted. While ZooKeeper stores</span></span><br><span class="line"><span class="comment"># the small ground truth for checkpoint and leader election, this location stores</span></span><br><span class="line"><span class="comment"># the larger objects, like persisted dataflow graphs.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Must be a durable file system that is accessible from all nodes</span></span><br><span class="line"><span class="comment"># (like HDFS, S3, Ceph, nfs, ...)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># high-availability.storageDir: hdfs:///flink/ha/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The list of ZooKeeper quorum peers that coordinate the high-availability</span></span><br><span class="line"><span class="comment"># setup. This must be a list of the form:</span></span><br><span class="line"><span class="comment"># "host1:clientPort,host2:clientPort,..." (default clientPort: 2181)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># high-availability.zookeeper.quorum: localhost:2181</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ACL options are based on https://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html#sc_BuiltinACLSchemes</span></span><br><span class="line"><span class="comment"># It can be either "creator" (ZOO_CREATE_ALL_ACL) or "open" (ZOO_OPEN_ACL_UNSAFE)</span></span><br><span class="line"><span class="comment"># The default value is "open" and it can be changed to "creator" if ZK security is enabled</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># high-availability.zookeeper.client.acl: open</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Fault-tolerance-and-checkpointing"><a href="#Fault-tolerance-and-checkpointing" class="headerlink" title="Fault tolerance and checkpointing"></a>Fault tolerance and checkpointing</h1><p>容错和恢复配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The backend that will be used to store operator state checkpoints if</span></span><br><span class="line"><span class="comment"># checkpointing is enabled.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Supported backends are 'jobmanager', 'filesystem', 'rocksdb', or the</span></span><br><span class="line"><span class="comment"># &lt;class-name-of-factory&gt;.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># state.backend: filesystem</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory for checkpoints filesystem, when using any of the default bundled</span></span><br><span class="line"><span class="comment"># state backends.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># state.checkpoints.dir: hdfs://namenode-host:port/flink-checkpoints</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Default target directory for savepoints, optional.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># state.savepoints.dir: hdfs://namenode-host:port/flink-checkpoints</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Flag to enable/disable incremental checkpoints for backends that</span></span><br><span class="line"><span class="comment"># support incremental checkpoints (like the RocksDB state backend).</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># state.backend.incremental: false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The failover strategy, i.e., how the job computation recovers from task failures.</span></span><br><span class="line"><span class="comment"># Only restart tasks that may have been affected by the task failure, which typically includes</span></span><br><span class="line"><span class="comment"># downstream tasks and potentially upstream tasks if their produced data is no longer available for consumption.</span></span><br><span class="line"></span><br><span class="line">jobmanager.execution.failover-strategy: region</span><br></pre></td></tr></table></figure></p>
<h1 id="Flink-HistoryServer-Configuration"><a href="#Flink-HistoryServer-Configuration" class="headerlink" title="Flink HistoryServer Configuration"></a>Flink HistoryServer Configuration</h1><p>job执行日志存储位置，需要独立启动historyserver服务<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The HistoryServer is started and stopped via bin/historyserver.sh (start|stop)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory to upload completed jobs to. Add this directory to the list of</span></span><br><span class="line"><span class="comment"># monitored directories of the HistoryServer as well (see below).</span></span><br><span class="line">jobmanager.archive.fs.dir: hdfs://haService/user/geosmart/flink/historylog</span><br><span class="line"></span><br><span class="line"><span class="comment"># The address under which the web-based HistoryServer listens.</span></span><br><span class="line">historyserver.web.address: 0.0.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># The port under which the web-based HistoryServer listens.</span></span><br><span class="line">historyserver.web.port: 8090</span><br><span class="line"></span><br><span class="line"><span class="comment"># Comma separated list of directories to monitor for completed jobs.</span></span><br><span class="line">historyserver.archive.fs.dir: hdfs://haService/user/geosmart/flink/historylog</span><br><span class="line"></span><br><span class="line"><span class="comment"># Interval in milliseconds for refreshing the monitored directories.</span></span><br><span class="line">historyserver.archive.fs.refresh-interval: 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># The maximum number of jobs to retain in each archive directory defined by `historyserver.archive.fs.dir`. If set to `-1`(default), there is no limit to the number of archives. If set to `0` or less than `-1` HistoryServer will throw an IllegalConfigurationException.</span></span><br><span class="line">historyserver.archive.retained-jobs: 10000</span><br><span class="line"></span><br><span class="line"><span class="comment"># (none)	String	This configuration parameter allows defining the Flink web directory to be used by the history server web interface. The web interface will copy its static files into the directory.</span></span><br><span class="line">historyserver.web.tmpdir: /tmp/flink_historyserver</span><br></pre></td></tr></table></figure></p>
<h1 id="Flink-Cluster-Security-Configuration"><a href="#Flink-Cluster-Security-Configuration" class="headerlink" title="Flink Cluster Security Configuration"></a>Flink Cluster Security Configuration</h1><p>flink集群安全配置<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Kerberos authentication for various components - Hadoop, ZooKeeper, and connectors -</span></span><br><span class="line"><span class="comment"># may be enabled in four steps:</span></span><br><span class="line"><span class="comment"># 1. configure the local krb5.conf file</span></span><br><span class="line"><span class="comment"># 2. provide Kerberos credentials (either a keytab or a ticket cache w/ kinit)</span></span><br><span class="line"><span class="comment"># 3. make the credentials available to various JAAS login contexts</span></span><br><span class="line"><span class="comment"># 4. configure the connector to use JAAS/SASL</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The below configure how Kerberos credentials are provided.</span></span><br><span class="line"><span class="comment"># A keytab will be used instead of a ticket cache if the keytab path and principal are set.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># security.kerberos.login.use-ticket-cache: false</span></span><br><span class="line">security.kerberos.login.keytab: /home/geosmart/keytab/geosmart.keytab</span><br><span class="line">security.kerberos.login.principal: geosmart</span><br><span class="line"></span><br><span class="line"><span class="comment"># The configuration below defines which JAAS login contexts</span></span><br><span class="line"><span class="comment"># security.kerberos.login.contexts: Client,KafkaClient</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Rest-amp-web-frontend"><a href="#Rest-amp-web-frontend" class="headerlink" title="Rest &amp; web frontend"></a>Rest &amp; web frontend</h1><p>REST和web前端配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The port to which the REST client connects to. If rest.bind-port has</span></span><br><span class="line"><span class="comment"># not been specified, then the server will bind to this port as well.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#rest.port: 8081</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The address to which the REST client will connect to</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#rest.address: 0.0.0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Port range for the REST and web server to bind to.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#rest.bind-port: 8080-8090</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The address that the REST &amp; web server binds to</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#rest.bind-address: 0.0.0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Flag to specify whether job submission is enabled from the web-based</span></span><br><span class="line"><span class="comment"># runtime monitor. Uncomment to disable.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#web.submit.enable: false</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Advanced"><a href="#Advanced" class="headerlink" title="Advanced"></a>Advanced</h1><p>高级配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Override the directories for temporary files. If not specified, the</span></span><br><span class="line"><span class="comment"># system-specific Java temporary directory (java.io.tmpdir property) is taken.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For framework setups on Yarn or Mesos, Flink will automatically pick up the</span></span><br><span class="line"><span class="comment"># containers' temp directories without any need for configuration.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Add a delimited list for multiple directories, using the system directory</span></span><br><span class="line"><span class="comment"># delimiter (colon ':' on unix) or a comma, e.g.:</span></span><br><span class="line"><span class="comment">#     /data1/tmp:/data2/tmp:/data3/tmp</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Note: Each directory entry is read from and written to by a different I/O</span></span><br><span class="line"><span class="comment"># thread. You can include the same directory multiple times in order to create</span></span><br><span class="line"><span class="comment"># multiple I/O threads against that directory. This is for example relevant for</span></span><br><span class="line"><span class="comment"># high-throughput RAIDs.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># io.tmp.dirs: /tmp</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The classloading resolve order. Possible values are 'child-first' (Flink's default)</span></span><br><span class="line"><span class="comment"># and 'parent-first' (Java's default).</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Child first classloading allows users to use different dependency/library</span></span><br><span class="line"><span class="comment"># versions in their application than those in the classpath. Switching back</span></span><br><span class="line"><span class="comment"># to 'parent-first' may help with debugging dependency issues.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># classloader.resolve-order: child-first</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The amount of memory going to the network stack. These numbers usually need</span></span><br><span class="line"><span class="comment"># no tuning. Adjusting them may be necessary in case of an "Insufficient number</span></span><br><span class="line"><span class="comment"># of network buffers" error. The default min is 64MB, the default max is 1GB.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># taskmanager.memory.network.fraction: 0.1</span></span><br><span class="line"><span class="comment"># taskmanager.memory.network.min: 64mb</span></span><br><span class="line"><span class="comment"># taskmanager.memory.network.max: 1gb</span></span><br></pre></td></tr></table></figure></p>
<h1 id="ZK-Security-Configuration"><a href="#ZK-Security-Configuration" class="headerlink" title="ZK Security Configuration"></a>ZK Security Configuration</h1><p>Zookeeper安全配置参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Below configurations are applicable if ZK ensemble is configured for security</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Override below configuration to provide custom ZK service name if configured</span></span><br><span class="line"><span class="comment"># zookeeper.sasl.service-name: zookeeper</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The configuration below must match one of the values set in "security.kerberos.login.contexts"</span></span><br><span class="line"><span class="comment"># zookeeper.sasl.login-context-name: Client</span></span><br></pre></td></tr></table></figure></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/config.html#history-server">flink-history-server</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/monitoring/logging.html">flink日志说明</a></li>
</ul>
]]></content>
      <tags>
        <tag>flink</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS常用脚本</title>
    <url>/2015/07/06/centos%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p>CentOS日常使用过程中积累的Shell脚本或Linux命令，持续维护更新  </p>
<a id="more"></a>
<h1 id="网络设置"><a href="#网络设置" class="headerlink" title="网络设置"></a>网络设置</h1><h2 id="HostName主机名"><a href="#HostName主机名" class="headerlink" title="HostName主机名"></a>HostName主机名</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看hostname</span></span><br><span class="line">hostname  </span><br><span class="line"><span class="meta">#</span><span class="bash">设置指定的域名解析地址</span></span><br><span class="line">/etc/hosts       </span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置主机名和网络配置</span></span><br><span class="line">/etc/sysconfig/network</span><br></pre></td></tr></table></figure>
<h2 id="静态IP设置"><a href="#静态IP设置" class="headerlink" title="静态IP设置"></a>静态IP设置</h2><p><a href="static-ip-centos6.sh">下载 static-ip-centos6.sh</a><br>参数: <code>static-ip.sh &lt;hostname&gt; &lt;interface&gt; &lt;baseip&gt; &lt;ipaddress&gt; &lt;gateway/dns&gt;</code><br>示例<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod +x  ./static-ip.sh &amp;&amp; ./static-ip.sh localhost eth0 192.168.1 81 1</span><br></pre></td></tr></table></figure></p>
<p><a href="static-ip-centos7.sh">下载 static-ip-centos7.sh</a><br>参数: 在文件中修改ip相关参数</p>
<p>手动设置IP  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">临时设置IP</span></span><br><span class="line">ifconfig eth0 192.168.1.160</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置DNS  </span></span><br><span class="line">/etc/resolv.conf  </span><br><span class="line">临时设置IP</span><br><span class="line">ifconfig eth0 192.168.1.160</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">针对特定的网卡进行手动设置</span></span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line"></span><br><span class="line">DEVICE="eth0"</span><br><span class="line">BOOTPROTO="static"</span><br><span class="line">HWADDR="00:0C:29:86:3D:16"</span><br><span class="line">IPV6INIT="yes"</span><br><span class="line">NM_CONTROLLED="yes"</span><br><span class="line">ONBOOT="yes"</span><br><span class="line">TYPE="Ethernet"</span><br><span class="line">UUID="dcf18d86-45ea-4b5c-9627-e75b19b3b6e7"</span><br><span class="line">IPADDR=192.168.1.82</span><br><span class="line">NETMAST=255.255.255.0</span><br><span class="line">DNS1=192.168.1.1</span><br></pre></td></tr></table></figure>
<h2 id="集群环境下ssh免密码登陆认证脚本"><a href="#集群环境下ssh免密码登陆认证脚本" class="headerlink" title="集群环境下ssh免密码登陆认证脚本"></a>集群环境下ssh免密码登陆认证脚本</h2><p><a href="">todo-gitrepository</a></p>
<ol>
<li>确保各节点安装ssh,expect</li>
<li>把所有文件拷贝到主节点上</li>
<li>配置hosts.conf和slaves.conf</li>
<li>执行keygen_master</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod +x keygen_master.sh</span><br><span class="line">./keygen_master.sh</span><br></pre></td></tr></table></figure>
<h1 id="PS查看进程"><a href="#PS查看进程" class="headerlink" title="PS查看进程"></a>PS查看进程</h1><p>通常用ps查看进程PID，kill终止进程</p>
<ul>
<li>grep 是搜索<br>例如：<code>ps -ef | grep java</code>表示查看所有进程里 CMD 是 java 的进程信息  </li>
<li>-aux 显示所有状态<br><code>ps -aux | grep java</code>  </li>
<li>kill 命令用于终止进程<br>例如： <code>kill -9 [PID]</code><br>-9 表示强迫进程立即停止</li>
</ul>
<h1 id="端口查看"><a href="#端口查看" class="headerlink" title="端口查看"></a>端口查看</h1><p>如查看80端口：<code>lsof -i tcp:80</code><br>列出所有端口：<code>netstat -ntlp</code></p>
<h1 id="nohup后台运行"><a href="#nohup后台运行" class="headerlink" title="nohup后台运行"></a>nohup后台运行</h1><p>后台运行test.jar<br><code>nohup java -jar test.jar</code><br>不输出nohup日志：&gt;/dev/null 2&gt;&amp;1 &amp;<br><code>nohup java -jar test.jar &gt;/dev/null 2&gt;&amp;1 &amp;</code></p>
<h1 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h1><ul>
<li>0 表示标准输入  </li>
<li>1 标准输出,在一般使用时，默认的是标准输出  </li>
<li>2 标准错误信息输出<br>可以用来指定需要重定向的标准输入或输出。例如，将某个程序的错误信息输出到log文件 中：./program 2&gt;log。这样标准输出还是在屏幕上，但是错误信息会输出到log文件中。另外，也可 以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。</li>
<li>/dev/null<br>它就像一个无底洞，所有重定向到它的信息都会消失得无影无踪。当我们不需要回显程序的所有信息时，就可以将输出重定到/dev/null。</li>
</ul>
<h1 id="读取文件头-尾-实时内容"><a href="#读取文件头-尾-实时内容" class="headerlink" title="读取文件头/尾/实时内容"></a>读取文件头/尾/实时内容</h1><ul>
<li>head filename读取头部，使用命令head。默认显示文件 filename 的前十行内容<br><code>head -n 20 filename</code>：显示文件的前20行内容<br><code>head -n -20 filename</code>  ：若n后面的整数为负数时，如则表示列出除尾部的20行外的所有行    </li>
<li>tail filename 读取尾部，使用命令tail，使用方法同head相似<br><code>tail -n 20 filename</code>：显示文件的最后20行内容<br><code>tail -n +20 filename</code>：显示文件自第20行开始后的所有行（包括第20行）  </li>
<li><code>tail -f filename</code>：动态显示最新的文件内容<br>具体用法man head或man tail获取  </li>
</ul>
<h1 id="chkconfig问题"><a href="#chkconfig问题" class="headerlink" title="chkconfig问题"></a>chkconfig问题</h1><p>chkconfig —add myservice问题：service myservice does not support chkconfig<br>我们一般在脚本开头加入下面两句就好了<br><code>vim  /etc/init.d/myservice</code><br>添加下面两句到 #!/bin/bash 之后</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> chkconfig: 2345 10 90</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> description: myservice ....</span></span><br></pre></td></tr></table></figure>
<h1 id="图形化界面切换CentOS6"><a href="#图形化界面切换CentOS6" class="headerlink" title="图形化界面切换CentOS6"></a>图形化界面切换CentOS6</h1><p><code>vim /etc/inittab</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Default runlevel. The runlevels used by RHS are:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 0 - halt (Do NOT <span class="built_in">set</span> initdefault to this)          --停机</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1 - Single user mode           --单用户模式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2 - Multiuser, without NFS (The same as 3, <span class="keyword">if</span> you <span class="keyword">do</span> not havenetworking)           --多用户模式，不支持NFS</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3 - Full multiuser mode          --多用户模式     </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 - unused          --没有使用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5 - X11          --图形界面方式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6 - reboot (Do NOT <span class="built_in">set</span> initdefault to this)          --重新启动</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --默认运行等级是5</span></span><br><span class="line">id:5:initdefault:</span><br></pre></td></tr></table></figure>
<h1 id="图形化界面切换CentOS7"><a href="#图形化界面切换CentOS7" class="headerlink" title="图形化界面切换CentOS7"></a>图形化界面切换CentOS7</h1><p>使用systemd创建符号链接指向默认运行级别。</p>
<ol>
<li>首先删除已经存在的符号链接<br><code>rm /etc/systemd/system/default.target</code></li>
<li>默认级别转换为3(文本模式)<br><code>ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target</code><br>或者默认级别转换为5(图形模式)<br><code>ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</code></li>
<li>重启<br><code>reboot</code></li>
</ol>
<h1 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h1><h2 id="mkdir-新建目录"><a href="#mkdir-新建目录" class="headerlink" title="mkdir 新建目录"></a>mkdir 新建目录</h2><p>mkdir -p 无目录新建目录</p>
<h2 id="touch-新建文件"><a href="#touch-新建文件" class="headerlink" title="touch 新建文件"></a>touch 新建文件</h2><p>eg：<code>touch test.log</code></p>
<h2 id="追加文本到文件"><a href="#追加文本到文件" class="headerlink" title="追加文本到文件"></a>追加文本到文件</h2><p>eg：<code>echo &quot;/opt/cm/etc/init.d/cloudera-scm-server start&quot; &gt;&gt; /etc/rc.local</code></p>
<h2 id="rm-文件删除参数："><a href="#rm-文件删除参数：" class="headerlink" title="rm 文件删除参数："></a>rm 文件删除参数：</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-r 就是向下递归，不管有多少级目录，一并删除</span><br><span class="line">-f 就是直接强行删除，不作任何提示的意思</span><br><span class="line">-rf 递归强制删除</span><br></pre></td></tr></table></figure>
<p>需要提醒的是：使用这个rm -rf的时候一定要格外小心，linux没有回收站的  </p>
<h2 id="tar文件解压"><a href="#tar文件解压" class="headerlink" title="tar文件解压"></a>tar文件解压</h2><p>tar在linux上是常用的打包、压缩、加压缩工具，他的参数很多，折里仅仅列举常用的压缩与解压缩参数   </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-c ：create 建立压缩档案的参数；</span><br><span class="line">-x ： 解压缩压缩档案的参数；</span><br><span class="line">-z ： 是否需要用gzip压缩；</span><br><span class="line">-v： 压缩的过程中显示档案；</span><br><span class="line">-f： 置顶文档名，在f后面立即接文件名，不能再加参数</span><br><span class="line">1 将tgz文件解压到指定目录</span><br><span class="line">tar   zxvf    test.tgz  -C  指定目录</span><br><span class="line">比如将/source/kernel.tgz解压到  /source/linux-2.6.29 目录</span><br><span class="line">tar  zxvf  /source/kernel.tgz  -C /source/ linux-2.6.29</span><br></pre></td></tr></table></figure>
<h1 id="VIM操作"><a href="#VIM操作" class="headerlink" title="VIM操作"></a>VIM操作</h1><p><a href="http://www.eepw.com.cn/article/48018.htm">http://www.eepw.com.cn/article/48018.htm</a></p>
<p>vi删除*.swp临时文件删除<br>i插入<br>esc命令行<br>:底行（x或:wq保存）</p>
<h1 id="查找操作"><a href="#查找操作" class="headerlink" title="查找操作"></a>查找操作</h1><h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><p>find是最常见和最强大的查找命令，你可以用它找到任何你想找的文件。<br>find的使用格式如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　$ find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt;</span><br><span class="line">　　- &lt;指定目录&gt;： 所要搜索的目录及其所有子目录。默认为当前目录。</span><br><span class="line">　　- &lt;指定条件&gt;： 所要搜索的文件的特征。</span><br><span class="line">　　- &lt;指定动作&gt;： 对搜索结果进行特定的处理。</span><br></pre></td></tr></table></figure></p>
<p>如果什么参数也不加，find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。<br>find的使用实例：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　$ find . -name &quot;my*&quot;</span><br><span class="line">搜索当前目录（含子目录，以下同）中，所有文件名以my开头的文件。</span><br><span class="line">　　$ find . -name &quot;my*&quot; -ls</span><br><span class="line">搜索当前目录中，所有文件名以my开头的文件，并显示它们的详细信息。</span><br><span class="line">　　$ find . -type f -mmin -10</span><br><span class="line">搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录。</span><br></pre></td></tr></table></figure></p>
<h2 id="locate"><a href="#locate" class="headerlink" title="locate"></a>locate</h2><p>locate命令其实是“find -name”的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。<br>locate命令的使用实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　$ locate &#x2F;etc&#x2F;sh</span><br><span class="line">搜索etc目录下所有以sh开头的文件。</span><br><span class="line">　　$ locate ~&#x2F;m</span><br><span class="line">搜索用户主目录下，所有以m开头的文件。</span><br><span class="line">　　$ locate -i ~&#x2F;m</span><br><span class="line">搜索用户主目录下，所有以m开头的文件，并且忽略大小写。</span><br></pre></td></tr></table></figure>
<h2 id="whereis"><a href="#whereis" class="headerlink" title="whereis"></a>whereis</h2><p>whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。<br>whereis命令的使用实例：<code>$ whereis grep</code></p>
<h2 id="which"><a href="#which" class="headerlink" title="which"></a>which</h2><p>which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。<br>which命令的使用实例：<code>$ which grep</code></p>
<h2 id="type"><a href="#type" class="headerlink" title="type"></a>type</h2><p>type命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。<br>type命令的使用实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　$ type cd</span><br><span class="line">系统会提示，cd是shell的自带命令（build-in）。</span><br><span class="line">　　$ type grep</span><br><span class="line">系统会提示，grep是一个外部命令，并显示该命令的路径。</span><br><span class="line">　　$ type -p grep</span><br><span class="line">加上-p参数后，就相当于which命令。</span><br></pre></td></tr></table></figure>
<h1 id="系统时间"><a href="#系统时间" class="headerlink" title="系统时间"></a>系统时间</h1><ul>
<li>date 查看系统时间  </li>
<li>date -s 修改时间<br>如：date -s  03/04/2013（将系统日期设定为2013年03月04日）</li>
<li>date -s  110:38（将系统时间设定为上午 10:38）<br>修改完后执行：clock -w  ,强制将时间写入COMS！</li>
</ul>
<h1 id="chmod命令详解"><a href="#chmod命令详解" class="headerlink" title="chmod命令详解　　"></a>chmod命令详解　　</h1><p>使用权限：所有使用者<br>使用方式：chmod [-cfvR] [—help] [—version] mode file…<br>说明：<br>Linux/Unix 的档案存取权限分为三级 : 档案拥有者、群组、其他。利用 chmod 可以藉以控制档案如何被他人所存取。<br>mode ：权限设定字串，格式如下 ：[ugoa…][[+-=][rwxX]…][,…]，其中u 表示该档案的拥有者，g 表示与该档案的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。</span><br><span class="line">r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该档案是个子目录或者该档案已经被设定过为可执行。</span><br><span class="line">-c : 若该档案权限确实已经更改，才显示其更改动作</span><br><span class="line">-f : 若该档案权限无法被更改也不要显示错误讯息</span><br><span class="line">-v : 显示权限变更的详细资料</span><br><span class="line">-R : 对目前目录下的所有档案与子目录进行相同的权限变更(即以递回的方式逐个变更)</span><br><span class="line">--help : 显示辅助说明</span><br><span class="line">--version : 显示版本</span><br><span class="line">　　范例：</span><br><span class="line">　　将档案 file1.txt 设为所有人皆可读取</span><br><span class="line">chmod ugo+r file1.txt</span><br><span class="line">　　将档案 file1.txt 设为所有人皆可读取</span><br><span class="line">chmod a+r file1.txt</span><br><span class="line">　　将档案 file1.txt 与 file2.txt 设为该档案拥有者，与其所属同一个群体者可写入，但其他以外的人则不可写入</span><br><span class="line">chmod ug+w,o-w file1.txt file2.txt</span><br><span class="line">　　将 ex1.py 设定为只有该档案拥有者可以执行</span><br><span class="line">chmod u+x ex1.py</span><br><span class="line">　　将目前目录下的所有档案与子目录皆设为任何人可读取</span><br><span class="line">chmod -R a+r *</span><br><span class="line">　　此外chmod也可以用数字来表示权限如 chmod 777 file</span><br><span class="line">　　语法为：chmod abc file</span><br><span class="line">　　其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。</span><br><span class="line">　　r=4，w=2，x=1</span><br><span class="line">　　若要rwx属性则4+2+1=7；</span><br><span class="line">　　若要rw-属性则4+2=6；</span><br><span class="line">　　若要r-x属性则4+1=7。</span><br><span class="line">　　范例：</span><br><span class="line">　　chmod a=rwx file 和 chmod 777 file 效果相同</span><br><span class="line">　　chmod ug=rwx,o=x file 和 chmod 771 file 效果相同</span><br><span class="line">　　若用chmod 4755 filename可使此程式具有root的权限</span><br></pre></td></tr></table></figure></p>
<h1 id="chown命令详解"><a href="#chown命令详解" class="headerlink" title="chown命令详解　　"></a>chown命令详解　　</h1><p>使用权限：root<br>使用方式：chown [-cfhvR] [—help] [—version] user[:group] file…<br>说明：Linux/Unix 是多人多工作业系统，所有的档案皆有拥有者。利用chown 可以将档案的拥有者加以改变。一般来说，这个指令只有是由系统管理者(root)所使用，一般使用者没有权限可以改变别人的档案拥有者，也没有权限可以自己的档案拥有者改设为别人。只有系统管理者(root)才有这样的权限。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">user : 新的档案拥有者的使用者</span><br><span class="line">IDgroup : 新的档案拥有者的使用者群体(group)</span><br><span class="line">-c : 若该档案拥有者确实已经更改，才显示其更改动作</span><br><span class="line">-f : 若该档案拥有者无法被更改也不要显示错误讯息</span><br><span class="line">-h : 只对于连结(link)进行变更，而非该 link 真正指向的档案</span><br><span class="line">-v : 显示拥有者变更的详细资料</span><br><span class="line">-R : 对目前目录下的所有档案与子目录进行相同的拥有者变更(即以递回的方式逐个变更)</span><br><span class="line">--help : 显示辅助说明</span><br><span class="line">--version : 显示版本</span><br><span class="line">　　范例：</span><br><span class="line">　　将档案 file1.txt 的拥有者设为 users 群体的使用者 jessie</span><br><span class="line">chown jessie:users file1.txt</span><br><span class="line">　　将目前目录下的所有档案与子目录的拥有者皆设为 users 群体的使用者 lamport</span><br><span class="line">chown -R lamport:users *</span><br><span class="line">-rw------- (600) -- 只有属主有读写权限。</span><br><span class="line">-rw-r--r-- (644) -- 只有属主有读写权限；而属组用户和其他用户只有读权限。</span><br><span class="line">-rwx------ (700) -- 只有属主有读、写、执行权限。</span><br><span class="line">-rwxr-xr-x (755) -- 属主有读、写、执行权限；而属组用户和其他用户只有读、执行权限。</span><br><span class="line">-rwx--x--x (711) -- 属主有读、写、执行权限；而属组用户和其他用户只有执行权限。</span><br><span class="line">-rw-rw-rw- (666) -- 所有用户都有文件读、写权限。这种做法不可取。</span><br><span class="line">-rwxrwxrwx (777) -- 所有用户都有读、写、执行权限。更不可取的做法。</span><br><span class="line">以下是对目录的两个普通设定：</span><br><span class="line">drwx------ (700) - 只有属主可在目录中读、写。</span><br><span class="line">drwxr-xr-x (755) - 所有用户可读该目录，但只有属主才能改变目录中的内容</span><br><span class="line">suid的代表数字是4，比如4755的结果是-rwsr-xr-x</span><br><span class="line">sgid的代表数字是2，比如6755的结果是-rwsr-sr-x</span><br><span class="line">sticky位代表数字是1，比如7755的结果是-rwsr-sr-t</span><br></pre></td></tr></table></figure></p>
<h1 id="scp命令详解"><a href="#scp命令详解" class="headerlink" title="scp命令详解　"></a>scp命令详解　</h1><h2 id="关于scp"><a href="#关于scp" class="headerlink" title="关于scp　"></a>关于scp　</h2><p>scp是secure copy的缩写，scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。</p>
<h2 id="scp命令的用途"><a href="#scp命令的用途" class="headerlink" title="scp命令的用途"></a>scp命令的用途</h2><p>scp在网络上不同的主机之间复制文件，它使用ssh安全协议传输数据，具有和ssh一样的验证机制，从而安全的远程拷贝文件。<br>scp命令基本格式：<code>scp [-1246BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file]
[-l limit] [-o ssh_option] [-P port] [-S program]
[[user@]host1:]file1 [...] [[user@]host2:]file2</code></p>
<h2 id="scp命令的参数说明"><a href="#scp命令的参数说明" class="headerlink" title="scp命令的参数说明"></a>scp命令的参数说明</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-1    强制scp命令使用协议ssh1</span><br><span class="line">-2    强制scp命令使用协议ssh2</span><br><span class="line">-4    强制scp命令只使用IPv4寻址</span><br><span class="line">-6    强制scp命令只使用IPv6寻址</span><br><span class="line">-B    使用批处理模式（传输过程中不询问传输口令或短语）</span><br><span class="line">-C    允许压缩。（将-C标志传递给ssh，从而打开压缩功能）</span><br><span class="line">-p 保留原文件的修改时间，访问时间和访问权限。</span><br><span class="line">-q    不显示传输进度条。</span><br><span class="line">-r    递归复制整个目录。</span><br><span class="line">-v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。</span><br><span class="line">-c cipher    以cipher将数据传输进行加密，这个选项将直接传递给ssh。</span><br><span class="line">-F ssh_config    指定一个替代的ssh配置文件，此参数直接传递给ssh。</span><br><span class="line">-i identity_file        从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。</span><br><span class="line">-l limit    限定用户所能使用的带宽，以Kbit/s为单位。</span><br><span class="line">-o ssh_option    如果习惯于使用ssh_config(5)中的参数传递方式，</span><br><span class="line">-P port 注意是大写的P, port是指定数据传输用到的端口号</span><br><span class="line">-S program    指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。</span><br></pre></td></tr></table></figure>
<h2 id="从本地服务器复制到远程服务器"><a href="#从本地服务器复制到远程服务器" class="headerlink" title="从本地服务器复制到远程服务器"></a>从本地服务器复制到远程服务器</h2><p>复制文件命令格式：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp local_file remote_username@remote_ip:remote_folder</span><br><span class="line">scp local_file remote_username@remote_ip:remote_file</span><br><span class="line">scp local_file remote_ip:remote_folder</span><br><span class="line">scp local_file remote_ip:remote_file</span><br></pre></td></tr></table></figure><br>实例<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp /home/linux/soft/scp.zip root@www.mydomain.com:/home/linux/others/soft</span><br><span class="line">scp /home/linux/soft/scp.zip root@www.mydomain.com:/home/linux/others/soft/scp2.zip</span><br><span class="line">scp /home/linux/soft/scp.zip www.mydomain.com:/home/linux/others/soft</span><br><span class="line">scp /home/linux/soft/scp.zip www.mydomain.com:/home/linux/others/soft/scp2.zip</span><br></pre></td></tr></table></figure><br>复制目录命令格式：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r local_folder remote_username@remote_ip:remote_folder</span><br><span class="line">scp -r local_folder remote_ip:remote_folder</span><br></pre></td></tr></table></figure><br>实例:将 本地 soft 目录 复制 到 远程 others 目录下，即复制后远程服务器上会有/home/linux/others/soft/ 目录<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /home/linux/soft/ root@www.mydomain.com:/home/linux/others/</span><br><span class="line">scp -r /home/linux/soft/ www.mydomain.com:/home/linux/others/</span><br></pre></td></tr></table></figure></p>
<h2 id="从远程服务器复制到本地服务器"><a href="#从远程服务器复制到本地服务器" class="headerlink" title="从远程服务器复制到本地服务器"></a>从远程服务器复制到本地服务器</h2><p>从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。<br>例如<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp root@www.mydomain.com:/home/linux/soft/scp.zip /home/linux/others/scp.zip</span><br><span class="line">scp  -r www.mydomain.com:/home/linux/soft/ /home/linux/others/</span><br></pre></td></tr></table></figure></p>
<h1 id="rpm命令"><a href="#rpm命令" class="headerlink" title="rpm命令"></a>rpm命令</h1><p>命令格式 rpm {-q|—query} [select-options] [query-options]</p>
<h1 id="yum命令"><a href="#yum命令" class="headerlink" title="yum命令"></a>yum命令</h1><h2 id="yum切换阿里云源"><a href="#yum切换阿里云源" class="headerlink" title="yum切换阿里云源"></a>yum切换阿里云源</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p><code>yum search {name}</code></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>yum install {name}</code></p>
]]></content>
      <categories>
        <category>OPS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop生态圈</title>
    <url>/2015/08/11/Hadoop%E7%94%9F%E6%80%81%E5%9C%88/</url>
    <content><![CDATA[<p>开始正式接触Hadoop，从CDH自动化分布式环境部署延伸的Hadoop生态圈的术语，列举如下：<br><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/glossary.html#topic_1_unique_3__title_27_unique_21">查看所有术语</a></p>
<hr>
<a id="more"></a>
<h1 id="Apache-Accumulo"><a href="#Apache-Accumulo" class="headerlink" title="Apache Accumulo"></a>Apache Accumulo</h1><p>基于谷歌 BigTable 设计的分类、分布键值存储。Accumulo 为在 HDFS 上运行的 NoSQL DBMS，支持高效存储和结构化数据检索，包括查询范围。Accumulo 表可用作 MapReduce 作业的输入和输出。Accumulo 功能包括自动负载平衡和分区、数据压缩和细粒度安全标签。</p>
<h1 id="Apache-Avro"><a href="#Apache-Avro" class="headerlink" title="Apache Avro"></a>Apache Avro</h1><p>在网上存储和传输数据的序列化系统。Avro 为 Avro 数据序列（通常称为“Avro 数据文件”）提供丰富的数据结构、紧凑的二级制编码和容器文件的支持。Avro 独立于语言，可使用多个语言绑定，包括 Java、C、C++、Python 和 Ruby。生成或使用文件的 CDH 中的所有组件支持 Avro 数据文件作为文件格式。<br>Avro 提供与系统（如 Apache Thrift）和协议缓冲类似的功能。</p>
<h1 id="Apache-Bigtop"><a href="#Apache-Bigtop" class="headerlink" title="Apache Bigtop"></a>Apache Bigtop</h1><p>开发封装和 Apache Hadoop 生态系统项目的互操作性测试的项目。</p>
<h1 id="Apache-Crunch"><a href="#Apache-Crunch" class="headerlink" title="Apache Crunch"></a>Apache Crunch</h1><p>用于编写、测试和运行 MapReduce 管道的 Java 库。请参见 Apache Crunch。</p>
<h1 id="Apache-Flume"><a href="#Apache-Flume" class="headerlink" title="Apache Flume"></a>Apache Flume</h1><p>一个分布式、可靠可用的系统，用于高效收集、聚合和移动大量文本或从多个不同源至集中式数据存储的流数据。</p>
<h1 id="Apache-Giraph"><a href="#Apache-Giraph" class="headerlink" title="Apache Giraph"></a>Apache Giraph</h1><p>一个在 Apache Hadoop 上运行的大型、容错的图像处理框架。</p>
<h1 id="Apache-Hadoop"><a href="#Apache-Hadoop" class="headerlink" title="Apache Hadoop"></a>Apache Hadoop</h1><p>一个免费的开源软件框架，支持数据密集型分布应用程序。Apache Hadoop的核心组件为 HDFS 和 MapReduce 和 YARN 处理框架。该术语也用于与 Hadoop 相关的生态系统项目，位于分布式计算和大规模数据处理的基础架构之下。</p>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>MapReduce采用”分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个分节点共同完成，然后通过整合各个节点的中间结果，得到最终结果。简单地说，MapReduce就是”任务的分解与结果的汇总”。<br>在Hadoop中，用于执行MapReduce任务的机器角色有两个：一个是JobTracker；另一个是TaskTracker，JobTracker是用于调度工作的，TaskTracker是用于执行工作的。一个Hadoop集群中只有一台JobTracker。<br>在分布式计算中，MapReduce框架负责处理了并行编程中分布式存储、工作调度、负载均衡、容错均衡、容错处理以及网络通信等复杂问题，把处理过程高度抽象为两个函数：map和reduce，map负责把任务分解成多个任务，reduce负责把分解后多任务处理的结果汇总起来。<br>需要注意的是，用MapReduce来处理的数据集（或任务）必须具备这样的特点：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<h2 id="MapReduce-v1-MRv1"><a href="#MapReduce-v1-MRv1" class="headerlink" title="MapReduce v1 (MRv1)"></a>MapReduce v1 (MRv1)</h2><ul>
<li>MapReduce 作业执行的运行时间框架。它定义两个守护程序：</li>
<li>JobTracker - 协调运行 MapReduce作业，并提供资源管理和作业生命周期管理。在 YARN 中，这些功能由两个单独组件执行。</li>
<li>TaskTracker - 运行 MapReduce 作业已拆分的任务。</li>
</ul>
<h2 id="WordCount流程"><a href="#WordCount流程" class="headerlink" title="WordCount流程"></a>WordCount流程</h2><p><a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">参考</a><br><a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html">中文教程</a></p>
<ol>
<li>HUE新建输入文件：txt<br>HUE地址：<a href="http://server1.lt.com:8888/filebrowser/；或者在xshell中su">http://server1.lt.com:8888/filebrowser/；或者在xshell中su</a> hdfs切换用户新建文件：file01.txt，file02.txt  </li>
</ol>
<ul>
<li>查看输入文件 ：<code>hadoop fs -ls /user/uadb/exchange/input/wordCount/</code>  </li>
<li>查看输入文件内容：<code>hadoop fs -cat   /user/uadb/exchange/input/wordCount/file*.txt</code>  </li>
</ul>
<ol>
<li>上传apreduce程序：jar</li>
<li>运行MapReduce程序：<code>hadoop jar /uadb/wordCount.jar me.demo.hadoop.mapreduce.WordCount /user/uadb/exchange/input/wordCount/ /user/uadb/exchange/output/wordCount</code><br>FatJar打包：<code>hadoop jar /uadb/wordCount.jar com.simontuffs.onejar.Boot  /user/uadb/exchange/input/wordCount/ /user/uadb/exchange/output/wordCount</code></li>
<li>查看执行结果： <code>hadoop   fs  -cat   /user/uadb/exchange/output/wordCount/*-0000*</code></li>
</ol>
<h1 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h1><p>Apache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。<br>YARN最初是为了修复MapReduce实现里的明显不足，并对可伸缩性（支持一万个节点和二十万个内核的集群）、可靠性和集群利用率进行了提升。YARN实现这些需求的方式是，把Job Tracker的两个主要功能（资源管理和作业调度/监控）分成了两个独立的服务程序——全局的资源管理（RM）和针对每个应用的应用 Master（AM），这里说的应用要么是传统意义上的MapReduce任务，要么是任务的有向无环图（DAG）。</p>
<p>运行分布式应用程序的通用体系结构。YARN 指定以下组件：</p>
<p>ResourceManager - 管理计算资源的全局分配至应用程序。<br>ApplicationMaster - 管理应用程序的生命周期<br>NodeManager - 启动和监视群集中机器上的计算容器<br>JobHistory Server - 跟踪已完成的应用程序<br>主应用程序为群集资源与资源管理器协商 - 按照多个容器的描述，每个应用程序拥有特定的内存限制 - 然后在这些容器中运行应用程序特定的进程。在群集节点上运行的节点管理器监督容器，确保应用程序未使用超出其已分配资源的资源。</p>
<p>MapReduce v2 (MRv2) 作为 YARN 应用程序实施。</p>
<h1 id="Apache-HBase"><a href="#Apache-HBase" class="headerlink" title="Apache HBase"></a>Apache HBase</h1><p>面向列的可伸缩分布式数据存储。它提供实时读/写随机访问 HDFS 托管的大规模数据集的权限。<br>Hbase Web UI：<a href="http://{master}:60010/">http://{master}:60010/</a></p>
<h2 id="Hbase表结构设计"><a href="#Hbase表结构设计" class="headerlink" title="Hbase表结构设计"></a>Hbase表结构设计</h2><p>在HBase中，数据是按Column Family来分割的，同一个Column Family下的所有列的数据放在一个文件（为简化下面的描述在此使用文件这个词，在HBase内部使用的是Store）中。</p>
<p>HBase本身的设计目标是 支持稀疏表，而 稀疏表通常会有很多列，但是每一行有值的列又比较少。<br>如果不使用Column Family的概念，那么有两种设计方案：<br>1.把所有列的数据放在一个文件中（也就是传统的按行存储）。那么当我们想要访问少数几个列的数据时，需要遍历每一行，读取整个表的数据，这样子是很低效的。<br>2.把每个列的数据单独分开存在一个文件中（按列存储）。那么当我们想要访问少数几个列的数据时，只需要读取对应的文件，不用读取整个表的数据，读取效率很高。然而，由于稀疏表通常会有很多列，这会导致文件数量特别多，这本身会影响文件系统的效率。</p>
<p>而Column Family的提出就是为了在上面两种方案中做一个折中。HBase中 将一个Column Family中的列存在一起，而不同Column Family的数据则分开。<br>由于在HBase中Column Family的数量通常很小，同时HBase建议把经常一起访问的比较类似的列放在同一个Column Family中，这样就可以在访问少数几个列时，只读取尽量少的数据。</p>
<h2 id="Hbase性能优化配置"><a href="#Hbase性能优化配置" class="headerlink" title="Hbase性能优化配置"></a>Hbase性能优化配置</h2><p>HBase Master 的 Java 堆栈大小（字节）-Master Default Group：377M（默认）&gt;<br>HBase RegionServer 的 Java 堆栈大小（字节）-RegionServer Default Group :588M（默认）&gt;1024M<br>HBase 客户端写入缓冲-hbase.client.write.buffer：2M（默认）&gt;</p>
<h2 id="HBaseMaster"><a href="#HBaseMaster" class="headerlink" title="HBaseMaster"></a>HBaseMaster</h2><p>HMaster 负责给HRegionServer分配区域,并且负责对集群环境中的HReginServer进行负载均衡，HMaster还负责监控集群环境中的HReginServer的运行状况，如果某一台HReginServer down机，HBaseMaster将会把不可用的HReginServer来提供服务的HLog和表进行重新分配转交给其他HReginServer来提供，HBaseMaster还负责对数据和表进行管理，处理表结构和表中数据的变更，因为在 META 系统表中存储了所有的相关表信息。并且HMaster实现了ZooKeeper的Watcher接口可以和zookeeper集群交互。</p>
<h2 id="HRegionServer"><a href="#HRegionServer" class="headerlink" title="HRegionServer"></a>HRegionServer</h2><p>HReginServer负责处理用户的读和写的操作。HReginServer通过与HBaseMaster通信获取自己需要服务的数据表，并向HMaster反馈自己的运行状况。当一个写的请求到来的时候，它首先会写到一个叫做HLog的write-ahead log中。HLog被缓存在内存中，称为Memcache，每一个HStore只能有一个Memcache。当Memcache到达配置的大小以后，将会创建一个MapFile，将其写到磁盘中去。这将减少HReginServer的内存压力。当一起读取的请求到来的时候，HReginServer会先在Memcache中寻找该数据，当找不到的时候，才会去在MapFiles 中寻找。</p>
<h2 id="HBase-Client"><a href="#HBase-Client" class="headerlink" title="HBase Client"></a>HBase Client</h2><p>HBase Client负责寻找提供需求数据的HReginServer。在这个过程中，HBase Client将首先与HMaster通信，找到ROOT区域。这个操作是Client和Master之间仅有的通信操作。一旦ROOT区域被找到以后，Client就可以通过扫描ROOT区域找到相应的META区域去定位实际提供数据的HReginServer。当定位到提供数据的HReginServer以后，Client就可以通过这个HReginServer找到需要的数据了。这些信息将会被Client缓存起来，当下次请求的时候，就不需要走上面的这个流程了。</p>
<h2 id="HBase-Service"><a href="#HBase-Service" class="headerlink" title="HBase Service"></a>HBase Service</h2><p>HBase Thrift Server和HBase REST Server是通过非Java程序对HBase进行访问的一种途径。</p>
<h1 id="Lily-HBase-Indexer"><a href="#Lily-HBase-Indexer" class="headerlink" title="Lily HBase Indexer"></a>Lily HBase Indexer</h1><p>Lily HBase Indexer provides the ability to quickly and easily search for any content stored in HBase.<br>It allows you to quickly and easily index HBase rows into Solr, without writing a line of code. It doesn’t require Lily, but originates from years of experience indexing HBase as part of Lily - the Customer Intelligence Data Management Platform from NGDATA.<br>Lily HBase Indexer drives HBase indexing support in Cloudera Search, the SEP trigger notification mechanism is used inside Lily as well.</p>
<p>Lily HBase NRT Indexer服务，Lily HBase Indexer是一款灵活的、可扩展的、高容错的、事务性的，并且近实时的处理HBase列索引数据的分布式服务软件。它是NGDATA公司开发的Lily系统的一部分，已开放源代码。Lily HBase Indexer使用SolrCloud来存储HBase的索引数据，当HBase执行写入、更新或删除操作时，Indexer通过HBase的replication功能来把这些操作抽象成一系列的Event事件，并用来保证写入Solr中的HBase索引数据的一致性。并且Indexer支持用户自定义的抽取，转换规则来索引HBase列数据。Solr搜索结果会包含用户自定义的columnfamily:qualifier字段结果，这样应用程序就可以直接访问HBase的列数据。而且Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</p>
<h1 id="Morphlines"><a href="#Morphlines" class="headerlink" title="Morphlines"></a>Morphlines</h1><p><a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/index.html">Morphlines</a>是一款开源的，用来减少构建hadoop ETL数据流程时间的应用程序。它可以替代传统的通过MapReduce来抽取、转换、加载数据的过程，提供了一系列的命令工具，<br>具体可以参见：<a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。">http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。</a><br>对于HBase的其提供了extractHBaseCells命令来读取HBase的列数据。<br>我们采用Cloudera Manager来管理morphlines.conf文件，使用CM来管理morphlines.conf文件除了上面提到的好处之外，还有一个好处就是当我们需要增加索引列的时候，如果采用本地路径方式将需要重新注册Lily HBase Indexer的配置文件，而采用CM管理的话只需要修改morphlines.conf文件后重启Key-Value HBase Indexer服务即可,CM会自动分发给集群。</p>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>Hadoop分布式文件系统（Distributed File System）</p>
<ul>
<li>Namenode<br>Namenode 管理者文件系统的Namespace。它维护着文件系统树(filesystem tree)以及文件树中所有的文件和文件夹的元数据(metadata)。管理这些信息的文件有两个，分别是Namespace 镜像文件(Namespace image)和操作日志文件(edit log)，这些信息被Cache在RAM中，当然，这两个文件也会被持久化存储在本地硬盘。Namenode记录着每个文件中各个块所在的数据节点的位置信息，但是他并不持久化存储这些信息，因为这些信息会在系统启动时从数据节点重建。<br>Namenode结构图课抽象为如图：<br><img src="http://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" alt="HDFS Architecture"><br>NameNode Web UI：<a href="http://master.lt.com:50070/">http://master.lt.com:50070/</a></li>
</ul>
<p>客户端(client)代表用户与namenode和datanode交互来访问整个文件系统。客户端提供了一些列的文件系统接口，因此我们在编程时，几乎无须知道datanode和namenode，即可完成我们所需要的功能。</p>
<ul>
<li>Datanode<br>Datanode是文件系统的工作节点，他们根据客户端或者是namenode的调度存储和检索数据，并且定期向namenode发送他们所存储的块(block)的列表。</li>
</ul>
<h1 id="Apache-Solr"><a href="#Apache-Solr" class="headerlink" title="Apache Solr"></a>Apache Solr</h1><p>Solr是Apache Lucene项目的开源企业搜索平台。其主要功能包括全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及富文本（如Word、PDF）的处理。Solr是高度可扩展的，并提供了分布式搜索和索引复制。Solr 4还增加了NoSQL支持，以及基于Zookeeper的分布式扩展功能SolrCloud。</p>
<ul>
<li>Solr可用于Hbase的二级索引</li>
</ul>
<h1 id="Apache-Hive"><a href="#Apache-Hive" class="headerlink" title="Apache Hive"></a>Apache Hive</h1><p>Hadoop 的数据仓库系统，使用诸如 SQL 的语言（称为 HiveQL），有助于实现汇总和 HDFS 中存储的大数据集的分析。</p>
<h1 id="HiveServer"><a href="#HiveServer" class="headerlink" title="HiveServer"></a>HiveServer</h1><p>支持通过 Apache Thrift 连接将客户端连接至 Hive 的服务器进程。</p>
<h1 id="HiveServer2"><a href="#HiveServer2" class="headerlink" title="HiveServer2"></a>HiveServer2</h1><p>支持通过网络连接将客户端连接至 Hive 的服务器进程。这些客户端可以是本机命令行编辑器或使用 ODBC 或 JDBC 驱动程序的应用程序和工具。</p>
<h1 id="HiveQL"><a href="#HiveQL" class="headerlink" title="HiveQL"></a>HiveQL</h1><p>Hadoop 的一种查询语言，使用类似于标准 SQL 的语法，以在 HDFS 上执行 MapReduce 作业。HiveQL 不支持所有的 SQL 功能。不支持事务和物化视图，对索引和查询的支持有限。它支持不属于标准 SQL 的功能，如多表格，包括多表格插入和创建选择的表格。</p>
<p>在内部，编译器将 HiveQL 语句转换为 MapReduce 作业的有向无环图，提交至 Hadoop，以执行。Beeswax 包含在 Hue内，为 HiveQL 查询提供图形化前端。</p>
<h1 id="Apache-Mahout"><a href="#Apache-Mahout" class="headerlink" title="Apache Mahout"></a>Apache Mahout</h1><p>Hadoop 的机器学习库。它是您能够构建克扩展至大型数据集的机器学习库，从而简化了构建智能应用程序的任务。Mahout 支持的主要使用情形包括：</p>
<ul>
<li>建议挖掘 -基于过去偏好标识用户喜好，如在线购物建议。</li>
<li>群集 - 类似项目的组；如解决类似主题的文档</li>
<li>分类 - 学习现有类别中成员的共同之处，然后使用该信息分类新项目。</li>
<li>频繁的项目集挖掘 - 采用一组项目组（如查询会话或购物车中的条目），识别通常一起出现的项目。</li>
</ul>
<h1 id="Apache-Oozie"><a href="#Apache-Oozie" class="headerlink" title="Apache Oozie"></a>Apache Oozie</h1><p>协调数据接收、存储、转换和分析操作的工作流程和协调服务。</p>
<h1 id="Apache-Pig"><a href="#Apache-Pig" class="headerlink" title="Apache Pig"></a>Apache Pig</h1><p>数据流语言和在 MapReduce 顶部构建的并行执行框架。在内部，编译器将 Pig 语句转换为 MapReduce 作业的有向无环图，提交至 Hadoop，以执行。</p>
<h1 id="Apache-Sentry"><a href="#Apache-Sentry" class="headerlink" title="Apache Sentry"></a>Apache Sentry</h1><p>企业级大数据安全的下一步骤，为存储在 Apache Hadoop 中的数据提供细粒度授权。独立的安全模块，集成开源 SQL 查询引擎 Apache Hive 和 Cloudera Impala，Sentry 提供高级身份验证控制以为企业数据集启用多用户应用程序和跨职能流程。</p>
<h1 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h1><p>分布式计算的一般框架，为迭代和交互式处理提供出色性能。Spark 为 Java、Scala 和 Python 展示用户友好的 API。</p>
<h1 id="Apache-Sqoop"><a href="#Apache-Sqoop" class="headerlink" title="Apache Sqoop"></a>Apache Sqoop</h1><p>在 Hadoop 和外部结构化数据存储（如关系数据库）之间高效批量传输数据的工具。Sqoop 导入表格内容至 HDFS、Apache Hive 和 Apache HBase，并生成允许用户解译表架构的 Java 类。Sqoop 也可以从 Hadoop 存储中提取数据，并将记录从 HDFS 导出至外部结构化数据存储，如关系数据库和企业数据仓库。</p>
<p>Sqoop 有两个版本：Sqoop 和 Sqoop 2。Sqoop 要求客户端安装和配置。Sqoop 2 是基于网络的服务，具有客户命令行界面。拥有 Sqoop 2 连接器，在服务器上配置数据库驱动。</p>
<h1 id="Apache-ZooKeeper"><a href="#Apache-ZooKeeper" class="headerlink" title="Apache ZooKeeper"></a>Apache ZooKeeper</h1><p>维护配置信息、命名并提供分布式同步和组服务的集中式服务。</p>
<h1 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h1><p>Cloudera Apache Hadoop 分布包含核心 Hadoop（HDFS、MapReduce、YARN）以及以下相关项目：Apache Avro、Apache Flume、Fuse-DFS、Apache HBase、Apache Hive、Hue、Cloudera Impala、Apache Mahout、Apache Oozie、Apache Pig、Cloudera Search、Apache Sentry、Apache Spark、Apache Sqoop、Apache Whirr、Apache ZooKeeper、DataFu 和 Kite。</p>
<p>CDH 为免费 100% 开源，并在 Apache 2.0 许可证下许可。CDH 支持多个 Linux 分配。</p>
<h1 id="Cloudera-Manager"><a href="#Cloudera-Manager" class="headerlink" title="Cloudera Manager"></a>Cloudera Manager</h1><h2 id="Cloudera-Manager定义"><a href="#Cloudera-Manager定义" class="headerlink" title="Cloudera Manager定义"></a>Cloudera Manager定义</h2><p>CDH、Cloudera Impala 和 Cloudera Search 的端到瑞管理应用程序。Cloudera Manager 允许管理员轻松有效地协调、监控和管理 Hadoop 群集和 CDH 安装。</p>
<h2 id="Cloudera-Manager版本"><a href="#Cloudera-Manager版本" class="headerlink" title="Cloudera Manager版本"></a>Cloudera Manager版本</h2><p>Cloudera Manager 有两个可用版本：Cloudera Express 和 Cloudera Enterprise。</p>
<h3 id="Cloudera-Express"><a href="#Cloudera-Express" class="headerlink" title="Cloudera Express"></a>Cloudera Express</h3><p>免费下载，包含 CDH，涵盖企业级 Apache Hadoop、Apache HBase、Cloudera Impala、Cloudera Search、Apache Spark 和 Cloudera Manager 分布，提供强大的集群管理功能，如自动部署、集中管理、监控和诊断工具。Cloudera Express 使数据驱动的企业可评估 Apache Hadoop。</p>
<h2 id="Cloudera-Management-Service"><a href="#Cloudera-Management-Service" class="headerlink" title="Cloudera Management Service"></a>Cloudera Management Service</h2><p>Cloudera Management Service 可作为一组角色实施各种管理功能：</p>
<ul>
<li>Activity Monitor - 收集有关 MapReduce 服务运行的活动的信息。默认情况下未添加此角色。</li>
<li>Host Monitor - 收集有关主机的运行状况和指标信息</li>
<li>Service Monitor - 收集有关服务的运行状况和指标信息以及 YARN 和 Impala 服务中的活动信息</li>
<li>Event Server - 聚合 relevant Hadoop 事件并将其用于警报和搜索</li>
<li>Alert Publisher - 为特定类型的事件生成和提供警报</li>
<li>Reports Manager - 生成报告，它提供用户、用户组和目录的磁盘使用率的历史视图，用户和 YARN 池的处理活动，以及 HBase 表和命名空间。此角色未在 Cloudera Express 中添加。<br>Cloudera Manager 将单独管理每个角色，而不是作为 Cloudera Manager Server 的一部分进行管理，可实现可扩展性（例如，在大型部署中，它可用于将监控器角色置于自身的主机上）和隔离。</li>
</ul>
<p>此外，对于特定版本的 Cloudera Enterprise 许可证，Cloudera Management Service 还为 Cloudera Navigator 提供 Navigator Audit Server 和 Navigator Metadata Server 角色。</p>
<h1 id="Cloudera-Impala"><a href="#Cloudera-Impala" class="headerlink" title="Cloudera Impala"></a>Cloudera Impala</h1><p>可实时查询存储在 HDFS 或 Apache HBase 中数据的服务。它支持相同的元数据和 ODBC 和 JDBC 驱动程序作为 Apache Hive 和基于 Hive 标准查询语言 (HiveQL) 的查询语言。要避免延迟，Impala 规避 MapReduce 通过特殊分布式查询引擎（与商业并行 RDBMS 中的引擎相似）直接访问数据。</p>
<h1 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a>Hue</h1><p>为 CDH 服务构建自定义 GUI 应用程序的服务和包含以下内置应用程序的工具：Apache Pig、Apache HBase 和 Sqoop 2 shell，Apache Pig 编辑器、Beeswax Hive UI，Cloudera Impala 查询编辑器，Solr 搜索应用程序Hive 元存储管理器，Oozie 应用程序编辑器、调度程序和提交者，Apache HBase 浏览器，Sqoop 2 应用程序，HDFS 文件管理器和 MapReduce 和 YARN 作业浏览器。</p>
<p>主页：<a href="http://master.lt.com:8888/">http://master.lt.com:8888/</a><br>MapReduce任务查看：<a href="http://192.168.1.100:8888/jobbrowser/">http://192.168.1.100:8888/jobbrowser/</a><br>Hbase主页：<a href="http://192.168.1.100:8888/hbase">http://192.168.1.100:8888/hbase</a><br><a href="http://blog.cloudera.com/blog/2013/09/how-to-manage-hbase-data-via-hue/">Hue Hbase文档</a></p>
<p>Hive主页：<a href="http://192.168.1.100:8888/beeswax/">http://192.168.1.100:8888/beeswax/</a></p>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ol>
<li>Hue-Hbase表中文字段插入和编辑问题</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CDH</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>GATE中文自然语言处理学习笔记</title>
    <url>/2015/09/17/GATE%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><img src="https://gate.ac.uk/plugins/gau-0.1/images/logo-gate.png" alt=""></p>
<h1 id="GATE"><a href="#GATE" class="headerlink" title="GATE"></a>GATE</h1><blockquote>
<p>GATE(文本工程通用框架)项目开始于 1995 年英国的谢菲尔德大学.经历了近 20 年的不断发展，GATE 已经被应用于广泛的研究和项目开发。  </p>
</blockquote>
<ul>
<li>GATE 框架采用了基于组件的软件开发方式和面向对象的灵活编程。</li>
<li>GATE 框架是由纯 Java 语言开发的免费开源软件，遵循 GNU library license。</li>
<li>GATE 使用的编码方式是Unicode，可以支持多种语言编码，并且针对各种斯拉夫语言、日尔曼语言、拉丁系语言和印度语做过系统测试。</li>
<li>GATE 支持的文档类型包括 XML、RTF、Email、HTML、SGML以及纯文本文件。</li>
<li>GATE 作为一个框架，规定其框架内所有的自然语言处理软件系统元素都可以有效的被细分成不同的几种组件，在 GATE 中它们被称为资源。在 GATE 框架下组件的集合被称为 CREOLE。CREOLE 组件是通过 Java Beans 的形式来实现的，CREOLE 在 GATE中分为三种形式：语言组件（LR），处理组件(PR)和可视化组件(VR)。</li>
</ul>
<hr>
<a id="more"></a>
<h2 id="GATE资源："><a href="#GATE资源：" class="headerlink" title="GATE资源："></a>GATE资源：</h2><blockquote>
<p><a href="http://gatechinese.com/blog/category/gate%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">GATE中文自然语言处理</a></p>
</blockquote>
<p><img src="GATEFrame.png" alt="GATE框架"></p>
<h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h1><h2 id="CorpusController"><a href="#CorpusController" class="headerlink" title="CorpusController"></a>CorpusController</h2><h2 id="RealtimeCorpusController"><a href="#RealtimeCorpusController" class="headerlink" title="RealtimeCorpusController"></a>RealtimeCorpusController</h2><h2 id="SerialAnalyserController"><a href="#SerialAnalyserController" class="headerlink" title="SerialAnalyserController"></a>SerialAnalyserController</h2><h1 id="Gazetteer"><a href="#Gazetteer" class="headerlink" title="Gazetteer"></a>Gazetteer</h1><p>词典库（Gazetteer）由一组词典列表组成，列表包含实体名称如城市，组织机构，星期等。列表用于发现文本中包含这些名称的文档和命名实体识别。通常词“词典库”可交替地用于实体列表集合，并利用这些列表发现文本中出现这些名称的处理资源。<br>当词典库PR在一个文件上运行时，每个匹配的文本字符串创建一个标注类型Lookup。词典库通常不依靠Token或任何其它标注，而是基于文档的字词内容发现相匹配的字符串。这意味着一个条目可以跨越多个词，也可以把开始和结束作为一个词。<br>如果一个词典库正工作的文本恰好满足词语边界，则词典发现词语边界的方法不同于GATE tokeniser发现词语边界的方法。如果文本中所有词典实体匹配好了，则创建一个Lookup标注。<br>词典库实体怎样匹配文本的细节取决于词典库处理资源及其参数。  </p>
<h2 id="Gazetteer生效机制"><a href="#Gazetteer生效机制" class="headerlink" title="Gazetteer生效机制"></a>Gazetteer生效机制</h2><p>入口:list.def<br>gazetteer： xx.lst<br>格式：<code>gazetteerFileName:marjorType:minorType</code></p>
<h2 id="ANNIE词典库"><a href="#ANNIE词典库" class="headerlink" title="ANNIE词典库"></a>ANNIE词典库</h2><p>ANNIE词典库是由ANNIE插件提供的。每个独立的词典都是一个普通的文本文件，每行一个条目。</p>
<h2 id="GAZE词典库"><a href="#GAZE词典库" class="headerlink" title="GAZE词典库"></a>GAZE词典库</h2><p>Gaze是一个编辑词典列表，定义词典和把词典映射到本体的工具。即适用于Plain/Linear 词典（默认）、Hash词典库也适用于Ontology-enabled 词典 (Onto词典)。每当执行保存操作时，重新初始化词典PR关联的视图。注意GAZE不生产规模非常大的词典 (我们假设不浏览超过4000实体，不拷贝超过10000个实体)。</p>
<h2 id="Onto词典"><a href="#Onto词典" class="headerlink" title="Onto词典"></a>Onto词典</h2><p>Onto词典或者Hierarchical词典，是一个处理资源，能将特定词典列表的实体加入到GATE本体语言资源的类中。Onto词典指定类而不是主要或次要类型，意识到列表和类ID之间的映射关系。Gaze可视资源能显示列表，本体映射和本体类等级，也提供编辑这些内容的方法。</p>
<h2 id="Hash词典"><a href="#Hash词典" class="headerlink" title="Hash词典"></a>Hash词典</h2><p>Hash词典是<a href="http://www.ontotext.com/">OntoText Lab</a>完成的一个词典。它的实现基于几个java.util.HashMap对象简单的查找，并由Atanas Kiryakov的奇妙想法——在HashMaps的搜寻快于在有限状态机的搜寻而得到启发。Hash词典处理资源是ANNIE插件的一部分。<br>词典处理资源用以下方式实现：每个短语，即每一个列表条目被分割成几个部分，各部分取决于位于它们之间的空格，例如，短语：“form is emptiness”有三个部分：“form”， “is”和“emptiness”。也有一个HashMaps列表：mapsList和列表中最长的短语有同样多的元素。所以第一部分短语放在第一个映射。第一部分+空格+第二部分被放置在第二个映射等。完整的词组是放置在适当的映射，并引用一个查找对象是相连。</p>
<h2 id="Flexible词典"><a href="#Flexible词典" class="headerlink" title="Flexible词典"></a>Flexible词典</h2><p>Flexible词典提供用户灵活的弹性选择他们自己定制的输入和一个外部词典。例如，用户可能想将文本的词语替换成他们的基本形式(这是一种形态学分析仪的输出)或在运行词典之前分割中文文本(用中文Tokeniser)。<br>The Flexible 词典 performs lookup over a document based on the values of an arbitrary feature of an arbitrary annotation type, by using an externally provided 词典.使用外部词典是很重要的，这允许使用任何类型的词典(例如本体词典)。</p>
<h2 id="词典列表collection"><a href="#词典列表collection" class="headerlink" title="词典列表collection"></a>词典列表collection</h2><p>词典列表collection直接从一组标注的训练文本收集实体事件，构成有实体的词典列表。实体类型和词典列表的结构是由用户定义的。一旦列表collection，一个语义语法用于寻找新文本相同的实体。<br>如果没有列表存在，对于每个标注类型要先创建一个空列表。处理资源运行前，列表集必须加载到GATE。如果已有列表存在，列表只是简单的增加任何新实体。列表collection只收集每个实体的一个事件：在添加新的之前要先检查实体已经不存在。</p>
<h2 id="OntoRoot词典"><a href="#OntoRoot词典" class="headerlink" title="OntoRoot词典"></a>OntoRoot词典</h2><p>OntoRoot词典是一种动态创建的词典，即结合其他少量的通用Gate资源，对于给定的本体的内容产生基于本体的标注。这个词典是“Gazetteer_Ontology_Based”插件的一部分，已开发成为TAO项目的一部分。</p>
<h2 id="大型KB词典"><a href="#大型KB词典" class="headerlink" title="大型KB词典"></a>大型KB词典</h2><p>大型KB 词典为ontology-aware自然语言处理提供支持。你可以从RDF装载任何本体，然后使用词典获得lookup标注，标注有实例和类URI。<br>大型KB词典作为插件词典 LKB存在。<br>当前版本的大型KB  词典不使用GATE本体语言资源。相反，它使用自己的原理去加载处理本体。当前版本在不久的未来可能会显著改变。<br>大型KB 词典是从语义搜索平台Ontotext KIM中的一个组件学习起来的。这词典是由KIM发展团队开发的（见<a href="http://nmwiki.ontotext.com/lkb_Gazetteer/team-list.html）。在kim名称左边你可以找到源代码、资料/文件管理或源文件。">http://nmwiki.ontotext.com/lkb_Gazetteer/team-list.html）。在kim名称左边你可以找到源代码、资料/文件管理或源文件。</a></p>
<h1 id="JAPE"><a href="#JAPE" class="headerlink" title="JAPE"></a>JAPE</h1><p>JAPE 的全称是 a Java Annotation Patterns Engine，Java 标注模式引擎，<br>JAPE 提供了基于正规表达式的标注有限状态转换。JAPE 是通用模式定义语言 CPSL(Common Pattern Specification Language1)的一个版本。我们通过 JAPE 语言可以编写 GATE 能够识别的规则，通过这些规则来进行较准确的命名实体识别。</p>
<h2 id="grammer-jape"><a href="#grammer-jape" class="headerlink" title="grammer-jape"></a>grammer-jape</h2><p>入口：base.jape<br>MultiPhase:<br>Phases: 列表<br>jape：:xx.jape<br>示例：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//沿西部干线由南向北行驶至六合区程桥街道荷花社区方桥河桥路段</span></span><br><span class="line">Phase: spacepattern_path</span><br><span class="line">Input: Lookup  AtomToken Token Location</span><br><span class="line">Options: control = appelt  debug = <span class="literal">true</span></span><br><span class="line">Rule: path1</span><br><span class="line">Priority: <span class="number">4120</span></span><br><span class="line">(</span><br><span class="line">&#123;Lookup.majorType == sp_path,Lookup.minorType==prefix&#125;</span><br><span class="line">((&#123;AtomToken&#125;)[<span class="number">1</span>,<span class="number">30</span>]):context</span><br><span class="line">&#123;Lookup.majorType == sp_path,Lookup.minorType==suffix&#125;</span><br><span class="line">):path</span><br><span class="line">--&gt;</span><br><span class="line">:path.Path = &#123; type = Path, context = :context@string &#125;</span><br></pre></td></tr></table></figure>
<p>relationship如何构建？<br>annotation和entity的关系如何构建</p>
<h2 id="JAPE标注类型"><a href="#JAPE标注类型" class="headerlink" title="JAPE标注类型"></a>JAPE标注类型</h2><ul>
<li>Lookup：Annie默认标注结果  </li>
<li>Token：Lang_Chinese，最长分词，包含符号<br>用途：数字，附号标注  </li>
<li><p>IKAToken：IKanalyzer分词标注—-两两分词，不处理符号</p>
<ul>
<li>采用了特有的”正向迭代最细粒度切分算法”，具有80万字/秒的高速处理能力</li>
<li>采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。</li>
<li>优化的词典存储，更小的内存占用。支持用户词典扩展定义</li>
<li>针对Lucene全文检索优化的查询分析器IKQueryParser；采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。</li>
</ul>
</li>
<li><p>AtomToken：原子分词，最细颗粒度分词  </p>
</li>
</ul>
<h2 id="Tokeniser-Rules"><a href="#Tokeniser-Rules" class="headerlink" title="Tokeniser Rules"></a>Tokeniser Rules</h2><p>Tokeniser Rules标注解析器。根据数字、标点符号和单词将文本分解成不同的Token。目的是将标记解析效率最大化，并通过语法规则（Grammar rules）减轻负担以此提高标记解析工作的灵活性。<br>JAPE规则包括两部分，LHS和RHS，与LHS匹配上的标注集将会按照RHS的操作执行。</p>
<ul>
<li><p>LHS(left hand sode)包含正规表达式操作符（比如*, ?, +）的标注模式<br>  | 或者</p>
<ul>
<li>零次或者多次发生<br>? 零次或者一次发生</li>
</ul>
<ul>
<li>一次或者多次发生</li>
</ul>
</li>
<li><p>RHS(right hand side)包含了标注集操作描述，格式：<code>{LHS} &gt; {Annotation type};{attribute1}={value1};...;{attributen}={value n}</code></p>
</li>
</ul>
<h2 id="Token-Types"><a href="#Token-Types" class="headerlink" title="Token Types"></a>Token Types</h2><p>Word、Number、Symbol、Punctuation、SpaceToken</p>
<h2 id="JAPE优先级控制类型"><a href="#JAPE优先级控制类型" class="headerlink" title="JAPE优先级控制类型"></a>JAPE优先级控制类型</h2><ul>
<li>Brill:  Brill 默认的控制风格，作用是在给定的范围内对文档进行匹配并添加类型，当多个匹配规则都匹配到一个文本时默认都会把相应的类型添加上去，这些类型没有重要等级。</li>
<li>All: All 作用类似于Brill，但是All的匹配支持内嵌匹配</li>
<li>First First只匹配第一个匹配到的匹配规则并添加对应类型，所以此时使用’*’,’?’或’+’这类匹配规则是不恰当的</li>
<li>Once:  Once 一旦匹配到匹配规则，则整个JAPE解析直接退出</li>
<li>Appelt: Applet 根据优先规则，匹配唯一一个匹配规则</li>
</ul>
<h2 id="JAPE高亮插件"><a href="#JAPE高亮插件" class="headerlink" title="JAPE高亮插件"></a>JAPE高亮插件</h2><p>找到一个Linux平台的，gedit的插件：<a href="http://joenoodles.com/2012/10/jape-syntax-highlighting">jape-syntax-highlighting</a>，待尝试</p>
<p>当前处理方式</p>
<ol>
<li>myeclipse设置*.jape默认打开程序为sublime text<br><code>General&gt;Editors&gt;File Associations</code></li>
<li>在sublime text代开jape后缀文件，并将Syntax设置为open all with current extention as java</li>
<li>sublimet text3安装SublimeAStyleFormatter插件进行代码格式化<ul>
<li><code>ctrl+alt+f</code>: Format current file  </li>
<li><code>ctrl+k, ctrl+f</code>: Format current selection<br>TODO：暂不能自动格式化jape，和语法高亮报错</li>
</ul>
</li>
</ol>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><h1 id="relationshioType的定义原理"><a href="#relationshioType的定义原理" class="headerlink" title="relationshioType的定义原理"></a>relationshioType的定义原理</h1><p>sentence（有限状态机）包含关系，根据实际情况定义<br>Temporal+SpacePattern(Region+Path)+person</p>
<h1 id="GATE在多线程中的配置"><a href="#GATE在多线程中的配置" class="headerlink" title="GATE在多线程中的配置"></a>GATE在多线程中的配置</h1><p><a href="https://gate.ac.uk/sale/tao/#x1-1760007.14">Using GATE Embedded in a Multithreaded Environment</a><br>All the standard ANNIE PRs are safe when independent instances are used in diﬀerent threads concurrently, as are the standard transient document, transient corpus and controller classes. A typical pattern of development for a multithreaded GATE-based application is:</p>
<pre><code>* Develop your GATE processing pipeline in GATE Developer.
* Save your pipeline as a .gapp ﬁle.
* In your application’s initialisation phase, load n copies of the pipeline using `PersistenceManager.loadObjectFromFile()` , or load the pipeline once and then make copies of it using `Factory.duplicate`, and either give one copy to each thread or store them in a pool (e.g. a LinkedList).
* When you need to process a text, get one copy of the pipeline from the pool, and return it to the pool when you have ﬁnished processing.
</code></pre><p>Alternatively you can use the Spring Framework as described in the next section to handle the pooling for you.</p>
<h2 id="Spring-pooling"><a href="#Spring-pooling" class="headerlink" title="Spring pooling"></a>Spring pooling</h2><p><a href="https://gist.github.com/geosmart/ee8ca82b03dfa10a2bdb58767060fa6f">Spring集成GATE池资源管理</a></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="spring集成开发的plugin如何在gate中运行"><a href="#spring集成开发的plugin如何在gate中运行" class="headerlink" title="spring集成开发的plugin如何在gate中运行"></a>spring集成开发的plugin如何在gate中运行</h2><p>由于插件最终需在gate框架中运行，建议以maven进行项目包/结构管理，fatjar编译打包；  </p>
<ul>
<li>参考Lang_Chinese插件修改gapp(根据creole.xml)，新增PR配置<br><a href="https://gate.ac.uk/sale/tao/splitch3.html">gapp参考</a><br>配置文件参考</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Geocoding 地址解析 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">CREOLE-DIRECTORY</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">JAR</span> <span class="attr">SCAN</span>=<span class="string">"true"</span>&gt;</span>gto.geocoding.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">JAR</span>&gt;</span>lib/util-1.2.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">JAR</span>&gt;</span>lib/uadb.trext-1.2.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">CREOLE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RESOURCE</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">NAME</span>&gt;</span>GeocodingProcesser<span class="tag">&lt;/<span class="name">NAME</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">COMMENT</span>&gt;</span>地址正向解析<span class="tag">&lt;/<span class="name">COMMENT</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">HELPURL</span>&gt;</span>http://gisc.chzu.edu.cn/mysnspace/geocoding<span class="tag">&lt;/<span class="name">HELPURL</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">CLASS</span>&gt;</span>gto.geocoding.processor.GeocodingProcessMain<span class="tag">&lt;/<span class="name">CLASS</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"inputASName"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"GTO"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The annotation set to be used as input for the transducer"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</span><br><span class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"outputASName"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"GTO"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The annotation set to be used as output for the transducer"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">OPTIONAL</span>=<span class="string">"true"</span>&gt;</span>java.lang.String</span><br><span class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"geocodingMethod"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"LT"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The GeocodingMethodEnum to geocoding"</span> <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</span><br><span class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"geocodingUrl"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"http://192.168.1.52:8080/uadb.app/rest/v100/dz/geocoding"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The geocoding url"</span> <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</span><br><span class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">RESOURCE</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">CREOLE</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">CREOLE-DIRECTORY</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>将插件复制于GATE\plugins根目录内；  </li>
<li>在gate中手动配置PR顺序，执行标注无误后，另存为gapp<br>urlList新增URLHolder</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">gate.util.persistence.PersistenceManager-URLHolder</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">urlString</span>&gt;</span>$relpath$../../../../gto.geocoding/<span class="tag">&lt;/<span class="name">urlString</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">gate.util.persistence.PersistenceManager-URLHolder</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>CollectionPersistence新增PRPersistence  </li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">gate.util.persistence.PRPersistence</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">runtimeParams</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">localMap</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>inputASName<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>GTO<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>outputASName<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>GTO<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>geocodingMethod<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>LT<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>geocodingUrl<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>http://192.168.1.52:8080/uadb.app/rest/v100/dz/geocoding<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">localMap</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">runtimeParams</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resourceType</span>&gt;</span>gto.geocoding.processor.GeocodingProcessMain<span class="tag">&lt;/<span class="name">resourceType</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resourceName</span>&gt;</span>GeocodingProcess<span class="tag">&lt;/<span class="name">resourceName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">initParams</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">localMap</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">initParams</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">features</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">localMap</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">features</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">gate.util.persistence.PRPersistence</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Jface运行GATE环境路径设置问题"><a href="#Jface运行GATE环境路径设置问题" class="headerlink" title="Jface运行GATE环境路径设置问题"></a>Jface运行GATE环境路径设置问题</h2><p>问题：GATE环境，以Fatjar打包JFace程序，错误日志：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Could not check plugin-mappings.xml</span><br><span class="line">java.net.MalformedURLException: no protocol: plugin-mappings.xml</span><br><span class="line">gate.util.GateException: java.net.MalformedURLException: no protocol: creole.xml      </span><br><span class="line">gate.creole.ResourceInstantiationException:Couldnot get resource data <span class="keyword">for</span> gate.corpora.CorpusImpl.</span><br><span class="line">You may need first to load the plugin that contains your resource.</span><br><span class="line">For example, to create a gate.creole.tokeniser.DefaultTokeniser</span><br><span class="line">you need first to load the ANNIE plugin.</span><br><span class="line">Go to the menu File-&gt;Manage CREOLE plugins or use the method</span><br><span class="line">Gate.getCreoleRegister().registerDirectories(pluginDirectoryURL)</span><br></pre></td></tr></table></figure>
<p>解决：路径问题，单斜杠改成双斜杠</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//错误</span></span><br><span class="line">System.setProperty(<span class="string">"gate.builtin.ic.dir"</span>, <span class="keyword">new</span> File(gateDir + <span class="string">"/resources/creole"</span>).toURL().toURI().toString());</span><br><span class="line"><span class="comment">//正确</span></span><br><span class="line">String builtinDir = <span class="keyword">new</span> File(gateDir + <span class="string">"\\resources\\creole"</span>).toURI().toURL().toString();</span><br><span class="line">System.setProperty(<span class="string">"gate.builtin.creole.dir"</span>, builtinDir);</span><br></pre></td></tr></table></figure>
<h2 id="gate插件加载错误"><a href="#gate插件加载错误" class="headerlink" title="gate插件加载错误"></a>gate插件加载错误</h2><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">gate.creole.ResourceInstantiationException: Could not get resource data <span class="keyword">for</span> gate.creole.gazetteer.DefaultGazetteer.</span><br><span class="line">gate.creole.gazetteer.DefaultGazetteer can be found in the ANNIE plugin</span><br></pre></td></tr></table></figure>
<ul>
<li><p>问题定位：需要在GATE中注册ANNIE插件，初始化后千万别忘得了！</p>
</li>
<li><p>解决方案：</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> initialized = <span class="keyword">false</span>;</span><br><span class="line">String gateDir = System.getProperty(<span class="string">"user.dir"</span>) + <span class="string">"/src/main/resources/gate"</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"---startup"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!initialized) &#123;</span><br><span class="line">  <span class="comment">// 初始化GATE环境</span></span><br><span class="line">  gateCommonService.setGateDir(gateDir);</span><br><span class="line">  gateCommonService.initGate();</span><br><span class="line">  <span class="comment">//注册插件</span></span><br><span class="line">  gateCommonService.registerGatePlugins(<span class="keyword">new</span> String[] &#123;<span class="string">"ANNIE"</span>, <span class="string">"Lang_Chinese"</span>&#125;);</span><br><span class="line">  initialized = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerGatePlugins</span><span class="params">(String[] pluginNames)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (String pluginName : pluginNames) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      URL pathUrl = getGatePluginPath(pluginName);</span><br><span class="line">      Gate.getCreoleRegister().registerDirectories(pathUrl);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (GateException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Linux中gate初始化错误"><a href="#Linux中gate初始化错误" class="headerlink" title="Linux中gate初始化错误"></a>Linux中gate初始化错误</h2><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Using file:/uadb/uadb.etl.pre/resources/gate/%<span class="number">5</span>Cresources%<span class="number">5</span>Ccreole/ as built-in CREOLE directory URL</span><br><span class="line"> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">22</span>:<span class="number">08</span>:<span class="number">26</span>,<span class="number">255</span> [main] [gate.creole.CreoleRegisterImpl] [WARN] - Could not check plugin-mappings.xml</span><br><span class="line"> java.io.FileNotFoundException: /uadb/uadb.etl.pre/resources/gate/\resources\creole/plugin-mappings.xml (No such file or directory)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>问题定位：window下用的\和\符号在linux下和unix下不可用</p>
</li>
<li><p>解决方案：路径符号由\改成//</p>
</li>
</ul>
<h2 id="Spring集成GATE，Fatjar打包后的标注乱码问题"><a href="#Spring集成GATE，Fatjar打包后的标注乱码问题" class="headerlink" title="Spring集成GATE，Fatjar打包后的标注乱码问题"></a>Spring集成GATE，Fatjar打包后的标注乱码问题</h2><ul>
<li>问题描述：main和junit测试标注正常，但fatjar打包后的程序业务标注未生成<br>  应标注：[Number, Token, Lookup, SpaceToken, Split, Sentence, IKAToken, AtomToken, Context, Place, Mapcode, Location, Region,Scale, Entity]<br>  实际标注：[Split, Token, SpaceToken, DEFAULT_TOKEN, Sentence, IKAToken,AtomToken]</li>
<li>问题定位<br>chineseNE子管道配置的标注有问题，多出个DEFAULT_TOKEN，Sentence正常标注，但未生成Number和Lookup标注，</li>
<li>解决方案<br>gate环境用spring集成，程序是调用gapp执行标注piopeline，jape和gazetteer等资源都是外部化的，为什么不行？<br>进行各种测试排除，发现输出日志中错误的都是乱码，断定是读文件的编码问题！！！这种问题，解决过程中纠结的要死，解决了感觉自己绝逼傻透了！<br>想起那首记忆深刻的程序员之诗，<code>手持两把锟斤拷，口中直呼烫烫烫，脚踏千朵屯屯屯，笑看万物锘锘锘</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//错误</span></span><br><span class="line">Document doc = Factory.newDocument(file.toURI().toURL());</span><br><span class="line"><span class="comment">//正确</span></span><br><span class="line">Document doc = Factory.newDocument(file.toURI().toURL(), <span class="string">"UTF-8"</span>);</span><br></pre></td></tr></table></figure>
<h2 id="Gazetteer问题"><a href="#Gazetteer问题" class="headerlink" title="Gazetteer问题"></a>Gazetteer问题</h2><ul>
<li>问题描述：Correct format for gazetteer entry features is: <a href="[separator][featureName]=[featureValue]">entry</a>*</li>
<li>解决：gazetteer辞典中不能带有冒号，会识别成<code>list.def</code>然后抛错</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>GATE</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM学习笔记（三）垃圾收集器与内存分配策略</title>
    <url>/2016/03/09/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<p>Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。</p>
<hr>
<a id="more"></a>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>垃圾收集（Garbage Collection，GC）需要完成的三件事情：</p>
<ol>
<li>哪些内存需要回收？<br>-[] 内存区域-回收条件</li>
<li>什么时候回收？<br>-[] 多线程/安全点</li>
<li>如何回收？<br>-[] 回收算法</li>
</ol>
<p>当要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，我们就需要对这些”自动化”的技术实施必要的监控和调节。</p>
<ol>
<li><code>程序计数器、虚拟机栈、本地方法栈</code>3个区域随线程而生，随线程而灭；每一个栈帧中分配多少内存基本上在类结构确定下来的时候就已知。因此这几个区域的内存分配和回收都具有确定性，不需过多考虑回收问题，方法结束或者线程结束时，内存自然就随之回收了。</li>
<li><code>Java堆和方法区</code>则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，只有在程序处于运行期间才知道会创建哪些对象，这部分内存的分配和回收都是<code>动态</code>的，垃圾收集器所关注的是这部分内存！</li>
</ol>
<h1 id="对象已死吗？"><a href="#对象已死吗？" class="headerlink" title="对象已死吗？"></a>对象已死吗？</h1><p>垃圾回收器在对堆进行回收前，首要确定的事情就是这些对象之间哪些还<code>存活</code>着，哪些已经<code>死去</code>？</p>
<h2 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h2><ul>
<li>定义：引用计数算法（<code>Reference Counting</code>）:给对象添加一个引用计数器，每当一个地方引用它时，计数器值就+1；当引用失效时，计数器值就-1；任何时刻计数器为0的对象就是不可能被再使用的；</li>
<li>优点：实现简单，判定效率高；微软的COM技术、Python中都使用了Reference Couting算法进行内存管理；</li>
<li>缺点：由于其很难解决对象之间相互循环引用的问题，主流Java虚拟机里面都没有选用Refrence Couting算法来管理内存；</li>
</ul>
<h2 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h2><ul>
<li>定义：可达性分析（<code>Reachability Analysis</code>）判断对象存活的基本思路：通过一系列的称为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain）,当一个对象到GC Roots没有任何引用链相连（即GC Roots到这个对象不可达）时，则证明此对象是不可用的；<br><img src="可达性分析算法.png" alt="可达性分析算法"></li>
<li>Java语言中，可作为GC Roots对象包括：</li>
</ul>
<ol>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象；</li>
<li>方法区中类静态属性引用的对象；</li>
<li>方法区中产量引用的对象；</li>
<li>本地方法栈中JNI（即一般的Native方法）引用的对象</li>
</ol>
<h2 id="再谈引用"><a href="#再谈引用" class="headerlink" title="再谈引用"></a>再谈引用</h2><p>JDk1.2之后，Java对引用概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，4种强度一次逐渐减弱。</p>
<ol>
<li>强引用（<code>Strong Reference</code>）是指在程序代码之中普遍存在的，类似<code>Object obj=new Object()</code>这类的引用，只要强引用存在，对象就不会发生GC；</li>
<li>软引用（<code>Soft Reference</code>）是用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生OOM异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收后还没有足够的内存，才会抛出OOM异常。</li>
<li>弱引用（<code>Weak Reference</code>）是用来描述非必须对象的，强度比软引用更弱，被弱引用关联的对象只能生存到下一次GC发生之前。当垃圾回收器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。</li>
<li>虚引用（<code>Phantom Reference</code>）也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。</li>
</ol>
<h2 id="回收方法区"><a href="#回收方法区" class="headerlink" title="回收方法区"></a>回收方法区</h2><ul>
<li>在方法区中进行垃圾收集的性价比一般比较低；而在Heap中，尤其是在新生代，常规应用进行一次垃圾收集一般回收70%~95%的空间，而永久代的垃圾收集效率远低于此；</li>
<li>永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类；</li>
<li>回收废弃常量与回收Java堆中的对象类似；</li>
<li>判定一个类是否是无用的类条件相对苛刻：<ul>
<li>该类所有实例都已被回收，即Java堆中不存在该类的任何实例；</li>
<li>加载该类的<code>ClassLoader</code>已经被回收；</li>
<li>该类对应的<code>java.lang.Class</code>对象没有在任何地方被引用，无法在任何地方通过反射访问该方法。</li>
</ul>
</li>
</ul>
<p>在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p>
<h1 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h1><p>只介绍内存回收的方法论（算法思想及发展过程），不讨论具体算法实现。</p>
<h2 id="标记-清除算法（Mak-Sweep）"><a href="#标记-清除算法（Mak-Sweep）" class="headerlink" title="标记-清除算法（Mak-Sweep）"></a>标记-清除算法（Mak-Sweep）</h2><ul>
<li>定义：MS算法分标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。<br><img src="标记-清除算法示意图.png" alt="标记-清除算法示意图"></li>
<li>两点不足：<ul>
<li>效率问题，标记和清除两个过程的效率都不高；</li>
<li>空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多后导致以后程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前出发一次垃圾收集动作；</li>
</ul>
</li>
</ul>
<h2 id="复制算法（Coping）"><a href="#复制算法（Coping）" class="headerlink" title="复制算法（Coping）"></a>复制算法（Coping）</h2><ul>
<li>定义：Coping算法将可用内存按容量划分为大小相等的两块，每次使用其中一块。当这一块的内存用完了，就将还存活的对象复制到另一块上面，然后再把已使用的内存清理掉。<br><img src="复制算法示意图.png" alt="复制算法示意图"></li>
<li>优点：每次对整个半区进行回收，内存分配时不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效；</li>
<li>不足：提高效率的代价是将内存缩小到原来的一半；<br>现代商业虚拟机都采用这种收集算法来回收新生代，但新生代中的对象一般98%是<code>朝生夕死</code>，无需按照1:1比例来划分内存空间，而是将内存分为1块较大的Eden（伊甸园）空间和2块较小的Survivor（幸存者）空间，每次使用Eden和其中1块Survivor。</li>
<li>回收时，将Eden和Survivor中还存活的对象一次性复制到另外一个Survivor空间中，最后清理掉Eden和刚才用过的Survivor空间。</li>
<li>HotSpot VM默认Eden和Survivor的比例是8:1:1，即只浪费10%的内存。</li>
<li>98%的对象可回收只是一般场景下的数据，无法保证每次回收都只有不多于10%的对象存活，所以当Survivor空间不足时，需要依赖其他内存（老年代）进行<code>分配担保（Handle Promotion）</code>，让对象进入老年代。</li>
</ul>
<h2 id="标记-整理算法（Mark-Compact）"><a href="#标记-整理算法（Mark-Compact）" class="headerlink" title="标记-整理算法（Mark-Compact）"></a>标记-整理算法（Mark-Compact）</h2><ul>
<li>出场背景：复制算法在对象存活率较高时复制操作较多，效率会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以对应被使用内存中的所有对象都100%存活的极端情况，所以老年代一般不直接选用这种算法。</li>
<li>定义：根据老年代的特点，提出标记-整理（Mark-Compact）算法，标记过程仍然与<code>标记-清除</code>算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理调用端边界以外的内存。<br><img src="标记-整理算法.png" alt="标记-整理算法"></li>
<li>内存碎片整理<br><img src="内存碎片整理.png" alt="内存碎片整理"></li>
<li>标记-清除算法 vs 标记-整理算法<br><img src="mark_sweep_vs_mark_compact.png" alt="mark_sweep_vs_mark_compact"></li>
</ul>
<h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>当前商业虚拟机的垃圾收集都采用<code>分代收集</code>(Generational Collection)算法，根据对象存活周期的不同将内存分为几块。</p>
<ul>
<li>一般把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法；</li>
<li>新生代每次垃圾回收时都发现有大批对象死去,只有<code>少量对象存活</code>，故采用<code>复制</code>算法，以少量对象复制的成本即可完成收集；</li>
<li>老年代中因为<code>对象存活率高</code>、没有额外空间对其进行分配担保，必须采用<code>标记-清理</code>或<code>标记-整理</code>算法来进行回收。</li>
</ul>
<h1 id="HotSpot的算法实现"><a href="#HotSpot的算法实现" class="headerlink" title="HotSpot的算法实现"></a>HotSpot的算法实现</h1><p>HotSpot虚拟机上实现对象存活判断算法和垃圾收集算法时，必须对算法的执行效率有严格的考量，才能保证虚拟机高效运行。</p>
<h2 id="枚举根基点（GC-Roots）"><a href="#枚举根基点（GC-Roots）" class="headerlink" title="枚举根基点（GC Roots）"></a>枚举根基点（GC Roots）</h2><ul>
<li>可作为GC Roots的节点主要在全局性的引用（如常量或静态变量）与执行上下文（如栈帧中的本地变量表）中；</li>
<li>可达性分析对执行时间的敏感体还现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行（即对象引用关系在某个时间点冻结），这点是导致GC必须停顿所有Java执行线程<code>（Stop The World）</code>的一个重要原因，即使号称不会发生停顿的CMS收集器中，GC Roots也是必须要停顿的。</li>
<li><code>准确式内存管理</code>（Exact Memory Management）,即虚拟机可以知道内存中某个位置的数据具体是什么类型。</li>
<li>HotSpot VM采用<code>OopMap</code>(oop,Ordinary Object Pointer,普通对象指针)数据结构，在类加载完成的时候，将对象内什么偏移量上是什么类型的数据计算出来，在<code>JIT(Just-In-Time Compiler)</code>编译过程中，也会在特定的位置（Safepoint）记录下栈和寄存器中哪些位置是引用。</li>
</ul>
<h2 id="安全点（Safepoint）"><a href="#安全点（Safepoint）" class="headerlink" title="安全点（Safepoint）"></a>安全点（Safepoint）</h2><ul>
<li>关于OopMap</li>
</ul>
<ol>
<li>在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但是可能会导致引用关系变化；</li>
<li>OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，将会需要大量的额外空间，这样GC的空间成本将会变得很高。</li>
</ol>
<ul>
<li>安全点定义<br>HotSpot没有为每条指令都生成OopMap，只是在特定的位置记录了这些信息，这些位置称为安全点(Sapfepoint)，即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。</li>
<li>安全点的选定</li>
</ul>
<ol>
<li>安全点的选定既不能太少以至于让GC等待时间太长，也不能过于频繁以至于过分增大运行时的负荷。</li>
<li>安全点的选定基本上是以程序<code>是否具有让程序长时间执行的特性</code>为标准选定的，<code>长时间执行</code>的最明显特性就是指令序列复用，如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。</li>
</ol>
<ul>
<li>如何在GC发生时让所有线程（这里不包括执行JNI调用的线程）都跑到最近的安全点上再停顿下来，有两张方案可供选择：</li>
</ul>
<ol>
<li><code>抢先式中断</code>（Preemptive Suspension）：不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它跑到安全点。<br>现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。</li>
<li><code>主动式中断</code>（Voluntary Suspension）：当GC需要中断线程的时候，不直接对线程进行操作，仅仅简单的设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起（VM将内存页设置为不可读，线程会产生自陷异常，在预先注册异常处理器中<code>暂停线程</code>实现等待），轮询标志的地方和安全点是重合的。</li>
</ol>
<h2 id="安全区域（Safe-Region）"><a href="#安全区域（Safe-Region）" class="headerlink" title="安全区域（Safe Region）"></a>安全区域（Safe Region）</h2><ul>
<li>安全区域产生背景<br>Safepoint机制保证了程序执行时，在不太长时间内就会遇到可进入GC的Safepoint；但是当程序不执行（没有CPU分配时间）的时候（如线程出于Sleep状态或者Block状态），这时线程无法响应JVM的中断请求，走到安全的地方中断挂起，JVM也不可能等待线程重新分配CPU时间。对于这种情况，就需要安全区域（Safe Region）来解决。</li>
<li>安全区域定义<br>安全区域是指在一段代码片中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的。可以将Safe Region看作被扩展了的Safepoint。</li>
<li>工作原理<br>执行函数在进入安全区域时设置ready flag。在它离开安全区域以前，它先检查GC是否完成了枚举（或者收集），并且不再需要执行函数呆在阻塞状态。如果是真，它就向前执行，离开安全区域； 否则，它就像安全点一样阻塞他自己。</li>
</ul>
<h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><p>介绍垃圾收集器之前，需要明确一点，就是在新生代采用的停止复制算法中，“停 止（Stop-the-world）”的意义是在回收内存时，需要暂停其他所 有线程的执行。这个是很低效的，现在的各种新生代收集器越来越优化这一点，但仍然只是将停止的时间变短，并未彻底取消停止。</p>
<h2 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h2><ul>
<li>新生代收集器，使用停止复制算法，使用一个线程进行GC，串行，其它工作线程暂停。</li>
<li>使用-XX:+UseSerialGC可以使用Serial+Serial Old模式运行进行内存回收（这也是虚拟机在Client模式下运行的默认值）</li>
</ul>
<h2 id="ParNew收集器（Parallel-New）"><a href="#ParNew收集器（Parallel-New）" class="headerlink" title="ParNew收集器（Parallel New）"></a>ParNew收集器（Parallel New）</h2><ul>
<li>新生代收集器，使用停止复制算法，Serial收集器的多线程版，用多个线程进行GC，并行，其它工作线程暂停，关注缩短垃圾收集时间。</li>
<li>使用-XX:+UseParNewGC开关来控制使用ParNew+Serial Old收集器组合收集内存；使用-XX:ParallelGCThreads来设置执行内存回收的线程数。</li>
</ul>
<h2 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h2><ul>
<li><p>新生代收集器，使用停止复制算法，关注CPU吞吐量，即运行用户代码的时间/总时间，<br>比如：JVM运行100分钟，其中运行用户代码99分钟，垃圾收集1分钟，则吞吐量是99%，</p>
</li>
<li><p>这种收集器能最高效率的利用CPU，适合运行后台运算（关注缩短垃圾收集时间的收集器，如CMS，等待时间很少，所以适 合用户交互，提高用户体验）。</p>
</li>
<li>使用-XX:+UseParallelGC开关控制使用Parallel Scavenge+Serial Old收集器组合回收垃圾（这也是在Server模式下的默认值）；</li>
<li>使用-XX:GCTimeRatio来设置用户执行时间占总时间的比例，默认99，即1%的时间用来进行垃圾回收。</li>
<li>使用-XX:MaxGCPauseMillis设置GC的最大停顿时间（这个参数只对Parallel Scavenge有效），</li>
<li>用开关参数-XX:+UseAdaptiveSizePolicy可以进行动态控制，如自动调整Eden/Survivor比例，老年代对象年龄，新生代大小等，这个参数在ParNew下没有。</li>
</ul>
<h2 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h2><ul>
<li>老年代收集器，单线程收集器，串行，</li>
<li>使用标记整理（整理的方法是Sweep（清理）和Compact（压缩），清理是将废弃的对象干掉，只留幸存的对象，压缩是将移动对象，将空间填满保证内存分为2块，一块全是对象，一块空闲）算法，</li>
<li>使用单线程进行GC，其它工作线程暂停（注意，在老年代中进行标记整理算法清理，也需要暂停其它线程），</li>
<li>在JDK1.5之前，Serial Old收集器与ParallelScavenge搭配使用。</li>
</ul>
<h2 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h2><ul>
<li>老年代收集器，多线程，并行，多线程机制与Parallel Scavenge差不错，</li>
<li>使用标记整理（与Serial Old不同，这里的整理是Summary（汇总）和Compact（压缩），汇总的意思就是将幸存的对象复制到预先准备好的区域，而不是像Sweep（清理）那样清理废弃的对象）算法，</li>
<li>在Parallel Old执行时，仍然需要暂停其它线程。</li>
<li>Parallel Old在多核计算中很有用。</li>
<li>Parallel Old出现后（JDK 1.6），与Parallel Scavenge配合有很好的效果，充分体现Parallel Scavenge收集器吞吐量优先的效果。</li>
<li>使用-XX:+UseParallelOldGC开关控制使用Parallel Scavenge +Parallel Old组合收集器进行收集。</li>
</ul>
<h2 id="CMS收集器（Concurrent-Mark-Sweep）"><a href="#CMS收集器（Concurrent-Mark-Sweep）" class="headerlink" title="CMS收集器（Concurrent Mark Sweep）"></a>CMS收集器（Concurrent Mark Sweep）</h2><ul>
<li>老年代收集器，致力于获取最短回收停顿时间（即缩短垃圾回收的时间），使用标记清除算法，多线程，优点是并发收集（用户线程可以和GC线程同时工作），停顿小。</li>
<li>使用-XX:+UseConcMarkSweepGC进行ParNew+CMS+Serial Old进行内存回收，</li>
<li>优先使用ParNew+CMS，当用户线程内存不足时，采用备用方案Serial Old收集。</li>
<li>CMS收集的执行过程是：初始标记(CMS-initial-mark) -&gt; 并发标记(CMS-concurrent-mark) —&gt;预清理(CMS-concurrent-preclean)—&gt;可控预清理(CMS-concurrent-abortable-preclean)-&gt; 重新标记(CMS-remark) -&gt; 并发清除(CMS-concurrent-sweep) -&gt;并发重设状态等待下次CMS的触发(CMS-concurrent-reset)</li>
<li>在CMS清理过程中，只有初始标记和重新标记需要短暂停顿，并发标记和并发清除都不需要暂停用户线程，因此效率很高，很适合高交互的场合。</li>
<li>CMS也有缺点，它需要消耗额外的CPU和内存资源，在CPU和内存资源紧张，CPU较少时，会加重系统负担（CMS默认启动线程数为(CPU数量+3)/4）。</li>
<li>在并发收集过程中，用户线程仍然在运行，仍然产生内存垃圾，所以可能产生“浮动垃圾”，本次无法清理，只能下一次Full GC才清理，因此在GC期间，需要预留足够的内存给用户线程使用。</li>
<li>使用CMS的收集器并不是老年代满了才触发Full GC，而是在使用了一大半（默认68%，即2/3，使用-XX:CMSInitiatingOccupancyFraction来设置）的时候就要进行Full GC，如果用户线程消耗内存不是特别大，可以适当调高-XX:CMSInitiatingOccupancyFraction以降低GC次数，提高性能，如果预留的用户线程内存不够，则会触发Concurrent Mode Failure，此时，将触发备用方案：使用Serial Old 收集器进行收集，但这样停顿时间就长了，因此-XX:CMSInitiatingOccupancyFraction不宜设的过大。</li>
<li>CMS采用的是标记清除算法，会导致内存碎片的产生，可以使用-XX：+UseCMSCompactAtFullCollection来设置是否在Full GC之后进行碎片整理，用-XX：CMSFullGCsBeforeCompaction来设置在执行多少次不压缩的Full GC之后，来一次带压缩的Full GC。</li>
</ul>
<h2 id="G1收集器（Garbage-First）"><a href="#G1收集器（Garbage-First）" class="headerlink" title="G1收集器（Garbage-First）"></a>G1收集器（Garbage-First）</h2><p>面向服务器端应用的垃圾收集器，计划未来替代CMS收集器。</p>
<h2 id="理解GC日志"><a href="#理解GC日志" class="headerlink" title="理解GC日志"></a>理解GC日志</h2><h2 id="垃圾收集器参数总结"><a href="#垃圾收集器参数总结" class="headerlink" title="垃圾收集器参数总结"></a>垃圾收集器参数总结</h2><h1 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h1><h2 id="对象优先在Eden分配"><a href="#对象优先在Eden分配" class="headerlink" title="对象优先在Eden分配"></a>对象优先在Eden分配</h2><h2 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h2><h2 id="长期存活的对象将进入老年代"><a href="#长期存活的对象将进入老年代" class="headerlink" title="长期存活的对象将进入老年代"></a>长期存活的对象将进入老年代</h2><h2 id="动态对象年龄判定"><a href="#动态对象年龄判定" class="headerlink" title="动态对象年龄判定"></a>动态对象年龄判定</h2><h2 id="空间分配担保"><a href="#空间分配担保" class="headerlink" title="空间分配担保"></a>空间分配担保</h2>]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch学习笔记</title>
    <url>/2016/07/22/Elasticsearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。<br>Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。<br>不过，Elasticsearch不仅仅是Lucene和全文搜索，我们还能这样去描述它：</p>
<ul>
<li>分布式的实时文件存储，每个字段都被索引并可被搜索</li>
<li>分布式的实时分析搜索引擎</li>
<li>可以扩展到上百台服务器，处理PB级结构化或非结构化数据<br>而且，所有的这些功能被集成到一个服务里面，你的应用可以通过简单的RESTful API、各种语言的客户端甚至命令行与之交互。</li>
</ul>
<p>在Elasticsearch中，文档归属于一种类型(type),而这些类型存在于索引(index)中，类比传统关系型数据库：</p>
<p>  Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns<br>  Elasticsearch -&gt; Indices   -&gt; Types  -&gt; Documents -&gt; Fields</p>
<p>Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。</p>
<hr>
<a id="more"></a> 
<h1 id="Document-文档"><a href="#Document-文档" class="headerlink" title="Document 文档"></a>Document 文档</h1><p>程序中大多的实体或对象能够被序列化为包含键值对的JSON对象，键(key)是字段(field)或属性(property)的名字，值(value)，可以是字符串、数字、布尔类型、另一个对象、值数组或者其他特殊类型，比如表示日期的字符串或者表示地理位置的对象。</p>
<p>通常，我们可以认为对象(object)和文档(document)是等价相通的。但他们还是有所差别：</p>
<ul>
<li>对象(Object)是一个JSON结构体——类似于哈希、hashmap、字典或者关联数组；</li>
<li>对象(Object)中还可能包含其他对象(Object)。 </li>
<li>Elasticsearch中，文档(document)这个术语有着特殊含义，它特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识并存储于Elasticsearch中）。</li>
</ul>
<h2 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a>文档元数据</h2><p>一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是： </p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">节点</th>
<th style="text-align:left">说明              </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">_index</td>
<td style="text-align:left">文档存储的地方</td>
</tr>
<tr>
<td style="text-align:left">_type</td>
<td style="text-align:left">文档代表的对象的类</td>
</tr>
<tr>
<td style="text-align:left">_id</td>
<td style="text-align:left">文档的唯一标识</td>
</tr>
</tbody>
</table>
</div>
<h3 id="index"><a href="#index" class="headerlink" title="_index"></a>_index</h3><p>索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。</p>
<blockquote>
<p>事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。<br>然而，这只是一些内部细节——我们的程序完全不用关心分片。<br>我们唯一需要做的仅仅是选择一个索引名。这个名字必须是全部小写，不能以下划线开头，不能包含逗号。</p>
</blockquote>
<h3 id="type"><a href="#type" class="headerlink" title="_type"></a>_type</h3><p>在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一个类(class)，这个类定义了属性或与对象关联的数据。user类的对象可能包含姓名、性别、年龄和Email地址。</p>
<p>在Elasticsearch中，我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的。</p>
<ul>
<li>每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。</li>
<li>所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。</li>
<li>_type的名字可以是大写或小写，不能包含下划线或逗号。我们将使用blog做为类型名。</li>
</ul>
<h3 id="id"><a href="#id" class="headerlink" title="_id"></a>_id</h3><p>id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档，你可以自定义_id，也可以让Elasticsearch帮你自动生成。</p>
<h1 id="Index-索引"><a href="#Index-索引" class="headerlink" title="Index 索引"></a>Index 索引</h1><p>文档通过index API被索引——使数据可以被存储和搜索。<br>但是首先需要决定文档所在。文档通过其_index、_type、_id唯一确定。</p>
<h1 id="Elasticsearch-CRUD"><a href="#Elasticsearch-CRUD" class="headerlink" title="Elasticsearch CRUD"></a>Elasticsearch CRUD</h1><h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>request：<code>GET /{_index}/{_type}/{_id}?pretty</code>，如<code>/website/blog/123?pretty</code>；<br>response：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_index"</span> :   <span class="string">"website"</span>,</span><br><span class="line">  <span class="attr">"_type"</span> :    <span class="string">"blog"</span>,</span><br><span class="line">  <span class="attr">"_id"</span> :      <span class="string">"123"</span>,</span><br><span class="line">  <span class="attr">"_version"</span> : <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"found"</span> :    <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"_source"</span> :  &#123;</span><br><span class="line">      <span class="attr">"title"</span>: <span class="string">"My first blog entry"</span>,</span><br><span class="line">      <span class="attr">"text"</span>:  <span class="string">"Just trying this out..."</span>,</span><br><span class="line">      <span class="attr">"date"</span>:  <span class="string">"2014/01/01"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="pretty"><a href="#pretty" class="headerlink" title="pretty"></a>pretty</h3><blockquote>
<p>在任意的查询字符串中增加pretty参数，类似于上面的例子。会让Elasticsearch美化输出(pretty-print)JSON响应以便更加容易阅读。_source字段不会被美化，它的样子与我们输入的一致。</p>
</blockquote>
<h3 id="检索部分文档"><a href="#检索部分文档" class="headerlink" title="检索部分文档"></a>检索部分文档</h3><p>通常，GET请求将返回文档的全部，存储在_source参数中。</p>
<ul>
<li>请求个别字段可以使用_source参数。多个字段可以使用逗号分隔，如<code>GET /website/blog/123?_source=title,text</code>；</li>
<li>只想得到_source字段而不要其他的元数据，你可以这样请求：<code>GET /website/blog/123/_source</code>；</li>
</ul>
<h3 id="检查文档是否存在"><a href="#检查文档是否存在" class="headerlink" title="检查文档是否存在"></a>检查文档是否存在</h3><p>如果你想做的只是检查文档是否存在——你对内容完全不感兴趣——使用HEAD方法来代替GET。HEAD请求不会返回响应体，只有HTTP头：</p>
<ul>
<li>存在返回<code>200 OK</code>状态：</li>
<li>不存在返回<code>404 Not Found</code>：</li>
</ul>
<h3 id="mget批量查询"><a href="#mget批量查询" class="headerlink" title="mget批量查询"></a>mget批量查询</h3><p>从Elasticsearch中检索多个文档，相对于逐条get检索，更快的方式是在一个请求中使用multi-get或者mget API。</p>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>文档在Elasticsearch中是不可变的——我们不能修改他们。如果需要更新已存在的文档，可以使用index API 重建索引(reindex) 或者替换掉它。<br>在内部，Elasticsearch已经标记旧文档为删除并添加了一个完整的新文档。旧版本文档不会立即消失，但你也不能去访问它。<br>Elasticsearch会在你继续索引更多数据时清理被删除的文档。</p>
<h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>当索引一个文档，如何确定是完全创建了一个新的还是覆盖了一个已经存在的呢？<br>请记住<code>_index、_type、_id</code>三者唯一确定一个文档。</p>
<h3 id="Elasticsearch自动生成唯一-id"><a href="#Elasticsearch自动生成唯一-id" class="headerlink" title="Elasticsearch自动生成唯一_id"></a>Elasticsearch自动生成唯一_id</h3><p>所以要想保证文档是新加入的，最简单的方式是使用POST方法让Elasticsearch自动生成唯一_id：<br><code>POST /website/blog/</code> </p>
<h3 id="自定义的-id"><a href="#自定义的-id" class="headerlink" title="自定义的_id"></a>自定义的_id</h3><p>如果使用自定义的_id，必须告诉Elasticsearch应该在<code>_index、_type、_id</code>三者都不同时才接受请求。有两种实现方式</p>
<ol>
<li>使用op_type查询参数：<code>PUT /website/blog/123?op_type=create</code>；</li>
<li>在URL后加/_create做为端点：<code>PUT /website/blog/123/_create</code>；</li>
</ol>
<p>响应结果</p>
<ul>
<li>如果请求成功的创建了一个新文档，Elasticsearch将返回正常的元数据且响应状态码是<code>201 Created</code>；</li>
<li>如果包含相同的_index、_type和_id的文档已经存在，Elasticsearch将返回<code>409 Conflict</code>响应状态码；</li>
</ul>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>使用DELETE方法：<code>DELETE /website/blog/123</code>；</p>
<ul>
<li>如果文档被找到，Elasticsearch将返回200 OK状态码和以下响应体。注意_version数字已经增加了。 </li>
<li>如果文档未找到，我们将得到一个404 Not Found状态码， </li>
</ul>
<blockquote>
<p><em>. 尽管文档不存在——“found”的值是false——_version依旧增加了。这是内部记录的一部分，它确保在多节点间不同操作可以有正确的顺序。
</em>. 除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才会在后台进行删除内容的清理。</p>
</blockquote>
<h2 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h2><p>就像mget允许一次性检索多个文档一样，<br><code>bulk API</code>允许我们使用单一请求来实现多个文档的<code>create、index、update或delete</code>‘；这对索引类似于日志活动这样的数据流非常有用，它们可以以成百上千的数据为一个批次按序进行索引。<br>bulk请求体如下，它有一点不同寻常：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123; action: &#123; metadata &#125;&#125;\n</span><br><span class="line">&#123; request body        &#125;\n</span><br><span class="line">&#123; action: &#123; metadata &#125;&#125;\n</span><br><span class="line">&#123; request body        &#125;\n</span><br></pre></td></tr></table></figure>
<p>这种格式类似于用”\n”符号连接起来的一行一行的JSON文档流(stream)。两个重要的点需要注意：</p>
<ul>
<li>每行必须以”\n”符号结尾，包括最后一行。这些都是作为每行有效的分离而做的标记。</li>
<li>每一行的数据不能包含未被转义的换行符，它们会干扰分析——这意味着JSON不能被美化打印。</li>
</ul>
<p><a href="http://es.xiaoleilu.com/040_Distributed_CRUD/35_Bulk_format.html">为什么bulk API需要带换行符的奇怪格式，而不是像mget API一样使用JSON数组？</a><br>在分布式环境下，Elasticsearch则从网络缓冲区中一行一行的直接读取数据。它使用换行符识别和解析action/metadata行，以决定哪些分片来处理这个请求。这利于任务分解，可以减少JSON序列化RAM消耗，从而降低JVM GC时间；</p>
<h3 id="行为-action"><a href="#行为-action" class="headerlink" title="行为(action)"></a>行为(action)</h3><p>action/metadata这一行定义了文档行为(what action)发生在哪个文档(which document)之上。</p>
<p>行为(action)必须是以下几种：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">行为</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">create</td>
<td style="text-align:left">当文档不存在时创建之。</td>
</tr>
<tr>
<td style="text-align:left">index</td>
<td style="text-align:left">创建新文档或替换已有文档。</td>
</tr>
<tr>
<td style="text-align:left">update</td>
<td style="text-align:left">局部更新文档。</td>
</tr>
<tr>
<td style="text-align:left">delete</td>
<td style="text-align:left">删除一个文档。</td>
</tr>
</tbody>
</table>
</div>
<p>在索引、创建、更新或删除时必须指定文档的<code>_index、_type、_id</code>这些元数据(metadata)。</p>
<h3 id="请求体-request-body"><a href="#请求体-request-body" class="headerlink" title="请求体(request body)"></a>请求体(request body)</h3><p>请求体由文档的_source组成——文档所包含的一些字段以及其值，即提供文档用来检索。</p>
<ul>
<li>update操作需要请求体，请求体的组成应该与update API（doc, upsert, script等等）一致。</li>
<li>delete操作不需要请求体(request body)。</li>
</ul>
<h3 id="响应结果"><a href="#响应结果" class="headerlink" title="响应结果"></a>响应结果</h3><p>每个子请求都被独立的执行，所以一个子请求的错误并不影响其它请求。<br>如果任何一个请求失败，顶层的error标记将被设置为true，然后错误的细节将在相应的请求中被报告：</p>
<h3 id="请求最佳大小（sweetspot）"><a href="#请求最佳大小（sweetspot）" class="headerlink" title="请求最佳大小（sweetspot）"></a>请求最佳大小（sweetspot）</h3><p>整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。<br>有一个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。<br>最佳大小，当然并不是一个固定的数字。它完全取决于硬件、文档的大小和复杂度以及索引和搜索的负载。  </p>
<p>如何找到最佳点(sweetspot)：</p>
<ul>
<li>试着批量索引标准的文档，随着大小的增长，当性能开始降低，说明每个批次的大小太大了。</li>
<li>开始的数量可以在1000~5000个文档之间，如果文档非常大，可以使用较小的批次。</li>
<li>通常着眼于请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的批次最好保持在5-15MB大小间。</li>
</ul>
<h1 id="Shard和Replica"><a href="#Shard和Replica" class="headerlink" title="Shard和Replica"></a>Shard和Replica</h1><h2 id="shard分片"><a href="#shard分片" class="headerlink" title="shard分片"></a>shard分片</h2><p>每个Index（对应Database）包含多个Shard，默认是5个，分散在不同的Node上，但不会存在两个相同的Shard存在一个Node上，这样就没有备份的意义了。Shard是一个最小的Lucene索引单元。<br>当插入document的时候，Elasticsearch通过对docid进行hash来确定其放在哪个shard上面，然后在shard上面进行索引存储。<br>shard代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。</p>
<h2 id="replica副本"><a href="#replica副本" class="headerlink" title="replica副本"></a>replica副本</h2><p>replicas就是备份，Elasticsearch采用的是Push Replication模式，当你往 master主分片上面索引一个文档，该分片会复制该文档(document)到剩下的所有 replica副本分片中，这些分片也会索引这个文档。<br>es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
<h1 id="gateway"><a href="#gateway" class="headerlink" title="gateway"></a>gateway</h1><p>代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再 重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和 amazon的s3云存储服务。</p>
<h1 id="discovery-zen"><a href="#discovery-zen" class="headerlink" title="discovery.zen"></a>discovery.zen</h1><p>代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。</p>
<h1 id="Transport"><a href="#Transport" class="headerlink" title="Transport"></a>Transport</h1><p>代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。</p>
<h1 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a>analyzer</h1><p>分布式搜索elasticsearch中文分词集成：elasticsearch官方只提供smartcn这个中文分词插件，效果不是很好，好在国内有medcl大神写的两个中文分词插件，一个是<a href="https://github.com/medcl/elasticsearch-analysis-ik">IKAnalyzer分词插件</a>的，一个是<a href="https://github.com/medcl/elasticsearch-analysis-mmseg">mmseg</a>的</p>
<h2 id="IKAnalyzer分词安装"><a href="#IKAnalyzer分词安装" class="headerlink" title="IKAnalyzer分词安装"></a>IKAnalyzer分词安装</h2><p>下载elasticsearch-analysis-ik源码并打包<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/medcl/elasticsearch-analysis-ik</span><br><span class="line">cd elasticsearch-analysis-ik</span><br><span class="line">mvn clean</span><br><span class="line">mvn compile</span><br><span class="line">mvn package</span><br></pre></td></tr></table></figure><br>拷贝和解压release下的文件: #{project_path}/elasticsearch-analysis-ik/target/releases/elasticsearch-analysis-ik-*.zip 到你的 elasticsearch 插件目录, 如: plugins/ik 重启elasticsearch </p>
<h2 id="IKAnalyzer测试中文分词"><a href="#IKAnalyzer测试中文分词" class="headerlink" title="IKAnalyzer测试中文分词"></a>IKAnalyzer测试中文分词</h2><p>IKAnalyzer分词测试：<a href="http://es1.es.com:9200/mycompany/_analyze?analyzer=ik&amp;pretty=true&amp;text=中华人民共和国国歌">http://es1.es.com:9200/mycompany/_analyze?analyzer=ik&amp;pretty=true&amp;text=中华人民共和国国歌</a></p>
<h2 id="对指定field建全文索引"><a href="#对指定field建全文索引" class="headerlink" title="对指定field建全文索引"></a>对指定field建全文索引</h2><ul>
<li>对index=cloudx_web_v3,type=T_EVENT_LOG的name字段以IKAnalyzer建全文索引<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”analyzer”:”ik”,”search_analyzer”:”ik”}}}}’</li>
<li>测试索引：curl -XPOST <a href="http://es1.es.com:9200/cloudx_web_v3/_search?pretty">http://es1.es.com:9200/cloudx_web_v3/_search?pretty</a>  -d ‘{“query”:{“match”:{“name”:{“query”:”规则 专用”,”operator”:”and”}}}}’ </li>
</ul>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="field-must-be-set-when-search-analyzer-is-set"><a href="#field-must-be-set-when-search-analyzer-is-set" class="headerlink" title="field must be set when search_analyzer is set"></a>field must be set when search_analyzer is set</h3><ul>
<li>请求参数：<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”indexAnalyzer”:”ik”,”searchAnalyzer”:”ik”}}}}’</li>
<li><p>问题日志：<br>{“error”:{“root_cause”:[{“type”:”mapper_parsing_exception”,”reason”:”analyzer on field [name] must be set when search_analyzer is set”}],”type”:”mapper_parsing_exception”,”reason”:”analyzer on field [name] must be set when search_analyzer is set”},”status”:400}</p>
</li>
<li><p>问题解决：参考旧版本教程的坑，V2.3.4的参数改了，应为<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”analyzer”:”ik”,”search_analyzer”:”ik”}}}}’</p>
</li>
</ul>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="如何合理设置shard和replica"><a href="#如何合理设置shard和replica" class="headerlink" title="如何合理设置shard和replica"></a>如何合理设置shard和replica</h2><p><a href="http://www.cnblogs.com/richaaaard/p/5231905.html">ElasticSearch性能调优-Shard数</a></p>
<h3 id="shard数"><a href="#shard数" class="headerlink" title="shard数"></a>shard数</h3><ul>
<li><p>shard数==node数时<br>此时性能最佳，但是由于ElasticSearch的不可变性（Immutable）的限制，系统无法对Shard进行重新拆分分配，除非重新索引这个文件集合，而重建索引开销巨大,所以，为了支持未来可能的水平扩展，一般会为集群分配比node数更多的shard数，也就是说每个节点会有多个Shard。</p>
</li>
<li><p>shard数==node数*2<br>shard过多就会引入另外一系列的性能问题，如对于任意一次完整的搜索，ElasticSearch会分别对每个shard进行查询，最后进行汇总。当节点数和shard数是一对一的时候，所有的查询可以并行运行。但是，对于具有多个shard的节点，如果磁盘是15000RPM或SSD，可能会相对较快，但是这也会存在等待响应的问题，所以通常不推荐一个节点超过2个shard。</p>
</li>
</ul>
<h3 id="replica数"><a href="#replica数" class="headerlink" title="replica数"></a>replica数</h3><p>Replica也是Shard，与shard不同的是，replica只会参与读操作，同时也能提高集群的可用性。<br>对于Replica来说，它的主要作用就是提高集群错误恢复的能力，所以replica的数目与shard的数目以及node的数目相关，<br>与shard不同的是，replica的数目可以在集群建立之后变更，且代价较小，所以相比shard的数目而言，没有那么重要。<br>3 node, 3 shard, 1 replica (each)，2个node宕机，服务仍然正常运行。</p>
<h2 id="如何防止elasticsearch的脑裂问题"><a href="#如何防止elasticsearch的脑裂问题" class="headerlink" title="如何防止elasticsearch的脑裂问题"></a><a href="https://segmentfault.com/a/1190000004504225">如何防止elasticsearch的脑裂问题</a></h2><blockquote>
<p>如果刚开始使用elasticsearch，建议配置一个3节点集群。这样你可以设置minimum_master_nodes为2，减少了脑裂的可能性，但仍然保持了高可用的优点：你可以承受一个节点失效但集群还是正常运行的。<br>但如果已经运行了一个两节点elasticsearch集群怎么办？可以选择为了保持高可用而忍受脑裂的可能性，或者选择为了防止脑裂而选择高可用性。为了避免这种妥协，最好的选择是给集群添加一个节点。这听起来很极端，但并不是。<br>对于每一个elasticsearch节点你可以设置node.data参数来选择这个节点是否需要保存数据。缺省值是“true”，意思是默认每个elasticsearch节点同时也会作为一个数据节点。<br>在一个两节点集群，你可以添加一个新节点并把node.data参数设置为“false”。这样这个节点不会保存任何分片，但它仍然可以被选为主（默认行为）。因为这个节点是一个无数据节点，所以它可以放在一台便宜服务器上。<br>现在你就有了一个三节点的集群，可以安全的把minimum_master_nodes设置为2，避免脑裂而且仍然可以丢失一个节点并且不会丢失数据。</p>
<p>If discovery.zen.master_election.filter_client is true </p>
<ol>
<li>pings from client nodes (nodes where node.client is true, or both node.data and node.master are false) are ignored during master election; the default value is true.   </li>
<li>pings from non-master-eligible data nodes (nodes where node.data is true and node.master is false) are ignored during master election; the default value is false.   </li>
<li>Pings from master-eligible nodes are always observed during master election.  </li>
</ol>
<p>Nodes can be excluded from becoming a master by setting node.master to false.<br>Note, once a node is a client node (node.client set to true), it will not be allowed to become a master (node.master is automatically set to false).</p>
</blockquote>
<p>master和data同时配置会产生一些神奇的效果：</p>
<ol>
<li>当master为false，而data为true时，会对该节点产生严重负荷；</li>
<li>当master为true，而data为false时，该节点作为一个协调者； </li>
<li>当master为false，data也为false时，该节点就变成了一个负载均衡器。 </li>
</ol>
<h2 id="如何给Elasticsearch设置合适的Heap内存"><a href="#如何给Elasticsearch设置合适的Heap内存" class="headerlink" title="如何给Elasticsearch设置合适的Heap内存"></a><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html">如何给Elasticsearch设置合适的Heap内存</a></h2><p>设置Elastic Heap内存（for Elasticsearch faster GCs）：<code>export ES_HEAP_SIZE=3g</code>，<br>建议分配可用内存的50%给ElasticSearch（如<code>aggregating on analyzed string fields</code>比较少的话，可以设置更小，以留下足够的空闲内存给lucene），<br>注意Lucene的segments是不可变的，为提高聚合和倒排索引的性能，lucene需要占用系统内存作为缓存</p>
<h2 id="如何删除document中的重复数据？"><a href="#如何删除document中的重复数据？" class="headerlink" title="如何删除document中的重复数据？"></a>如何删除document中的重复数据？</h2><p><a href="https://qbox.io/blog/minimizing-document-duplication-in-elasticsearch">minimizing-document-duplication-in-elasticsearch</a><br><a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_search?pretty=true">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_search?pretty=true</a> -d <code>{json}</code><br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"duplicateCount"</span>: &#123;</span><br><span class="line">            <span class="attr">"terms"</span>: &#123;</span><br><span class="line">                <span class="attr">"field"</span>: <span class="string">"name"</span>,</span><br><span class="line">                <span class="attr">"min_doc_count"</span>: <span class="number">2</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">                <span class="attr">"duplicateDocuments"</span>: &#123;</span><br><span class="line">                    <span class="attr">"top_hits"</span>: &#123;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="ES参考资料"><a href="#ES参考资料" class="headerlink" title="ES参考资料"></a>ES参考资料</h1><ul>
<li><a href="http://www.cnblogs.com/richaaaard/category/783901.html">Richaaaard的Elasticsearch系列教程</a></li>
<li><a href="https://github.com/garyelephant/blog/blob/master/elasticsearch_optimization_checklist.md">ES调优参数列表</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Drools学习笔记</title>
    <url>/2016/08/22/Drools%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>You can build a simple rules engine yourself. All you need is to create a bunch of objects with conditions and actions, store them in a collection, and run through them to evaluate the conditions and execute the actions.<br>                -Martin Fowler</p>
<hr>
<a id="more"></a> 
<h1 id="为什么会有规则引擎-？"><a href="#为什么会有规则引擎-？" class="headerlink" title="为什么会有规则引擎 ？"></a>为什么会有规则引擎 ？</h1><p>背景：复杂企业级项目的开发以及其中随外部条件不断变化的业务规则（business logic），迫切需要分离商业决策者的商业决策逻辑和应用开发者的技术决策，并把这些商业决策放在中心数据库或其他统一的地方，让它们能在运行时（即商务时间）可以动态地管理和修改从而提供软件系统的柔性和适应性。规则引擎正是应用于上述动态环境中的一种解决方法。</p>
</blockquote>
<p>企业管理者对企业级IT系统的开发有着如下的要求：</p>
<ul>
<li>为提高效率，管理流程必须自动化，即使现代商业规则异常复杂；</li>
<li>市场要求业务规则经常变化，IT系统必须依据业务规则的变化快速、低成本的更新；</li>
<li>为了快速、低成本的更新，业务人员应能直接管理IT系统中的规则，不需要程序开发人员参与；</li>
</ul>
<h1 id="什么是规则引擎-？"><a href="#什么是规则引擎-？" class="headerlink" title="什么是规则引擎 ？"></a>什么是规则引擎 ？</h1><p>也许这又是一种“先有蛋还是先有鸡”哲学争论，在JSR-94种也几乎没有定义,规则引擎这个术语是非常不明确的，因为任何以任意形式使用能够应用于数据生成结果的规则的系统都可以称为规则引擎。包括像表单验证和动态表达式引擎这样的简单系统都可以称之为规则引擎。<br>可以这样理解规则引擎由推理引擎发展而来，是一种嵌入在应用程序中的组件，实现了将业务决策从应用程序代码中分离出来，并使用预定义的语义模块编写业务决策。接受数据输入，解释业务规则，并根据规则做出业务决策。</p>
<blockquote>
<p>Drools is Rule Engine or a Production Rule System（产生式规则系统） that uses the rule-based approach to implement and Expert System. Expert Systems（专家系统） are knowledge-based systems that use knowledge representation（知识表达） to process acquired knowledge into a knowledge base（知识库） that can be used for reasoning（推理）.<br>A Production Rule System is Turing complete with a focus on knowledge representation to express propositional and first-order logic in a concise, non-ambiguous and declarative manner.<br>The brain of a Production Rules System is an Inference Engine（推理机） that can scale to a large number of rules and facts. The Inference Engine matches facts and data against Production Rules（根据规则匹配数据和事实）<br>– also called Productions or just Rules – to infer conclusions which result in actions.<br>A Production Rule is a two-part structure that uses first-order logic（一阶逻辑） for reasoning over knowledge representation.<br>A business rule engine（商业规则引擎） is a software system that executes one or more business rules in a runtime production environment.<br>A Rule Engine（定义做什么而不是怎么做） allows you to define “What to Do”（声明式编程） and not “How to do it.”（命令式编程）</p>
</blockquote>
<h2 id="规则引擎的优点"><a href="#规则引擎的优点" class="headerlink" title="规则引擎的优点"></a>规则引擎的优点</h2><h3 id="Declarative-Programming（声明式编程）"><a href="#Declarative-Programming（声明式编程）" class="headerlink" title="Declarative Programming（声明式编程）"></a>Declarative Programming（声明式编程）</h3><p>规则引擎允许你描述做什么而不是如何去做。<br>这里的主要优点是使用规则更加容易对复杂的问题进行表述，并得到验证。 (规则比编码更容易阅读).<br>规则系统能够解决非常非常困难的问题，并提供了方案怎样达到和在解决问题的方向上所作的每一个决定的原因（这对于类似神经网络这样的AI系统来说不容易达到）<br>与code不同，DSL易于编写复杂业务逻辑，对复杂问题的描述也变得简单化，且更易于阅读，理解和核查。<br>如SQL和D3.js也是声明式编程</p>
<h3 id="Logic-and-Data-Separation（逻辑与数据分离）"><a href="#Logic-and-Data-Separation（逻辑与数据分离）" class="headerlink" title="Logic and Data Separation（逻辑与数据分离）"></a>Logic and Data Separation（逻辑与数据分离）</h3><p>The data resides in the Domain Objects and the business logic resides in the Rules. Depending upon the kind of project, this kind of separation can be very advantageous.<br>数据保存在系统对象中，逻辑保存在规则中。这根本性的打破了面向对象系统中将数据和逻辑耦合起来的局面，这点是有利的也是不利的，在于你的观察角度。<br>这样做的结果是，未来逻辑发生改变时更容易被维护，因为逻辑保存在规则中，这点在逻辑是跨领域或多领域中使用时尤其有用。<br>通过将逻辑集中在一个或数个清晰的规则文件中，取代了之前分散在代码中的局面。</p>
<h3 id="Speed-and-Scalability（速度和可测量性）"><a href="#Speed-and-Scalability（速度和可测量性）" class="headerlink" title="Speed and Scalability（速度和可测量性）"></a>Speed and Scalability（速度和可测量性）</h3><p>The Rete OO algorithm on which Drools is written is already a proven algorithm. With the help of Drools, your application becomes very scalable. If there are frequent change requests, one can add new rules without having to modify the existing rules.<br>Rete算法、Leaps算法,以及由此衍生出来的 Drools的 Rete、Leaps算法，提供了对系统数据对象非常有效率的匹配。这些都是高效率尤其当你的数据是不完全的改变（规则引擎能够记得之前的匹配）。这些算法经过了大量实际考验的证明。</p>
<h3 id="Centralization-of-Knowledge（集中化知识管理）"><a href="#Centralization-of-Knowledge（集中化知识管理）" class="headerlink" title="Centralization of Knowledge（集中化知识管理）"></a>Centralization of Knowledge（集中化知识管理）</h3><p>By using Rules, you create a repository of knowledge (a knowledge base) which is executable. It is a single point of truth for business policy. Ideally, Rules are so readable that they can also serve as documentation.<br>通过使用规则，将建立一个可执行的规则库。这意味着规则库代表着现实中的业务策略的唯一对应，理想情况下可读性高的规则还可以被当作文档使用。</p>
<h3 id="Tool-Integration（工具集成）"><a href="#Tool-Integration（工具集成）" class="headerlink" title="Tool Integration（工具集成）"></a>Tool Integration（工具集成）</h3><p>Tools such as Eclipse provide ways to edit and manage rules and get immediate feedback, validation, and content assistance. Auditing and debugging tools are also available.<br>例如Eclipse（将来可能在基于Web的界面上）这样的工具为规则的修改与管理、即时获得反馈、内容验证与修补提供了办法。审查与调试工具同样也可用了。</p>
<h1 id="什么情况下使用规则引擎-？"><a href="#什么情况下使用规则引擎-？" class="headerlink" title="什么情况下使用规则引擎 ？"></a>什么情况下使用规则引擎 ？</h1><p>最简短的回答就是“当没有令人满意的传统的程序设计方法能够解决这个问题时”。<br>下面对这个所谓的传统解决方法的一个描述：</p>
<ul>
<li>对于传统代码来说，问题需要的精确度太高。</li>
<li>这种问题可能并不复杂，但是你找不到一种稳定的方法去建立它。</li>
<li>问题超越了任何有明显运算法则的方案。</li>
<li>它是一个难以解决的复杂问题，没有明显的传统解决方案或者问题没有一个准确的定论。</li>
<li>业务逻辑经常发生改变：逻辑本身是简单的（但不是指过于简单），但是规则经常发生变化。在许多软件组织中正式版本的间隔是较长并且较少的，规则可以在适当的安全前提下帮助提供一定的敏捷性。</li>
<li>领域专家（或者业务分析师）是非技术人员：领域专家通常对业务规则和流程具有很好的认知。他们通常是不了解软件技术的人员，但是具有很好的逻辑性。规则能够让他们用自己的术语来描述业务逻辑。当然他们仍然需要严密的思考和良好的逻辑思维能力（许多在非软件技术型岗位上的人没有进行过形式逻辑的训练，因此在和他们工作时要特别小心，在将业务知识编撰成规则时，要特别注意业务规则和流程应当是当前能够理解的）。</li>
</ul>
<h1 id="什么情况下不能使用规则引擎-？"><a href="#什么情况下不能使用规则引擎-？" class="headerlink" title="什么情况下不能使用规则引擎 ？"></a>什么情况下不能使用规则引擎 ？</h1><ul>
<li>因为规则引擎是动态的 (动态的在这里意味着规则可以象数据一样保存、管理和更新),它们通常被看作发布软件系统的一种解决方案(大多数IT部门似乎存在的目的是防止软件系统被遗弃)。如果这是你希望使用规则引擎的原因，应当意识到在可以写出公开发布的规则时，规则引擎能够以最佳方式工作。</li>
<li>另一个方面，你也可以考虑使用数据驱动的设计（查找表）或者脚本/流程引擎等有能够在数据库中管理并能够动态更新的脚本。对特定的工作要使用恰当的工具。<br>当然，必要时老虎钳可以当作锤子用，但那并不是发明老虎钳的本意。”</li>
</ul>
<h1 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h1><p>一个应用程序一般可分为3部分：一个和用户交互的前台(UI), 一个和后台系统，例如数据库交互的服务层(DAO)，以及他们中间的业务逻辑(BLL)。<br>使用框架构建前台和后台系统已经成为普遍共识，如 Spring , Struts，Hibernate，Mybatis等；<br>而没有一个标准的方法来构建业务逻辑，为什么没有一个框架来替换冗繁，易错的if…then语句呢，这个框架应该和其它前台或后台框架一样，易于配置，具有可读性和重用性。<br>Drools 规则引擎就是解决我们这个问题的框架。 </p>
<p>Drools是一个基于java的规则引擎，开源的，可以将复杂多变的规则从硬编码中解放出来，以规则脚本的形式存放在文件中，使得规则的变更不需要修正代码重启机器就可以立即在线上环境生效。</p>
<blockquote>
<p>Drools is a business rule management system (BRMS) with a forward and backward chaining inference based rules engine, more correctly known as a production rule system, using an enhanced implementation of the Rete algorithm.</p>
<p>KIE (Knowledge Is Everything) is the new umbrella name to drools, optaPlanner, jBPM, Guvnor, uberFire and related technologies.<br>Drools supports the JSR-94 standard for its business rule engine and enterprise framework for the construction, maintenance, and enforcement of business policies in an organization, application, or service.</p>
<p>Drools is a Business Logic integration Platform (BLiP). It is written in Java. It is an open source project that is backed by JBoss and Red Hat, Inc. It extends and implements the Rete Pattern matching algorithm（实现并扩展了Rete模式匹配算法）.<br>In layman’s terms, Drools is a collection of tools that allow us to separate and reason over logic and data found within business processes（分离数据与业务逻辑，推理）. The two important keywords we need to notice are Logic and Data.</p>
</blockquote>
<p>Drools 分为两个主要部分：构建（ Authoring ）和运行时（ Runtime ）。</p>
<h2 id="Authoring（构建）"><a href="#Authoring（构建）" class="headerlink" title="Authoring（构建）"></a>Authoring（构建）</h2><p>构建的过程涉及到.drl或.xml规则文件的创建，它们被读入一个解析器，使用ANTLR3语法进行解析。<br>解析器对语法进行正确性的检查，然后产生一种中间结构“ descr ”， descr 用 AST 来描述规则。<br>AST 然后被传到PackageBuilder ，由 PackagBuilder 来产生 Packaged 对象。<br>PackageBuilder 还承担着一些代码产生和编译的工作，这些对于产生 Package 对象都时必需的。<br>Package 对象是一个可以配置的，可序列化的，由一个或多个规则组成的对象。</p>
<h2 id="Runtime（运行时）"><a href="#Runtime（运行时）" class="headerlink" title="Runtime（运行时）"></a>Runtime（运行时）</h2><p>It involves the creation of working memory(被推理机进行匹配的数据称为 WorkingMemory) and handling the activation.</p>
<h1 id="Rule（规则）"><a href="#Rule（规则）" class="headerlink" title="Rule（规则）"></a>Rule（规则）</h1><p>Rules are pieces of knowledge often expressed as, “When some conditions occur, then do some tasks.”<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rule  <span class="string">"&lt;name&gt;"</span></span><br><span class="line">      &lt;attribute&gt; &lt;value&gt;</span><br><span class="line">      </span><br><span class="line">      when</span><br><span class="line">         &lt;conditions&gt;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">then</span></span><br><span class="line">         &lt;actions&gt;</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<h1 id="Pattern-Matching（模式匹配）"><a href="#Pattern-Matching（模式匹配）" class="headerlink" title="Pattern Matching（模式匹配）"></a>Pattern Matching（模式匹配）</h1><p>对新的数据和被修改的数据进行规则的匹配称为模式匹配（ Pattern Matching ）。进行匹配的引擎称为推理机（Inference Engine ）。被访问的规则称为 ProductionMemory ，被推理机进行匹配的数据称为 WorkingMemory。 Agenda 管理被匹配规则的执行。<br>推理机所采用的模式匹配算法有下列几种： Linear，RETE，Treat，Leaps。<br>DroDrools是为Java量身定制的基于Charles  Forgy的RETE算法的规则引擎的实现。具有了OO接口的RETE,使得商业规则有了更自然的表达。</p>
<p>在规则引擎中，将知识表达为规则（rules），要分析的情况定义为事实（facts）。<br>二者在内存中的存储分别称为<code>Production Memory</code>和<code>Working Memory</code>，如下图：<br><img src="rules-inference_engine-facts.png" alt="rules-inference_engine-facts"><br>rules和facts是规则引擎接受的输入参数，而规则引擎本身包括两个组成部分：<code>Pattern Matcher</code>和<code>Agenda</code>。Pattern Matcher根据facts找到匹配的rules，Agenda管理PatternMatcher挑选出来的规则的执行次序。在外围，还会有一个执行引擎（Execution Engine）负责根据Agenda输出的rules执行具体的操作。</p>
<p>其中Pattern Matcher是规则引擎负责推理的核心。和人类的思维相对应，<br>规则引擎中也存在两种推理方式：<code>正向推理（Forward-Chaining）</code>和<code>反向推理（Backward-Chaining）</code>。</p>
<ul>
<li>正向推理也叫演绎法，由事实驱动，从 一个初始的事实出发，不断地应用规则得出结论。首先在候选队列中选择一条规则作为启用规则进行推理，记录其结论作为下一步推理时的证据。如此重复这个过程，直到再无可用规则可被选用或者求得了所要求的解为止。</li>
<li>反向推理也叫归纳法，由目标驱动，首先提出某个假设，然后寻找支持该假设的证据，若所需的证据都能找到，说明原假设是正确的；若无论如何都找不到所需要的证据，则说明原假设不成立，此时需要另做新的假设。</li>
</ul>
<p><a href="http://www.blogjava.net/guangnian0412/archive/2006/06/01/49712.html">RETE算法</a></p>
<h1 id="Drools-常用术语"><a href="#Drools-常用术语" class="headerlink" title="Drools-常用术语"></a>Drools-常用术语</h1><h2 id="Rules（规则）"><a href="#Rules（规则）" class="headerlink" title="Rules（规则）"></a>Rules（规则）</h2><p>The heart of the Rules Engine where you specify conditions (if ‘a’ then ‘b’).</p>
<p>业务调研中很重要的内容就是了解业务规则。在企业流程中，可能还会接触到流程规则。<br>在IT技术领域，很多地方也应用了规则，比如路由表，防火墙策略，乃至角色权限控制(RBAC)，或者Web框架中的URL匹配。<br>不管是哪种规则，都规定了一组确定的条件和此条件所产生的结果。</p>
<ul>
<li>每条规则都是一组条件决定的一系列结果；</li>
<li>一条规则可能与其他规则共同决定最终结果；</li>
<li>可能存在条件互相交叉的规则，此时有必要规定规则的优先级；</li>
</ul>
<h2 id="Facts（事实）"><a href="#Facts（事实）" class="headerlink" title="Facts（事实）"></a>Facts（事实）</h2><p>Facts are the data on which the rules will act upon.<br>From Java perspective, Facts are the POJO (Plain Old Java Object).</p>
<h2 id="KnowledgeBuilder"><a href="#KnowledgeBuilder" class="headerlink" title="KnowledgeBuilder"></a>KnowledgeBuilder</h2><p>KnowledgeBuilder是用来在业务代码中收集已经编好的规则，找到这些规则并把这些规则文件进行编译，<br>最终产生一批编译好的KnowledgePackage（规则包）给其它的应用程序使用。<br>创建KnowledgeBuilder对象使用的是KnowledgeBuilderFactory的newKnowledgeBuilder方法。</p>
<h2 id="Knowledge-Base"><a href="#Knowledge-Base" class="headerlink" title="Knowledge Base"></a>Knowledge Base</h2><ul>
<li>Knowledge Base是管理一系列rules, processes和 internal types的接口. 它在<code>org.drools.KnowledgeBase</code>包中；</li>
<li>KnowledgeBase 是Drools提供的用来收集应用当中知识（Knowledge）定义的知识库对象，在一个KnowledgeBase当中可以包含普通的规则、规则流、函数定义、用户自定义对象等；</li>
<li>KnowledgeBase本身不包含任何业务数据对象(fact 对象)，业务对象都是插入到由KnowledgeBase产生的两种类型的session对象；</li>
<li>一系列Knowledge definitions组成knowledge packages；</li>
<li>Knowledge definitions 可以新增和移除；</li>
<li>Knowledge Base的主要目的是为了重用，因为Knowledge definitions成本很高； </li>
<li>Knowledge Base 提供新建knowledge sessions的方法；</li>
</ul>
<h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><p>knowledge session是激发规则的核心组件，knowledge session容纳所有规则和资源， knowledge session由KnowledgeBase创建。<br>规则引擎工作时会将facts插入session中，当满足特定的condition时，对应的rule就会被激发。<br>knowledge session从knowledge base中获取，是与drools规则引擎交互的主要接口，knowledge session有两种类型:</p>
<h3 id="Stateful-Knowledge-Session"><a href="#Stateful-Knowledge-Session" class="headerlink" title="Stateful Knowledge Session"></a>Stateful Knowledge Session</h3><p>StatefulKnowledgeSession对象是一种最常用的与规则引擎进行交互的方式，它可以与规则引擎建立一个持续的交互通道。<br>StatefulKnowledgeSession执行完之后一定要调用dispose()方法释放资源。<br>StatefulKnowledgeSession可以接受外部插入(insert方法)的业务数据——也叫fact，一个对象通常可以对应一个普通的POJO, 而一个POJO有若干个属性来描述这个业务对象，比如一个PeopleEvent中包含了isComing(人是否进来属性), roomed(房间号)，每一个属性对应getter和setter方法，供规则定义来使用（注意：在规则定义中isComing默认的getter方法是getIsComing()）。<br>如果规则当中需要有数据传出，那么可以通过在StatefulKnowledgeSession当中设置global对象来实现，一个global对象也是一个普通的Java对象，在向StatefulKnowledgeSession当中设置global对象时不用insert方法而用setGlobal方法实现。</p>
<p>一些stateless session常用的用例：</p>
<ul>
<li>Monitoring 监控<br>Stock market monitoring and analysis for semi-automatic buying.</li>
<li>Diagnostics 诊断<br>Fault finding, medical diagnostics</li>
<li>Logistics<br>Parcel tracking and delivery provisioning  </li>
</ul>
<h3 id="Stateless-Knowledge-Session"><a href="#Stateless-Knowledge-Session" class="headerlink" title="Stateless Knowledge Session"></a>Stateless Knowledge Session</h3><p>Stateless Knowledge Session是一个无状态的session，形成最简单的用例，不利用推理<br>Stateless Knowledge Session可以像function一样被调用，可传入一些数据和接收一些结果。<br>一般 stateless session包括:</p>
<ul>
<li>Validation 验证<br>Is this person eligible for a mortgage?</li>
<li>Calculation 计算<br>Compute a mortgage premium.</li>
<li>Routing and Filtering 路由和过滤<br>Filter incoming messages, such as emails, into folders.<br>Send incoming messages to a destination</li>
</ul>
<h3 id="Stateless和Stateful两种session的区别"><a href="#Stateless和Stateful两种session的区别" class="headerlink" title="Stateless和Stateful两种session的区别"></a>Stateless和Stateful两种session的区别</h3><ul>
<li>StatelessKnowledgeSession是在StatefulKnowledgeSession基础上进行进一步的封装，</li>
<li>StatelessKnowledgeSession跟StatefulKnowledgeSession的区别就是它不需要调用dispose方法释放内存资源了，</li>
<li>StatelessKnowledgeSession不能重复的执行插入fact的操作、也不能重复的调用fireAllRules方法来执行所有的规则，因为它不能保存状态，<br>对应的这些要完成的工作在StatelessKnowledgeSession当中只有execute方法，通过这个方法可以实现插入所有的fact并且可以同时执行所有的规则或规则流。</li>
</ul>
<h2 id="MVEL（MVFLEX-Expression-Language-）"><a href="#MVEL（MVFLEX-Expression-Language-）" class="headerlink" title="MVEL（MVFLEX Expression Language ）"></a>MVEL（MVFLEX Expression Language ）</h2><p>MVEL is a hybrid dynamic/statically typed, embeddable Expression Language and runtime for the Java Platform.<br>MVEL is particularly ideal for restrictive environments that can’t use bytecode generation due to <code>memory restrictions</code> or sand boxing. Instead of trying to re-invent Java, it instead aims to provide a familiar syntax for Java programmers while also adding <code>syntactic sugar</code> for short and concise expressions.</p>
<h1 id="Rule-Attributes"><a href="#Rule-Attributes" class="headerlink" title="Rule Attributes"></a>Rule Attributes</h1><h2 id="ruleflow-group"><a href="#ruleflow-group" class="headerlink" title="ruleflow-group"></a>ruleflow-group</h2><h2 id="agenda-group"><a href="#agenda-group" class="headerlink" title="agenda-group"></a>agenda-group</h2><h2 id="activation-group"><a href="#activation-group" class="headerlink" title="activation-group"></a>activation-group</h2><h2 id="salience"><a href="#salience" class="headerlink" title="salience"></a>salience</h2><h2 id="no-loop"><a href="#no-loop" class="headerlink" title="no-loop"></a>no-loop</h2><h2 id="lock-on-action"><a href="#lock-on-action" class="headerlink" title="lock-on-action"></a>lock-on-action</h2><h2 id="Agenda"><a href="#Agenda" class="headerlink" title="Agenda"></a>Agenda</h2><p>The Agenda is a Rete feature. It maintains set of rules that are able to execute, its job is to schedule that execution in a deterministic order.</p>
<p>It’s a logical concept. The agenda is the logical place where activations are waiting to be fired.<br>Agenda是一个逻辑概念，逻辑上存储待执行规则（activations）。</p>
<h2 id="Activations（被匹配的规则）"><a href="#Activations（被匹配的规则）" class="headerlink" title="Activations（被匹配的规则）"></a>Activations（被匹配的规则）</h2><p>Activations are the ‘then’ part of the rule. Activations are placed in the agenda where the appropriate rule is fired.<br>Activations是rule的’then’部分，存储在Agenda中的已匹配但未激发的rule，即Activations；</p>
<h2 id="DRL规则文件的语法"><a href="#DRL规则文件的语法" class="headerlink" title="DRL规则文件的语法"></a>DRL规则文件的语法</h2><h2 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h2><p>Every Rule starts with a package name. The package acts as a namespace for Rules. Rule names within a package must be unique. Packages in Rules are similar to packages in Java.<br>package是Rules的命名空间，且必须唯一</p>
<h2 id="Import-statement"><a href="#Import-statement" class="headerlink" title="Import statement"></a>Import statement</h2><p>Whatever facts you want to apply the rule on, those facts needs to be imported.<br>导入定义Fatcs的className</p>
<h2 id="Rule-Definition"><a href="#Rule-Definition" class="headerlink" title="Rule Definition"></a>Rule Definition</h2><ul>
<li>Rule consists of the Rule Name, the condition, and the Consequence. </li>
<li>Drools keywords： rule, when, then,  end. </li>
<li>The when part is the condition in both the rules and the then part is the consequence. </li>
<li>In rule terminology, the when part is also called as LHS (left hand side) and the then part as the RHS (right hand side) of the rule.</li>
</ul>
<h1 id="Drools-API"><a href="#Drools-API" class="headerlink" title="Drools API"></a>Drools API</h1><p>规则引擎中，将知识表达为规则（rules），要分析的情况定义为事实（facts）。二者在内存中的存储分别称为Production Memory和Working Memory。在外围，还会有一个执行引擎（Execution Engine）。<br>与此对应，规则引擎API也分成三个部分。在Drools中，分别叫做Knowledge API，Fact API和Execution API。</p>
<h2 id="Knowledge-API"><a href="#Knowledge-API" class="headerlink" title="Knowledge API"></a>Knowledge API</h2><p>Drools将知识库(KnowledgeBase)作为JSR94中的规则执行集(RuleExecutionSet)。知识库中的知识以包(KnowledgePackage)为单位组合而成。每个包中聚合多个规则(Rule)。<br>通常，一个包中的内容会在一个或多个资源(Resource)中保存。资源的类型可以有很多种,如.drl 文件、.dslr 文件或 xls 文件等。<br>规则包还可以从规则流(rule flow) 文件中获取。</p>
<h2 id="Fact-API"><a href="#Fact-API" class="headerlink" title="Fact API"></a>Fact API</h2><p>要操作Working Memory，首先要建立规则引擎的一个会话。<br>Drools中的有状态会话和无状态会话分别为StatefulKnowledgeSession和StatelessKnowledgeSession，都可以由KnowledgeBase建立。<br>通过会话可以进行操作Fact对象，执行规则等交互。</p>
<h2 id="Execution-API"><a href="#Execution-API" class="headerlink" title="Execution API"></a>Execution API</h2><p>插入到WorkingMemory中的对象，并不是克隆，而是对原对象的引用。这就意味着引擎中可以改变外部的对象，这是引擎与外部数据交互的一个通道。<br>此外，insert()方法还会返回一个FactHandler，作为引擎中该Fact对象的一个句柄。<br>最后，session上可以注册AgendaEventListener、ProcessEventListener和WorkingMemoryEventListener，这也是常用的交互方式。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://www.iigrowing.cn/java_gui_ze_yin_qing_zong_jie.html">JAVA规则引擎总结</a><br><a href="http://holbrook.github.io/pages/tags.html#规则引擎-ref">心内求法-规则引擎系列博客</a><br><a href="http://martinfowler.com/bliki/RulesEngine.html">martinfowler-RulesEngine</a></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="drl逻辑编译问题"><a href="#drl逻辑编译问题" class="headerlink" title="drl逻辑编译问题"></a>drl逻辑编译问题</h2><p>据说drl中写的逻辑明明是对的，但是编译判断还是会有问题，待验证</p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Drools</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之B-Tree</title>
    <url>/2017/10/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BB-Tree/</url>
    <content><![CDATA[<p>B-tree is a tree data structure that keeps data sorted and allows <code>searches,sequential access, insertions, and deletions in logarithmic time</code>. The B-tree is a generalization of a binary search tree in that a node can have more than two children. Unlike self-balancing binary search trees, the B-tree is optimized for systems that <code>read and write large blocks of data</code>. It is commonly used in <code>databases</code> and <code>file-systems</code></p>
<p>B-树是一类树，包括B-树、B+树、B*树等，是一棵自平衡的搜索树，它类似普通的平衡二叉树，不同的一点是B-树允许每个节点有更多的子节点。B-树是专门为外部存储器设计的，如磁盘，它对于读取和写入大块数据有良好的性能，所以一般被用在文件系统及数据库中。</p>
<hr>
<a id="more"></a>
<h2 id="数据结构之B-Tree"><a href="#数据结构之B-Tree" class="headerlink" title="数据结构之B-Tree"></a>数据结构之B-Tree</h2><h1 id="外存储器—磁盘"><a href="#外存储器—磁盘" class="headerlink" title="外存储器—磁盘"></a>外存储器—磁盘</h1><p>计算机存储设备一般分为两种：<code>内存储器(main memory</code>)和<code>外存储器(external memory)</code>。 内存存取速度快，但容量小，价格昂贵，而且不能长期保存数据(在不通电情况下数据会消失)。<br>外存储器—磁盘是一种直接存取的存储设备(DASD)。它是以存取时间变化不大为特征的。可以直接存取任何字符组，且容量大、速度较其它外存设备更快。</p>
<h2 id="磁盘的读-写原理和效率"><a href="#磁盘的读-写原理和效率" class="headerlink" title="磁盘的读/写原理和效率"></a>磁盘的读/写原理和效率</h2><blockquote>
<p>磁盘是一个扁平的圆盘(与电唱机的唱片类似)。盘面上有许多称为磁道的圆圈，数据就记录在这些磁道上。磁盘可以是单片的，也可以是由若干盘片组成的盘组，每一盘片上有两个面。</p>
</blockquote>
<p>磁盘上数据必须用一个<code>三维地址</code>唯一标示：<code>柱面号、盘面号、块号(磁道上的盘块)</code>。<br>读/写磁盘上某一指定数据需要下面3个步骤：</p>
<ol>
<li>首先移动臂根据柱面号使磁头移动到所需要的<code>柱面</code>上，这一过程被称为<code>定位或查找</code> 。</li>
<li>根据盘面号来确定指定盘面上的<code>磁道</code>。</li>
<li>盘面确定以后，盘片开始旋转，将指定块号的磁道段移动至<code>磁头</code>下。</li>
</ol>
<p>经过上面三个步骤，指定数据的存储位置就被找到。这时就可以开始读/写操作了。<br>访问某一具体信息，由3部分时间组成：</p>
<ul>
<li><code>查找时间(seek time)</code> Ts: 完成上述步骤(1)所需要的时间。这部分时间代价最高，最大可达到0.1s左右。</li>
<li><code>等待时间(latency time)</code> Tl: 完成上述步骤(3)所需要的时间。由于盘片绕主轴旋转速度很快，一般为7200转/分(电脑硬盘的性能指标之一, 家用的普通硬盘的转速一般有5400rpm(笔记本)、7200rpm几种)。因此一般旋转一圈大约0.0083s。</li>
<li><code>传输时间(transmission time)</code> Tt: 数据通过系统总线传送到内存的时间，一般传输一个字节(byte)大概0.02us=2*10^(-8)s</li>
</ul>
<p>磁盘读取数据是以盘块(block)为基本单位的。位于同一盘块中的所有数据都能被一次性全部读取出来。而磁盘IO代价主要花费在查找时间Ts上。<br>因此我们应该尽量将相关信息存放在同一盘块，同一磁道中。或者至少放在同一柱面或相邻柱面上，以求在读/写信息时尽量减少磁头来回移动的次数，避免过多的查找时间Ts。</p>
<p>在大规模数据存储方面，大量数据存储在外存磁盘中，而在外存磁盘中读取/写入块(block)中某数据时，首先需要定位到磁盘中的某块，如何有效地查找磁盘中的数据，需要一种合理高效的外存数据结构，就是下面所要重点阐述的B-Tree结构，以及相关的变种结构：B+-Tree结构和B*-Tree结构。</p>
<h1 id="B-Tree（Balanced-Tree）"><a href="#B-Tree（Balanced-Tree）" class="headerlink" title="B-Tree（Balanced Tree）"></a>B-Tree（Balanced Tree）</h1><blockquote>
<p>B-tree is a tree data structure that keeps data sorted and allows <code>searches,sequential access, insertions, and deletions in logarithmic time</code>. The B-tree is a generalization of a binary search tree in that a node can have more than two children. Unlike self-balancing binary search trees, the B-tree is optimized for systems that <code>read and write large blocks of data</code>. It is commonly used in <code>databases</code> and <code>file-systems</code>.</p>
</blockquote>
<h1 id="B-Tree的定义"><a href="#B-Tree的定义" class="headerlink" title="B-Tree的定义"></a>B-Tree的定义</h1><p>B 树是为了磁盘或其它存储设备而设计的一种多叉（相对于二叉，B树每个内结点有多个分支，即多叉）平衡查找树。B-Tree在<code>降低磁盘I/0操作</code>方面要比红黑树更好一些。许多数据库系统都一般使用B树或者B树的各种变形结构。<br>B树与红黑树最大的不同在于，B树的结点可以有许多子女，从几个到几千个。</p>
<blockquote>
<p>为什么又说B树与红黑树很相似呢？</p>
</blockquote>
<p>因为B-Tree与红黑树一样，一棵含n个结点的B树的高度也为O（lgn），但可能比一棵红黑树的高度小许多，应为它的分支因子比较大。所以，B树可以在O（logn）时间内，实现各种如插入（insert），删除（delete）等动态集合操作。<br>如下图所示，即是一棵B树，一棵关键字为英语中辅音字母的B树，现在要从树种查找字母R（包含n[x]个关键字的内结点x，x有n[x]+1]个子女（也就是说，一个内结点x若含有n[x]个关键字，那么x将含有n[x]+1个子女）。<br>所有的叶结点都处于相同的深度，带阴影的结点为查找字母R时要检查的结点）：<br><img src="./1507623083018.png" alt="B-Tree示例"></p>
<h2 id="B-Tree的性质"><a href="#B-Tree的性质" class="headerlink" title="B-Tree的性质"></a>B-Tree的性质</h2><blockquote>
<p>一颗m阶树需满足以下条件：</p>
<ol>
<li>m阶树中每个节点最多有m个孩子；</li>
<li>树中每个非叶子节点（除了根节点）至少有ceil(m/2)个孩子；</li>
<li>若根节点不是叶子节点，则至少有2个孩子；</li>
<li>有k个孩子的非叶子节点包含k-1个key；</li>
<li>所有的叶子节点在同一层级；</li>
</ol>
<p>B树中的每个结点根据实际情况可以包含大量的关键字信息和分支(当然是不能超过磁盘块的大小，根据磁盘驱动(disk drives)的不同，一般块的大小在1k~4k左右)；这样<code>树的深度降低</code>了，这就意味着查找一个元素只要<code>很少结点从外存磁盘中读入内存，很快访问到要查找的数据</code>。</p>
</blockquote>
<h1 id="数据结构（源码）"><a href="#数据结构（源码）" class="headerlink" title="数据结构（源码）"></a>数据结构（源码）</h1><p><img src="B-Tree插入图.png" alt="B-Tree插入图"></p>
<blockquote>
<p>A B Tree insertion example with each iteration. The nodes of this B tree have at most 3 children </p>
</blockquote>
<h2 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B-Tree"></a>B-Tree</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BTree</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; <span class="keyword">implements</span> <span class="title">ITree</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// Default to 2-3 Tree</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> minKeySize = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> minChildrenSize = minKeySize + <span class="number">1</span>; <span class="comment">// 2</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxKeySize = <span class="number">2</span> * minKeySize; <span class="comment">// 2</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxChildrenSize = maxKeySize + <span class="number">1</span>; <span class="comment">// 3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node&lt;T&gt; root = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Constructor for B-Tree which defaults to a 2-3 B-Tree.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BTree</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">true    <span class="comment">/**</span></span><br><span class="line"><span class="comment">	     * Constructor for B-Tree of ordered parameter. Order here means minimum number of keys in a non-root node.</span></span><br><span class="line"><span class="comment">	     *</span></span><br><span class="line"><span class="comment">	     * <span class="doctag">@param</span> order of the B-Tree.</span></span><br><span class="line"><span class="comment">	     */</span></span><br><span class="line">true    <span class="function"><span class="keyword">public</span> <span class="title">BTree</span><span class="params">(<span class="keyword">int</span> order)</span> </span>&#123;</span><br><span class="line">true        <span class="keyword">this</span>.minKeySize = order;</span><br><span class="line">true        <span class="keyword">this</span>.minChildrenSize = minKeySize + <span class="number">1</span>;</span><br><span class="line">true        <span class="keyword">this</span>.maxKeySize = <span class="number">2</span> * minKeySize;</span><br><span class="line">true        <span class="keyword">this</span>.maxChildrenSize = maxKeySize + <span class="number">1</span>;</span><br><span class="line">true    &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="B-Tree节点"><a href="#B-Tree节点" class="headerlink" title="B-Tree节点"></a>B-Tree节点</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T[] keys = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> keysSize = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> Node&lt;T&gt;[] children = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> childrenSize = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> Comparator&lt;Node&lt;T&gt;&gt; comparator = <span class="keyword">new</span> Comparator&lt;Node&lt;T&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Node&lt;T&gt; arg0, Node&lt;T&gt; arg1)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> arg0.getKey(<span class="number">0</span>).compareTo(arg1.getKey(<span class="number">0</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> Node&lt;T&gt; parent = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Node</span><span class="params">(Node&lt;T&gt; parent, <span class="keyword">int</span> maxKeySize, <span class="keyword">int</span> maxChildrenSize)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.parent = parent;</span><br><span class="line">        <span class="keyword">this</span>.keys = (T[]) <span class="keyword">new</span> Comparable[maxKeySize + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">this</span>.keysSize = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">this</span>.children = <span class="keyword">new</span> Node[maxChildrenSize + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">this</span>.childrenSize = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="新增节点"><a href="#新增节点" class="headerlink" title="新增节点"></a>新增节点</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//空树，直接新增Node</span></span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">        root = <span class="keyword">new</span> Node&lt;T&gt;(<span class="keyword">null</span>, maxKeySize, maxChildrenSize);</span><br><span class="line">        root.addKey(value);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Node&lt;T&gt; node = root;</span><br><span class="line">        <span class="comment">//迭代子树</span></span><br><span class="line">        <span class="keyword">while</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//无children，直接新增到root节点</span></span><br><span class="line">            <span class="keyword">if</span> (node.numberOfChildren() == <span class="number">0</span>) &#123;</span><br><span class="line">                node.addKey(value);</span><br><span class="line">                <span class="comment">//节点key个数&lt;=最大key个数时，停止迭代</span></span><br><span class="line">                <span class="keyword">if</span> (node.numberOfKeys() &lt;= maxKeySize) &#123;</span><br><span class="line">                    <span class="comment">// A-OK</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//树节点分裂</span></span><br><span class="line">                split(node);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Navigate</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 比当前节点第1个值小或相等，从左孩子继续迭代</span></span><br><span class="line">            T lesser = node.getKey(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (value.compareTo(lesser) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                node = node.getChild(<span class="number">0</span>);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 比当前节点值大，从右孩子继续迭代</span></span><br><span class="line">            <span class="keyword">int</span> numberOfKeys = node.numberOfKeys();</span><br><span class="line">            <span class="keyword">int</span> last = numberOfKeys - <span class="number">1</span>;</span><br><span class="line">            T greater = node.getKey(last);</span><br><span class="line">            <span class="keyword">if</span> (value.compareTo(greater) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//取右孩子的最后一个key，继续迭代</span></span><br><span class="line">                node = node.getChild(numberOfKeys);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Search internal nodes</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; node.numberOfKeys(); i++) &#123;</span><br><span class="line">                T prev = node.getKey(i - <span class="number">1</span>);</span><br><span class="line">                T next = node.getKey(i);</span><br><span class="line">                <span class="keyword">if</span> (value.compareTo(prev) &gt; <span class="number">0</span> &amp;&amp; value.compareTo(next) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    node = node.getChild(i);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    size++;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="分裂节点"><a href="#分裂节点" class="headerlink" title="分裂节点"></a>分裂节点</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 节点key个数&gt;最大key个数时，取中值分裂</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> node to split.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">split</span><span class="params">(Node&lt;T&gt; nodeToSplit)</span> </span>&#123;</span><br><span class="line">      Node&lt;T&gt; node = nodeToSplit;</span><br><span class="line">      <span class="comment">//取中值</span></span><br><span class="line">      <span class="keyword">int</span> numberOfKeys = node.numberOfKeys();</span><br><span class="line">      <span class="keyword">int</span> medianIndex = numberOfKeys / <span class="number">2</span>;</span><br><span class="line">      T medianValue = node.getKey(medianIndex);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//分裂后的左节点及其孩子处理</span></span><br><span class="line">      Node&lt;T&gt; left = <span class="keyword">new</span> Node&lt;T&gt;(<span class="keyword">null</span>, maxKeySize, maxChildrenSize);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; medianIndex; i++) &#123;</span><br><span class="line">          left.addKey(node.getKey(i));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (node.numberOfChildren() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= medianIndex; j++) &#123;</span><br><span class="line">              Node&lt;T&gt; c = node.getChild(j);</span><br><span class="line">              left.addChild(c);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//分裂后的右节点及其孩子处理</span></span><br><span class="line">      Node&lt;T&gt; right = <span class="keyword">new</span> Node&lt;T&gt;(<span class="keyword">null</span>, maxKeySize, maxChildrenSize);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = medianIndex + <span class="number">1</span>; i &lt; numberOfKeys; i++) &#123;</span><br><span class="line">          right.addKey(node.getKey(i));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (node.numberOfChildren() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> j = medianIndex + <span class="number">1</span>; j &lt; node.numberOfChildren(); j++) &#123;</span><br><span class="line">              Node&lt;T&gt; c = node.getChild(j);</span><br><span class="line">              right.addChild(c);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//如果没有父节点，分裂节点作为父节点</span></span><br><span class="line">      <span class="keyword">if</span> (node.parent == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// new root, height of tree is increased</span></span><br><span class="line">          Node&lt;T&gt; newRoot = <span class="keyword">new</span> Node&lt;T&gt;(<span class="keyword">null</span>, maxKeySize, maxChildrenSize);</span><br><span class="line">          newRoot.addKey(medianValue);</span><br><span class="line">          node.parent = newRoot;</span><br><span class="line">          root = newRoot;</span><br><span class="line">          node = root;</span><br><span class="line">          node.addChild(left);</span><br><span class="line">          node.addChild(right);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">//如果存在父节点，将分裂节点key添加到父节点中</span></span><br><span class="line">          Node&lt;T&gt; parent = node.parent;</span><br><span class="line">          parent.addKey(medianValue);</span><br><span class="line">          parent.removeChild(node);</span><br><span class="line">          parent.addChild(left);</span><br><span class="line">          parent.addChild(right);</span><br><span class="line"></span><br><span class="line">          <span class="comment">//若父节点key数&gt;最大key数,继续分裂</span></span><br><span class="line">          <span class="keyword">if</span> (parent.numberOfKeys() &gt; maxKeySize) split(parent);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h2 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h2><p><img src="B-Tree的3种删除情况1.png" alt="B-Tree的3种删除情况1"><br><img src="./1507879798931.png" alt="B-Tree的3种删除情况2"></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">public T remove(T value) &#123;</span><br><span class="line">       T removed = null;</span><br><span class="line">       Node&lt;T&gt; node = this.getNode(value);</span><br><span class="line">       removed = remove(value, node);</span><br><span class="line">       return removed;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 从Node中删除key</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * @param value 删除节点key值</span></span><br><span class="line"><span class="comment">    * @param node  删除节点</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   private T remove(T value, Node&lt;T&gt; node) &#123;</span><br><span class="line">       if (node == null) return null;</span><br><span class="line"></span><br><span class="line">       T removed = null;</span><br><span class="line">       int index = node.indexOf(value);</span><br><span class="line">       <span class="comment">//删除节点的key</span></span><br><span class="line">       removed = node.removeKey(value);</span><br><span class="line">       <span class="comment">//叶子节点</span></span><br><span class="line">       if (node.numberOfChildren() == 0) &#123;</span><br><span class="line">           <span class="comment">//节点存在父节点 &amp; 且节点key个数&lt;最小节点key个数</span></span><br><span class="line">           if (node.parent != null &amp;&amp; node.numberOfKeys() &lt; minKeySize) &#123;</span><br><span class="line">               <span class="comment">//重平衡</span></span><br><span class="line">               this.combined(node);</span><br><span class="line">           &#125; else if (node.parent == null &amp;&amp; node.numberOfKeys() == 0) &#123;</span><br><span class="line">               <span class="comment">//删根节点</span></span><br><span class="line">               root = null;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; else &#123;//内部节点</span><br><span class="line">           <span class="comment">//获取左孩子节点的最右边的节点作为替换值</span></span><br><span class="line">           Node&lt;T&gt; lesser = node.getChild(index);</span><br><span class="line">           Node&lt;T&gt; greatest = this.getGreatestNode(lesser);</span><br><span class="line">           T replaceValue = this.removeGreatestValue(greatest);</span><br><span class="line">           node.addKey(replaceValue);</span><br><span class="line">           <span class="comment">//节点存在父节点 &amp; 节点key个数&lt;最小节点key个数，继续重平衡</span></span><br><span class="line">           if (greatest.parent != null &amp;&amp; greatest.numberOfKeys() &lt; minKeySize) &#123;</span><br><span class="line">               this.combined(greatest);</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="comment">//节点的孩子孩子个数&gt;最大孩子节点个数，对节点进行分裂</span></span><br><span class="line">           if (greatest.numberOfChildren() &gt; maxChildrenSize) &#123;</span><br><span class="line">               this.split(greatest);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       size--;</span><br><span class="line"></span><br><span class="line">       return removed;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>当节点key个数 小于 最小key个数时， 将孩子节点的key与父节点进行合并<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当节点key个数 小于 最小key个数时， 将孩子节点的key与父节点进行合并</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> node 与节点的孩子节点进行合并</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">combined</span><span class="params">(Node&lt;T&gt; node)</span> </span>&#123;</span><br><span class="line">        Node&lt;T&gt; parent = node.parent;</span><br><span class="line">        <span class="keyword">int</span> index = parent.indexOf(node);</span><br><span class="line">        <span class="keyword">int</span> indexOfLeftNeighbor = index - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> indexOfRightNeighbor = index + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        Node&lt;T&gt; rightNeighbor = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//右兄弟节点key个数</span></span><br><span class="line">        <span class="keyword">int</span> rightNeighborSize = -minChildrenSize;</span><br><span class="line">        <span class="keyword">if</span> (indexOfRightNeighbor &lt; parent.numberOfChildren()) &#123;</span><br><span class="line">            rightNeighbor = parent.getChild(indexOfRightNeighbor);</span><br><span class="line">            rightNeighborSize = rightNeighbor.numberOfKeys();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从兄弟节点借key</span></span><br><span class="line">        <span class="keyword">if</span> (rightNeighbor != <span class="keyword">null</span> &amp;&amp; rightNeighborSize &gt; minKeySize) &#123;</span><br><span class="line">            <span class="comment">//尝试从右兄弟节点借key</span></span><br><span class="line">            T removeValue = rightNeighbor.getKey(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">int</span> prev = getIndexOfPreviousValue(parent, removeValue);</span><br><span class="line">            T parentValue = parent.removeKey(prev);</span><br><span class="line">            T neighborValue = rightNeighbor.removeKey(<span class="number">0</span>);</span><br><span class="line">            node.addKey(parentValue);</span><br><span class="line">            parent.addKey(neighborValue);</span><br><span class="line">            <span class="keyword">if</span> (rightNeighbor.numberOfChildren() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                node.addChild(rightNeighbor.removeChild(<span class="number">0</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Node&lt;T&gt; leftNeighbor = <span class="keyword">null</span>;</span><br><span class="line">            <span class="comment">//左兄弟节点key个数</span></span><br><span class="line">            <span class="keyword">int</span> leftNeighborSize = -minChildrenSize;</span><br><span class="line">            <span class="keyword">if</span> (indexOfLeftNeighbor &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                leftNeighbor = parent.getChild(indexOfLeftNeighbor);</span><br><span class="line">                leftNeighborSize = leftNeighbor.numberOfKeys();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (leftNeighbor != <span class="keyword">null</span> &amp;&amp; leftNeighborSize &gt; minKeySize) &#123;</span><br><span class="line">                <span class="comment">//尝试从左兄弟节点借key</span></span><br><span class="line">                T removeValue = leftNeighbor.getKey(leftNeighbor.numberOfKeys() - <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">int</span> prev = getIndexOfNextValue(parent, removeValue);</span><br><span class="line">                T parentValue = parent.removeKey(prev);</span><br><span class="line">                T neighborValue = leftNeighbor.removeKey(leftNeighbor.numberOfKeys() - <span class="number">1</span>);</span><br><span class="line">                node.addKey(parentValue);</span><br><span class="line">                parent.addKey(neighborValue);</span><br><span class="line">                <span class="keyword">if</span> (leftNeighbor.numberOfChildren() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    node.addChild(leftNeighbor.removeChild(leftNeighbor.numberOfChildren() - <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rightNeighbor != <span class="keyword">null</span> &amp;&amp; parent.numberOfKeys() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//借不到key，尝试与右兄弟节点key合并</span></span><br><span class="line">                T removeValue = rightNeighbor.getKey(<span class="number">0</span>);</span><br><span class="line">                <span class="keyword">int</span> prev = getIndexOfPreviousValue(parent, removeValue);</span><br><span class="line">                T parentValue = parent.removeKey(prev);</span><br><span class="line">                parent.removeChild(rightNeighbor);</span><br><span class="line">                node.addKey(parentValue);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rightNeighbor.keysSize; i++) &#123;</span><br><span class="line">                    T v = rightNeighbor.getKey(i);</span><br><span class="line">                    node.addKey(v);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rightNeighbor.childrenSize; i++) &#123;</span><br><span class="line">                    Node&lt;T&gt; c = rightNeighbor.getChild(i);</span><br><span class="line">                    node.addChild(c);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (parent.parent != <span class="keyword">null</span> &amp;&amp; parent.numberOfKeys() &lt; minKeySize) &#123;</span><br><span class="line">                    <span class="comment">//删除key后导致父节点key数小于最小key个数，继续重平衡</span></span><br><span class="line">                    <span class="keyword">this</span>.combined(parent);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parent.numberOfKeys() == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="comment">//父节点没有key了，将节点作为新的root节点</span></span><br><span class="line">                    node.parent = <span class="keyword">null</span>;</span><br><span class="line">                    root = node;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (leftNeighbor != <span class="keyword">null</span> &amp;&amp; parent.numberOfKeys() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//借不到key，尝试与左兄弟节点key合并</span></span><br><span class="line">                T removeValue = leftNeighbor.getKey(leftNeighbor.numberOfKeys() - <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">int</span> prev = getIndexOfNextValue(parent, removeValue);</span><br><span class="line">                T parentValue = parent.removeKey(prev);</span><br><span class="line">                parent.removeChild(leftNeighbor);</span><br><span class="line">                node.addKey(parentValue);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; leftNeighbor.keysSize; i++) &#123;</span><br><span class="line">                    T v = leftNeighbor.getKey(i);</span><br><span class="line">                    node.addKey(v);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; leftNeighbor.childrenSize; i++) &#123;</span><br><span class="line">                    Node&lt;T&gt; c = leftNeighbor.getChild(i);</span><br><span class="line">                    node.addChild(c);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (parent.parent != <span class="keyword">null</span> &amp;&amp; parent.numberOfKeys() &lt; minKeySize) &#123;</span><br><span class="line">                    <span class="comment">//删除key后导致父节点key数小于最小key个数，继续重平衡</span></span><br><span class="line">                    <span class="keyword">this</span>.combined(parent);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parent.numberOfKeys() == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="comment">//父节点没有key了，将节点作为新的root节点</span></span><br><span class="line">                    node.parent = <span class="keyword">null</span>;</span><br><span class="line">                    root = node;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="查询节点"><a href="#查询节点" class="headerlink" title="查询节点"></a>查询节点</h2><h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><p>时间复杂度：O(log(n))<br>空间复杂度：O(n)    </p>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>B和B+主要用在文件系统以及数据库中做索引等，</p>
<blockquote>
<p>Advantages of B-tree usage for databases<br>The B-tree uses all of the ideas described above. In particular, a B-tree:</p>
<ul>
<li>keeps keys in sorted order for sequential traversing</li>
<li>uses a hierarchical index to minimize the number of disk reads</li>
<li>uses partially full blocks to speed insertions and deletions</li>
<li>keeps the index balanced with a recursive algorithm</li>
<li>In addition, a B-tree minimizes waste by making sure the <code>interior nodes are at least half full.</code> A B-tree can <code>handle an arbitrary number of insertions and deletions.</code></li>
</ul>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://en.wikipedia.org/wiki/B-tree">Wikipedia-B-tree</a><br><a href="https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/03.02.html">BTree</a><br><a href="http://www.geeksforgeeks.org/b-tree-set-3delete/">B-Tree | Set 3 (Delete)</a></p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>B-Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>期货基础知识</title>
    <url>/2018/01/14/%E6%9C%9F%E8%B4%A7%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>整理量化投资学习笔记-期货</p>
<hr>
<a id="more"></a>
<h2 id="期货基础知识"><a href="#期货基础知识" class="headerlink" title="期货基础知识"></a>期货基础知识</h2><h1 id="期货基础知识-1"><a href="#期货基础知识-1" class="headerlink" title="期货基础知识"></a>期货基础知识</h1><h2 id="期货定义"><a href="#期货定义" class="headerlink" title="期货定义"></a>期货定义</h2><p>期货（ futures ），一般指期货合约（ futures contracts），就是指在将来确定的时间按照确定的价格和品质在规定的地点购买或出售一定数量标的物的合约。<br>期货合约可以分为远期合约（forward）和标准合约(futures)，一般将标准合约称为期货合约。下文如无特指，提到的期货合约均指标准合约。</p>
<h3 id="远期合约"><a href="#远期合约" class="headerlink" title="远期合约"></a>远期合约</h3><p>远期合约是指合约双方约定在未来某个特定时间以约定的价格买卖特定数量的标的物（或基础资产）的协议。</p>
<h3 id="标准合约"><a href="#标准合约" class="headerlink" title="标准合约"></a>标准合约</h3><p>标准合约是指合约双方约定在未来某个特定时间,特定的地点（一般为集中的期货交易所），以特定的价格买卖特定数量的标的物的协议，其交易的合约<br>是由交易所规定的标准化合约，包括标的物的等级、数量、交割日期、交割地点与交割方式等 。<br>从某种意义上来说，期货是未来的东西，是一种可以买卖的标准化了的合约。</p>
<blockquote>
<p>期货的价格和现货的价格之间关系之一，期货的由来是因为现货的投资需求而来的，以前，因为交易活动的封闭性，现货价格实际上对期货价格起着决定性作用。<br>由于期货交易的不断发展，其交易的区间已经扩展到整个世界当中去，而且由于期货交易采用的是电子竞价系统进行的，再加上有世界各方投资者的加入，其价格已经是全方位的表现，因此现在的现货价格定位都是以期货价格乘以百分比之后得出来的。<br>期货价格和现货价格关系之二，期货本身的作用便是套期保值，那么既然期货的价格属于全方位的，也就是说反映了市场上供应的变化情况，期货价格高也就预示着远期市场的供不应求，这样一来就一定会造成现货价格随之一起上升。</p>
</blockquote>
<h1 id="期货的功能"><a href="#期货的功能" class="headerlink" title="期货的功能"></a>期货的功能</h1><h2 id="套期保值"><a href="#套期保值" class="headerlink" title="套期保值"></a>套期保值</h2><p>提供了避险和对冲工具，让市场更稳定和更有效；</p>
<h2 id="价格发现"><a href="#价格发现" class="headerlink" title="价格发现"></a>价格发现</h2><p>另外它成本低杠杆高，因此对市场信息更加敏感，股指期货价格往往先于现货市场反应第一手信息。</p>
<h2 id="期货市场组织结构"><a href="#期货市场组织结构" class="headerlink" title="期货市场组织结构"></a>期货市场组织结构</h2><ul>
<li>核心服务层：期货交易所、结算公司、经纪公司</li>
<li>相关服务机构：交割仓库、结算银行、信息咨询机构、会计事务所、律师事务所</li>
<li>期货投资者：所有期货交易者</li>
<li>期货监管机构：中国证监协会、期货行业协会</li>
</ul>
<h2 id="期货分类"><a href="#期货分类" class="headerlink" title="期货分类"></a>期货分类</h2><h3 id="金融期货（-Finacial-futures）"><a href="#金融期货（-Finacial-futures）" class="headerlink" title="金融期货（ Finacial futures）"></a>金融期货（ Finacial futures）</h3><p>标的：金融工具(产品)<br>金融期货类别：</p>
<ul>
<li>外汇期货</li>
<li>利率期货</li>
<li>股票期货</li>
<li>股指期货<br><img src="金融期货-现金交割.png" alt="金融期货-现金交割"><h3 id="商品期货（Commodity-futures）"><a href="#商品期货（Commodity-futures）" class="headerlink" title="商品期货（Commodity futures）"></a>商品期货（Commodity futures）</h3>标的：实物商品<br>商品期货类别：</li>
<li>农产品期货</li>
<li>能源期货</li>
<li>工业金属期货</li>
<li>贵金属期货<br><img src="商品期货-实物交割.png" alt="商品期货-实物交割"></li>
</ul>
<h3 id="国内期货品种"><a href="#国内期货品种" class="headerlink" title="国内期货品种"></a>国内期货品种</h3><p><img src="Alt text.png" alt="Alt text"></p>
<h1 id="期货交易"><a href="#期货交易" class="headerlink" title="期货交易"></a>期货交易</h1><h2 id="期货交易的特征（与股票的区别）"><a href="#期货交易的特征（与股票的区别）" class="headerlink" title="期货交易的特征（与股票的区别）"></a>期货交易的特征（与股票的区别）</h2><ol>
<li><code>交易集中化</code></li>
<li><code>保证金制度</code>（以小搏大、杠杆效应）：期货交易者按照规定标准交纳的资金（一般10%），用于结算和保证履约；</li>
<li><code>逐日盯市</code>： <code>T+0交易</code>，当日无负债结算</li>
<li><code>交割率低</code>： 到期后通常不用实物交割</li>
<li><code>双向交易与对冲机制</code><ul>
<li><code>买空卖空</code>：股票市场你有股票才能卖，没有股票就只能买。在期货市场，既可以先买后卖，也可以先卖后买。当然股票市场也可以做空，就是融券，需要一定资金规模需求（50万以上）。</li>
</ul>
</li>
<li><code>强行平仓制度</code>：<ul>
<li>交易保证金不足，且未在规定时间内补足；</li>
<li>客户持仓超出规定的持仓限额；</li>
<li>因客户违规受到处罚；</li>
<li>根据交易所的紧急措施应于强行平仓；</li>
</ul>
</li>
<li><code>到期交割</code>：买入股票后只要股票不退市就可以无限期持有，亏了可以强行放在那里，等着它涨回来讲不定还有机会；而期货合约的寿命是有限的，等合约期限快到期时，你必须对手中期货合约的头寸进行了结；</li>
</ol>
<blockquote>
<p>保证金种类</p>
<pre><code>* 维持保证金：客户必须保持其保证金帐户内的最低保证金金额。
* 履约保证金：为确保履行合约而由期货合约买卖双方或期权卖方存放于交易帐户内的押金。商品期货保证金不是一种股票的支付，也不是为交易该商品而预付的定金，而是一种良好信誉押金。
* 结算保证金：确保结算会员(通常为公司或企业)将其顾客的期货和期权合约空盘履约的金融保证。结算保证金有别于客户履约保证金。客户履约保证金存放于经纪人处，而结算保证金则存放于票据交换所。
</code></pre><p>实物交割只能企业法人才可以，自然人只能对冲了结，不能进行实物交割。</p>
</blockquote>
<h2 id="期货交易的收敛性"><a href="#期货交易的收敛性" class="headerlink" title="期货交易的收敛性"></a>期货交易的收敛性</h2><p><img src="期货交易的收敛性.png" alt="期货交易的收敛性"></p>
<h2 id="期货交易的策略（-Trading-Strategy）"><a href="#期货交易的策略（-Trading-Strategy）" class="headerlink" title="期货交易的策略（ Trading Strategy）"></a>期货交易的策略（ Trading Strategy）</h2><h3 id="投机-Speculate（基本面结合技术面分析）"><a href="#投机-Speculate（基本面结合技术面分析）" class="headerlink" title="投机-Speculate（基本面结合技术面分析）"></a>投机-Speculate（基本面结合技术面分析）</h3><p>以获利价差为目的的期货交易行为；<br>无货沽空：投机者在交易市场上出售自己并不持有的股票、黄金、证券等的商品期货，并希望在将来以较低的价格买入同等数量的同种商品或资产。</p>
<h3 id="套利-Arbitrage（以期货合约定价公式为依据）"><a href="#套利-Arbitrage（以期货合约定价公式为依据）" class="headerlink" title="套利-Arbitrage（以期货合约定价公式为依据）"></a>套利-Arbitrage（以期货合约定价公式为依据）</h3><p>投机者或对冲者都可以使用的一种交易技术，即在某市场买进现货或期货商，同时在另一个市场卖出相同或类似的商品，并希望两个交易会产生<code>价差</code>而获利。</p>
<blockquote>
<p>投机交易和套利交易有本质的区别在于，套利交易是同一投资品在不同市场产生了价差，才会去做低买高卖的套利行为，而投机交易则是要预测市场波动的趋势，相比而言，投机交易的风险要更大，因为不确定性比套利交易大。</p>
</blockquote>
<h4 id="期现套利"><a href="#期现套利" class="headerlink" title="期现套利"></a>期现套利</h4><p>期现套利是指某种期货合约，当<code>期货市场与现货市场在价格上出现差距</code>，从而利用两个市场的价格差距，低买高卖而获利。<br>理论上，期货价格是商品未来的价格，现货价格是商品目前的价格，按照经济学上的同一价格理论，两者间的差距，即“基差”（基差=现货价格－期货价格）应该等于该商品的持有成本。一旦基差与持有成本偏离较大，就出现了期现套利的机会。<br>其中，期货价格要高出现货价格，并且超过用于交割的各项成本，如运输成本、质检成本、仓储成本、开具发票所增加的成本等等。<br> 期现套利主要包括正向买进期现套利和反向买进期现套利两种。</p>
<h4 id="跨期套利"><a href="#跨期套利" class="headerlink" title="跨期套利"></a>跨期套利</h4><p>所谓跨期套利就是在同一期货品种的不同月份合约上建立数量相等、方向相反的交易头寸，最后以对冲或交割方式结束交易、获得收益的方式。<br>最简单的跨期套利就是买入近期的期货品种，卖出远期的期货品种。</p>
<h4 id="跨品种套利"><a href="#跨品种套利" class="headerlink" title="跨品种套利"></a>跨品种套利</h4><h4 id="跨市场套利"><a href="#跨市场套利" class="headerlink" title="跨市场套利"></a>跨市场套利</h4><h3 id="套期保值-Hedge（以持有的现货资产为依据）"><a href="#套期保值-Hedge（以持有的现货资产为依据）" class="headerlink" title="套期保值-Hedge（以持有的现货资产为依据）"></a>套期保值-Hedge（以持有的现货资产为依据）</h3><p>套期保值与投机是期货市场两个相反的策略，投机者利用期货合约从价格变化中获利，而套期保值者是为了规避价格波动带来的风险。</p>
<h4 id="空头套期保值"><a href="#空头套期保值" class="headerlink" title="空头套期保值"></a>空头套期保值</h4><p>卖出期货合约，以防止将来卖出现货商品时因价格下跌而导致的损失。当卖出现货商品时，将先以前卖出的期货合约通过买进另一数量、类别和交割月份相等的期货合约相对冲，以结束保值。亦称卖期保值<br><img src="利用原油期货套期保值.png" alt="利用原油期货套期保值"><br><img src="期货保值原理图.png" alt="期货保值原理图"></p>
<h4 id="多头套期保值"><a href="#多头套期保值" class="headerlink" title="多头套期保值"></a>多头套期保值</h4><p>多头套期保值是指交易者先在期货市场买进期货，以便在将来现货市场买进时不致于因价格上涨而给自己造成经济损失的一种期货交易方式。<br>例如，一个电力供应商现在采购原油是担心未来采购时价格上涨，电力供应商可以通过购买原油期货合约来锁定原油的购买价格。</p>
<h1 id="期货价格"><a href="#期货价格" class="headerlink" title="期货价格"></a>期货价格</h1><h2 id="影响期货价格的因素"><a href="#影响期货价格的因素" class="headerlink" title="影响期货价格的因素"></a>影响期货价格的因素</h2><p>商品价格的波动主要是受市场供应和需求等基本因素的影响，即任何减少供应或增加消费的经济因素，将导致价格上涨的变化；反之，任何增加供应或减少商品消费的因素，将导致库存增加、价格下跌。然而，随着现代经济的发展，一些非供求因素也对期货价格的变化起到越来越大的作用，这就使期货市场变得更加复杂，更加难以预料。影响期货价格变化的基本因素要概括起来主要有以下八个：</p>
<ol>
<li>供求关系。<br>期货交易是市场经济的产物，因此，它的价格变化受市场供求关系的影响。当供大于求时，期货价格下跌；反之，期货价格就上升。</li>
<li>经济周期。<br>在期货市场上，价格变动还受经济周期的影响，在经济周期的各个阶段，都会出现随之波动的价格上涨和下降现象。</li>
<li>政府政策。<br>各国政府制定的某些政策和措施会对期货市场价格带来不同程度的影响。</li>
<li>政治因素。<br>期货市场对政治气候的变化非常敏感，各种政治性事件的发生常常对价格造成不同程度的影响。</li>
<li>社会因素。<br>社会因素指公众的观念、社会心理趋势、传播媒介的信息影响。</li>
<li>季节性因素。<br>许多期货商品，尤其是农产品有明显的季节性，价格亦随季节变化而波动。</li>
<li>心理因素。<br>所谓心理因素，就是交易者对市场的信心程度，人称“人气”。如对某商品看好时，即使无任何利好因素，该商品价格也会上涨；而当看淡时，无任何利淡消息，价格也会下跌。又如一些大投机商品们还经常利用人们的心理因素，散布某些消息，并人为地进行投机性的大量抛售或补进，谋取投机利润。</li>
<li>金融货币变动因素。<br>在世界经济发展过程，各国的通货膨胀，货币汇价以及利率的上下波动，已成为经济生活中的普遍现象，这对期货市场带来了日益明显的影响。</li>
</ol>
<p><img src="期货价格.png" alt="期货价格"></p>
<h2 id="预期假设"><a href="#预期假设" class="headerlink" title="预期假设"></a>预期假设</h2><h2 id="现货溢价"><a href="#现货溢价" class="headerlink" title="现货溢价"></a>现货溢价</h2><h2 id="期货溢价"><a href="#期货溢价" class="headerlink" title="期货溢价"></a>期货溢价</h2><p><img src="现代资产组合理论.png" alt="现代资产组合理论"></p>
<h1 id="股指期货"><a href="#股指期货" class="headerlink" title="股指期货"></a>股指期货</h1><p>股指期货即股票指数期货，是以<code>股价指数</code>作为标的物的金融期货合约。股指期货的交易与普通的商品期货交易一样，具备相同的特征；<br>股指期货属于金融衍生品的一种。股指期货是可以通过做多和做空来双向获取利润的。</p>
<h2 id="股指期货交易指令"><a href="#股指期货交易指令" class="headerlink" title="股指期货交易指令"></a>股指期货交易指令</h2><ol>
<li><code>市价指令</code>：指不限定价格的、按照当时市场上可执行的最优报价成交的指令。未成交部分自动撤消。集合竞价指令申报时间不接受市价指令申报；</li>
<li><code>限价指令</code>：指按照限定价格或者更优价格成交的指令。限价指令当日有效，未成交部分可以撤销；</li>
<li><code>其他指令</code>。<br>注：交易指令每次最小下单手数为1手，市价指令每次最大下单数量为50手。限价指令每次最大下单数量为100手。进行投机交易的客户号某一合约单边持仓限额100手。</li>
</ol>
<h2 id="股指期货软件交易名词"><a href="#股指期货软件交易名词" class="headerlink" title="股指期货软件交易名词"></a>股指期货软件交易名词</h2><ul>
<li>买开仓：是指下单时买入多单，也就是对指数看多、看涨。</li>
<li>卖开仓：是指下单时买入空单，也就是对指数看空、看跌。</li>
<li>买平仓：是指下单时把买入的多单卖出。</li>
<li>卖平仓：是指下单时把买入的空单卖出。</li>
<li>买平今：是专指下单时把当天买入的多单卖出。</li>
<li>卖平今：是专指下单时把当天买入的空单卖出</li>
<li>结算：是指根据期货交易所公布的结算价格对交易双方的交易盈亏状况进行的资金清算。</li>
<li>交割：是指期货合约到期时，根据期货交易所的规则和程序，交易双方通过该期货合约所载商品所有权的转移，了结到期未平仓合约的过程。<ul>
<li>现金交割：是指到期末平仓期货合约进行交割时，用结算价格来计算未平仓合约的盈亏，以现金支付的方式最终了结期货合约的交割方式。</li>
<li>实物交割：是指期货合约的买卖双方于合约到期时，根据交易所制订的规则和程序，通过期货合约标的物的所有权转移，将到期未平仓合约进行了结的行为。商品期货交易一般采用实物交割的方式。</li>
</ul>
</li>
<li>开仓：开始买入或卖出期货合约的交易行为称为”开仓”或”建立交易部位”。</li>
<li>平仓：是指期货交易者买入或者卖出与其所持期货合约的品种、数量及交割月份相同但交易方向相反的期货合约，了结期货交易的行为。</li>
<li>持仓量：是指期货交易者所持有的未平仓合约的数量。</li>
<li>持仓限额：是指期货交易所对期货交易者的持仓规定的最高数额。</li>
<li>仓单：是指交割仓库开出并经期货交易所认定的标准化提货凭证。</li>
<li>撮合成交：是指期货交易所的计算机交易系统对交易双方的交易指令进行配对的过。</li>
<li>涨跌停板：是指期货合约在一个交易日中的交易价格不得高于或者低于规定的涨跌幅度，超出该涨跌幅度的报价将被视为无效，不能成交。</li>
<li>头寸：一种市场约定。期货合约买方处于多头(买空)部位，期货合约卖方处于空头(卖空)部位。</li>
<li>基差：同一商品当时现货市场价格与期货市场价格间的差异。</li>
<li>逼仓：期货交易所会员或客户利用资金优势，通过控制期货交易头寸或垄断可供交割的现货商品，故意抬高或压低期货市场价格，超量持仓、交割，迫使对方违约或以不利的价格平仓以牟取暴利的行为。根据操作手法不同，又可分为“多逼空“和“空逼多”两种方式。</li>
<li>空逼多：操纵市场者利用资金或实物优势，在期货市场上大量卖出某种期货合约，使其拥有的空头持仓大大超过多方能够承接实物的能力。从而使期货市场的价格急剧下跌，迫使投机多头以低价位卖出持有的合约认赔出局，或出于资金实力接货而受到违约罚款，从而牟取暴利。</li>
<li>多逼空：在一些小品种的期货交易中，当操纵市场者预期可供交割的现货商品不足时，即凭借资金优势在期货市场建立足够的多头持仓以拉高期货价格，同时大量收购和囤积可用于交割的实物，于是现货市场的价格同时升高。这样当合约临近交割时，追使空头会员和客户要么以高价买回期货合约认赔平仓出局;要么以高价买入现货进行实物交割，甚至因无法交出实物而受到违约罚款，这样多头头寸持有者即可从中牟取暴利。</li>
<li>套期图利：同时买进和卖出两种相关商品，并希望在日后对冲交易部位时有所获利。例如，买进和卖出同一商品、但不同交割月份的期货合约;买进和卖出相同交割月份，相同商品、但不同交易所的期货合约;买进和卖出相同交割月份，但不同商品的期货合约(但二商品间有相互关联的关系)。</li>
<li>升贴水：交割升贴水是由交易所制定的，期货交割升贴水可分为四类：第一，现货价格与期货价格间的升贴水；第二，替代交割物与标准交割物间的升贴水；第三，跨年度交割的升贴水；第四，不同交割地间的升贴水。</li>
</ul>
<h2 id="股指期货做多和做空"><a href="#股指期货做多和做空" class="headerlink" title="股指期货做多和做空"></a>股指期货做多和做空</h2><p>股指期货是可以通过做多和做空来双向获取利润的，以上证指数举例说明：<br>比如2015年1月11日上证指数是3212点。每点假设为100元，假设合约期是3个月。</p>
<h3 id="股指期货做多"><a href="#股指期货做多" class="headerlink" title="股指期货做多"></a>股指期货做多</h3><p>如果今天你买3份指数期货了，那么就花了3212<em>100元</em>3份=963600元。<br>3个月到期的那一天，4月11日，</p>
<ul>
<li>如果上证指数是4113点，那么你卖出你的三份指数（期货到期是必须卖的），4113<em>100元</em>3份=1233900元，那你就会挣了1233900—963600=270300元。</li>
<li>如果上证指数是3000点，那么同理可证3000<em>100</em>3=900000元，你就会赔了963600—900000=63600元。<h3 id="股指期货做空"><a href="#股指期货做空" class="headerlink" title="股指期货做空"></a>股指期货做空</h3>如果今天你卖（<em>是卖啊，不是买，需要注意的是这里的卖不是真的卖了，而是相当于你卖了三份证券公司借给你的期货合约，到期是要还的哦</em>）三份指数期货了，那么就得到了3212<em>100元</em>3份=963600元(这个钱是暂时冻结的 )。<br>3个月到期的那一天，4月11日，</li>
<li>如果上证指数是4113点，那么你买三份指数（到期必须买，因为你卖过三份，所以必须要买回来还上），4113<em>100元</em>3份=1233900元，那你就会赔了1233900—963600=270300元。</li>
<li>如果上证指数是3000点，那么同理可证3000<em>100</em>3=900000元，你就会挣了963600—900000=63600元。</li>
</ul>
<blockquote>
<p>特别说明：在这3个月中，你可以随时卖出自己的股指期货合约，结算按实时的点数结算。</p>
</blockquote>
<h1 id="期货资金管理掌握原则"><a href="#期货资金管理掌握原则" class="headerlink" title="期货资金管理掌握原则"></a>期货资金管理掌握原则</h1><ol>
<li>在投机市场中投资总额必须控制在自有资产的50%；</li>
<li>每次交易量控制在可用资金的10%—30%以内，最多不能超过50%；</li>
<li>单笔交易最大亏损额必须控制在总资金的10%以内；</li>
<li>每次交易都应设置止损指令，加仓资金单独设立止损保护，在盈利的情况下让利润奔跑，及时斩断亏损而不是斩断盈利；</li>
<li>以金字塔方式买入，以金字塔方式卖出；</li>
<li>风险收益比为1：3才值得尝试。</li>
</ol>
<h1 id="AI在期货市场的应用"><a href="#AI在期货市场的应用" class="headerlink" title="AI在期货市场的应用"></a>AI在期货市场的应用</h1><p>人工智能在期货市场中的应用主要是用机器学习等技术促进量化投资和程序化交易。<br><img src="量化投资的黑箱.png" alt="量化投资的黑箱"></p>
<ul>
<li>投资组合构建模型：阿尔法模型、风险控制模型、交易成本模型</li>
<li>订单执行模型</li>
</ul>
<h2 id="期货产品风险定价"><a href="#期货产品风险定价" class="headerlink" title="期货产品风险定价"></a>期货产品风险定价</h2><p>不合趋势的价差</p>
<h2 id="期现套利-1"><a href="#期现套利-1" class="headerlink" title="期现套利"></a>期现套利</h2><h2 id="商品期货跨品种配对交易"><a href="#商品期货跨品种配对交易" class="headerlink" title="商品期货跨品种配对交易"></a>商品期货跨品种配对交易</h2><p>统计套利：跨期套利、跨品种套利</p>
<h2 id="市场择时"><a href="#市场择时" class="headerlink" title="市场择时"></a>市场择时</h2><p>包括宏观择时、行业轮动、风格轮动等</p>
<h2 id="期货订单高频交易"><a href="#期货订单高频交易" class="headerlink" title="期货订单高频交易"></a>期货订单高频交易</h2><p>程序化买卖开仓</p>
<h2 id="期货量化投资策略"><a href="#期货量化投资策略" class="headerlink" title="期货量化投资策略"></a>期货量化投资策略</h2><p>构建alpha市场中性策略；</p>
<h2 id="趋势交易"><a href="#趋势交易" class="headerlink" title="趋势交易"></a>趋势交易</h2><h3 id="阿尔法模型"><a href="#阿尔法模型" class="headerlink" title="阿尔法模型"></a>阿尔法模型</h3><p><code>阿尔法对冲，穿越牛熊</code><br>同时持有空头和多头，通过一定手段保证总体收益为正<br>实际中，持有多头股票组合同时卖空股指期货，当大盘上涨时只要保证股票组合的收益大于股指期货的亏损就能实现整体盈利；同理，当大盘下跌时，保证股票的亏损小于股指期货的盈利就能实现整体正的收益。长时间的累积，就能实现稳健的收益，无惧黑天鹅<br>以今天为例，假设我股票多头亏损了6.9%，但期货端收益7%，从而整体我的收益是0.1%（7%-6.9%），试想，在别人亏损7%的时候我能实现盈利0.1%。。。</p>
<h1 id="期货相关概念"><a href="#期货相关概念" class="headerlink" title="期货相关概念"></a>期货相关概念</h1><h2 id="远期合约和期货合约"><a href="#远期合约和期货合约" class="headerlink" title="远期合约和期货合约"></a>远期合约和期货合约</h2><h3 id="远期合约-1"><a href="#远期合约-1" class="headerlink" title="远期合约"></a>远期合约</h3><p>远期合约（forward contract）是指合约双方同意在未来日期按照固定价格交换金融资产的合约，承诺以当前约定的条件在未来进行交易的合约。<br>远期合约是一种金融衍生工具。远期价格和即期价格的差异为远期溢价或远期折价。远期溢价或折价可以视作买方的利润或亏损。<br>远期合约可用于风险对冲（特别是汇率风险）或用于投机行为。</p>
<h3 id="期货合约"><a href="#期货合约" class="headerlink" title="期货合约"></a>期货合约</h3><p>期货合约则是指由期货<code>交易所</code>统一制订的、规定在将来某一特定的时间和地点交割一定数量和质量实物商品或金融商品的<code>标准化合约</code>。</p>
<h3 id="远期合约与期货的区别"><a href="#远期合约与期货的区别" class="headerlink" title="远期合约与期货的区别"></a>远期合约与期货的区别</h3><p>远期合约和期货合约有紧密的关联，相比期货合约，远期合约不是标准化合约，也不在交易所进行交易。</p>
<h2 id="空头-多头"><a href="#空头-多头" class="headerlink" title="空头/多头"></a>空头/多头</h2><p>交易所对合约条款作了规定，所有交易者可以协商的只有期货价格。</p>
<ol>
<li>short position 空头头寸：在交割日购买商品；</li>
<li>long position 多头头寸：在合约到期日出售商品；</li>
</ol>
<blockquote>
<p>多头是合约的”买方”，空头是合约的”卖方”；</p>
</blockquote>
]]></content>
      <categories>
        <category>量化投资</category>
      </categories>
      <tags>
        <tag>量化投资</tag>
        <tag>期货</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK-PriorityBlockingQueue原理</title>
    <url>/2019/10/09/JDK-PriorityBlockingQueue%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>研究了<a href="https://github.com/geosmart/geosmart.io/issues/12">PriorityQueue原理</a>，知道JDK源码怎么实现的优先队列，这次是要搞清<code>PriorityBlockingQueue</code>阻塞优先队列是如何实现的；</p>
<p>本文从PriorityBlockingQueue的<code>概念，结构，参数，源码解析（offer,poll,remove,add,grow），性能，线程安全性，使用场景，常见问题</code>8个方面进行分析。</p>
<p>关键点：与PriorityQueue一样的排序规则，无界队列，实现Queue,Collection,Iterator接口、不允许null键/值、提供阻塞操作、线程安全、不保证队列内元素的顺序；</p>
<a id="more"></a> 
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>An unbounded BlockingQueue blocking queue that uses the <code>same ordering rules as class PriorityQueue</code> and supplies <code>blocking retrieval operations</code>.  </p>
<ul>
<li>While this queue is logically unbounded, attempted additions may fail due to resource exhaustion (causing OutOfMemoryError). </li>
<li>This class does not permit null elements.  </li>
<li>A priority queue relying on <code>Comparable natural ordering</code> also does not permit insertion of <code>non-comparable</code> objects (doing so results in ClassCastException).</li>
<li>This class and its iterator implement all of the optional methods of the Collection and Iterator interfaces.  </li>
<li>The Iterator provided in method iterator() is <code>not guaranteed</code> to traverse the elements of the PriorityBlockingQueue in any particular <code>order</code>. If you need ordered traversal, consider using <code>Arrays.sort(pq.toArray())</code>.  Also, method drainTo can be used to remove some or all elements in priority  order and place them in another collection.</li>
<li>Operations on this class make <code>no guarantees</code> about the <code>ordering</code> of elements with <code>equal priority</code>.<br>If you need to enforce an ordering, you can define custom classes or comparators that use a secondary key to break ties in primary priority values. </li>
</ul>
<p>For example, here is a class that applies <code>first-in-first-out</code> tie-breaking to comparable elements. To use it, you would insert a  <code>new FIFOEntry(anEntry)</code> instead of a plain entry object.</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FIFOEntry</span>&lt;<span class="title">E</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;? <span class="title">super</span> <span class="title">E</span>&gt;&gt;  <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">FIFOEntry</span>&lt;<span class="title">E</span>&gt;&gt; </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> <span class="keyword">final</span> AtomicLong seq = <span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line">   <span class="keyword">final</span> <span class="keyword">long</span> seqNum;</span><br><span class="line">   <span class="keyword">final</span> E entry;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">FIFOEntry</span><span class="params">(E entry)</span> </span>&#123;</span><br><span class="line">     seqNum = seq.getAndIncrement();</span><br><span class="line">     <span class="keyword">this</span>.entry = entry;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> E <span class="title">getEntry</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> entry; &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(FIFOEntry&lt;E&gt; other)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">int</span> res = entry.compareTo(other.entry);</span><br><span class="line">     <span class="keyword">if</span> (res == <span class="number">0</span> &amp;&amp; other.entry != <span class="keyword">this</span>.entry)</span><br><span class="line">       res = (seqNum &lt; other.seqNum ? -<span class="number">1</span> : <span class="number">1</span>);</span><br><span class="line">     <span class="keyword">return</span> res;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>This class is a member of the Java Collections Framework</li>
</ul>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>基于二叉堆实现，参考<a href="">JDK-PriorityQueue原理</a></p>
<blockquote>
<p>PriorityQueue的类关系</p>
</blockquote>
<p><img src="priority_blocking_queue_hier.png" alt="priority_queue_hier"></p>
<blockquote>
<p>PriorityQueue的类成员</p>
</blockquote>
<p><img src="priority_blocking_queue_class.png" alt="priority_queue_class"></p>
<h1 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h1><ul>
<li><code>int.initialCapacity</code>：初始化容量，默认为<code>11</code>；</li>
<li><code>Comparator.comparator</code>:用于队列中元素排序；</li>
<li><code>int.size</code>:记录队列中元素个数；</li>
<li><code>ReentrantLock.lock</code>:用于所有public方法操作的加锁；</li>
<li><code>Condition.notEmpty</code>:用于阻塞对空队列的操作；</li>
<li><code>int.allocationSpinLock</code>: 队列扩容时用于CAS；</li>
<li><code>PriorityQueue.queue</code>：用PriorityQueue进行序列化和反序列化；</li>
<li>构造函数：新建1个空的队列；</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PriorityBlockingQueue</span><span class="params">(<span class="keyword">int</span> initialCapacity,Comparator&lt;? <span class="keyword">super</span> E&gt; comparator)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">this</span>.lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="keyword">this</span>.notEmpty = lock.newCondition();</span><br><span class="line">    <span class="keyword">this</span>.comparator = comparator;</span><br><span class="line">    <span class="keyword">this</span>.queue = <span class="keyword">new</span> Object[initialCapacity];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h1><blockquote>
<ul>
<li>The implementation uses an <code>array-based binary heap</code>, with public operations protected with a <code>single lock</code>. </li>
<li>However, allocation during resizing uses a simple <code>spinlock</code> (used only while not holding main lock) in order to allow takes to operate concurrently with allocation.<br>This avoids repeated postponement of waiting consumers and consequent element build-up. </li>
<li>The need to back away from lock during allocation makes it impossible to simply wrap delegated <code>java.util.PriorityQueue</code> operations within a lock, as was done in a previous version of this class. </li>
<li>To maintain interoperability, a plain PriorityQueue is still used during serialization, which maintains compatibility at the expense of transiently doubling overhead.</li>
</ul>
</blockquote>
<h2 id="heapify"><a href="#heapify" class="headerlink" title="heapify"></a>heapify</h2><p>参考<a href="https://github.com/geosmart/geosmart.io/blob/master/blog/JDK-PriorityQueue%E5%8E%9F%E7%90%86.md">PriorityQueue</a><br>从最后一个父节点开始siftdown，直到根节点</p>
<h2 id="add-put-offer"><a href="#add-put-offer" class="headerlink" title="add/put/offer"></a>add/put/offer</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Inserts the specified element into this priority queue.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> offer(e);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Inserts the specified element into this priority queue.</span></span><br><span class="line"><span class="comment">    * As the queue is unbounded, this method will never block.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">       offer(e); <span class="comment">// never need to block</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Inserts the specified element into this priority queue.</span></span><br><span class="line"><span class="comment">    * As the queue is unbounded, this method will never block or return false.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e, <span class="keyword">long</span> timeout, TimeUnit unit)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> offer(e); <span class="comment">// never need to block</span></span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">       <span class="comment">//加锁</span></span><br><span class="line">       lock.lock();</span><br><span class="line">       <span class="keyword">int</span> n, cap;</span><br><span class="line">       Object[] array;</span><br><span class="line">       <span class="comment">//如果队列元素个数&gt;=队列容量，则扩容</span></span><br><span class="line">       <span class="keyword">while</span> ((n = size) &gt;= (cap = (array = queue).length)) &#123;</span><br><span class="line">           tryGrow(array, cap);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           Comparator&lt;? <span class="keyword">super</span> E&gt; cmp = comparator;</span><br><span class="line">           <span class="keyword">if</span> (cmp == <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="comment">//上浮</span></span><br><span class="line">               siftUpComparable(n, e, array);</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               siftUpUsingComparator(n, e, array, cmp);</span><br><span class="line">           &#125;</span><br><span class="line">           size = n + <span class="number">1</span>;</span><br><span class="line">           <span class="comment">//设置notEmpty条件</span></span><br><span class="line">           notEmpty.signal();</span><br><span class="line">       &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">           <span class="comment">//解锁</span></span><br><span class="line">           lock.unlock();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>siftUp参考<a href="https://github.com/geosmart/geosmart.io/issues/12">JDK-PriorityQueue原理</a></p>
</blockquote>
<p><code>tryGrow</code>扩容要点</p>
<ul>
<li>lock是全局锁，如果在扩容时加锁会导致其他线程出队时会阻塞；</li>
<li>而队列很大时，扩容操作（arraycopy）是比较费时的，如果此时占用锁，那么其他线程在这个时候是不能进行出队操作，这样会<code>降低并发处理能力</code>；</li>
<li>所以为了更好的性能，扩容时先释放锁；</li>
<li>但是释放锁后，会导致多个线程同时进行扩容，此时用spinLock以<code>CAS</code>控制只有1个线程可以执行扩容，其他CAS失败的则跳过（newArray=null）；</li>
<li>CAS失败的线程调用<code>Thread.yield()</code>让出CPU时间，目的是让让CAS成功的线程扩容后优先调用lock.lock重新获取锁，但是这得不到一定的保证，有可能调用Thread.yield()的线程先获取了锁；</li>
<li>在扩容时，若其他线程在执行了出队操作，直接cop扩容会导致copy的不是最新的数据，所以此时要加锁后再copy；</li>
<li>在加锁时，如果其他线程执行出了/如队操作，队列发生了变化（queue != array），当前扩容操作要取消；如果成功加锁且队列没发生改变，则可执行扩容操作；<blockquote>
<p>关键点：解全局锁，CAS乐观锁申请数组大小，扩容前恢复加锁</p>
</blockquote>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Tries to grow array to accommodate at least one more element  (but normally expand by about 50%),</span></span><br><span class="line"><span class="comment">    * giving up (allowing retry) on contention (which we expect to be rare).</span></span><br><span class="line"><span class="comment">    * Call only while  holding lock.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> array  the heap array</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> oldCap the length of the array</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">tryGrow</span><span class="params">(Object[] array, <span class="keyword">int</span> oldCap)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// must release and then re-acquire main lock</span></span><br><span class="line">       <span class="comment">//1. lock是全局锁，为了更好的性能，扩容时先释放锁，避免其他线程出/入队时造成阻塞</span></span><br><span class="line">       <span class="comment">//队列很大时，扩容操作（arraycopy）是比较费时的，</span></span><br><span class="line">       <span class="comment">//如果此时占用锁，那么其他线程在这个时候是不能进行出/入队操作，这样会降低并发处理能力。</span></span><br><span class="line">       <span class="comment">//但释放锁，会导致多个线程同时进行扩容，此时用spinLock以CAS控制只有1个线程可以执行扩容</span></span><br><span class="line">       lock.unlock();</span><br><span class="line">       Object[] newArray = <span class="keyword">null</span>;</span><br><span class="line">       <span class="comment">//2. 并发通过执行一次CAS控制扩容，只有1个线程会CAS成功并扩容，其他CAS失败的则跳过（newArray=null）</span></span><br><span class="line">       <span class="keyword">if</span> (allocationSpinLock == <span class="number">0</span> &amp;&amp; UNSAFE.compareAndSwapInt(<span class="keyword">this</span>, allocationSpinLockOffset, <span class="number">0</span>, <span class="number">1</span>)) &#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               <span class="comment">//设置扩容比例，小于64时2倍，大于64后1.5倍, grow faster if small</span></span><br><span class="line">               <span class="keyword">int</span> newCap = oldCap + ((oldCap &lt; <span class="number">64</span>) ?</span><br><span class="line">                       (oldCap + <span class="number">2</span>) :</span><br><span class="line">                       (oldCap &gt;&gt; <span class="number">1</span>));</span><br><span class="line">               <span class="comment">//处理大小越界</span></span><br><span class="line">               <span class="keyword">if</span> (newCap - MAX_ARRAY_SIZE &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                   <span class="comment">// possible overflow</span></span><br><span class="line">                   <span class="keyword">int</span> minCap = oldCap + <span class="number">1</span>;</span><br><span class="line">                   <span class="keyword">if</span> (minCap &lt; <span class="number">0</span> || minCap &gt; MAX_ARRAY_SIZE) &#123;</span><br><span class="line">                       <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">                   &#125;</span><br><span class="line">                   newCap = MAX_ARRAY_SIZE;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="comment">//3. 如果其他线程没有对队列进行改变，直接新建数组；</span></span><br><span class="line">               <span class="comment">//如果其他线程可能执行了出/入队操作，则当前线程不需要扩容，所以要加上queue == array判断</span></span><br><span class="line">               <span class="keyword">if</span> (newCap &gt; oldCap &amp;&amp; queue == array) &#123;</span><br><span class="line">                   newArray = <span class="keyword">new</span> Object[newCap];</span><br><span class="line">               &#125;</span><br><span class="line">           &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">               <span class="comment">//重置SpinLock状态</span></span><br><span class="line">               allocationSpinLock = <span class="number">0</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// back off if another thread is allocating</span></span><br><span class="line">       <span class="comment">//4. CAS失败的线程调用Thread.yield()让出CPU时间，目的是让CAS成功的线程扩容后优先调用lock.lock重新获取锁，</span></span><br><span class="line">       <span class="comment">//但是这得不到一定的保证，有可能调用Thread.yield()的线程先获取了锁。</span></span><br><span class="line">       <span class="keyword">if</span> (newArray == <span class="keyword">null</span>) &#123;</span><br><span class="line">           Thread.yield();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//5. 在扩容时，若其他线程在执行出/入队操作，直接copy会导致copy的不是最新的数据，所以此时要加锁后再copy</span></span><br><span class="line">       lock.lock();</span><br><span class="line">       <span class="comment">//6. 加锁时，如果其他线程执行出/入队操作，队列发生了变化（queue!= array），当前扩容操作要取消；</span></span><br><span class="line">       <span class="comment">//如果成功加锁且队列没发生改变，则可执行扩容操作</span></span><br><span class="line">       <span class="keyword">if</span> (newArray != <span class="keyword">null</span> &amp;&amp; queue == array) &#123;</span><br><span class="line">           queue = newArray;</span><br><span class="line">           System.arraycopy(array, <span class="number">0</span>, newArray, <span class="number">0</span>, oldCap);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h2 id="take-poll"><a href="#take-poll" class="headerlink" title="take/poll"></a>take/poll</h2><blockquote>
<p>take阻塞出队<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">        <span class="comment">//上锁，可中断</span></span><br><span class="line">        lock.lockInterruptibly();</span><br><span class="line">        E result;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//阻塞直到队列返回结果</span></span><br><span class="line">            <span class="keyword">while</span> ((result = dequeue()) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">//阻塞等待恢复信号</span></span><br><span class="line">                notEmpty.await();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//解锁</span></span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>poll阻塞出队（设置超时时间）<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> nanos = unit.toNanos(timeout);</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lockInterruptibly();</span><br><span class="line">    E result;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//阻塞直到队列返回结果，或者等待超时</span></span><br><span class="line">        <span class="keyword">while</span> ((result = dequeue()) == <span class="keyword">null</span> &amp;&amp; nanos &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//阻塞等待恢复信号（超时时间）</span></span><br><span class="line">            nanos = notEmpty.awaitNanos(nanos);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>dequeue出队操作<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mechanics for poll().  Call only while holding lock.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">dequeue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = size - <span class="number">1</span>;</span><br><span class="line">    <span class="comment">//没元素返回空</span></span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//拿出队头元素，用于返回</span></span><br><span class="line">        Object[] array = queue;</span><br><span class="line">        E result = (E) array[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将队尾元素放到队头，并从队头开始执行siftDown</span></span><br><span class="line">        E x = (E) array[n];</span><br><span class="line">        array[n] = <span class="keyword">null</span>;</span><br><span class="line">        Comparator&lt;? <span class="keyword">super</span> E&gt; cmp = comparator;</span><br><span class="line">        <span class="keyword">if</span> (cmp == <span class="keyword">null</span>) &#123;</span><br><span class="line">            siftDownComparable(<span class="number">0</span>, x, array, n);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            siftDownUsingComparator(<span class="number">0</span>, x, array, n, cmp);</span><br><span class="line">        &#125;</span><br><span class="line">        size = n;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Inserts item x at position k, maintaining heap invariant by demoting x down the tree repeatedly</span></span><br><span class="line"><span class="comment"> * until it is less than or equal to its children or is a leaf.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> k     the position to fill</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> x     the item to insert</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> array the heap array</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> n     heap size</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">siftDownComparable</span><span class="params">(<span class="keyword">int</span> k, T x, Object[] array, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//拿出父节点值</span></span><br><span class="line">        Comparable&lt;? <span class="keyword">super</span> T&gt; key = (Comparable&lt;? <span class="keyword">super</span> T&gt;) x;</span><br><span class="line">        <span class="comment">//存在叶子节点时 loop while a non-leaf</span></span><br><span class="line">        <span class="keyword">int</span> half = n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (k &lt; half) &#123;</span><br><span class="line">            <span class="comment">// assume left child is least</span></span><br><span class="line">            <span class="keyword">int</span> child = (k &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">//最小值</span></span><br><span class="line">            Object c = array[child];</span><br><span class="line">            <span class="keyword">int</span> right = child + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">//存在right且right比left大</span></span><br><span class="line">            <span class="keyword">if</span> (right &lt; n &amp;&amp;</span><br><span class="line">                    ((Comparable&lt;? <span class="keyword">super</span> T&gt;) c).compareTo((T) array[right]) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                c = array[child = right];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//父节点比最小值小，不需要交换，终止loop</span></span><br><span class="line">            <span class="keyword">if</span> (key.compareTo((T) c) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//父节点值以最小值替换</span></span><br><span class="line">            array[k] = c;</span><br><span class="line">            <span class="comment">//父节点移到最小值位置</span></span><br><span class="line">            k = child;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//父节点值，最终赋给交换n轮后的叶子节点</span></span><br><span class="line">        array[k] = key;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>关于ReentrantLock.lockInterruptibly</p>
<ol>
<li>获取并持有锁直到当前线程未被中断。</li>
<li>获取该锁并立即返回（如果该锁没有被另一个线程持有），将锁的保持计数设置为 1。</li>
<li>如果该锁已被另一个线程持有，则当前线程不可被调度（即阻塞状态，CPU不会给该线程分配时间片）直到<ul>
<li>当前线程获取到该锁；</li>
<li>其他线程中断当前线程；</li>
</ul>
</li>
<li>如果该锁被当前线程持有，则将锁的持有计数设置为1，</li>
<li>如果当前线程在进入此方法时已经设置了该线程的中断状态；或者在等待获取锁的同时被中断。则抛出<code>InterruptedException</code>异常，同时清除当前线程的中断状态；</li>
</ol>
</blockquote>
<ol>
<li>在此实现中，因为<code>lockInterruptibly</code>方法是一个<code>显式中断</code>点，所以要<code>优先响应中断</code>，而不是响应锁的普通获取或重入获取；<blockquote>
<p>注意程序要响应中断还是比较expensive的，有时候甚至imposibble，所以如果线程支持中断，一定要声明清楚！<br><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/Lock.html#lockInterruptibly--">jdk8-lock-lockInterruptibly</a></p>
</blockquote>
</li>
</ol>
<blockquote>
<p>关于Condition.await<br>await方法的调用将导致当前线程等待直到signalled或interrupted调用时才恢复；<br>condition关联的lock会被原子释放，当前线程将不可调度直到以下4种情况触发：</p>
<ol>
<li>其他线程调用当前condition的signal()方法，并且当前线程正好被唤醒；</li>
<li>其他线程调用当前condition的signalAll()方法；</li>
<li>其他线程终止当前线程， and interruption of thread suspension is supported; </li>
<li><code>spurious wakeup</code>发生；<br>在所有情况中，在当前method能返回前，当前线程必须重新获取condition关联的锁；<br>在线程返回时await会保证一直持有condition关联的锁；</li>
</ol>
</blockquote>
<h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><p>加锁后，删除节点<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> i = indexOf(o);</span><br><span class="line">        <span class="keyword">if</span> (i == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        removeAt(i);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">removeAt</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    Object[] array = queue;</span><br><span class="line">    <span class="keyword">int</span> n = size - <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// removed last element</span></span><br><span class="line">    <span class="keyword">if</span> (n == i) &#123;</span><br><span class="line">        array[i] = <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        E moved = (E) array[n];</span><br><span class="line">        array[n] = <span class="keyword">null</span>;</span><br><span class="line">        Comparator&lt;? <span class="keyword">super</span> E&gt; cmp = comparator;</span><br><span class="line">        <span class="keyword">if</span> (cmp == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//从删除节点开始下沉</span></span><br><span class="line">            siftDownComparable(i, moved, array, n);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            siftDownUsingComparator(i, moved, array, n, cmp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//siftDown后，若元素没有改变，可能是因为要删除的结点和堆尾结点是跨子树，或者要删除的结点是叶子结点</span></span><br><span class="line">        <span class="keyword">if</span> (array[i] == moved) &#123;</span><br><span class="line">            <span class="keyword">if</span> (cmp == <span class="keyword">null</span>) &#123;</span><br><span class="line">                siftUpComparable(i, moved, array);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                siftUpUsingComparator(i, moved, array, cmp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    size = n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>从当前节点上浮到根节点<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">siftUpComparable</span><span class="params">(<span class="keyword">int</span> k, T x, Object[] array)</span> </span>&#123;</span><br><span class="line">    Comparable&lt;? <span class="keyword">super</span> T&gt; key = (Comparable&lt;? <span class="keyword">super</span> T&gt;) x;</span><br><span class="line">    <span class="keyword">while</span> (k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> parent = (k - <span class="number">1</span>) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        Object e = array[parent];</span><br><span class="line">        <span class="keyword">if</span> (key.compareTo((T) e) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        array[k] = e;</span><br><span class="line">        k = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    array[k] = key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="peek"><a href="#peek" class="headerlink" title="peek"></a>peek</h2><p>加锁后，返回堆顶节点<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peek</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (size == <span class="number">0</span>) ? <span class="keyword">null</span> : (E) queue[<span class="number">0</span>];</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="size"><a href="#size" class="headerlink" title="size"></a>size</h2><p>加锁后，返回堆大小<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="contains"><a href="#contains" class="headerlink" title="contains"></a>contains</h2><p>加锁后，返回堆大小<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> indexOf(o) != -<span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">        Object[] array = queue;</span><br><span class="line">        <span class="keyword">int</span> n = size;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (o.equals(array[i])) &#123;</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><ul>
<li>O(1)：peek</li>
<li>O(n)：heapify</li>
<li>O(nlog(n)):put,remove</li>
</ul>
</blockquote>
<h1 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h1><p>PriorityBlockingQueue中的锁</p>
<ul>
<li><code>ReentrantLock</code>：重入锁，对queue的所有public操作加锁；</li>
<li><code>Condition</code>：竞态条件，如果队列为空，take/poll时<code>await</code>阻塞，offer时<code>signal</code>取消阻塞；</li>
<li><code>Unsafe</code>：扩容时，以<code>compareAndSwapInt</code>执行CAS操作</li>
</ul>
<blockquote>
<p><code>关于UnSafe</code></p>
<ul>
<li><code>Unsafe</code>是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接<code>访问系统内存资源</code>、<code>自主管理内存资源</code>等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。</li>
<li>由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。</li>
</ul>
<p><code>关于CAS</code></p>
<ul>
<li>什么是CAS? 即比较并替换，实现并发算法时常用到的一种技术。CAS操作包含三个操作数——内存位置、预期原值及新值。</li>
<li>执行CAS操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。我们都知道，CAS是一条CPU的原子指令（<code>cmpxchg</code>指令），不会造成所谓的数据不一致问题，<code>Unsafe</code>提供的CAS方法（如<code>compareAndSwap</code>XXX）底层实现即为CPU指令cmpxchg。</li>
<li>CAS在<code>java.util.concurrent.atomic</code>相关类、<code>Java AQS</code>、<code>CurrentHashMap</code>等实现上有非常广泛的应用。</li>
</ul>
</blockquote>
<h2 id="锁的定义"><a href="#锁的定义" class="headerlink" title="锁的定义"></a>锁的定义</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Lock used for all public operations</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock lock;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Condition for blocking when empty</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Condition notEmpty;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Spinlock for allocation, acquired via CAS.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> allocationSpinLock;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unsafe mechanics</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> sun.misc.Unsafe UNSAFE;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> allocationSpinLockOffset;</span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        UNSAFE = sun.misc.Unsafe.getUnsafe();</span><br><span class="line">        Class&lt;?&gt; k = PriorityBlockingQueue<span class="class">.<span class="keyword">class</span></span>;</span><br><span class="line">        allocationSpinLockOffset = UNSAFE.objectFieldOffset</span><br><span class="line">            (k.getDeclaredField(<span class="string">"allocationSpinLock"</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> Error(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>参考<a href="https://github.com/geosmart/geosmart.io/blob/master/blog/JDK-PriorityQueue原理.md">PriorityQueue</a></p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="PriorityBlockingQueue中用到了那些锁？"><a href="#PriorityBlockingQueue中用到了那些锁？" class="headerlink" title="PriorityBlockingQueue中用到了那些锁？"></a>PriorityBlockingQueue中用到了那些锁？</h2><ul>
<li>CAS</li>
<li>ReentranLock</li>
</ul>
<h2 id="PriorityBlockingQueue中的Blocking体现在哪些操作？"><a href="#PriorityBlockingQueue中的Blocking体现在哪些操作？" class="headerlink" title="PriorityBlockingQueue中的Blocking体现在哪些操作？"></a>PriorityBlockingQueue中的Blocking体现在哪些操作？</h2><ul>
<li>read：take</li>
<li>write：grow，offer</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/PriorityBlockingQueue.html">jdk8.PriorityBlockingQueue</a> </li>
<li><a href="https://github.com/geosmart/geosmart.io/issues/12">JDK-PriorityQueue原理</a> </li>
<li><a href="https://github.com/geosmart/geosmart.io/issues/11">二叉堆实现原理</a> </li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK-PriorityQueue原理</title>
    <url>/2019/10/03/JDK-PriorityQueue%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>研究了<a href="https://github.com/geosmart/geosmart.io/issues/11">二叉堆实现原理</a>，现在来看看JDK里面基于二叉堆的优先队列怎么实现的！</p>
<p>关键点：基于priority heap，无界队列，实现Queue,Collection,Iterator接口、不允许null键/值、非线程安全、enqueue和dequeue都是O(long(n))，remove和contains是O(n)，peek是O(1)；</p>
<p>从PriorityQueue的<code>概念，结构，参数，源码解析（offer,poll,remove,add,grow），性能，线程安全性，使用场景，常见问题</code>8个方面进行分析。</p>
</blockquote>
<a id="more"></a> 
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><blockquote>
<ul>
<li>优先队列跟普通的队列不一样，普通队列遵循FIFO规则出队入队，而优先队列每次都是优先级最高出队。</li>
<li>优先队列内部维护着一个堆，每次取数据的时候都从堆顶取，这是优先队列的基本工作原理。</li>
<li><p>jdk的优先队列使用PriorityQueue这个类，使用者可以自己定义优先级规则。</p>
</li>
<li><p>An <code>unbounded priority queue</code> based on a <code>priority heap</code>. </p>
</li>
<li>The elements of the priority queue are ordered according to their <code>natural ordering</code>, or by a <code>Comparator provided</code> at queue &gt;construction time, depending on which constructor is used. </li>
<li>A priority queue does <code>not permit null elements</code>. </li>
<li>A priority queue relying on natural ordering also does <code>not permit insertion of non-comparable objects</code> (doing so may result in &gt;ClassCastException).</li>
<li>The <code>head of this queue</code> is the <code>least element</code> with respect to the <code>specified ordering</code>. If multiple elements are tied for &gt;least value, the head is one of those elements — ties are broken arbitrarily. </li>
<li>The queue retrieval operations <code>poll</code>, <code>remove</code>, <code>peek</code>, and element access the element at the head of the queue.</li>
<li><code>A priority queue is unbounded</code>, but has an <code>internal capacity</code> governing the size of an <code>array</code> used to store the elements on &gt;the queue. It is always at least as large as the queue size. As elements are added to a priority queue, its <code>capacity grows &gt;automatically</code>. The details of the growth policy are not specified.</li>
<li>This class and its iterator implement all of the optional methods of the <code>Collection and Iterator interfaces</code>. </li>
<li>The Iterator provided in method iterator() is <code>not guaranteed</code> to traverse the elements of the priority queue in any particular &gt;<code>order</code>. If you need ordered traversal, consider using <code>Arrays.sort(pq.toArray())</code>.</li>
<li>Note that this implementation is <code>not synchronized</code>. Multiple threads should not access a PriorityQueue instance concurrently if &gt;any of the threads modifies the queue. Instead, use the <code>thread-safe PriorityBlockingQueue</code> class.</li>
<li>Implementation note: this implementation provides <ul>
<li><code>O(log(n)) time</code> for the <code>enqueuing</code> and <code>dequeuing</code> methods (<code>offer, poll, remove() and add</code>); </li>
<li><code>linear time</code> for the <code>remove(Object) and contains(Object)</code> methods; </li>
<li><code>constant time</code> for the retrieval methods (<code>peek, element, and size</code>).<br>This class is a member of the <code>Java Collections Framework</code>.</li>
</ul>
</li>
</ul>
<p>PriorityQueue的类关系</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/geosmart/geosmart.io/master/blog/img/priority_queue_hier.png" alt="priority_queue_hier"></p>
<blockquote>
<p>PriorityQueue的类成员</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/geosmart/geosmart.io/master/blog/img/priority_queue_class1.png" alt="priority_queue_class"></p>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>一维数组</p>
<ul>
<li>Priority queue represented as a <code>balanced binary heap</code>:</li>
<li>the two children of queue[n] are queue[2<em>n+1] and queue[2</em>(n+1)].  </li>
<li>The priority queue is <code>ordered by comparator</code>, or by the elements’ <code>natural ordering</code>, </li>
<li>if comparator is null: For each node n in the heap and each descendant d of n, n &lt;= d.  </li>
<li>The element with the <code>lowest value</code> is in queue[0], assuming the queue is nonempty.<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// non-private to simplify nested class access</span></span><br><span class="line"><span class="keyword">transient</span> Object[] queue;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h1><ul>
<li><code>initialCapacity</code>：初始化容量，默认为<code>11</code>；</li>
<li><code>comparator</code>:用于队列中元素排序；</li>
<li><code>size</code>:记录队列中元素个数；</li>
<li><code>modCount</code>:记录队列修改次数；</li>
<li>构造函数：新建1个空的队列；<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PriorityQueue</span><span class="params">(<span class="keyword">int</span> initialCapacity, Comparator&lt;? <span class="keyword">super</span> E&gt; comparator)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.queue = <span class="keyword">new</span> Object[initialCapacity];</span><br><span class="line">    <span class="keyword">this</span>.comparator = comparator;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>如果是由<code>SortedSet</code>,<code>PriorityQueue</code>这种有序的结构构建优先队列，直接<code>Arrays.copyOf</code>把数据复制到queue数组中；</li>
<li>如果是由无序数组构建优先队列，需要把数据复制到queue数组中后，执行<code>构建堆(heapify)</code>操作；</li>
</ul>
<h1 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h1><h2 id="heapify-构建堆"><a href="#heapify-构建堆" class="headerlink" title="heapify-构建堆"></a>heapify-构建堆</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Establishes the heap invariant (described above) in the entire tree,</span></span><br><span class="line"><span class="comment"> * assuming nothing about the order of the elements prior to the call.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">heapify</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//从最后一个非叶子节点（父亲节点）开始遍历所有父节点，直到堆顶</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = (size &gt;&gt;&gt; <span class="number">1</span>) - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">        <span class="comment">//下沉（将3 or 2者中较大元素下沉）</span></span><br><span class="line">        siftDown(i, (E) queue[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="siftDown-下沉"><a href="#siftDown-下沉" class="headerlink" title="siftDown-下沉"></a>siftDown-下沉</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Inserts item x at position k, maintaining heap invariant by demoting x down the tree repeatedly</span></span><br><span class="line"><span class="comment"> * until it is less than or equal to its children or is a leaf.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> k the position to fill</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> x the item to insert</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDown</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (comparator != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//按自定义顺序swap下沉</span></span><br><span class="line">        siftDownUsingComparator(k, x);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//按字典顺序swap下沉</span></span><br><span class="line">        siftDownComparable(k, x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>按字典顺序swap下沉<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDownComparable</span><span class="params">(<span class="keyword">int</span> parent, E x)</span> </span>&#123;</span><br><span class="line">    Comparable&lt;? <span class="keyword">super</span> E&gt; parentVal = (Comparable&lt;? <span class="keyword">super</span> E&gt;) x;</span><br><span class="line">    <span class="keyword">int</span> half = size &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="comment">//二叉树结构，下标大于size/2都是叶子节点，其他的节点都有子节点。</span></span><br><span class="line">    <span class="comment">//循环直到k没有子节点：loop while a non-leaf</span></span><br><span class="line">    <span class="keyword">while</span> (parent &lt; half) &#123;</span><br><span class="line">        <span class="comment">//假设left节点为child中的最小值节点</span></span><br><span class="line">        <span class="keyword">int</span> left = (parent &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> right = left + <span class="number">1</span>;</span><br><span class="line">        Object minVal = queue[left];</span><br><span class="line">        <span class="comment">//存在right，且right&lt;left，则最小为right</span></span><br><span class="line">        <span class="keyword">if</span> (right &lt; size &amp;&amp; ((Comparable&lt;? <span class="keyword">super</span> E&gt;) minVal).compareTo((E) queue[right]) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            left = right;</span><br><span class="line">            minVal = queue[right];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果parent节点&lt;min(left,right),则不需要swap</span></span><br><span class="line">        <span class="keyword">if</span> (parentVal.compareTo((E) minVal) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//否则swap parent节点和min(left,right)的节点</span></span><br><span class="line">        queue[parent] = minVal;</span><br><span class="line">        <span class="comment">//当前父节点取最小值的index继续loop</span></span><br><span class="line">        parent = left;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//1.当前节点没有子节点，则k是叶子节点的下标，没有比它更小的了，直接赋值即可</span></span><br><span class="line">    <span class="comment">//2.当前节点下沉n轮后，将节点的值放到最终不需要再交换的位置（没有比它更小的或者到达叶子节点）</span></span><br><span class="line">    queue[parent] = parentVal;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>按自定义顺序swap下沉，与siftDownComparable类似<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDownUsingComparator</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> half = size &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (k &lt; half) &#123;</span><br><span class="line">        <span class="keyword">int</span> child = (k &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">        Object c = queue[child];</span><br><span class="line">        <span class="keyword">int</span> right = child + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (right &lt; size &amp;&amp;</span><br><span class="line">            comparator.compare((E) c, (E) queue[right]) &gt; <span class="number">0</span>)</span><br><span class="line">            c = queue[child = right];</span><br><span class="line">        <span class="keyword">if</span> (comparator.compare(x, (E) c) &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        queue[k] = c;</span><br><span class="line">        k = child;</span><br><span class="line">    &#125;</span><br><span class="line">    queue[k] = x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="offer"><a href="#offer" class="headerlink" title="offer"></a>offer</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The number of times this priority queue has been structurally modified </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 节点插入到队列 </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//修改次数+1</span></span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">int</span> i = size;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= queue.length) &#123;</span><br><span class="line">        <span class="comment">//队列已满时，按50%动态扩容</span></span><br><span class="line">        grow(i + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    size = i + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//队列为空时</span></span><br><span class="line">        queue[<span class="number">0</span>] = e;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//上浮调整堆顺序</span></span><br><span class="line">        siftUp(i, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>队列已满时，动态扩容：小于64时2倍扩容，大于64时0.5倍扩容；<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Increases the capacity of the array.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> minCapacity the desired minimum capacity</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = queue.length;</span><br><span class="line">    <span class="comment">// Double size if size&lt;64; else grow by 50%</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = oldCapacity + (</span><br><span class="line">        (oldCapacity &lt; <span class="number">64</span>) ? (oldCapacity + <span class="number">2</span>) :(oldCapacity &gt;&gt; <span class="number">1</span>)</span><br><span class="line">        );</span><br><span class="line">    <span class="comment">// overflow-conscious code 防越界</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">        newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">    <span class="comment">//将queue中数据复制到扩容后的queue</span></span><br><span class="line">    queue = Arrays.copyOf(queue, newCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hugeCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// overflow</span></span><br><span class="line">    <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (minCapacity &gt; MAX_ARRAY_SIZE) ?</span><br><span class="line">            Integer.MAX_VALUE :</span><br><span class="line">            MAX_ARRAY_SIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>节点上浮调整<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Inserts item x at position k, </span></span><br><span class="line"><span class="comment"> * maintaining heap invariant by promoting x up the tree until it is greater than or equal to its parent, or is the root. </span></span><br><span class="line"><span class="comment"> * 为保持堆的性质，将插入元素x一路上浮，直到满足x节点值&gt;=父节点值，或者到达根节点；</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> k the position to fill 插入位置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> x the item to insert 插入元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUp</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (comparator != <span class="keyword">null</span>) &#123;</span><br><span class="line">        siftUpUsingComparator(k, x);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        siftUpComparable(k, x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>按字典顺序swap上浮<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUpComparable</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    Comparable&lt;? <span class="keyword">super</span> E&gt; key = (Comparable&lt;? <span class="keyword">super</span> E&gt;) x;</span><br><span class="line">    <span class="comment">//从当前节点循环上浮到堆顶节点</span></span><br><span class="line">    <span class="keyword">while</span> (k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//k节点的父节点索引</span></span><br><span class="line">        <span class="keyword">int</span> parent = (k - <span class="number">1</span>) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//k节点的父节点值</span></span><br><span class="line">        Object e = queue[parent];</span><br><span class="line">        <span class="comment">//比较k节点与父节点的值大小，父节点值较小时，终止遍历</span></span><br><span class="line">        <span class="keyword">if</span> (key.compareTo((E) e) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//父节点值较大时，交换k节点与父节点值</span></span><br><span class="line">        queue[k] = e;</span><br><span class="line">        <span class="comment">//当前节点移到父节点，继续向上遍历</span></span><br><span class="line">        k = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将当前节点值赋给交换后的父节点</span></span><br><span class="line">    queue[k] = key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>按自定义顺序swap上浮，与siftUpComparable类似<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUpUsingComparator</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> parent = (k - <span class="number">1</span>) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        Object e = queue[parent];</span><br><span class="line">        <span class="keyword">if</span> (comparator.compare(x, (E) e) &gt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        queue[k] = e;</span><br><span class="line">        k = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    queue[k] = x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> offer(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Removes the ith element from queue.</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * Normally this method leaves the elements at up to i-1,</span></span><br><span class="line"><span class="comment"> * inclusive, untouched.  Under these circumstances, it returns null.</span></span><br><span class="line"><span class="comment"> * Occasionally, in order to maintain the heap invariant,</span></span><br><span class="line"><span class="comment"> * it must swap a later element of the list with one earlier thani.</span></span><br><span class="line"><span class="comment"> * Under these circumstances,</span></span><br><span class="line"><span class="comment"> * this method returns the element that was previously at the end of the list and is now at some position before i.</span></span><br><span class="line"><span class="comment"> * This fact is used by iterator.remove so as to avoid missing traversing elements.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">removeAt</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> i &gt;= <span class="number">0</span> &amp;&amp; i &lt; size;</span><br><span class="line">    <span class="comment">// 修改次数+1</span></span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// 堆尾元素Index</span></span><br><span class="line">    <span class="keyword">int</span> s = --size;</span><br><span class="line">    <span class="keyword">if</span> (s == i) &#123;</span><br><span class="line">        <span class="comment">//如果删除的是堆尾元素，不需要进行siftUp</span></span><br><span class="line">        queue[i] = <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//拿出堆尾元素</span></span><br><span class="line">        E moved = (E) queue[s];</span><br><span class="line">        queue[s] = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//将堆尾元素放到要删除的元素的位置，并执行siftDown</span></span><br><span class="line">        siftDown(i, moved);</span><br><span class="line">        <span class="comment">//siftDown后，若元素没有改变，可能是因为要删除的结点和堆尾结点是跨子树，或者要删除的结点是叶子结点</span></span><br><span class="line">        <span class="keyword">if</span> (queue[i] == moved) &#123;</span><br><span class="line">            <span class="comment">//如果删除的元素和堆尾元素不在一个子树，需要siftUp操作</span></span><br><span class="line">            siftUp(i, moved);</span><br><span class="line">            <span class="keyword">if</span> (queue[i] != moved) &#123;</span><br><span class="line">                <span class="keyword">return</span> moved;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意</p>
<ul>
<li>普通元素删除，将堆尾元素和要删除的位置替换，然后<code>siftDown</code>就可以；</li>
<li>但当删除的元素和堆尾元素之间如果是<code>跨子树</code>的话，需要从删除位置执行<code>siftUp</code>操作；<br>示例<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      0</span><br><span class="line">  4       1</span><br><span class="line">5   6   2   3</span><br></pre></td></tr></table></figure>
删除5，siftdown后<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      0</span><br><span class="line">  4       1</span><br><span class="line">3   6   2</span><br></pre></td></tr></table></figure>
此时还需要siftup一次，才能满足二叉堆的结构<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      0</span><br><span class="line">  3       1</span><br><span class="line">4   6   2</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<h2 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">poll</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">//queue修改次数+1</span></span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">//堆顶元素</span></span><br><span class="line">    E result = (E) queue[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">//堆尾索引</span></span><br><span class="line">    <span class="keyword">int</span> s = --size;</span><br><span class="line">    <span class="comment">//堆尾元素</span></span><br><span class="line">    E x = (E) queue[s];</span><br><span class="line">    <span class="comment">//置空堆尾元素</span></span><br><span class="line">    queue[s] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (s != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//堆尾元素拿出作为堆顶值后，从堆顶执行下沉</span></span><br><span class="line">        siftDown(<span class="number">0</span>, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//返回堆顶元素</span></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="peek"><a href="#peek" class="headerlink" title="peek"></a>peek</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peek</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//返回堆顶元素</span></span><br><span class="line">    <span class="keyword">return</span> (size == <span class="number">0</span>) ? <span class="keyword">null</span> : (E) queue[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><p>参考二叉堆性能</p>
<ul>
<li><code>O(log(n)) time</code> for the <code>enqueuing</code> and <code>dequeuing</code> methods (<code>offer, poll, remove() and add</code>);</li>
<li><code>linear time</code> for the <code>remove(Object) and contains(Object)</code> methods;</li>
<li><code>constant time</code> for the retrieval methods (<code>peek, element, and size</code>).<h1 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h1>并发修改队列时非线程安全，线程安全版本使用<code>PriorityBlockingQueue</code><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><h2 id="PriorityQueue处理优先级场景"><a href="#PriorityQueue处理优先级场景" class="headerlink" title="PriorityQueue处理优先级场景"></a>PriorityQueue处理优先级场景</h2>如医院急诊科接诊要按病痛的优先级处理；构建好优先队列后逐个poll即可；</li>
</ul>
<h2 id="PriorityQueue求TopK大-小的元素"><a href="#PriorityQueue求TopK大-小的元素" class="headerlink" title="PriorityQueue求TopK大/小的元素"></a>PriorityQueue求TopK大/小的元素</h2><p>使用<code>小顶堆</code>来实现TopK问题求解：维护一个大小为K的最大堆，那么在堆中的数都是TopK。</p>
<ul>
<li>处理过程：在添加一个元素之后，如果小顶堆的大小大于 K，那么需要将小顶堆的堆顶元素去除</li>
<li>时间复杂度：O(Nlog(K)) </li>
<li>空间复杂度： O(K)</li>
<li>特别适合处理<code>海量数据</code></li>
</ul>
<p>在海量数据场景下，单机通常不能存放下所有数据。</p>
<ul>
<li>拆分：可以按照<code>哈希取模</code>方式拆分到多台机器上；在每个机器上维护<code>最大堆</code>；</li>
<li>整合：将每台机器得到的最大堆<code>合并</code>成最终的最大堆。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test_topK</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = <span class="number">4</span>;</span><br><span class="line">    List&lt;Integer&gt; array = Arrays.asList(<span class="number">11</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">7</span>);</span><br><span class="line"></span><br><span class="line">    PriorityQueue topKQueue = <span class="keyword">new</span> PriorityQueue();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; array.size(); i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> o = array.get(i);</span><br><span class="line">        <span class="keyword">if</span> (topKQueue.size() &lt; k) &#123;</span><br><span class="line">            <span class="comment">//一直加到K</span></span><br><span class="line">            topKQueue.add(o);</span><br><span class="line">            System.out.println(String.format(<span class="string">"add %s"</span>, o));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Object min = topKQueue.peek();</span><br><span class="line">            <span class="keyword">if</span> (o &gt; (<span class="keyword">int</span>) min) &#123;</span><br><span class="line">                <span class="comment">//最小堆大小超过K且当前元素比堆顶大时，移除堆顶元素，并加入新元素</span></span><br><span class="line">                HeapPrinter.dump(topKQueue.toArray());</span><br><span class="line">                topKQueue.poll();</span><br><span class="line">                topKQueue.add(o);</span><br><span class="line">                System.out.println(String.format(<span class="string">"poll %s, add %s"</span>, min, o));</span><br><span class="line">                HeapPrinter.dump(topKQueue.toArray());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(String.format(<span class="string">"skip %s"</span>, o));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：可以skip比堆顶还小的元素</p>
<p>求 Top k，更简单的方法可以直接用内置的<code>TreeMap</code>或者<code>TreeSet</code>，</p>
<p>TODO：TreeMap和TreeSet源码解析</p>
<p>Scanning through a large collection of statistics to report the top N items<br>eg.N busiest network connections, N most valuable customers, N largest disk users…</p>
<h2 id="PriorityQueue在Hadoop中的应用"><a href="#PriorityQueue在Hadoop中的应用" class="headerlink" title="PriorityQueue在Hadoop中的应用"></a>PriorityQueue在Hadoop中的应用</h2><p>在 hadoop 中，排序是 MapReduce 的灵魂，MapTask 和 ReduceTask 均会对数据按 Key 排序，这个操作是 MR 框架的默认行为，不管你的业务逻辑上是否需要这一操作。</p>
<ul>
<li>MapReduce 框架中，用到的排序主要有两种：<code>快速排序</code>和<code>基于堆实现的优先队列</code>。</li>
<li>Mapper 阶段： 从 map 输出到环形缓冲区的数据会被排序（这是 MR 框架中改良的快速排序），这个排序涉及<code>partition</code>和<code>key</code>，<br>当缓冲区容量占用 80%，会<code>spill</code>数据到磁盘，生成<code>IFile</code>文件，<br><code>Map</code>结束后，会将<code>IFile</code>文件排序<code>合并</code>成一个大文件（基于堆实现的优先级队列），以供不同的<code>reduce</code>来拉取相应的数据。</li>
<li>Reducer 阶段：<br>从 Mapper 端取回的数据已是部分有序，Reduce Task 只需进行一次<code>归并排序</code>即可保证数据整体有序。<br>为了提高效率，Hadoop 将<code>sort</code>阶段和<code>reduce</code>阶段<code>并行化</code>，<br>在<code>sort</code>阶段，Reduce Task 为内存和磁盘中的文件建立了<code>小顶堆</code>，保存了指向该小顶堆根节点的迭代器，并不断的移动迭代器，<br>以将 key 相同的数据<code>顺次</code>交给<code>reduce()</code>函数处理，期间移动迭代器的过程实际上就是不断调整小顶堆的过程（建堆→取堆顶元素→重新建堆→取堆顶元素…），这样，sort 和 reduce 可以并行进行。</li>
</ul>
</blockquote>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol>
<li>PriorityQueue的底层数组叫什么？原理是什么？如何实现排序的？</li>
<li>如何在N（N&gt;&gt;10000）个数据中找到最大的K个数？要求复杂度小于O(N*N)！</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/PriorityQueue.html">jdk8.PriorityQueue</a> </li>
<li><a href="https://juejin.im/post/5cba5cb9518825327e23f078">堆排序</a></li>
<li><a href="https://juejin.im/post/5cba5cb9518825327e23f078">java集合之PriorityQueue源码分析</a></li>
<li><a href="https://stackoverflow.com/questions/38696556/in-java-priority-queue-implementation-remove-at-method-why-it-does-a-sift-up-af">priorityQueue元素删除问题</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ数据读写过程</title>
    <url>/2019/11/11/RabbitMQ%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>RabbitMQ<code>如何存储</code>消息，RabbitMQ如何<code>接收消息</code>和<code>投递消息</code>？</p>
<a id="more"></a> 
<h1 id="RabbitMQ的内部结构"><a href="#RabbitMQ的内部结构" class="headerlink" title="RabbitMQ的内部结构"></a>RabbitMQ的内部结构</h1><h2 id="RabbitMQ的进程结构"><a href="#RabbitMQ的进程结构" class="headerlink" title="RabbitMQ的进程结构"></a>RabbitMQ的进程结构</h2><p><img src="rabbitmq_进程结构.png" alt="RabbitMQ的进程架构"></p>
<blockquote>
<p>事件驱动模型（或者说反应堆模型），这是一种高性能的非阻塞io线程模型，在Erlang中称为进程模型。</p>
</blockquote>
<ul>
<li><code>cp_acceptor</code>：负责接受客户端<code>连接</code>，然后为客户端连接创建rabbit_reader<br>、rabbit_writer、rabbit_channel进程</li>
<li><code>rabbit_reader</code>：负责解析客户端AMQP帧，然后将请求发送给rabbit_channel进程</li>
<li><code>rabbit_writer</code>：负责向客户端<code>返回</code>数据</li>
<li><code>rabbit_channel</code>：负责解析AMQP方法，以及对消息进行<code>路由</code>，然后发送给对应的队列进程。</li>
<li><code>rabbit_amqqueue_process</code>：rabbit队列进程，该进程一般在rabbitmq创建队列时被创建，其主要负责消息的<code>接收</code>/<code>投递</code>逻辑</li>
<li><code>rabbit_msg_store</code>：存储服务器进程，主要负责消息的<code>持久化存储</code></li>
</ul>
<blockquote>
<ul>
<li>tcp_acceptor和rabbit_msg_store只会有一个;</li>
<li>rabbit_amqqueue_process进程的数量则和队列数量保持一致;</li>
<li>每个客户端连接对应一个rabbit_reader和rabbit_writer进程;</li>
<li>每一个连接的通道对应一个rabbit_channel进程。</li>
</ul>
<p>通常来说，客户端发起一条connection的同时，可以打开多条channel，相对connection的open/close来说，对channel进行open和close的操作开销会更小。</p>
<p>最佳实践是一个生产者/消费者进程对应一个connection，具体发送时，一个线程对应一个channel即可。</p>
</blockquote>
<h2 id="RabbitMQ中队列的内部结构"><a href="#RabbitMQ中队列的内部结构" class="headerlink" title="RabbitMQ中队列的内部结构"></a>RabbitMQ中队列的内部结构</h2><p><img src="rabbitmq_struct.png" alt="rabbit队列结构"></p>
<ul>
<li>RabbitMQ完全实现了AMQP协议，类似于一个邮箱服务。Exchange负责根据ExchangeType和RoutingKey将消息投递到对应的消息队列中，消息队列负责在消费者获取消息前暂存消息。</li>
<li>在RabbitMQ中，<code>MessageQueue</code>主要由两部分组成，<ul>
<li><code>AMQPQueue</code>：实现AMQP协议的逻辑功能，包括接收消息，投递消息，Confirm消息等；</li>
<li><code>BackingQueue</code>：提供AMQQueue调用的接口，完成消息的存储和持久化工作</li>
</ul>
</li>
</ul>
<h2 id="RabbitMQ中队列的存储状态"><a href="#RabbitMQ中队列的存储状态" class="headerlink" title="RabbitMQ中队列的存储状态"></a>RabbitMQ中队列的存储状态</h2><p>BackingQueue由Q1,Q2,Delta,Q3,Q4五个子队列构成，在BackingQueue中，消息的生命周期有4个状态：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>queue</th>
<th>state\store</th>
<th>message itself</th>
<th>message index(message position)</th>
</tr>
</thead>
<tbody>
<tr>
<td>q1,q4</td>
<td>alpha</td>
<td>RAM</td>
<td>RAM</td>
</tr>
<tr>
<td>q2,q3</td>
<td>beta</td>
<td>DISK</td>
<td>RAM</td>
</tr>
<tr>
<td>q2,q3</td>
<td>gamma</td>
<td>DISK</td>
<td>RAM&amp;DISK</td>
</tr>
<tr>
<td>delta</td>
<td>delta</td>
<td>DISK</td>
<td>DISK</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><code>alpha</code>: 消息的内容和消息索引都在RAM中。（Q1，Q4）</li>
<li><code>beta</code>: 消息的内容保存在Disk上，消息索引保存在RAM中。（Q2，Q3）</li>
<li><code>gamma</code>: 消息的内容保存在Disk上，消息索引在DISK和RAM上都有。（Q2，Q3）</li>
<li><code>delta</code>: 消息内容和索引都在Disk上。(Delta）</li>
</ul>
<blockquote>
<p>5个内部队列</p>
<ul>
<li>q1和q4队列中只有alpha状态的消息；</li>
<li>q2和q3包含beta和gamma状态的消息；</li>
<li>delta队列是消息按序存盘后的一种逻辑队列，只有delta状态的消息。所以delta队列并不在内存中，其他4个队列则是由erlang queue模块实现。</li>
</ul>
</blockquote>
<p>这里以持久化消息为例（可以看到非持久化消息的生命周期会简单很多），从Q1到Q4，消息实际经历了一个<code>RAM-&gt;DISK-&gt;RAM</code>这样的过程，<br>BackingQueue的设计有点类似于Linux的虚拟内存<code>Swap</code>区，</p>
<ul>
<li>当队列<code>负载很高</code>时，通过将部分消息放到磁盘上来<code>·</code>节省内存空间`，</li>
<li>当<code>负载降低</code>时，消息又从磁盘回到内存中，让整个队列有很好的<code>弹性</code>。<br>因此触发消息流动的主要因素是：</li>
</ul>
<ol>
<li><code>消息被消费</code>；</li>
<li><code>内存不足</code>。</li>
</ol>
<ul>
<li>RabbitMQ会根据<code>消息的传输速度</code>来计算当前<code>内存中允许保存的最大消息数量</code>（Traget_RAM_Count），</li>
<li>当<code>内存中保存的消息数量 + 等待ACK的消息数量 &gt; Target_RAM_Count</code>时，RabbitMQ才会把消息<code>写到磁盘</code>上，</li>
<li>所以说虽然理论上消息会按照<code>Q1-&gt;Q2-&gt;Delta-&gt;Q3-&gt;Q4</code>的顺序流动，但是并不是每条消息都会经历所有的子队列以及对应的生命周期。</li>
<li><p>从RabbitMQ的Backing Queue结构来看，当<code>内存不足</code>时，消息要经历多个生命周期，在Disk和RAM之间置换，这实际会<code>降低RabbitMQ的处理性能</code>（后续的流控就是关联的解决方法）。</p>
</li>
<li><p>对于持久化消息，RabbitMQ先将消息的内容和索引保存在磁盘中，然后才处于上面的某种状态（即只可能处于<code>alpha、gamma、delta</code>三种状态之一）。 </p>
<blockquote>
<p>the term <code>gamma</code> seldom appears. </p>
</blockquote>
</li>
</ul>
<h2 id="RabbitMQ的流控-信用机制-Credit"><a href="#RabbitMQ的流控-信用机制-Credit" class="headerlink" title="RabbitMQ的流控-信用机制(Credit)"></a>RabbitMQ的流控-信用机制(Credit)</h2><ul>
<li>当RabbitMQ出现内存(默认是0.4)或者磁盘资源达到阈值时，会触发流控机制：<code>阻塞Producer的Connection</code>，让生产者不能继续发送消息，直到内存或者磁盘资源得到释放。 </li>
<li>Erlang进程之间并不共享内存（binaries类型除外），而是通过消息传递来通信，每个进程都有自己的进程邮箱。Erlang默认没有对进程邮箱大小设限制，所以当有大量消息持续发往某个进程时，会导致该进程邮箱过大，最终内存溢出并崩溃。</li>
<li>在RabbitMQ中，如果生产者持续高速发送，而消费者消费速度较低时，如果没有流控，很快就会使内部进程邮箱大小达到内存阈值，阻塞生产者（得益于block机制，并不会崩溃）。然后RabbitMQ会进行page操作，将内存中的数据持久化到磁盘中。</li>
<li>因此，要保证各个进程占用的内容在一个合理的范围，RabbitMQ的流控采用了一种<code>信用机制(Credit)</code>，为每个进程维护了4类键值对：<ul>
<li><code>{credit_from,From}</code>-该值表示还能向消息接收进程From<code>发送</code>多少条消息;</li>
<li><code>{credit_to,To}</code>-表示当前进程再<code>接收</code>多少条消息，就要向消息<code>发送</code>进程增加Credit数量;</li>
<li><code>credit_blocked</code>-表示当前进程被哪些进程block了，比如进程A向B发送消息，那么当A的进程字典中{credit_from,B}的值为0是，那么A的credit_blocked值为[B];</li>
<li><code>credit_deferred</code>-<code>消息接收</code>进程向<code>消息发送</code>进程增加Credit的<code>消息列表</code>，当进程被Block时会记录消息信息，<code>Unblock后依次发送这些消息</code>;</li>
</ul>
</li>
</ul>
<p><img src="rabbitmq_credit.png" alt="rabbitMq信用机制"><br>如图所示:</p>
<ul>
<li>A进程当前可以发送给B的消息有100条，每发一次，值减1，直到为0，A才会被Block住。</li>
<li>B消费消息后，会给A增加新的Credit，这样A才可以持续的发送消息。</li>
</ul>
<p>这里只画了两个进程，多进程串联的情况下，这中影响也就是从底向上传递的。</p>
<h2 id="RabbitMQ的消息状态"><a href="#RabbitMQ的消息状态" class="headerlink" title="RabbitMQ的消息状态"></a>RabbitMQ的消息状态</h2><p>每个消息存储在RabbitMQ中都有自己的状态：Ready，Unacked,Ack</p>
<ul>
<li>Ready：等待消费状态。</li>
<li>Unacked:等待被确认状态，当前消息已经被发送到了客户端。当客户端端断开后，如果这条消息没有被确认，这条消息重新进入Ready中。</li>
<li>Ack：已被确认状态</li>
</ul>
<h2 id="RabbitMQ的消息类型"><a href="#RabbitMQ的消息类型" class="headerlink" title="RabbitMQ的消息类型"></a>RabbitMQ的消息类型</h2><p>Messages, and their position in the queue, can be <code>in memory</code> or <code>on disk</code>, or both. </p>
<ul>
<li><code>Persistent messages</code> will have both message and position pushed to disk as soon as they arrive; </li>
<li><code>Transient messages</code> can be written to disk (and thus both types can be evicted from memory) under memory pressure. </li>
</ul>
<p>The question of whether a message is in <code>RAM</code> and whether it is <code>persistent</code> are orthogonal（正交，即可同时存在）.<br>Messages are persisted using the <code>queue index</code>（队列索引） and the <code>message store</code>（消息数据）. </p>
<ul>
<li><code>queue index</code> holds the <code>position</code> of the message <strong>within this queue</strong> along with a couple of small bits of <code>metadata</code></li>
<li><code>message store</code> holds the message itself (including headers and other properties).</li>
<li><code>small messages</code> can be embedded directly in the queue index and bypass the message store altogether.</li>
</ul>
<h1 id="RabbitMQ的消息存储"><a href="#RabbitMQ的消息存储" class="headerlink" title="RabbitMQ的消息存储"></a>RabbitMQ的消息存储</h1><p>RabbitMQ的消息持久化实际包括两部分：</p>
<ul>
<li><code>队列索引(rabbit_queue_index)</code>：负责维护队列中落盘消息的信息，包括消息的存储地点、是否已经被交付给消费者、是否已被消费者ack等，每个队列都有一个与之对应的rabbit_queue_index。</li>
<li><code>消息存储(rabbit_msg_store)</code>：rabbit_msg_store以键值对的形式存储消息，每个节点有且只有一个，所有队列共享。rabbit_msg_store又可以分为<code>msg_store_persistent</code>和<code>msg_store_transient</code>，<ul>
<li>msg_store_persistent负责持久化消息的存储，不会丢失，</li>
<li>msg_store_transient负责非持久化消息的存储，重启后消息会丢失。</li>
</ul>
</li>
</ul>
<blockquote>
<p>通过配置环境变量<code>RABBITMQ_MNESIA_BASE</code>可以指定存储目录，一般配置RABBITMQ_MNESIA_BASE=/srv/rabbitmq。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ls -hl  /var/lib/rabbitmq/mnesia/rabbit65 | grep msg_store</span><br><span class="line">drwxr-xr-x.  2 rabbitmq rabbitmq   21 Sep  9 21:26 msg_store_persistent</span><br><span class="line">drwxr-xr-x   2 rabbitmq rabbitmq   19 Jul 19 21:25 msg_store_transient</span><br></pre></td></tr></table></figure>
<p>其中<code>msg_store_transient</code>、queues和<code>msg_store_persistent</code>就是实际消息的存储目录。</p>
<h2 id="rabbit-msg-store存储"><a href="#rabbit-msg-store存储" class="headerlink" title="rabbit_msg_store存储"></a>rabbit_msg_store存储</h2><ul>
<li>RabbitMQ通过配置queue_index_embed_msgs_below可以指定根据消息存储位置，</li>
<li>默认queue_index_embed_msgs_below是<code>4096</code>字节(包含消息体、属性及headers)，小于该值的消息存在<code>rabbit_queue_index</code>中。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ls -hl  /var/lib/rabbitmq/mnesia/rabbit65/msg_store_persistent</span><br><span class="line">-rw-r--r-- 1 rabbitmq rabbitmq 2.5M Sep 10 19:16 356.rdq</span><br><span class="line"></span><br><span class="line">sudo ls -hl  /var/lib/rabbitmq/mnesia/rabbit65/msg_store_transient</span><br><span class="line">-rw-r--r-- 1 rabbitmq rabbitmq 0 Jul 19 21:25 0.rdq</span><br></pre></td></tr></table></figure>
<ul>
<li>经过rabbit_msg_store处理的消息都会以<code>追加</code>的方式写入到文件中，文件名从0开始累加，后缀是<code>.rdq</code>，</li>
<li>当一个文件的大小超过指定的限制(<code>file_size_limit</code>)后，关闭这个文件再创建一个新的文件存储。 </li>
</ul>
<blockquote>
<p><code>rdq</code>文件消息格式<br> <code>&lt;&lt;Size:64, MsgId:16/binary, MsgBody&gt;&gt;</code></p>
<ul>
<li>MsgId为RabbitMQ通过rabbit_guid:gen()每一个消息生成的GUID，</li>
<li>MsgBody会包含消息对应的<code>exchange</code>，<code>routing_keys</code>，<code>消息的内容</code>，消息对应的<code>协议版本</code>，消息<code>内容格式</code>。</li>
</ul>
</blockquote>
<ul>
<li>消息存储时，RabbitMQ会在<code>ETS(Erlang Term Storge)</code>表中记录消息在文件中的<code>位置映射</code>和文件的相关信息。</li>
<li>消息读取时，先根据消息的<code>msg_id</code>找到对应的文件，如果文件存在且未被锁住则直接打开文件，如果文件不存在或者锁住了则发请求到<code>rabbit_msg_store</code>处理。</li>
</ul>
<h2 id="队列的索引文件"><a href="#队列的索引文件" class="headerlink" title="队列的索引文件"></a>队列的索引文件</h2><p>查看索引信息<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> ls -hl  /var/lib/rabbitmq/mnesia/rabbit65/queues/9ETDQOQ2E4JS49H80ILRO1YHA</span><br><span class="line">total 24K</span><br><span class="line">-rw-r--r-- 1 rabbitmq rabbitmq 21K Aug 14 20:19 1.idx</span><br><span class="line">-rw-r--r-- 1 rabbitmq rabbitmq   0 Aug 14 20:19 journal.jif</span><br></pre></td></tr></table></figure></p>
<ul>
<li>rabbit_queue_index顺序存储段文件，文件编号从0开始，后缀.idx，</li>
<li>每个段文件包含固定的<code>SEGMENT_ENTRY_COUNT</code>条记录。</li>
<li>SEGMENT_ENTRY_COUNT默认是<code>16384</code>，每个<code>rabbit_queue_index</code>从磁盘读取消息的时候至少读取一个段文件。</li>
</ul>
<h1 id="RabbitMQ的消息读写过程"><a href="#RabbitMQ的消息读写过程" class="headerlink" title="RabbitMQ的消息读写过程"></a>RabbitMQ的消息读写过程</h1><p><img src="rabbitmq_存储.jpg" alt="rabbitMQ存储"></p>
<ul>
<li>rabbit_channel进程确定了消息将要投递的目标队列，</li>
<li>rabbit_amqqueue_process是队列进程，每个队列都有一个对应的进程，实际上rabbit_amqqueue_process进程只是提供了逻辑上对队列的相关操作，他的真正操作是通过调用指定的backing_queue模块提供的相关接口实现的，</li>
<li>默认情况该backing_queue的实现模块为rabbit_variable_queue。<h2 id="消息publish"><a href="#消息publish" class="headerlink" title="消息publish"></a>消息publish</h2>rabbit_amqqueue_process对消息的主要处理逻辑位于<code>deliver_or_enqueue</code>函数，该方法将消息直接传递给消费者，或者将消息存储到队列当中。</li>
</ul>
<p>整体处理逻辑如下：</p>
<ol>
<li>首先处理消息的<code>mandory标志</code>，和<code>confirm属性</code>。<ul>
<li>mandatory标志告诉服务器至少将该消息route到一个队列中，否则将消息返还给生产者。</li>
<li>confirm则是消息的发布确认。</li>
</ul>
</li>
<li>然后判断队列中是否有消费者正在等待，如果有则直接调用<code>backing_queue</code>的接口给客户端发送消息。</li>
<li>如果队列上没有消费者，根据当前相关设置判断消息是否需要<code>丢弃</code>，不需要丢弃的情况下调用backing_queue的接口将消息入队。</li>
</ol>
<p><img src="rabbitmq_publish.jpg" alt="rabbitMQ_publish"><br><img src="rabbitmq_backing_queue.jpg" alt="rabbitMQ_backing_queue"></p>
<ul>
<li>如果调用到该方法的BQ:publish则说明当前队列没有消费者正在等待，消息将进入到队列。backing_queue实现了消息的存储，他会尽力将durable=true的消息做持久化存储。</li>
<li>初始默认情况下，<code>非持久化消息</code>直接进入<code>内存队列</code>，此时效率最高，当内存占用逐渐达到一个阈值时，消息和消息索引逐渐往磁盘中移动，随着消费者的不断消费，内存占用的减少，消息逐渐又从磁盘中被转到内存队列中。</li>
<li>消息在这些Queue中传递的”一般”过程<code>q1-&gt;q2-&gt;delta-&gt;q3-&gt;q4</code>，一般负载较轻的情况消息不需要走完每个Queue，大部分都可以跳过。</li>
<li>每次入队消息后，判断RabbitMQ系统中使用的内存是否过多，此操作是尝试将内存中的队列数据写入到磁盘中.</li>
<li>内存中的消息数量（RamMsgCount）及内存中的等待ack的消息数量（RamAckIndex）的和大于允许的内存消息数量（TargetRamCount）时，多余数量的消息内容会被写到磁盘中.</li>
</ul>
<h2 id="消息consuming"><a href="#消息consuming" class="headerlink" title="消息consuming"></a>消息consuming</h2><p><img src="rabbitmq_consuming.jpg" alt="rabbitMQ_consuming"></p>
<blockquote>
<p>获取消息</p>
<ul>
<li>尝试从q4队列中获取一个消息，如果成功，则返回获取到的消息，如果失败，则尝试通过试用fetch_from_q3/1从q3队列获取消息，成功则返回，如果为空则返回空；</li>
<li>注意fetch_from_q3从Q3获取消息，如果Q3为空，则说明整个队列都是空的，无消息，消费者等待即可。</li>
</ul>
<p>取出消息后</p>
<ul>
<li>如果Q4不为空，取出消息后直接返回；</li>
<li>如果Q4为空，Q3不为空，从Q3取出消息后，判断Q3是否为空，如果Q3为空，Delta不为空，则将Delta中的消息转移到Q3中，下次直接从Q3消费；</li>
<li>如果Q3和Delta都是空的，则可以认为Delta和Q2的消息都是空的，此时将Q1的消息转移到Q4，下次直接从Q4消费即可。</li>
</ul>
</blockquote>
<h2 id="过期消息删除"><a href="#过期消息删除" class="headerlink" title="过期消息删除"></a>过期消息删除</h2><p>消息的删除只是从<code>ETS(Erlang Term Storge)</code>表删除执行消息的相关信息，同时更新对应的存储文件的相关信息，并不立即对文件中的消息进程删除，后续会有专门的<code>垃圾回收进程</code>负责合并待回收消息文件。</p>
<blockquote>
<p>标记删除，类似habse/cassandra里面的<code>tombstone</code></p>
</blockquote>
<ul>
<li><p>当所有文件中的垃圾消息（已经被删除的消息）比例大于阈值（<code>GARBAGE_FRACTION = 0.5</code>）时，会触发<code>文件合并</code>操作（至少有3个文件存在的情况下），以提高磁盘利用率。</p>
<blockquote>
<p>类似hbase中的<code>minor/major compaction</code><br>执行合并的两个文件一定是逻辑上相邻的两个文件。执行合并时首先锁定这两个文件，并对前面文件中的有效数据进行整理，再将后面文件的有效数据写入到前面的文件，同时更新ETS表中的记录，最后删除后面的文件</p>
</blockquote>
</li>
<li><p><code>publish</code>消息时写入内容，<code>ack</code>消息时删除内容（更新该文件的有用数据大小），当一个文件的有用数据等于0时，删除该文件。</p>
</li>
</ul>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="消息什么时候会刷到磁盘？"><a href="#消息什么时候会刷到磁盘？" class="headerlink" title="消息什么时候会刷到磁盘？"></a>消息什么时候会刷到磁盘？</h2><ul>
<li>写入文件前会有一个<code>Buffer</code>，大小为1M（1048576），数据在写入文件时，首先会写入到这个Buffer，如果Buffer已满，则会将Buffer写入到文件（未必刷到磁盘）；</li>
<li>有个<code>固定的刷盘时间</code>：<code>25ms</code>，也就是不管Buffer满不满，每隔25ms，Buffer里的数据及未刷新到磁盘的文件内容必定会刷到磁盘；</li>
<li>每次消息写入后，如果没有后续写入请求，则会直接将已写入的消息刷到磁盘：使用Erlang的<code>receive x after 0</code>来实现，只要进程的信箱里没有消息，则产生一个timeout消息，而timeout会触发刷盘操作。</li>
</ul>
<h2 id="消息文件何时删除？"><a href="#消息文件何时删除？" class="headerlink" title="消息文件何时删除？"></a>消息文件何时删除？</h2><ul>
<li>当所有文件中的垃圾消息（已经被删除的消息）比例大于阈值（<code>GARBAGE_FRACTION = 0.5</code>）时，会触发<code>文件合并</code>操作（至少有三个文件存在的情况下），以提高磁盘利用率。</li>
<li><code>publish</code>消息时写入内容，<code>ack</code>消息时删除内容（更新该文件的有用数据大小），当一个文件的<code>有用数据等于0时</code>，删除该文件。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://sq.163yun.com/blog/article/163362787003510784">RabbitMQ存储机制源码分析</a></li>
<li><a href="https://www.slideshare.net/RabbitMQ-summit/a-walkthrough-of-the-design-and-architecture-of-rabbitmq-ayanda-dube-125711827">a-walkthrough-of-the-design-and-architecture-of-rabbitmq</a></li>
<li><a href="https://blog.csdn.net/vipshop_fin_dev/article/details/81612935">rabbitmq消息队列原理</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkOnK8S踩坑记录</title>
    <url>/2021/11/28/FlinkOnK8S%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>dolphinscheduler的调度任务有flink流任务，flinkx数据同步，默认仅支持flink on yarn,<br>本文记录了折腾flink on k8s的踩坑过程，主要难点是flink on k8s自身不支持pvc带来的各种妥协，<br>镜像的制作，hive的兼容。</p>
<a id="more"></a>
<h1 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h1><p>本来之前用的都是flink-1.10，但是1.10对k8s的支持还是beta的，(类似spark的２.4版本，到3.0才真正可用)。kerberos的支持，node-selector,application模式，secrets敏感数据的安全增强。<br>另外flinkx插件对k8s的支持也只支持flink-1.12，所以折腾了会就升级1.12了.</p>
<ul>
<li>flink版本：flink-1.12-scala-2.12</li>
<li>k8s版本：1.15.3</li>
</ul>
<h1 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h1><h2 id="工作架构"><a href="#工作架构" class="headerlink" title="工作架构"></a>工作架构</h2><p><img src="flinkOnK8s.jpg" alt="flinkOnK8s工作流程"><br>支持<code>applicationMode</code>和<code>sessionMode</code>，我用的是<code>applicationMode</code>.</p>
<h2 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h2><ul>
<li><p>jobmanager</p>
<ul>
<li>service：jobmanager的rpc服务</li>
<li>deployment：控制pod的副本数</li>
<li>pod:实际执行jobmanager逻辑</li>
<li>ui-ingress：用户创建，路由到service</li>
</ul>
</li>
<li><p>taskmanager</p>
<ul>
<li>pod: 根据slot和parallel动态启动多个</li>
</ul>
</li>
<li><p>historyserver：独立部署</p>
</li>
</ul>
<h1 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h1><h2 id="制作docker镜像"><a href="#制作docker镜像" class="headerlink" title="制作docker镜像"></a>制作docker镜像</h2><p>因为flink native k8s不支持pvc，只能读取本地的资源文件，所以好多需要用到外部动态资源的都是根据环境变量，在entrypoint启动前完成：</p>
<ol>
<li>设置hosts</li>
<li>minio客户端下载flink启动jar</li>
<li>设置flinkx的classpath</li>
<li>设置hadoop classpath</li>
</ol>
<p>附件：<br><a href="flink-dockerfile">flink-dockerfile</a><br><a href="flink-entrypoint.sh">flink-entrypoint.sh</a><br><a href="minio_client.py">minio_client.py</a></p>
<blockquote>
<p>1.12后续版本版本也支持podTemplate中以sidecar的形式实现上述操作。<br>这点spark做的好多了，flink这个基础的volume都不支持，太坑了</p>
</blockquote>
<h2 id="配置K8S环境"><a href="#配置K8S环境" class="headerlink" title="配置K8S环境"></a>配置K8S环境</h2><p>需要运维新增<code>namespace</code>和<code>service account</code></p>
<h2 id="JobManager的HA"><a href="#JobManager的HA" class="headerlink" title="JobManager的HA"></a>JobManager的HA</h2><p>K8s的HA实现原理：leader选举是间接通过etcd实现，恢复时状态数据从savepoint获取。</p>
<blockquote>
<p>注意delete deploy的时候，<code>high-availability.storageDir</code>数据不会删除,需要自己清理</p>
</blockquote>
<p>flink-conf新增以下配置实现<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">high-availability:</span> <span class="string">org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory</span></span><br><span class="line"><span class="comment">#JobManager metadata is persisted in the file system high-availability.storageDir and only a pointer to this state is stored in Kubernetes.</span></span><br><span class="line"><span class="comment"># The storageDir stores all metadata needed to recover a JobManager failure.</span></span><br><span class="line"><span class="attr">high-availability.storageDir:</span> <span class="string">s3:///flink/recovery</span></span><br><span class="line"><span class="comment"># In order to identify the Flink cluster, you have to specify a kubernetes.cluster-id.</span></span><br><span class="line"><span class="attr">kubernetes.cluster-id:</span> <span class="string">cluster1337</span></span><br></pre></td></tr></table></figure></p>
<h2 id="查看flink日志"><a href="#查看flink日志" class="headerlink" title="查看flink日志"></a>查看flink日志</h2><p>目前3种方式查看</p>
<ol>
<li>kubectl logs $clusterId</li>
<li>flink web ui</li>
<li>kibana(fluent-bit会将pod日志都采集到es)</li>
</ol>
<blockquote>
<p>1和2只能在任务运行时查看，任务结束后看不了。</p>
</blockquote>
<h2 id="部署history-server"><a href="#部署history-server" class="headerlink" title="部署history-server"></a>部署history-server</h2><p>以deployment形式部署1个flink-historyserver，然后用service路由，增加1个nodeport外部访问</p>
<p><a href="flink-history-server">flink-history-server.yaml</a></p>
<h2 id="访问web-ui"><a href="#访问web-ui" class="headerlink" title="访问web-ui"></a>访问web-ui</h2><ul>
<li>官方提供的port-forward方案，<code>kubectl -n spark port-forward podName 4000:4040</code>，这种比较原始，每个flink run都需要启动一个代理服务，适合测试，不适合生产环境</li>
<li>生产环境应类似部署独立的ingress提供外部访问,每个flink应用会自动创建一个service，如<code>FLINK_DEMOx-kafka-hive-parquet-rest</code>手动为每个flink应用创建一个ingress,<br>然后用ingress controller访问：地址：<code>http://ip:port/apps/FLINK_DEMOx-kafka-hive-parquet/#/overview</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">FLINK_DEMOx-kafka-hive-parquet</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">FLINK_DEMO</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">"false"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">/$2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/apps/FLINK_DEMOx-kafka-hive-parquet(/|$)(.*)</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">FLINK_DEMOx-kafka-hive-parquet-rest</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>这儿比spark做的好，spark还得自己部署个service才行</p>
</blockquote>
<h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><p>目标：支持同时读取hdfs和minio<br>结论：flink是不强依赖hadoop版本的,HADOOP_CLASSPATH指定hadoop classpath就一定working，建议自己写测试程序验证，实在不行再编译源码。</p>
<h3 id="flink-s3-fs-hadoop如何兼容hadoop-2-6"><a href="#flink-s3-fs-hadoop如何兼容hadoop-2-6" class="headerlink" title="flink-s3-fs-hadoop如何兼容hadoop-2.6"></a>flink-s3-fs-hadoop如何兼容hadoop-2.6</h3><p>flink-1.12.2版本的flink-s3-fs-hadoop插件，依赖hadoop-３.1.0。<br>如果直接换成hadoop-2.6.0，会导致HadoopS3AccessHelper编译不通过，<br>下面3个依赖只在hadoop-aws-3.1.0版本中存在。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.s3a.S3AUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.s3a.WriteOperationHelper;</span><br><span class="line"><span class="keyword">import</span> com.amazonaws.SdkBaseException;</span><br></pre></td></tr></table></figure><br>是需要自己编译flink-s3-fs-hadoop？<br>还是有其他的兼容性方案，使得flink兼容hadoop-2.6.0</p>
<p>改为2.７.5测试<br>java.lang.NoSuchMethodError: org.apache.hadoop.tracing.TraceUtils.wrapHadoopConf(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/htrace/HTraceConfiguration;</p>
<p>改为3.1.0测试，无法识别<code>s3.endpoint</code>配置，发现坑爹玩意儿不读<code>flink-conf.yaml</code>，读取的是<code>core-site.xml</code>中的配置<br><code>HADOOP_CONF_DIR</code>和<code>FLINK_DIR_CONF</code>因为没有加入classpath都没用，只能识别test/resources根目录下的<code>core-site.xml</code></p>
<h3 id="s3a官方wordcount示例"><a href="#s3a官方wordcount示例" class="headerlink" title="s3a官方wordcount示例"></a>s3a官方wordcount示例</h3><p>./bin/start-cluster.<br>./bin/flink run examples/batch/WordCount.jar -input s3://FLINK<em>DEMO/<strong>FLINK</strong>/core-site.xml -output s3://FLINK<em>DEMO/__FLINK</em></em>/worcount.txt<br>一切正常…<br>那说明</p>
<h3 id="flink-1-12-2编译"><a href="#flink-1-12-2编译" class="headerlink" title="flink-1.12.2编译"></a>flink-1.12.2编译</h3><p>flink-filesystems项目的pom添加repository<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">name</span>&gt;</span>cloudera repo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">truetrue<span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">true<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean install \</span><br><span class="line">-Dfast \</span><br><span class="line">-Dskip.npm \</span><br><span class="line">-DskipTests \</span><br><span class="line">-Drat.skip&#x3D;true \</span><br><span class="line">-Dscala-2.12 \</span><br><span class="line">-Pinclude-hadoop \</span><br><span class="line">-Dhadoop.version&#x3D;2.6.5 \</span><br><span class="line">-Phive-1.1.0</span><br></pre></td></tr></table></figure></p>
<h3 id="flink-shaded-hadoop编译"><a href="#flink-shaded-hadoop编译" class="headerlink" title="flink-shaded-hadoop编译"></a>flink-shaded-hadoop编译</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean package \</span><br><span class="line">-DskipTests \</span><br><span class="line">-Pvendor-repos \ </span><br><span class="line">-Drat.skip&#x3D;true  \</span><br><span class="line">-Pinclude-hadoop  \</span><br><span class="line">-Dhadoop.version&#x3D;2.6.5</span><br></pre></td></tr></table></figure>
<p>自己打包的hadoop是能够读写hdfs了，但是s3a文件系统必须要hadoop-3.1.0，这边好了，那边又翘起来了（－－）</p>
<h3 id="flink-s3-fs-hadoop"><a href="#flink-s3-fs-hadoop" class="headerlink" title="flink-s3-fs-hadoop"></a>flink-s3-fs-hadoop</h3><p>hive和hdfs适配好了，然后s3那边又挂了…,hadoop-aws对hadoop的版本超级敏感，一个版本变化都肯呢个会导致起不来</p>
<h3 id="flink-filesystem的revert-classloader"><a href="#flink-filesystem的revert-classloader" class="headerlink" title="flink filesystem的revert classloader"></a>flink filesystem的revert classloader</h3><p>Flink按官方文档是采用SPI机制，自定义<code>revert classloader</code>的方式来动态加载filesystem，(org.apache.flink.core.plugin.PluginLoader)，按理不会和flink Classloader的类冲突。</p>
<blockquote>
<p>flink程序读取一个s3a://的文件，本地debug时没有FileSystem走的<code>initializeWithoutPlugins</code>，所以报错找不到s3a的文件系统，然后我小机灵就pom引入了flink-s3-fs-hadoop，然后就和user code中的class冲突了，hadoop版本不匹配，</p>
</blockquote>
<p>根本原因是这个插件的inverse class loader机制没生效。所以手动初始化一下filesystem的插件机制<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FileSystem.initialize(flinkConfig, PluginUtils.createPluginManagerFromRootFolder(flinkConfig));</span><br></pre></td></tr></table></figure></p>
<h3 id="PluginLoader的核心代码"><a href="#PluginLoader的核心代码" class="headerlink" title="PluginLoader的核心代码"></a>PluginLoader的核心代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Loads all classes from the plugin jar except for explicitly white-listed packages</span></span><br><span class="line"><span class="comment"> * (org.apache.flink, logging).</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;No class/resource in the system class loader (everything in lib/) can be seen in the</span></span><br><span class="line"><span class="comment"> * plugin except those starting with a whitelist prefix.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PluginClassLoader</span> <span class="keyword">extends</span> <span class="title">URLClassLoader</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ClassLoader PLATFORM_OR_BOOTSTRAP_LOADER;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClassLoader flinkClassLoader;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String[] allowedFlinkPackages;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String[] allowedResourcePrefixes;</span><br><span class="line"></span><br><span class="line">    PluginClassLoader(</span><br><span class="line">            URL[] pluginResourceURLs,</span><br><span class="line">            ClassLoader flinkClassLoader,</span><br><span class="line">            String[] allowedFlinkPackages) &#123;</span><br><span class="line">        <span class="keyword">super</span>(pluginResourceURLs, PLATFORM_OR_BOOTSTRAP_LOADER);</span><br><span class="line">        <span class="keyword">this</span>.flinkClassLoader = flinkClassLoader;</span><br><span class="line">        <span class="keyword">this</span>.allowedFlinkPackages = allowedFlinkPackages;</span><br><span class="line">        allowedResourcePrefixes =</span><br><span class="line">                Arrays.stream(allowedFlinkPackages)</span><br><span class="line">                        .map(packageName -&gt; packageName.replace(<span class="string">'.'</span>, <span class="string">'/'</span>))</span><br><span class="line">                        .toArray(String[]::<span class="keyword">new</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> Class&lt;?&gt; loadClass(<span class="keyword">final</span> String name, <span class="keyword">final</span> <span class="keyword">boolean</span> resolve)　 <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (getClassLoadingLock(name)) &#123;</span><br><span class="line">            <span class="keyword">final</span> Class&lt;?&gt; loadedClass = findLoadedClass(name);</span><br><span class="line">            <span class="keyword">if</span> (loadedClass != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> resolveIfNeeded(resolve, loadedClass);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (isAllowedFlinkClass(name)) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> resolveIfNeeded(resolve, flinkClassLoader.loadClass(name));</span><br><span class="line">                &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">                    <span class="comment">// fallback to resolving it in this classloader</span></span><br><span class="line">                    <span class="comment">// for cases where the plugin uses org.apache.flink namespace</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">super</span>.loadClass(name, resolve);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Class&lt;?&gt; resolveIfNeeded(<span class="keyword">final</span> <span class="keyword">boolean</span> resolve, <span class="keyword">final</span> Class&lt;?&gt; loadedClass) &#123;</span><br><span class="line">        <span class="keyword">if</span> (resolve) &#123;</span><br><span class="line">            resolveClass(loadedClass);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> loadedClass;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> URL <span class="title">getResource</span><span class="params">(<span class="keyword">final</span> String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (isAllowedFlinkResource(name)) &#123;</span><br><span class="line">            <span class="keyword">return</span> flinkClassLoader.getResource(name);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getResource(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Enumeration&lt;URL&gt; <span class="title">getResources</span><span class="params">(<span class="keyword">final</span> String name)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// ChildFirstClassLoader merges child and parent resources</span></span><br><span class="line">        <span class="keyword">if</span> (isAllowedFlinkResource(name)) &#123;</span><br><span class="line">            <span class="keyword">return</span> flinkClassLoader.getResources(name);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getResources(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isAllowedFlinkClass</span><span class="params">(<span class="keyword">final</span> String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.stream(allowedFlinkPackages).anyMatch(name::startsWith);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isAllowedFlinkResource</span><span class="params">(<span class="keyword">final</span> String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.stream(allowedResourcePrefixes).anyMatch(name::startsWith);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        ClassLoader platformLoader = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            platformLoader =　(ClassLoader)ClassLoader.class.getMethod("getPlatformClassLoader").invoke(null);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">            <span class="comment">// on Java 8 this method does not exist, but using null indicates the bootstrap</span></span><br><span class="line">            <span class="comment">// loader that we want</span></span><br><span class="line">            <span class="comment">// to have</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot retrieve platform classloader on Java 9+"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        PLATFORM_OR_BOOTSTRAP_LOADER = platformLoader;</span><br><span class="line">        ClassLoader.registerAsParallelCapable();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="用户程序加载"><a href="#用户程序加载" class="headerlink" title="用户程序加载"></a>用户程序加载</h2><p>flink1.12不能使用pvc挂载目录到容器内，userCode只能提前打包在image中，这在生产上基本不能使用。因为数据加工时，用户的代码总是自定义的jar包的形式出现。</p>
<p>另外打包方式可以采用shaded-plugin，将依赖都打成1个fatJar，flink的依赖改为provided。<code>classloader.resolve-order:child-first</code>模式加载就行，避免userCode和flink代码冲突</p>
<p>flink-1.12可在entrypoint中通过s3a的python sdk，从minio下载用户指定的userCode.jar，然后启动脚本用local://userCode.jar</p>
<blockquote>
<p>flink-1.13可以定义podTemplate，initContainer下载远程userCode到local</p>
<p>相关配置参数：<code>pipeline.jars</code>,<code>pipeline.classpath</code></p>
</blockquote>
<h2 id="kerberos认证"><a href="#kerberos认证" class="headerlink" title="kerberos认证"></a>kerberos认证</h2><p>Kerberos authentication for various components - Hadoop, ZooKeeper, and connectors<br>flink的kerberos配置<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">security.kerberos.login.contexts</span></span><br><span class="line"><span class="string">security.kerberos.login.keytab</span></span><br><span class="line"><span class="string">security.kerberos.login.principal</span></span><br><span class="line"><span class="string">security.kerberos.login.use-ticket-cache</span></span><br></pre></td></tr></table></figure><br>我是自己从远程下载当前用户的keytab然后在程序内认证的，不是走kinit的形式。</p>
<ol>
<li><p>默认读取/etc/krb5.conf而不是自定义的krb5.conf</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">reloadKrb5conf</span><span class="params">(String krb5confPath)</span> </span>&#123;</span><br><span class="line">    System.setProperty(<span class="string">"java.security.krb5.conf"</span>, krb5confPath);</span><br><span class="line">    Config.refresh();</span><br><span class="line">    KerberosName.resetDefaultRealm();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>kerberos使用keytab认证后，返回的用户是当前linux的系统用户（simple认证）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration securityConf = <span class="keyword">new</span> Configuration();</span><br><span class="line">securityConf.set(FileSystemUtil.KEY_HADOOP_SECURITY_AUTHORIZATION, <span class="string">"true"</span>);</span><br><span class="line">securityConf.set(FileSystemUtil.KEY_HADOOP_SECURITY_AUTHENTICATION, KRB_STR);</span><br><span class="line"><span class="comment">//强制刷新config会重新初始化UserGroupInformation的conf</span></span><br><span class="line">UserGroupInformation.setConfiguration(securityConf);</span><br><span class="line">LOG.trace(<span class="string">"login user:&#123;&#125; with keytab:&#123;&#125;"</span>, principal, keytab);</span><br><span class="line"><span class="keyword">return</span> UserGroupInformation.loginUserFromKeytabAndReturnUGI(principal, keytab);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="hive版本兼容"><a href="#hive版本兼容" class="headerlink" title="hive版本兼容"></a>hive版本兼容</h2><p>由于社区大多数用户都是hive作为数仓，所以flink和spark一样，都内置兼容hive的各个版本。<br>但注意flink的hive版本和自己的hiveServer的版本必须严格一致，用高版本的jdbc连接低版本的hiveserver是会报错的</p>
<p>引入<code>flink-sql-connector-hive</code>包即可，但是注意如果服务端是cdh的，官方的包可能报错，还是需要自己引入cdh对应的hive包</p>
<h2 id="hosts配置"><a href="#hosts配置" class="headerlink" title="hosts配置"></a>hosts配置</h2><p>flink run-application中新增环境变量<code>HOSTS_FILE</code>,<br>docker镜像的entrypoint中读取变量并并追加到<code>/etc/hosts</code></p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>flink不同集群环境的测试脚本</p>
<h2 id="测试WordCount"><a href="#测试WordCount" class="headerlink" title="测试WordCount"></a>测试WordCount</h2><p>/opt/flink/bin/flink run-application \<br>—target kubernetes-application \<br>-Dkubernetes.cluster-id=”flink-demo1” \<br>-Dkubernetes.container.image=”harbor.dc.xxx-it.com/x-bigdata/flink:0.1” \<br>-Dkubernetes.container.image.pull-policy=Always \<br>-Dkubernetes.namespace=dboard \<br>-Dkubernetes.service-account=dboard \<br>-Dkubernetes.jobmanager.cpu=1 \<br>-Dkubernetes.taskmanager.cpu=1 \<br>-Djobmanager.memory.flink.size=1gb \<br>-Dtaskmanager.memory.process.size=1gb \<br>-Dtaskmanager.numberOfTaskSlots=1 \<br>local:///opt/flink/examples/batch/WordCount.jar </p>
<h2 id="flink-on-k8sApplication"><a href="#flink-on-k8sApplication" class="headerlink" title="flink on k8sApplication"></a>flink on k8sApplication</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">set</span> -ex</span><br><span class="line">BASEDIR=$(<span class="built_in">cd</span> `dirname <span class="variable">$0</span>`; <span class="built_in">pwd</span>)</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$BASEDIR</span></span><br><span class="line"><span class="built_in">source</span> /opt/dolphinscheduler/conf/env/dolphinscheduler_env.sh</span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=/opt/dolphinscheduler/conf/config/kube_config.yaml</span><br><span class="line"><span class="built_in">export</span> FLINK_HOME=<span class="variable">$FLINK112_HOME</span></span><br><span class="line"><span class="built_in">export</span> FLINK_CONF_DIR=<span class="string">"<span class="variable">$FLINK_HOME</span>/conf"</span></span><br><span class="line"><span class="built_in">export</span> FLINK_CLASS_PATH=<span class="string">"<span class="variable">$FLINK_HOME</span>/lib/*"</span></span><br><span class="line"></span><br><span class="line">/usr/<span class="built_in">local</span>/openjdk-8/bin/java \</span><br><span class="line">-Dlog.file=/opt/cdh/lib/flink-1.12.2/<span class="built_in">log</span>/flink--client-10.199.150.66.log \</span><br><span class="line">-Dlog4j.configuration=file:/opt/cdh/lib/flink-1.12.2/conf/log4j-cli.properties \</span><br><span class="line">-Dlog4j.configurationFile=file:/opt/cdh/lib/flink-1.12.2/conf/log4j-cli.properties \</span><br><span class="line">-Dkubernetes.config.file=/opt/dolphinscheduler/conf/config/kube_config.yaml \</span><br><span class="line">-Dkubernetes.namespace=FLINK_DEMO \</span><br><span class="line">-Dkubernetes.service-account=FLINK_DEMO \</span><br><span class="line">-Dkubernetes.container.image=bigdata/flink:latest \</span><br><span class="line">-Dkubernetes.cluster-id=flink-5-19-2870-28819-48517 \</span><br><span class="line">-Dkubernetes.flink.conf.dir=/opt/cdh/lib/flink-1.12.2/conf \</span><br><span class="line">-Dkubernetes.flink.log.dir=/opt/cdh/lib/flink-1.12.2/<span class="built_in">log</span> \</span><br><span class="line">-Djobmanager.memory.process.size=1gb \</span><br><span class="line">-Dtaskmanager.memory.process.size=1gb \</span><br><span class="line">-Dtaskmanager.numberOfTaskSlots=1 \</span><br><span class="line">-Dkubernetes.jobmanager.cpu=1.0 \</span><br><span class="line">-Dparallelism.default=1  \</span><br><span class="line">-Dclassloader.resolve-order=parent-first \</span><br><span class="line">-classpath <span class="variable">$FLINK_CLASS_PATH</span>: \</span><br><span class="line">org.apache.flink.client.cli.CliFrontend run-application \</span><br><span class="line">--target kubernetes-application \</span><br><span class="line">-c org.apache.flink.examples.java.wordcount.WordCount \</span><br><span class="line"><span class="built_in">local</span>:///opt/cdh/lib/flink-1.12.2/examples/batch/WordCount.jar  \</span><br><span class="line">--input /opt/cdh/lib/flink-1.12.2/conf/flink-conf.yaml \</span><br><span class="line">--output /tmp/flink-conf.yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p>囧，没注意区分<code>flink run</code> 和　<code>flink run-application</code>导致的<code>Caused by: java.lang.IllegalStateException: No ExecutorFactory found to execute the application.</code>查了一下午.<br>run用的是<code>DefaultExecutorServiceLoader</code>, run-application用的是<code>DefaultClusterClientServiceLoader</code>，—target要与之对应</p>
</blockquote>
<h2 id="flink-command"><a href="#flink-command" class="headerlink" title="flink command"></a>flink command</h2><p>./bin/flink list —target kubernetes-application -Dkubernetes.cluster-id=flink-demo1<br>./bin/flink cancel —target kubernetes-application -Dkubernetes.cluster-id=flink-demo1 $jobId</p>
<h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/336070632">Flink1.12 native kubernetes 演进</a></li>
<li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/deployment/ha/kubernetes_ha.html">Flink1.12 kubernetes ha</a></li>
<li><a href="http://legendtkl.com/2020/11/27/flink-ha-kubernetes/">flink jm ha</a></li>
<li><a href="https://mvnrepository.com/artifact/org.apache.flink/flink-sql-connector-hive-1.2.2_2.12/1.12.2">maven:flink-sql-connector-hive</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/">flink-hive</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/s3.html#hadooppresto-s3-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8F%92%E4%BB%B6">flink-s3a</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-master/docs/ops/debugging/debugging_classloading/#inverted-class-loading-and-classloader-resolution-order">flink-inverted-class-loading-and-classloader-resolution-order</a></li>
<li><a href="https://developer.aliyun.com/article/771412">双亲委派模型与 Flink 的类加载策略</a></li>
</ul>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>flink</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title>GBDT学习笔记</title>
    <url>/2017/07/25/GBDT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="GBDT学习笔记"><a href="#GBDT学习笔记" class="headerlink" title="GBDT学习笔记"></a>GBDT学习笔记</h1><p>学习任何东西都可以按照3W的框架进行，容器技术也是一样，先回答 What、Why 和 How 这三个问题。</p>
<p>参考：<br>video：<a href="https://www.youtube.com/watch?v=IXZKgIsZRm0&amp;ab_channel=PyData">https://www.youtube.com/watch?v=IXZKgIsZRm0&amp;ab_channel=PyData</a></p>
<p>在说GBDT前，我们先说下它的俩前缀Gradient Boosting：</p>
<ul>
<li>Boosting: 这是一种迭代算法，每一次训练都是在前面已有模型的预测基础上进行。<br>最简单地说，先训练一个初始模型，对比真实值和预测值的残差；用残差再训练一个模型，再计算残差；再训练……。这样，每一个模型都专注于修正前面模型最不给力的效果方面。<br>于是，通过这种方式联合多个弱分类器，就能得到一个强分类器。</li>
<li>Gradient: 梯度。对于单个变量来说，就是一阶导数。<br>前面Boosting要计算残差，方法就很多了，你可以直接相减，也可以定义个函数。这里Gradient就是说用梯度来计算残差。</li>
</ul>
<p>所以说Gradient Boosting是一种算法框架，它是<code>用Grdient计算残差的Boosting过程，而GBDT只是用决策树来训练的一种具体实现</code>。</p>
<h1 id="概念定义-what"><a href="#概念定义-what" class="headerlink" title="概念定义 what"></a>概念定义 what</h1><h2 id="ensemble-learning（集成学习）"><a href="#ensemble-learning（集成学习）" class="headerlink" title="ensemble learning（集成学习）"></a>ensemble learning（集成学习）</h2><p>从下图，我们可以对集成学习的思想做一个概括。对于训练集数据，我们通过训练若干个个体学习器，通过一定的结合策略，就可以最终形成一个强学习器，以达到博采众长的目的。<br><img src="ensemble learning（集成学习）.png" alt="ensemble learning（集成学习）"><br>也就是说，集成学习有两个主要的问题需要解决，<br>第一是如何得到若干个个体学习器，<br>第二是如何选择一种结合策略，将这些个体学习器集合成一个强学习器。</p>
<h3 id="集成学习之个体学习器"><a href="#集成学习之个体学习器" class="headerlink" title="集成学习之个体学习器"></a>集成学习之个体学习器</h3><p>如何得到若干个个体学习器？ 这里我们有两种选择。</p>
<ol>
<li>第一种就是所有的个体学习器都是一个种类的，或者说是<code>同质</code>的。比如都是决策树个体学习器，或者都是神经网络个体学习器。<br>同质个体学习器使用最多的模型是<code>CART决策树</code>和<code>神经网络</code>。<br>同质个体学习器按照个体学习器之间<code>是否存在依赖关系</code>可以分为两类，<ul>
<li>第一个是个体学习器之间存在强依赖关系，一系列个体学习器基本都需要串行生成，代表算法是<code>boosting</code>系列算法，</li>
<li>第二个是个体学习器之间不存在强依赖关系，一系列个体学习器可以并行生成，代表算法是<code>bagging</code>和<code>随机森林（Random Forest）</code>系列算法。</li>
</ul>
</li>
<li>第二种是所有的个体学习器不全是一个种类的，或者说是<code>异质</code>的。比如我们有一个分类问题，对训练集采用<code>支持向量机个体学习器，逻辑回归个体学习器和朴素贝叶斯个体学习器</code>来学习，再通过某种结合策略来确定最终的分类强学习器。</li>
</ol>
<blockquote>
<p>目前来说，同质个体学习器的应用是最广泛的，一般我们常说的集成学习的方法都是指的同质个体学习器。</p>
</blockquote>
<h2 id="集成学习之boosting"><a href="#集成学习之boosting" class="headerlink" title="集成学习之boosting"></a>集成学习之boosting</h2><p>Boosting 是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行加权，所以随着迭代不断进行，误差会越来越小，所以模型的 bias 会不断降低。这种算法无法并行，例子比如 Adaptive Boosting.<br><img src="Boosting算法的工作机制.png" alt="Boosting算法的工作机制"><br>从图中可以看出，Boosting算法的工作机制</p>
<ol>
<li>从训练集用<code>初始权重</code>训练出一个弱学习器1，根据弱学习的<code>学习误差率</code>表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视；</li>
<li>基于调整权重后的训练集来训练弱学习器2；</li>
<li>如此重复进行，直到弱学习器数达到事先指定的数目T；</li>
<li>最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。</li>
</ol>
<p>Boosting系列算法里最著名算法主要有：</p>
<ul>
<li>AdaBoost算法</li>
<li>提升树(boosting tree)系列算法。提升树系列算法里面应用最广泛的是梯度提升树(Gradient Boosting Tree)。</li>
</ul>
<h2 id="Boosting算法的4个具体的问题"><a href="#Boosting算法的4个具体的问题" class="headerlink" title="Boosting算法的4个具体的问题"></a>Boosting算法的4个具体的问题</h2><p> 只要是boosting大家族的算法，都要解决这4个问题。</p>
<ol>
<li>如何计算学习误差率e?</li>
<li>如何得到弱学习器权重系数α?</li>
<li>如何更新样本权重D?</li>
<li>使用何种结合策略？</li>
</ol>
<h2 id="集成学习之bagging"><a href="#集成学习之bagging" class="headerlink" title="集成学习之bagging"></a>集成学习之bagging</h2><p>Bagging 是 Bootstrap Aggregating 的简称，意思就是再取样 (Bootstrap) 然后在每个样本上训练出来的模型取平均，所以是降低模型的 variance， 比如 Random Forest 这种先天并行的算法都有这个效果。</p>
<p>Bagging的算法原理和 boosting不同，它的弱学习器之间没有依赖关系，可以并行生成，我们可以用一张图做一个概括如下：</p>
<p><img src="Bagging的算法原理.png" alt="Bagging的算法原理"><br>从上图可以看出，bagging的个体弱学习器的训练集是通过<code>随机采样</code>得到的。通过T次的随机采样，我们就可以得到T个采样集，对于这T个采样集，我们可以分别独立的训练出T个弱学习器，再对这T个弱学习器通过集合策略来得到最终的强学习器。</p>
<p>对于这里的随机采样有必要做进一步的介绍，这里一般采用的是<code>自助采样法（Bootstap sampling）</code>,即对于m个样本的原始训练集，我们每次先随机采集一个样本放入采样集，接着把该样本放回，也就是说下次采样时该样本仍有可能被采集到，这样采集m次，最终可以得到m个样本的采样集，由于是随机采样，这样每次的采样集是和原始训练集不同的，和其他采样集也是不同的，这样得到多个不同的弱学习器。</p>
<blockquote>
<p>随机森林是bagging的一个特化进阶版，所谓的特化是因为随机森林的弱学习器都是决策树。所谓的进阶是随机森林在bagging的样本随机采样基础上，又加上了特征的随机选择，其基本思想没有脱离bagging的范畴。</p>
</blockquote>
<p>　　　　</p>
<h2 id="GBDT是什么？"><a href="#GBDT是什么？" class="headerlink" title="GBDT是什么？"></a>GBDT是什么？</h2><p>GBDT有很多简称，有</p>
<ul>
<li>GBT（Gradient Boosting Tree）, </li>
<li>GTB（Gradient Tree Boosting ）， </li>
<li>GBRT（Gradient Boosting Regression Tree）, </li>
<li><p>MART(Multiple Additive Regression Tree)，</p>
<p>  其实都是指的同一种算法，本文统一简称GBDT（Gradient Boosting Decision Tree）。GBDT在BAT大厂中也有广泛的应用，假如要选择3个最重要的机器学习算法的话，个人认为GBDT应该占一席之地。</p>
</li>
</ul>
<blockquote>
<p>GBDT 使用的弱分类器就是 Decision Tree，而融合的方法叫做 Gradient Boosting。</p>
</blockquote>
<h2 id="Gradient-梯度"><a href="#Gradient-梯度" class="headerlink" title="Gradient  梯度"></a>Gradient  梯度</h2><h3 id="梯度的提出只为回答一个问题"><a href="#梯度的提出只为回答一个问题" class="headerlink" title="梯度的提出只为回答一个问题"></a>梯度的提出只为回答一个问题</h3><p>函数在变量空间的某一点处，沿着哪一个方向有最大的变化率？ </p>
<h3 id="梯度定义grad"><a href="#梯度定义grad" class="headerlink" title="梯度定义grad"></a>梯度定义grad</h3><blockquote>
<p>函数在某一点的梯度是个向量，它的方向与函数在这点取得最大方向导数的方向一致，而它的模为方向导数的最大值。<br>函数在一点的梯度方向与等值线在这点的一个法线方向相同，它的指向为从数值较低的等值线指向数值较高的等值线，梯度的模就等于函数在这个法线方向的方向导数；<br>—-《同济大学高等数学下册》p49</p>
</blockquote>
<p>这里注意三点： </p>
<ol>
<li>梯度是一个向量，即有方向有大小； </li>
<li>梯度的方向是最大方向导数的方向； </li>
<li>梯度的值是最大方向导数的值。<br>梯度即函数在某一点最大的方向导数，函数沿梯度方向函数有最大的变化率。 </li>
</ol>
<h3 id="梯度的应用"><a href="#梯度的应用" class="headerlink" title="梯度的应用"></a>梯度的应用</h3><p>一个标量场 数量变化最快的方向就是梯度方向，<br>那么我们可以用梯度来优化损失函数，如梯度下降求损失函数的最小值…<br>形象理解就是：山坡某个点坡度最陡的方向</p>
<p>梯度本质就是一个向量。一个曲面上某点(x，y)，梯度是由该点偏导数得出的向量(a，b)。<br>可以类比成：你站在该点，按照向量所指的方向上山最陡。</p>
<h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><p> 导数：被定义为一个极限，其意义就是变化率<br>微分：是一个线性函数，其意义就是变化的具体数值<br>切线：有了导数之后就可以被确定下来了</p>
<ul>
<li>几何意义：f(x)在点x0处的导数为改点切线的斜率</li>
<li>物理意义：动点在某时刻t0的瞬时速度（极限值）<h2 id="方向导数"><a href="#方向导数" class="headerlink" title="方向导数"></a>方向导数</h2>方向导数就是一个曲面上的某点(x，y)，从该点起始沿特定方向函数的变化率。<br>可以类比成：有一个山峰，你站在山顶观察，北坡较陡南坡较缓。</li>
</ul>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><ul>
<li>Boosting是一族可将弱学习器提升为强学习器的算法，属于集成学习（ensemble learning）的范畴；</li>
<li>Boosting方法基于这样一种思想：<br>对于一个复杂任务来说，将多个专家的判定进行适当的综合得出的判断，要比其中任何一个专家单独的判断好。<br>通俗理解。</li>
</ul>
<ol>
<li>“三个臭皮匠顶个诸葛亮”，一堆弱分类器的组合就可以成为一个强分类器；</li>
<li>“知错能改，善莫大焉”，不断地在错误中学习，迭代来降低犯错概率；</li>
</ol>
<h3 id="弱学习算法和强学习算法"><a href="#弱学习算法和强学习算法" class="headerlink" title="弱学习算法和强学习算法"></a>弱学习算法和强学习算法</h3><p>要理解好Boosting的思想，首先需从弱学习算法和强学习算法来引入：</p>
<ul>
<li>强学习算法：存在一个多项式时间的学习算法以识别一组概念，且识别的正确率很高；</li>
<li>弱学习算法：识别一组概念的正确率仅比随机猜测略好；</li>
</ul>
<p>Kearns &amp; Valiant证明了<strong>弱学习算法与强学习算法的等价问题</strong>，<br>如果两者等价，只需找到一个比随机猜测略好的学习算法，就可以将其提升为强学习算法。</p>
<blockquote>
<p>那么是怎么实现“知错就改”的呢？<br>Boosting算法，通过一系列的迭代来优化分类结果，每迭代一次引入一个弱分类器，来克服现在已经存在的弱分类器组合的shortcomings；</p>
<ul>
<li>在Adaboost算法中，这个shortcomings的表征就是权值高的样本点；</li>
<li>而在Gradient Boosting算法中,这个shortcomings的表征就是梯度；</li>
</ul>
</blockquote>
<p>无论是Adaboost还是Gradient Boosting，都是通过这个shortcomings来告诉学习器怎么去提升模型，也就是“Boosting”这个名字的由来吧</p>
<h4 id="Adaboost-算法"><a href="#Adaboost-算法" class="headerlink" title="Adaboost 算法"></a>Adaboost 算法</h4><p><img src="Adaboost算法.png" alt="Adaboost算法"><br>前一个学习器改变权重w，然后再经过下一个学习器，最终所有的学习器共同组成最后的学习器。<br>如果一个样本在前一个学习器中被误分，那么它所对应的权重会被加重，相应地，被正确分类的样本的权重会降低。</p>
<h2 id="Gradient-boosting梯度提升"><a href="#Gradient-boosting梯度提升" class="headerlink" title="Gradient boosting梯度提升"></a>Gradient boosting梯度提升</h2><p>梯度提升（Gradient boosting）是一种用于回归、分类和排序任务的机器学习技术，属于Boosting算法族的一部分。<br>梯度提升同其他boosting方法一样，通过集成（ensemble）多个弱学习器，通常是决策树，来构建最终的预测模型。<br><img src="Alt text.png" alt="Alt text"><br><img src="Alt text.png" alt="Alt text"></p>
<ul>
<li>Gradient Boosting 在迭代的时候选择梯度下降的方向来保证最后的结果最好。</li>
<li>损失函数用来描述模型的“靠谱”程度，假设模型没有过拟合，损失函数越大，模型的错误率越高</li>
<li>如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度方向上下降。</li>
</ul>
<blockquote>
<p>Gradient Boosting是在boosting思想下的一种函数（也可以说是模型）的优化的方法，首先将函数分解为可加的形式（其实所有的函数都是可加的，只是是否好放在这个框架中，以及最终的效果如何）。然后进行m次迭代，通过使得损失函数在梯度方向上减少，最终得到一个优秀的模型。值得一提的是，每次模型在梯度方向上的减少的部分，可以认为是一个“小”的或者“弱”的模型，最终我们会通过加权(也就是每次在梯度方向上下降的距离）的方式将这些“弱”的模型合并起来，形成一个更好的模型。</p>
</blockquote>
<h2 id="Decision-Tree基本思想"><a href="#Decision-Tree基本思想" class="headerlink" title="Decision Tree基本思想"></a>Decision Tree基本思想</h2><h3 id="DT定义"><a href="#DT定义" class="headerlink" title="DT定义"></a>DT定义</h3><ul>
<li>机器学习中，决策树是一个预测模型，数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测；</li>
<li>他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。</li>
<li>决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 </li>
</ul>
<p>从数据产生决策树的机器学习技术叫做决策树学习，通俗说就是决策树。<br>一个决策树包含三种类型的节点：</p>
<ol>
<li>决策节点：通常用矩形框来表示</li>
<li>机会节点：通常用圆圈来表示</li>
<li>终结点：通常用三角形来表示<br><img src="决策树示例.png" alt="决策树示例"></li>
</ol>
<p>决策树学习也是数据挖掘中一个普通的方法。在这里，每个决策树都表述了一种树型结构，它由它的分支来对该类型的对象依靠属性进行分类。<br>每个决策树可以依靠对源数据库的分割进行数据测试。这个过程可以递归式的对树进行修剪。 当不能再进行分割或一个单独的类可以被应用于某一分支时，递归过程就完成了。</p>
<p>另外，随机森林分类器将许多决策树结合起来以提升分类的正确率。</p>
<p>决策树同时也可以依靠计算条件概率来构造。</p>
<h2 id="分类树-回归树"><a href="#分类树-回归树" class="headerlink" title="分类树/回归树"></a>分类树/回归树</h2><h3 id="分类树"><a href="#分类树" class="headerlink" title="分类树"></a>分类树</h3><p>以C4.5分类树为例，C4.5分类树在每次分枝时，<br>是穷举每一个feature的每一个阈值，<br>找到使得按照feature&lt;=阈值，和feature&gt;阈值分成的两个分枝的熵最大的阈值<br>(熵最大的概念可理解成尽可能每个分枝的男女比例都远离1:1)，</p>
<p>按照该标准分枝得到两个新节点，用同样方法继续分枝直到所有人都被分入性别唯一的叶子节点，<br>或达到预设的终止条件，<br>若最终叶子节点中的性别不唯一，则以多数人的性别作为该叶子节点的性别。</p>
<p>总结：<br>分类树使用<code>信息增益</code>或增益比率来划分节点；<br>每个节点样本的类别情况投票决定测试样本的类别。</p>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p>回归树总体流程也是类似，<br>区别在于，回归树的每个节点（不一定是叶子节点）都会得一个预测值，<br>以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。<br>分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差即(每个人的年龄-预测年龄)^2 的总和 / N。<br>也就是被预测出错的人数越多，错的越离谱，均方差就越大，通过<code>最小化均方差</code>能够找到最可靠的分枝依据。<br>分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，<br>若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<p>总结：<br>回归树使用最小均方差划分节点；<br>每个节点样本的均值作为测试样本的回归预测值。</p>
<h2 id="决策树-分裂成本"><a href="#决策树-分裂成本" class="headerlink" title="决策树-分裂成本"></a>决策树-分裂成本</h2><p>让我们进一步讨论用于分类和回归的成本函数。在这两种情况下，成本函数都在试图寻找分裂后结构相似程度最高的那种方式。其中的意义是，我们可以更加确信测试数据将会跟随哪个路径。<br><img src="Alt text.png" alt="Alt text"><br>比如预测房价：决策树开始分裂时需要考虑训练数据的所有特征；对于训练数据的特定分组，其输入响应的均值会被作为该组的预测值。上述函数会被用在所有的数据点，用以计算所有可能分裂的成本。损失最低的分裂方式将被筛选出来。另一种成本函数涉及到约化和标准差，更多信息可参考这里：<a href="http://www.saedsayad.com/decision_tree_reg.htm。">http://www.saedsayad.com/decision_tree_reg.htm。</a></p>
<p><img src="Alt text.png" alt="Alt text"><br>为评估某个分裂方式的优劣，我们用Gini分数来衡量训练数据分裂后的混乱程度。其中，pk表示特定分组中相同输入类别所占的比例。当某一数据组的所有输入都来自同一类别时，我们就得到了一个完美分类，此时的pk值不是1就是0，而G必定为0。但如果某个数据组中两个类别的数据各占一半，这就发生了最坏的情况，此时二元分类的pk=0.5, G=0.5。</p>
<p><a href="http://daniellaah.github.io/2017/Statistical-Learning-Notes-Chapter5-DecisionTree-2.html">《统计学习方法》笔记 (七) - 决策树(下)</a></p>
<h2 id="应用场景-why"><a href="#应用场景-why" class="headerlink" title="应用场景 why"></a>应用场景 why</h2><p>为什么需要GBDT？GBDT到底解决的是什么问题？</p>
<h2 id="算法推导-how"><a href="#算法推导-how" class="headerlink" title="算法推导 how"></a>算法推导 how</h2><p>GBDT如何工作，算法原理<br><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html">http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html</a></p>
<p><a href="http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/">http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/</a></p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p><img src="Alt text.png" alt="Alt text"><br><img src="Alt text.png" alt="Alt text"></p>
<p><a href="https://distill.pub/2017/momentum/">梯度下降</a><br><a href="http://www.r2d3.us/å¾è§£æºå¨å­¦ä¹ /">决策树</a></p>
<h1 id="GBDT总结"><a href="#GBDT总结" class="headerlink" title="GBDT总结"></a>GBDT总结</h1><p>GBDT是Gradient Boosting框架用决策树完成的一个具体实现。<br>Gradeint Boosting框架的本质思路是一个从基准值到目标值的逼近过程，也是一个基准弱模型向强模型的进化过程。<br>逼近过程是用损失函数来描述和控制的，具体的步进量（残差）由损失函数的梯度来指示。机器模型的作用是用来拟合和预测残差。</p>
<h2 id="XGBoost-GBDT相关blog推荐"><a href="#XGBoost-GBDT相关blog推荐" class="headerlink" title="XGBoost/GBDT相关blog推荐"></a>XGBoost/GBDT相关blog推荐</h2><p><a href="http://www.jianshu.com/p/02cfaae3fd01">http://www.jianshu.com/p/02cfaae3fd01</a><br>参考 <a href="https://zhuanlan.zhihu.com/p/27111288">https://zhuanlan.zhihu.com/p/27111288</a><br><a href="http://www.cnblogs.com/pinard/category/894692.html">http://www.cnblogs.com/pinard/category/894692.html</a></p>
<p>简书-提升方法(Boosting)算法笔记-Python<br><a href="http://www.jianshu.com/p/cbcfee8cf245">http://www.jianshu.com/p/cbcfee8cf245</a><br><a href="http://www.jianshu.com/p/4d32da99f18d">http://www.jianshu.com/p/4d32da99f18d</a></p>
<p>Gradient Boosting Interactive Playground<br><a href="http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html">http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html</a></p>
<p>Gradient Boosting explained<br><a href="http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html">http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html</a></p>
<p>在数据分析的过程中，我们经常需要对数据建模并做预测。在众多的选择中，<code>randomForest</code>, <code>gbm</code> 和 <code>glmnet</code>是三个尤其流行的 R 包，它们在 Kaggle 的各大数据挖掘竞赛中的出现频率独占鳌头，被坊间人称为 R 数据挖掘包中的三驾马车。</p>
<h1 id="DT（Decision-Tree）"><a href="#DT（Decision-Tree）" class="headerlink" title="DT（Decision Tree）"></a>DT（Decision Tree）</h1><p>决策树的判定过程就相当于树中从根结点到某一个叶子结点的遍历。每一步如何遍历是由数据各个特征的具体特征属性决定。</p>
<p><a href="https://zhuanlan.zhihu.com/p/26703300">深入浅出理解决策树算法</a># GBM（Gradient boosting machine）</p>
<h2 id="GBM定义"><a href="#GBM定义" class="headerlink" title="GBM定义"></a>GBM定义</h2><p>梯度提升机器（GBM，Gradient boosting machine）：这种方法通过训练一系列决策树来产生一个预测模型，在其中，后序决策树会校正前序决策树所产生的预测误差。</p>
<h2 id="GBM与传统Boosting算法区别"><a href="#GBM与传统Boosting算法区别" class="headerlink" title="GBM与传统Boosting算法区别"></a>GBM与传统Boosting算法区别</h2><p>Gradient Boosting是一种Boosting的方法，其与传统的Boosting的区别是，每一次的计算是为了减少上一次的残差(residual)，而为了消除残差，可以在残差减少的梯度(Gradient)方向上建立一个新的模型。<br>所以说，在Gradient Boosting中，每个新的模型的建立是为了使得之前模型的残差往梯度方向减少，与传统Boosting对正确、错误样本进行加权有着很大的区别。</p>
<h1 id="GBDT（Gradient-Boosting-Decision-Tree）"><a href="#GBDT（Gradient-Boosting-Decision-Tree）" class="headerlink" title="GBDT（Gradient Boosting Decision Tree）"></a>GBDT（Gradient Boosting Decision Tree）</h1><h2 id="GBDT定义"><a href="#GBDT定义" class="headerlink" title="GBDT定义"></a>GBDT定义</h2><p>GBDT(Gradient Boosting Decision Tree) ,又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。<br>GBDT中的树是回归树（不是分类树），GBDT用来做回归预测，调整后也可以用于分类。<br>GBDT的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合。</p>
<h2 id="Regression-Decision-Tree：回归树"><a href="#Regression-Decision-Tree：回归树" class="headerlink" title="Regression Decision Tree：回归树"></a>Regression Decision Tree：回归树</h2><p>  回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化平方误差。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<ul>
<li>回归树示例<br><img src="回归树示例.png" alt="回归树示例"></li>
<li>回归树算法（《统计学习方法》5.5.1 CART生成）：<br><img src="回归树算法.png" alt="回归树算法"></li>
</ul>
<h2 id="Boosting-Decision-Tree：提升树算法"><a href="#Boosting-Decision-Tree：提升树算法" class="headerlink" title="Boosting Decision Tree：提升树算法"></a>Boosting Decision Tree：提升树算法</h2><p>提升树是迭代多棵回归树来共同决策。当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，残差的意义如公式：残差 = 真实值 - 预测值 。提升树即是整个迭代过程生成的回归树的累加。<br>举个例子展现多棵决策树线性求和过程以及残差的意义。<br>训练一个提升树模型来预测年龄：训练集是4个人，A，B，C，D年龄分别是14，16，24，26。样本中有购物金额、上网时长、经常到百度知道提问等特征。提升树的过程如下：<br><img src="训练一个提升树模型来预测年龄.png" alt="训练一个提升树模型来预测年龄"><br>该例子很直观的能看到，预测值等于所有树值得累加，如A的预测值 = 树1左节点 值 15 + 树2左节点 -1 = 14。<br>因此，给定当前模型 fm-1(x)，只需要简单的拟合当前模型的残差。现将回归问题的提升树算法叙述如下：<br><img src="回归问题的提升树算法流程.png" alt="回归问题的提升树算法流程"></p>
<h2 id="Gradient-Boosting-Decision-Tree：梯度提升决策树"><a href="#Gradient-Boosting-Decision-Tree：梯度提升决策树" class="headerlink" title="Gradient Boosting Decision Tree：梯度提升决策树"></a>Gradient Boosting Decision Tree：梯度提升决策树</h2><p>提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数是平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。</p>
<h2 id="xgboost-gbdt在调参时为什么树的深度很少就能达到很高的精度？"><a href="#xgboost-gbdt在调参时为什么树的深度很少就能达到很高的精度？" class="headerlink" title="xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？"></a>xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？</h2><p>用xgboost/gbdt在在调参的时候把树的最大深度调成6就有很高的精度了。但是用DecisionTree/RandomForest的时候需要把树的深度调到15或更高。用RandomForest所需要的树的深度和DecisionTree一样我能理解，因为它是用bagging的方法把DecisionTree组合在一起，相当于做了多次DecisionTree一样。但是xgboost/gbdt仅仅用梯度上升法就能用6个节点的深度达到很高的预测精度，使我惊讶到怀疑它是黑科技了。请问下xgboost/gbdt是怎么做到的？它的节点和一般的DecisionTree不同吗？<br> <br>一句话的解释，来自周志华老师的机器学习教科书（ 机器学习-周志华）：Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。</p>
<p>随机森林(random forest)和GBDT都是属于集成学习（ensemble learning)的范畴。集成学习下有两个重要的策略Bagging和Boosting。</p>
<p>Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来。简单的多数投票一般就可以。其代表算法是随机森林。Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是AdaBoost, GBDT。</p>
<p>其实就机器学习算法来说，其泛化误差可以分解为两部分，偏差（bias)和方差(variance)。这个可由下图的式子导出（这里用到了概率论公式D(X)=E(X^2)-[E(X)]^2）。偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。这个有点儿绕，不过你一定知道过拟合。</p>
<p>如下图所示，当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。</p>
<p>当模型越简单时，即使我们再换一组数据，最后得出的学习器和之前的学习器的差别就不那么大，模型的方差很小。还是因为模型简单，所以偏差会很大。<br><img src="模型复杂度与偏差方差的关系图.png" alt="模型复杂度与偏差方差的关系图"></p>
<p>也就是说，当我们训练一个模型时，偏差和方差都得照顾到，漏掉一个都不行。</p>
<p>对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差(variance) ,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近.所以对于每个基分类器来说，目标就是如何降低这个偏差（bias),所以我们会采用深度很深甚至不剪枝的决策树。</p>
<p>对于Boosting来说，每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias）,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。 </p>
<h2 id="GBDT应用"><a href="#GBDT应用" class="headerlink" title="GBDT应用"></a>GBDT应用</h2><p>业界中，Facebook使用其来自动发现有效的特征、特征组合，来作为LR模型中的特征，以提高 CTR预估（Click-Through Rate Prediction）的准确性；GBDT在淘宝的搜索及预测业务上也发挥了重要作用</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://link.zhihu.com/?target=http://www.jianshu.com/p/005a4e6ac775">GBDT：梯度提升决策树</a><br><a href="https://link.zhihu.com/?target=http://blog.csdn.net/suranxu007/article/details/49910323">GBDT（MART） 迭代决策树入门教程</a><br><a href="http://hacker.duanshishi.com/?p=1348">http://hacker.duanshishi.com/?p=1348</a></p>
<h2 id="Xgboost与GBDT比较"><a href="#Xgboost与GBDT比较" class="headerlink" title="Xgboost与GBDT比较"></a>Xgboost与GBDT比较</h2><ul>
<li>传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</li>
<li>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。</li>
<li>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。</li>
<li>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）</li>
<li>列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。</li>
<li>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。<br><a href="https://www.zhihu.com/question/41354392">参考 机器学习算法中GBDT和XGBOOST的区别有哪些？</a></li>
</ul>
<h1 id="Xgboost（eXtreme-Gradient-Boosting）"><a href="#Xgboost（eXtreme-Gradient-Boosting）" class="headerlink" title="Xgboost（eXtreme Gradient Boosting）"></a>Xgboost（eXtreme Gradient Boosting）</h1><p>xgboost是GradientBoosting Machine的一个c++实现。现在xgboost已封装成了Python库，并制作成了xgboost工具的R语言接口提交到了CRAN上，也有用户将其封装成了 julia库。</p>
<h2 id="Xgboost特点"><a href="#Xgboost特点" class="headerlink" title="Xgboost特点"></a>Xgboost特点</h2><ol>
<li>xgboost能够自动利用CPU的多线程进行并行，同时在算法上加以改进提高了精度。</li>
<li>xgboost通过如下的优化使得效率大幅提高：</li>
</ol>
<ul>
<li>xgboost借助OpenMP ，能自动利用单机CPU的多核进行并行计算。需要注意的是，Mac上的Clang对OpenMP的支持较差，所以默认情况下只能单核运行。</li>
<li>xgboost自定义了一个数据矩阵类DMatrix，会在训练开始时进行一遍预处理，从而提高之后每次迭代的效率。</li>
</ul>
<blockquote>
<p>boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。<br>xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
</blockquote>
<h2 id="Xgboost与XGB-比较"><a href="#Xgboost与XGB-比较" class="headerlink" title="Xgboost与XGB 比较"></a>Xgboost与XGB 比较</h2><ul>
<li>Xgboost：速度快，效果好，功能多。</li>
<li>XGB的优势<ul>
<li>添加复杂度控制和后期剪枝防止过拟合；</li>
<li>对于loss function 具有通用性，只需求一阶二阶导数；</li>
<li>知道每个样本分到哪片叶子上，可提高模型表现；</li>
<li>可以使用线性模型代替树模型，从而得到L1+L2 的线性或逻辑回归。</li>
<li>分布式应用：XGB 直接在YARN 上使用、集成进现有Spark 机器学习工具。</li>
</ul>
</li>
</ul>
<h3 id="Xgboost实践"><a href="#Xgboost实践" class="headerlink" title="Xgboost实践"></a>Xgboost实践</h3><p><a href="http://machinelearningmastery.com/visualize-gradient-boosting-decision-trees-xgboost-python/">Plot a Single XGBoost Decision Tree</a></p>
<h1 id="GLM（Generalized-linear-model）广义线性模型"><a href="#GLM（Generalized-linear-model）广义线性模型" class="headerlink" title="GLM（Generalized linear model）广义线性模型"></a>GLM（Generalized linear model）广义线性模型</h1><h2 id="LM"><a href="#LM" class="headerlink" title="LM"></a>LM</h2>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK-HashMap原理</title>
    <url>/2019/10/26/JDK-HashMap%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>HashMap是Java中KV存储的实现，其如何解决Hash碰撞问题十分经典；<br>本文从HashMap的<code>概念，结构，参数，性能，线程安全性，源码解析（put,get,resize），使用场景，常见问题</code>8个方面进行分析。<br><a id="more"></a> </p>
<h1 id="HashMap概念"><a href="#HashMap概念" class="headerlink" title="HashMap概念"></a>HashMap概念</h1><blockquote>
<p>Hash table based <code>implementation of the Map interface</code>.<br>This implementation provides all of the optional map operations, and <code>permits null values and the null key.</code>&gt; (The HashMap class is roughly equivalent to Hashtable, except that it is <code>unsynchronized</code> and permits nulls.)<br>This class makes <code>no guarantees as to the order of the map</code>; in particular, it <code>does not guarantee that the order will remain constant over time</code>.</p>
</blockquote>
<p>关键点：Map接口的实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、不保证顺序不随时间变化。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HashMap&lt;String, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">map.put(<span class="string">"语文"</span>, <span class="number">1</span>);</span><br><span class="line">map.put(<span class="string">"数学"</span>, <span class="number">2</span>);</span><br><span class="line">map.put(<span class="string">"英语"</span>, <span class="number">3</span>);</span><br><span class="line">map.put(<span class="string">"历史"</span>, <span class="number">4</span>);</span><br><span class="line">map.put(<span class="string">"政治"</span>, <span class="number">5</span>);</span><br><span class="line">map.put(<span class="string">"地理"</span>, <span class="number">6</span>);</span><br><span class="line">map.put(<span class="string">"生物"</span>, <span class="number">7</span>);</span><br><span class="line">map.put(<span class="string">"化学"</span>, <span class="number">8</span>);</span><br><span class="line"><span class="keyword">for</span>(Entry&lt;String, Integer&gt; entry : map.entrySet()) &#123;</span><br><span class="line">    System.out.println(entry.getKey() + <span class="string">": "</span> + entry.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><img src="hashmap示例.png" alt="hashmap示例"></p>
<h1 id="HashMap结构"><a href="#HashMap结构" class="headerlink" title="HashMap结构"></a>HashMap结构</h1><p>从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。<br><img src="HashMap结构.png" alt="HashMap结构"></p>
<ul>
<li><p>HashMap类中有一个非常重要的字段，就是 <code>Node[] table</code>，即哈希桶数组。Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。</p>
<p><img src="Java-Collections_Map-API.jpg" alt="Java-Collections_Map-API"> </p>
</li>
<li>抽象类：AbstractMap</li>
<li>接口：Map</li>
<li><p>实体：EntrySet、KeySet、Node、TreeNode、Values</p>
</li>
<li><p>迭代器<br>EntryIterator、HashIterator、KeyIterator、ValueIterator</p>
</li>
<li><p>分割器<br>Spliterator、EntrySpliterator、HashMapSpliterator、KeySpliterator、ValueSpliterator</p>
</li>
</ul>
<h1 id="HashMap参数"><a href="#HashMap参数" class="headerlink" title="HashMap参数"></a>HashMap参数</h1><p>在HashMap中有2个重要参数， Capacity和Load factor</p>
<h2 id="Capacity（容量）"><a href="#Capacity（容量）" class="headerlink" title="Capacity（容量）"></a>Capacity（容量）</h2><blockquote>
<p>The capacity is the <code>number of buckets</code> in the hash table, The initial capacity is simply the capacity at the time the hash table is created.<br><code>Capacity</code>就是buckets的数目，默认值为16。</p>
</blockquote>
<h2 id="Load-factor（负载因子）"><a href="#Load-factor（负载因子）" class="headerlink" title="Load factor（负载因子）"></a>Load factor（负载因子）</h2><blockquote>
<p>The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.</p>
</blockquote>
<p><code>Load factor</code>是buckets填满程度的最大比例，默认值为0.75，当<code>bucket</code>填充的数目（即hashmap中元素的个数）大于$capacity * load factor$时就需要调整buckets的数目为当前的2倍。</p>
<h1 id="HashMap性能"><a href="#HashMap性能" class="headerlink" title="HashMap性能"></a>HashMap性能</h1><p>当前实现的HashMap实现提供了<code>constant-time</code>的方法来进行get, put 等基本操作。</p>
<ul>
<li>如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是<code>O(1)</code>，</li>
<li>如果Hash算法技术的结果碰撞非常多，假如Hash算法极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为<code>O(n)</code>和<code>O(lgn)</code>。</li>
</ul>
<h2 id="几个要注意的性能点（空间-时间的tradeoff）"><a href="#几个要注意的性能点（空间-时间的tradeoff）" class="headerlink" title="几个要注意的性能点（空间/时间的tradeoff）"></a>几个要注意的性能点（空间/时间的tradeoff）</h2><ol>
<li>假如哈希函数能够将元素分散到所有的buckets里。从Collection的角度来说，遍历HashMap需要的时间为<code>count(buckets)+count(bucket.entrySize)</code>。如果遍历频繁/对迭代性能要求很高，不要把<code>capacity</code>设置过大，也不要把<code>load factor</code>设置过小；<code>load factor</code>更大会减少空间消耗，更小会增加时间消耗（查找更费时）。</li>
<li>扩容是一个特别耗性能的操作，如果很多key-values对存储在 HashMap 实例中，给他<code>初始化一个足够大的capacity</code> ，避免map进行频繁的resize扩容。这样更有效率。</li>
<li>默认的<code>load factor=0.75</code>是对空间和时间效率的一个<code>平衡选择</code>，建议不要修改，除非在时间和空间比较特殊的情况下：<ul>
<li>空间换时间：如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；</li>
<li>时间换空间：如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。</li>
</ul>
</li>
</ol>
<h1 id="HashMap线程安全性"><a href="#HashMap线程安全性" class="headerlink" title="HashMap线程安全性"></a>HashMap线程安全性</h1><h2 id="HashMap为什么线程不安全"><a href="#HashMap为什么线程不安全" class="headerlink" title="HashMap为什么线程不安全"></a>HashMap为什么线程不安全</h2><p>为什么HashMap是线程不安全的？</p>
<h3 id="多线程resize-数据丢失问题"><a href="#多线程resize-数据丢失问题" class="headerlink" title="多线程resize-数据丢失问题"></a>多线程resize-数据丢失问题</h3><p>如果多个线程同时检测到元素个数超过<code>table size * loadFactor</code> ，这样就会发生多个线程<code>同时对Node数组进行扩容</code>，<br>都在重新计算元素位置以及复制数据，但是最终只有一个线程扩容后的数组会赋给 table，也就是说其他线程的都会丢失，并且各自线程 put 的数据也丢失；</p>
<h3 id="多线程put-数据覆盖问题"><a href="#多线程put-数据覆盖问题" class="headerlink" title="多线程put-数据覆盖问题"></a>多线程put-数据覆盖问题</h3><p>如果多个线程同时使用put方法添加元素，而且假设正好存在两个 put 的 key 发生了碰撞(根据 hash 值计算的 bucket 一样)，那么根据 HashMap 的实现，这两个 key 会添加到数组的同一个位置，这样最终就会发生其中一个线程的 put 的<code>数据被覆盖</code>；</p>
<h3 id="多线程put-死循环问题（JDK1-7）"><a href="#多线程put-死循环问题（JDK1-7）" class="headerlink" title="多线程put-死循环问题（JDK1.7）"></a>多线程put-死循环问题（JDK1.7）</h3><blockquote>
<p>HashMap在并发执行put操作时会引起死循环，导致CPU利用率接近100%。因为多线程会导致 HashMap 的 Node 链表形成环形数据结构，一旦形成环形数据结构，Node 的 next 节点永远不为空，就会在获取 Node 时产生死循环。-《Java并发编程的艺术》</p>
</blockquote>
<p>HashMap之所以在并发下的扩容造成死循环，是因为，在多个线程并发进行时：</p>
<ul>
<li>前一个线程先完成扩容，将原Map的链表rehash到自己的表中，并且链表变成了<code>倒序</code>，</li>
<li>另一个线程再扩容时，又进行自己的reshash，再次将倒序链表变为<code>正序链表</code>。</li>
<li>于是形成了一个环形链表，当get表中不存在的元素时，造成死循环。</li>
</ul>
<p>总之<code>多线程</code>+<code>头插法</code>引起的问题，考虑头插法的原因是<code>不用遍历链表，提高插入性能</code>，但在JDK8已经改为<code>尾插法</code>了，不存在这个问题。<br>曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。</p>
<blockquote>
<p>以上是JDK1.7导致的问题，1.8已经做了改进</p>
<ol>
<li>添加了红黑树，当链表长度大于8时，会将链表转为红黑树。</li>
<li>扩容后，新数组中的链表顺序依然与旧数组中的链表顺序保持一致。具体JDK8是用 head 和 tail 来保证链表的顺序和之前一样，这样就不会产生循环引用。也就没有死循环了。</li>
<li>虽然修复了死循环的BUG，但是HashMap 还是非线程安全类，仍然会产生数据丢失等问题。</li>
</ol>
</blockquote>
<h2 id="HashMap线程安全初始化"><a href="#HashMap线程安全初始化" class="headerlink" title="HashMap线程安全初始化"></a>HashMap线程安全初始化</h2><p>在多线程使用场景中，应该尽量避免使用线程不安全的<code>HashMap</code>，可用以下2种方式实现线程安全：</p>
<ol>
<li>ConcurrentHashMap： <code>Map map = new ConcurrentHashMap&lt;String, Object&gt;();</code></li>
<li>Collections.synchronizedMap：<code>Map map = Collections.synchronizedMap(new HashMap&lt;String, Object&gt;());</code></li>
</ol>
<h1 id="HashMap源码解析"><a href="#HashMap源码解析" class="headerlink" title="HashMap源码解析"></a>HashMap源码解析</h1><h2 id="hashcode方法"><a href="#hashcode方法" class="headerlink" title="hashcode方法"></a>hashcode方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h;</span><br><span class="line">    <span class="comment">//扰动函数</span></span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="hashcode方法.png" alt="hashcode方法"></p>
<blockquote>
<p>扰动函数：右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了<code>混合原始哈希码的高位和低位</code>，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。</p>
<p>Computes key.hashCode() and <code>spreads (XORs) higher bits of hash to lower.</code><br>Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that <code>spreads the impact of higher bits downward</code>.<br>There is a <code>tradeoff</code> between <code>speed, utility, and quality of bit-spreading</code>.<br>Because many common sets of hashes are already <code>reasonably distributed</code> (so don’t benefit from spreading),<br>and because we <code>use trees to handle large sets of collisions in bins</code>, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage,<br>as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds.</p>
</blockquote>
<p>在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用<code>&amp;</code>位操作，而非<code>%</code>求余)：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">(n - <span class="number">1</span>) &amp; hash</span><br></pre></td></tr></table></figure><br>设计者认为这方法很容易发生碰撞。为什么这么说呢？<br>不妨思考一下，在<code>n-1</code>为15(<code>0000000000000000 0000000000001111</code>)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。<br>因此，设计者想了一个顾全大局的方法(综合考虑了<code>速度、作用、质量</code>)，就是把高16bit和低16bit进行异或运算。<br>设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用<code>O(log_n)</code>的tree去做了。<br>仅仅异或运算，既<code>减少了系统的开销</code>，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。</p>
<h2 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h2><p><img src="HashMap之put方法.png" alt="HashMap之put方法"></p>
<ul>
<li>步骤1：数组是否未初始化？若未初始化则进行resize初始化;</li>
<li>步骤2：计算key对应的hash桶的下标,判断是否存在碰撞？若是没有碰撞直接放桶里;</li>
<li>步骤3：若发生hash碰撞，若键已存在就返回该Node，并用属性e引用，若键不存在就创建一个新的Node，并直接插入到桶（链表/树）中;</li>
<li>步骤4：该键已经存在,判断是否需要覆盖节点值;</li>
<li>步骤5：检查键值对数量是否超过临界值，是则扩容;</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implements Map.put and related methods.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> hash         hash for key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key          the key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> value        the value to put</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> onlyIfAbsent if true, don't change existing value</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> evict        if false, the table is in creation mode.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> previous value, or null if none</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//tab：hash桶</span></span><br><span class="line">    Node&lt;K, V&gt;[] tab;</span><br><span class="line">    <span class="comment">//p：当前插入位置的节点数据</span></span><br><span class="line">    Node&lt;K, V&gt; p;</span><br><span class="line">    <span class="comment">//n：hash表数组长度</span></span><br><span class="line">    <span class="comment">//i：当前插入值的数组下标</span></span><br><span class="line">    <span class="keyword">int</span> n, i;</span><br><span class="line">    <span class="comment">//步骤1：数组是否未初始化？若未初始化则进行resize初始化</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>) &#123;</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//步骤2：计算key在数组的下标:(n - 1) &amp; hash，若是没有碰撞直接放桶里</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>) &#123;</span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">//步骤3：发生hash碰撞，若键已存在就返回该Node，并用属性e引用，若键不存在就创建一个新的Node，并直接插入到桶中</span></span><br><span class="line">        <span class="comment">//当前实际插入node</span></span><br><span class="line">        Node&lt;K, V&gt; e;</span><br><span class="line">        <span class="comment">//当前插入key</span></span><br><span class="line">        K k;</span><br><span class="line">        <span class="comment">// 检查碰撞的节点是否是头节点</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">            <span class="comment">//e为当前插入位置的节点数据</span></span><br><span class="line">            e = p;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode) &#123;<span class="comment">//若该桶的内部结构是树</span></span><br><span class="line">            <span class="comment">//将插入的元素新增为树节点,e为插入树节点数据</span></span><br><span class="line">            e = ((TreeNode&lt;K, V&gt;) p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;<span class="comment">//若该桶的内部结构是链表</span></span><br><span class="line">            <span class="comment">//遍历链表：1-直到链表尾部时break，2-链表中存在key与插入key一致时break</span></span><br><span class="line">            <span class="comment">//处理完成后，e为插入节点数据（链表尾部节点）</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="comment">//e是p的下一个节点</span></span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//尾插法：新节点插入链表的尾部</span></span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">                    <span class="comment">//链表长度&gt;=8时，链表升级为树结构</span></span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) &#123; <span class="comment">// -1 for 1st</span></span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// key已经存在直接覆盖value：node的hash一致，key一致或key的内存地址一致</span></span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//链表遍历指针移动到下一个节点</span></span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//步骤4：该键已经存在</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line">            <span class="comment">//当前值</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="comment">//onlyIfAbsent表示不存在才插入，反之为存在才插入</span></span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">                e.value = value;</span><br><span class="line">            &#125;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            <span class="comment">//返回已有值，或覆盖后的值</span></span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ++modCount;</span><br><span class="line">    <span class="comment">//骤5：检查键值对数量是否超过临界值，是则扩容</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold) &#123;</span><br><span class="line">        resize();</span><br><span class="line">    &#125;</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="resize方法"><a href="#resize方法" class="headerlink" title="resize方法"></a>resize方法</h2><p>当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。</p>
<blockquote>
<p>如果不进行resize扩容，单个链表中的数据过多，get(),put(),remove()等方法效率都会降低。</p>
</blockquote>
<p>在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的：</p>
<blockquote>
<p>Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold.<br>Otherwise, because we are using <code>power-of-two expansion</code>, the elements from each bin must either <code>stay at same index</code>, or move with <code>a power of two offset</code> in the new table.</p>
</blockquote>
<p>大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是<code>2次幂</code>的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。</p>
<blockquote>
<p>怎么理解扩容后的元素按2次幂迁移？</p>
</blockquote>
<p>例如我们从16扩展为32时，具体的变化如下所示：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">16</span>-<span class="number">1</span>  =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span> </span><br><span class="line">hash1 =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span> </span><br><span class="line">hash2 =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0001</span> <span class="number">1111</span> </span><br><span class="line"><span class="comment">// 桶下标为 </span></span><br><span class="line">(<span class="number">16</span>-<span class="number">1</span>)&amp;hash1 = <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span> </span><br><span class="line">(<span class="number">16</span>-<span class="number">1</span>)&amp;hash2 = <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span></span><br></pre></td></tr></table></figure><br>容量为 16 时，hash1 和 hash2 经过桶下标计算后结果相同，会进入同一个桶中。<br>当容量扩展为 32 后，新的桶下标计算过程如下所示：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">32</span>-<span class="number">1</span>  =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0001</span> <span class="number">1111</span> </span><br><span class="line">hash1 =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span> </span><br><span class="line">hash2 =  <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0001</span> <span class="number">1111</span> </span><br><span class="line"><span class="comment">// 桶下标为 </span></span><br><span class="line">(<span class="number">32</span>-<span class="number">1</span>)&amp;hash1 = <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span> </span><br><span class="line">(<span class="number">32</span>-<span class="number">1</span>)&amp;hash2 = <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0001</span> <span class="number">1111</span></span><br></pre></td></tr></table></figure><br>hash1 和 hash2 经过桶下标公式(<code>n-1&amp;hash</code>)重新计算之后：</p>
<ul>
<li>hash1的结果不变，所以依旧在原来的桶里；</li>
<li>hash2的结果比原来多了1位，即 2^4 = 16，也就是<code>偏移了原来的桶容量大小</code>。</li>
</ul>
<p>如下图所示：<img src="resize16to32.png" alt="resize16to32"><br>因此，在扩充 HashMap 的时候，不需要重新计算 hash，只需要检查<code>二进制hash</code>中与<code>二进制桶下标</code>中新增的有效位的位置相同的那个位（以下简称“新增位”）是 0 还是 1 即可，</p>
<ul>
<li>新增位=0，索引不变；</li>
<li>新增位=1，索引变成<code>原索引+oldCap</code>；</li>
</ul>
<blockquote>
<p>如何检查新增位是 0 还是 1 呢？</p>
</blockquote>
<p>HashMap 中使用 <code>hash &amp; oldCap</code>位与运算(<code>&amp;</code>)检查该新增位。<code>oldCap是2的幂，故二进制表示只有一位是1，且该位正好与之对应</code>。<br>不得不说这个设计还是非常巧妙的，既省去了重新计算 hash 值的时间，且由于新增位是0还是1可以认为是随机的，因此<code>在扩容的过程，均匀的把之前碰撞的节点分散到新旧桶中</code>。</p>
<blockquote>
<p>resize源码执行流程</p>
</blockquote>
<ul>
<li>步骤1：根据 oldCap 判断是扩容还是初始化数组</li>
<li>步骤2；若已执行过初始化.在已有基础上扩容</li>
<li>步骤3：若未执行过初始化，使用默认容量初始化</li>
<li>步骤4：根据loadFactor计算扩容后的桶阈值</li>
<li>步骤5：实例化新的table数组</li>
<li>步骤6：遍历原桶的节点，将原桶的节点都移到新桶中</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 如果 table 数组为 null，则根据字段 threshold 中保持的初始容量进行分配。</span></span><br><span class="line"><span class="comment">    * 否则扩容，因为我们使用的是 2 的幂，所以每个桶中的元素必须保持相同的索引，或者在新 table 中以 2 的幂偏移。</span></span><br><span class="line"><span class="comment">    * Initializes or doubles table size.  If null, allocates in</span></span><br><span class="line"><span class="comment">    * accord with initial capacity target held in field threshold.</span></span><br><span class="line"><span class="comment">    * Otherwise, because we are using power-of-two expansion,</span></span><br><span class="line"><span class="comment">    * the elements from each bin must either stay at same index,</span></span><br><span class="line"><span class="comment">    * or move with a power of two offset in the new table.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the table 扩容后的hash桶</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">final</span> Node&lt;K, V&gt;[] resize() &#123;</span><br><span class="line">       Node&lt;K, V&gt;[] oldTab = table;</span><br><span class="line">       <span class="comment">//当前hash桶大小</span></span><br><span class="line">       <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">       <span class="comment">//当前扩容阈值</span></span><br><span class="line">       <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">       <span class="comment">//扩容后hash桶大小，新的扩容阈值</span></span><br><span class="line">       <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">       <span class="comment">//步骤1：根据 oldCap 判断是扩容还是初始化数组，若是扩容..</span></span><br><span class="line">       <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">           <span class="comment">//超过最大容量就不再扩容，任其发生碰撞</span></span><br><span class="line">           <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">               threshold = Integer.MAX_VALUE;</span><br><span class="line">               <span class="keyword">return</span> oldTab;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="comment">//没超过最大值，就扩容为原来的2倍</span></span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                   oldCap &gt;= DEFAULT_INITIAL_CAPACITY) &#123;</span><br><span class="line">               newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//步骤2；若已执行过初始化</span></span><br><span class="line">       <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) &#123; <span class="comment">// initial capacity was placed in threshold</span></span><br><span class="line">           newCap = oldThr;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123; <span class="comment">// zero initial threshold signifies using defaults</span></span><br><span class="line">           <span class="comment">//步骤3：若未执行过初始化，使用默认容量初始化</span></span><br><span class="line">           newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">           newThr = (<span class="keyword">int</span>) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">           <span class="comment">//步骤4：根据loadFactor计算扩容阈值</span></span><br><span class="line">           <span class="keyword">float</span> ft = (<span class="keyword">float</span>) newCap * loadFactor;</span><br><span class="line">           newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>) MAXIMUM_CAPACITY ?</span><br><span class="line">                   (<span class="keyword">int</span>) ft : Integer.MAX_VALUE);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//设置扩容阈值</span></span><br><span class="line">       threshold = newThr;</span><br><span class="line">       <span class="comment">//步骤5：实例化新的 table 数组</span></span><br><span class="line">       <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>, <span class="string">"unchecked"</span>&#125;)</span><br><span class="line">       Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) <span class="keyword">new</span> Node[newCap];</span><br><span class="line">       table = newTab;</span><br><span class="line">       <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="comment">//步骤6：遍历原桶的节点，将原桶的节点都移到新桶中</span></span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">               Node&lt;K, V&gt; e;</span><br><span class="line">               <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                   <span class="comment">//节点不为空时，去掉旧数组对该桶的引用</span></span><br><span class="line">                   oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                   <span class="comment">//若桶内无哈希碰撞，重新计算桶下标</span></span><br><span class="line">                   <span class="keyword">if</span> (e.next == <span class="keyword">null</span>) &#123;</span><br><span class="line">                       newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="comment">//若桶内部结构为树</span></span><br><span class="line">                   <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode) &#123;</span><br><span class="line">                       ((TreeNode&lt;K, V&gt;) e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                       <span class="comment">//若是该桶内部结构为链表，则碰撞的节点要么在原桶，要么在新桶，根据e.hash &amp; oldCap随机打散链表</span></span><br><span class="line">                       <span class="comment">//原桶的头尾节点引用</span></span><br><span class="line">                       Node&lt;K, V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                       <span class="comment">//新桶的头尾节点引用</span></span><br><span class="line">                       Node&lt;K, V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                       <span class="comment">//链表遍历指针</span></span><br><span class="line">                       Node&lt;K, V&gt; next;</span><br><span class="line">                       <span class="comment">//遍历桶内碰撞节点</span></span><br><span class="line">                       <span class="keyword">do</span> &#123;</span><br><span class="line">                           next = e.next;</span><br><span class="line">                           <span class="comment">// 新增位是 0 放原桶</span></span><br><span class="line">                           <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                               <span class="keyword">if</span> (loTail == <span class="keyword">null</span>) &#123;<span class="comment">//第一次遍历,记录头指针</span></span><br><span class="line">                                   loHead = e;</span><br><span class="line">                               &#125; <span class="keyword">else</span> &#123;<span class="comment">//后续根据尾指针遍历</span></span><br><span class="line">                                   loTail.next = e;</span><br><span class="line">                               &#125;</span><br><span class="line">                               loTail = e;</span><br><span class="line">                           &#125;</span><br><span class="line">                           <span class="comment">// 新增位是 1 放新桶</span></span><br><span class="line">                           <span class="keyword">else</span> &#123;</span><br><span class="line">                               <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>) &#123;</span><br><span class="line">                                   hiHead = e;</span><br><span class="line">                               &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                   hiTail.next = e;</span><br><span class="line">                               &#125;</span><br><span class="line">                               hiTail = e;</span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                       <span class="comment">// 原桶中放原链表</span></span><br><span class="line">                       <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           loTail.next = <span class="keyword">null</span>;</span><br><span class="line">                           newTab[j] = loHead;</span><br><span class="line">                       &#125;</span><br><span class="line">                       <span class="comment">// 新桶中放新链表</span></span><br><span class="line">                       <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           hiTail.next = <span class="keyword">null</span>;</span><br><span class="line">                           <span class="comment">//偏移大小=当前桶大小（2的指数）</span></span><br><span class="line">                           newTab[j + oldCap] = hiHead;</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> newTab;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h2 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h2><p>get大致思路如下：</p>
<ul>
<li>bucket里的第一个节点，直接命中；</li>
<li>如果有冲突，则通过key.equals(k)去查找对应的entry</li>
<li>若为树，则在树中通过key.equals(k)查找，O(logn)；</li>
<li>若为链表，则在链表中通过key.equals(k)查找，O(n)。<br>具体代码的实现如下：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implements Map.get and related methods</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; <span class="keyword">int</span> n; K k;</span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (first.hash == hash &amp;&amp; <span class="comment">// always check first node</span></span><br><span class="line">                ((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                <span class="keyword">return</span> first;</span><br><span class="line">            <span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    <span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                        ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                        <span class="keyword">return</span> e;</span><br><span class="line">                &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>HashMap是基于Map接口的实现，用于存储键-值对，它可以接收null的键值，是非同步的，<br>HashMap存储着Entry(hash, key, value, next)对象。<br>常用于内存缓存的实现；</p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="你知道HashMap的工作原理吗？"><a href="#你知道HashMap的工作原理吗？" class="headerlink" title="你知道HashMap的工作原理吗？"></a>你知道HashMap的工作原理吗？</h2><p>通过hash的方法，通过put和get存储和获取对象。</p>
<ul>
<li>存储对象时(<code>put</code>)，我们将K/V传给put方法，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。</li>
<li>获取对象时(<code>get</code>)，我们将K传给get方法，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。</li>
</ul>
<h2 id="HashMap与Hashtable的区别"><a href="#HashMap与Hashtable的区别" class="headerlink" title="HashMap与Hashtable的区别"></a>HashMap与Hashtable的区别</h2><p> Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。</p>
<p>HashMap 实现了所有map类的方法。并允许使用 null 作为 key 和 value。<br>HashMap和HashTable大致相同。<br>区别在于HashMap不是同步的，并允许null值，HashTable是同步，并且不允许null值。<br>HashMap不保证放入的元素按序存储。同时它也不保证当前的存储顺序会保持很长时间。</p>
<h2 id="为什么HashMap的Buckets大小为2的指数？不采样素数？"><a href="#为什么HashMap的Buckets大小为2的指数？不采样素数？" class="headerlink" title="为什么HashMap的Buckets大小为2的指数？不采样素数？"></a>为什么HashMap的Buckets大小为2的指数？不采样素数？</h2><p>在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是<code>合数</code>)，这是一种非常规的设计，<br>常规的设计是把桶的大小设计为素数。相对来说<code>素数导致冲突的概率要小于合数</code>，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（<code>Hashtable</code>扩容后不能保证还是素数）。</p>
<p>HashMap采用这种非常规设计，主要是<code>为了在扩容时做优化，为了减少冲突</code>，<br>HashMap定位哈希桶索引位置时，也加入了<code>高位参与运算</code>的过程。</p>
<h2 id="为什么HashMap的负载因子是0-75？"><a href="#为什么HashMap的负载因子是0-75？" class="headerlink" title="为什么HashMap的负载因子是0.75？"></a>为什么HashMap的负载因子是0.75？</h2><p>默认的<code>load factor=0.75</code>是对空间和时间效率的一个<code>平衡选择</code>，建议不要修改，除非在时间和空间比较特殊的情况下：</p>
<ul>
<li>空间换时间：如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；</li>
<li>时间换空间：如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。</li>
</ul>
<h2 id="如果HashMap的大小超过了负载因子-load-factor-定义的容量，怎么办？"><a href="#如果HashMap的大小超过了负载因子-load-factor-定义的容量，怎么办？" class="headerlink" title="如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？"></a>如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？</h2><p>如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。</p>
<h2 id="HashMap查询时复杂度一直是O-1-吗？"><a href="#HashMap查询时复杂度一直是O-1-吗？" class="headerlink" title="HashMap查询时复杂度一直是O(1)吗？"></a>HashMap查询时复杂度一直是O(1)吗？</h2><p>Java8之前，最差是<code>O(1)+O(n/backetSize)</code><br>Java8，复杂度为<code>O(1)+O(log(backetSize))</code></p>
<h2 id="你知道get和put的原理吗？equals-和hashCode-的都有什么作用？"><a href="#你知道get和put的原理吗？equals-和hashCode-的都有什么作用？" class="headerlink" title="你知道get和put的原理吗？equals()和hashCode()的都有什么作用？"></a>你知道get和put的原理吗？equals()和hashCode()的都有什么作用？</h2><p>通过对key的hashCode()进行hashing，并计算下标<code>( n-1 &amp; hash)</code>，从而获得buckets的位置。<br>如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点</p>
<h2 id="你知道hash的实现吗？为什么要这样实现？"><a href="#你知道hash的实现吗？为什么要这样实现？" class="headerlink" title="你知道hash的实现吗？为什么要这样实现？"></a>你知道hash的实现吗？为什么要这样实现？</h2><p>在Java 1.8的实现中，是通过hashCode()的高16位<code>异或</code>低16位实现的：<code>(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)</code>，<br>主要是从<code>speed、utility、quality</code>来考虑的，这么做可以在hash桶比较小的时候，保证考虑到<code>高低位都参与到hash的计算</code>中，同时不会有太大的开销。</p>
<h2 id="HashMap出现hash碰撞怎么处理？"><a href="#HashMap出现hash碰撞怎么处理？" class="headerlink" title="HashMap出现hash碰撞怎么处理？"></a>HashMap出现hash碰撞怎么处理？</h2><p>为解决哈希表hash碰撞，可以采用<code>开放地址法</code>和<code>链地址法</code>等来解决问题，Java中HashMap采用了链地址法。</p>
<h3 id="链地址法"><a href="#链地址法" class="headerlink" title="链地址法"></a>链地址法</h3><p>简单来说，就是<code>数组</code>加<code>链表</code>的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。</p>
<h3 id="开放地址法"><a href="#开放地址法" class="headerlink" title="开放地址法"></a>开放地址法</h3><ul>
<li><code>线性开放地址法</code><br>线性开放地址法就是在hash之后，当发现在位置上已经存在了一个变量之后，放到它下一个位置，假如下一个位置也冲突，则继续向下，依次类推，直到找到没有变量的位置，放进去。</li>
<li><code>平方开放地址法</code><br>平方地址法就是在hash之后，当正确位置上存在冲突，不放到挨着的下一个位置，而是放到第2^0位置，假如继续冲突放到2^1的位置，依次2^3… 直到遇到不冲突的位置放进去。</li>
<li><code>双散列开放地址法</code><br>双散列同上，不过不是放到2^的位置，而是放到key - hash(key, tablesize)的位置，假如继续冲突，则放到2 (key - hash(key,tablesize))的位置。</li>
</ul>
<p>如果还是产生了频繁的碰撞，会发生什么问题呢？<br>作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题：</p>
<blockquote>
<p>Improve the performance of java.util.HashMap under <code>high hash-collision conditions</code> by using <code>balanced trees</code> rather than <code>linked lists</code> to store map entries. Implement the same improvement in the LinkedHashMap class.</p>
</blockquote>
<p>之前已经提过，在获取HashMap的元素时，基本分两步：</p>
<ul>
<li>首先根据hashCode()做hash，然后确定bucket的index；</li>
<li>如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。</li>
</ul>
<p>在<code>Java 8之前</code>的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是<code>O(1)+O(n)</code>，n为bucket.size。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。</p>
<p>因此在<code>Java 8</code>中，利用<code>红黑树</code>替换链表，这样复杂度就变成了<code>O(1)+O(logn)</code>了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="Java运算符"><a href="#Java运算符" class="headerlink" title="Java运算符"></a>Java运算符</h2><p>A = 0011 1100<br>B = 0000 1101<br><code>＆</code>（位运算）：如果相对应位都是1，则结果为1，否则为0。如<code>A&amp;B</code>=<code>0000 1100</code><br><code>^</code>（异或运算）：如果相对应位值相同，则结果为0，否则为1。如<code>（A ^ B）</code>=<code>0011 0001</code><br><code>&gt;&gt;&gt;</code>（按位右移补零操作符）：左操作数的值按右操作数指定的位数右移，移动得到的空位以零填充。如<code>A&gt;&gt;&gt;2</code>=<code>0000 1111</code></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://yikun.github.io/2015/04/01/Java HashMap工作原理及实现">Java HashMap工作原理及实现</a><br><a href="https://tech.meituan.com/java-hashmap.html">Java 8系列之重新认识HashMap</a><br><a href="http://www.nowamagic.net/academy/detail/3008060">散列冲突处理：链地址法</a><br><a href="https://visualgo.net/en/hashtable">HashMap 可视化</a></p>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析Java中的锁</title>
    <url>/2020/02/05/%E6%B5%85%E6%9E%90Java%E4%B8%AD%E7%9A%84%E9%94%81/</url>
    <content><![CDATA[<blockquote>
<p>现如今程序大多运行在核多线程的硬件环境下，为了保证资源的读写安全，于是出现了各种各样的锁，那么锁是什么？为什么要有锁？有哪些锁？不同锁的实现原理、优缺点、适用场景是什么？有哪些使用案例？</p>
<p>本文主要介绍Java中的锁，涉及到下面几种分类：</p>
<ul>
<li>乐观锁/悲观锁；</li>
<li>共享锁/互斥锁；</li>
<li>读锁/写锁；</li>
<li>轻量级锁/重量级锁；</li>
<li>偏向锁/可重入锁；</li>
<li>非公平锁/公平锁；</li>
</ul>
</blockquote>
<a id="more"></a>
<h1 id="日常生活中的锁"><a href="#日常生活中的锁" class="headerlink" title="日常生活中的锁"></a>日常生活中的锁</h1><p>日常生活中的锁几乎与私有制同时诞生，目的都是为了保护私有资源的安全性，只能授权后的人才能解锁；</p>
<ul>
<li>比如家里的大门的锁，只有一家人有钥匙才能进入；当然特殊情况，比如钥匙都丢了，可以找师傅开锁（<code>锁中断</code>）；</li>
<li>比如公共卫生间，大门外部无锁，内部隔间有锁（<code>读写锁</code>）；</li>
</ul>
<h1 id="硬件中的锁"><a href="#硬件中的锁" class="headerlink" title="硬件中的锁"></a>硬件中的锁</h1><p>在硬件层面，CPU提供了<code>基本的原子操作</code>，以及<code>内存总线锁</code>、<code>缓存锁定</code>等机制来保证复杂内存操作的原子性；</p>
<ol>
<li><p>CPU自动保证基本内存操作的原子性</p>
<ul>
<li>CPU保证从系统内存当中<code>读取或者写入一个字节是原子</code>的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址；</li>
<li>复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问，于是处理器提供<code>总线锁定</code>和<code>缓存锁定</code>两个机制来保证复杂内存操作的原子性。 </li>
</ul>
</li>
<li><p>使用<code>总线锁</code>保证原子性</p>
<ul>
<li>如果<code>多个处理器</code>同时对<code>共享变量</code>进行读改写操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，由于读和写的时间差，操作完之后共享变量的值会和期望的不一致；</li>
<li>那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存；</li>
<li>处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个<code>LOCK＃</code>信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。</li>
</ul>
</li>
<li><p>使用<code>缓存锁定</code>保证原子性</p>
<ul>
<li>在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下<code>使用缓存锁定代替总线锁定来进行优化</code>。</li>
<li>频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁；</li>
<li>所谓<code>缓存锁定</code>就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言<code>LOCK＃</code>信号，而是修改内部的内存地址，并允许它的<code>缓存一致性机制</code>来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效， </li>
<li>但有两种情况下处理器不会使用缓存锁定。<ul>
<li>1)当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。</li>
<li>2)有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="操作系统中的锁"><a href="#操作系统中的锁" class="headerlink" title="操作系统中的锁"></a>操作系统中的锁</h1><p>操作系统内核像多进程多线程编程一样也需要一些<code>同步机制</code>来同步各执行单元对共享数据的访问。<br>尤其是在<code>多处理器系统</code>上，更需要一些同步机制来同步不同处理器上的执行单元对<code>共享数据</code>的访问。<br>基于CPU硬件原子性的机制，在主流的Linux内核中包含了几乎所有现代的操作系统具有的同步机制，</p>
<p>这些同步机制包括：</p>
<ol>
<li>原子操作</li>
<li>信号量（semaphore）</li>
<li>读写信号量（rw_semaphore）</li>
<li>自旋锁（spinlock）</li>
<li>大内核锁(BKL，Big Kernel Lock)</li>
<li>读写锁（rwlock）</li>
<li>大读者锁（brlock），只包含在2.4内核中</li>
<li>RCU，Read-Copy Update，在开发内核2.5.43中引入该技术的并正式包含在2.6内核中</li>
<li>顺序锁seqlock（只包含在2.6以后内核中）。</li>
</ol>
<h1 id="Java中的锁"><a href="#Java中的锁" class="headerlink" title="Java中的锁"></a>Java中的锁</h1><p>在说Java的锁之前，得先说Java内存模型JMM，JMM的规定导致需要通过各种锁来实现同步，保证多线程环境下变量操作的安全性（原子性，可见性，有序性）；</p>
<h2 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h2><p>Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model,JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。</p>
<blockquote>
<p>在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编写程序。</p>
</blockquote>
<ul>
<li>Java内存模型规定了所有的变量都存储在<code>主内存</code>（Main Memory）中,每条线程还有自己的<code>工作内存</code>（Working Memory）;</li>
<li>线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。</li>
<li>不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成;</li>
</ul>
<p>线程、主内存、工作内存三者的交互关系<br><img src="JMM.png" alt="JMM"></p>
<p>Java的多线程之间是通过共享内存进行通信的，而由于采用<code>共享内存进行通信</code>，在通信过程中会存在一系列如可见性、原子性、顺序性等问题，而JMM就是围绕着多线程通信以及与其相关的一系列特性而建立的模型。<br>JMM定义了一些语法集，这些语法集映射到Java语言中就是<code>volatile</code>、<code>synchronized</code>等关键字。</p>
<blockquote>
<p>JMM的实现与CPU、CPU高速缓存、主内存之间的交互是类似的，因此也要参考操作系统一样实现自己的同步机制，而且Java为了要实现<code>WORA</code>，需要跨平台去针对不同的操作系统做适配；</p>
</blockquote>
<h1 id="sychronized关键字"><a href="#sychronized关键字" class="headerlink" title="sychronized关键字"></a>sychronized关键字</h1><blockquote>
<p>关键词：互斥锁、CAS、偏向锁、自旋锁、轻量级锁、重量级锁</p>
</blockquote>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>在java语言中存在两种内建的synchronized语法：</p>
<ol>
<li><code>synchronized语句</code>:当Java源代码被javac编译成bytecode的时候，会在同步块的入口位置和退出位置分别插入<code>monitorenter</code>和<code>monitorexit</code>字节码指令。</li>
<li><code>synchronized方法</code>:会被翻译成普通的方法调用和返回指令如:<code>invokevirtual</code>、<code>areturn</code>指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的<code>access_flags</code>字段中的synchronized标志位置1，表示该方法是同步方法，并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。</li>
</ol>
<p>那么<code>monitorenter</code>和<code>monitorexit</code>以及<code>access_flags</code>底层又是通过什么底层技术来实现的原子操作呢？</p>
<ul>
<li>在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的<code>Mutex Lock</code>来实现的，但是由于使用<code>Mutex Lock</code>需要将当前线程挂起并从<code>用户态</code>切换到<code>内核态</code>来执行，这种切换的代价是非常昂贵的；</li>
<li>在linux的内核中互斥锁是通过<code>spinlock自旋锁</code>实现的；</li>
<li><p>而spinlock是依靠cpu硬件的锁机制（内存总线锁/缓存锁）实现的原子操作；</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* /linux/include/linux/mutex.h */</span> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mutex</span> &#123;</span></span><br><span class="line">  <span class="comment">/* 1: unlocked, 0: locked, negative: locked, possible waiters */</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">//指示互斥锁的状态,1没有上锁，可以获得，0/负数 被锁定，默认为1</span></span><br><span class="line">  <span class="keyword">atomic_t</span>                count;</span><br><span class="line">  <span class="comment">//等待获取互斥锁中使用的自旋锁。在获取互斥锁的过程中，操作会在自旋锁的保护中进行。初始化为为锁定。</span></span><br><span class="line">  <span class="keyword">spinlock_t</span>              wait_lock;</span><br><span class="line">  <span class="comment">//等待互斥锁的进程队列</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>        <span class="title">wait_list</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_DEBUG_MUTEXES</span></span><br><span class="line">      <span class="class"><span class="keyword">struct</span> <span class="title">thread_info</span>      *<span class="title">owner</span>;</span></span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">char</span>              *name;</span><br><span class="line">      <span class="keyword">void</span>                    *magic;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_DEBUG_LOCK_ALLOC</span></span><br><span class="line">      <span class="class"><span class="keyword">struct</span> <span class="title">lockdep_map</span>      <span class="title">dep_map</span>;</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>synchronized有三种方式来加锁</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">对比</th>
<th style="text-align:left">加锁类型</th>
<th style="text-align:left">获取锁位置</th>
<th style="text-align:left">示例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">修饰实例方法</td>
<td style="text-align:left">对象锁</td>
<td style="text-align:left">进入同步代码前要获得当前实例的锁</td>
<td style="text-align:left"><code>synchronized (this) {}</code><br /><code>synchronized void access(){}</code></td>
</tr>
<tr>
<td style="text-align:left">修饰静态方法</td>
<td style="text-align:left">类锁</td>
<td style="text-align:left">进入同步代码前要获得类锁修饰代码块</td>
<td style="text-align:left"><code>synchronized static void access(){}</code></td>
</tr>
<tr>
<td style="text-align:left">修饰代码块</td>
<td style="text-align:left">类锁</td>
<td style="text-align:left">进入同步代码块前</td>
<td style="text-align:left"><code>synchronized (TestLock.class){}</code></td>
</tr>
</tbody>
</table>
</div>
<p>在JDK1.5之前，多线程并发中，synchronized一直都是重量级锁，在JDK1.6之后，这个关键字被做了很多的优化，从而让以往的<code>重量级锁</code>变得不再那么重。<br>为了减少获得锁和释放锁带来的性能开销，引入了偏向锁、轻量级锁的概念。<br>因此在synchronized中，锁存在4种状态，分别是:<code>无锁、偏向锁、轻量级锁、重量级锁</code>; 锁的状态根据竞争激烈的程度从低到高不断升级。</p>
<h3 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h3><ul>
<li>对象头（Object Header）的对象运行时数据（Mark Word）中存储了对象的锁状态信息，栈帧中存储了Mark Word的副本称之为<code>Lock Record</code>；</li>
<li>MarkWord记录了对象和锁有关的信息，当对象被synchronized加同步锁时，那么围绕这个锁的一系列操作都和MarkWord有关系。MarkWord 在32位虚拟机的长度是32bit、在64位虚拟机的长度是64bit。 MarkWord里面存储的数据会随着锁标志位的变化而变化；</li>
</ul>
<p><img src="markword.png" alt="markword"></p>
<p>synchronized中4种锁状态对应的的Mark Word内容</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">锁状态</th>
<th style="text-align:left">存储内容</th>
<th style="text-align:left">存储内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">无锁</td>
<td style="text-align:left">对象的hashCode、对象分代年龄、是否是偏向锁（0）</td>
<td style="text-align:left">01</td>
</tr>
<tr>
<td style="text-align:left">偏向锁</td>
<td style="text-align:left">偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1）</td>
<td style="text-align:left">01</td>
</tr>
<tr>
<td style="text-align:left">轻量级锁</td>
<td style="text-align:left">指向栈中锁记录的指针</td>
<td style="text-align:left">00</td>
</tr>
<tr>
<td style="text-align:left">重量级锁</td>
<td style="text-align:left">指向互斥量（重量级锁）的指针</td>
<td style="text-align:left">10</td>
</tr>
</tbody>
</table>
</div>
<h3 id="sychronized锁的升级过程"><a href="#sychronized锁的升级过程" class="headerlink" title="sychronized锁的升级过程"></a>sychronized锁的升级过程</h3><h4 id="无锁"><a href="#无锁" class="headerlink" title="无锁"></a>无锁</h4><ul>
<li>sychronized修饰的代码块/类/方法默认是无锁状态；</li>
<li>无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。</li>
<li>无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。</li>
</ul>
<blockquote>
<p>CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。</p>
</blockquote>
<h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><ul>
<li>偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。</li>
</ul>
<blockquote>
<p>当1个线程执行到同步代码时，会执行一次CAS操作（比较MarkWord和LockRecord）来尝试获取锁，获取成功时会把ThreadId写入MarkWord。后续这个线程进入和退出这段加了同步锁的代码块时，<code>不需要再次加锁和释放锁</code>,而是直接比较对象头里面是否存储了指向当前线程的偏向锁。如果相等表示偏向锁是偏向于当前线程的，就不需要再尝试获得锁了。</p>
</blockquote>
<ul>
<li><p>引入偏向锁是为了在无多线程竞争的情况下尽量<code>减少不必要的轻量级锁执行路径</code>，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadId的时候依赖<code>一次CAS原子指令</code>即可。</p>
</li>
<li><p>偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。</p>
</li>
<li>偏向锁的撤销，需要等待<code>SafePoint</code>（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到<code>无锁</code>（标志位为<code>01</code>）或<code>轻量级锁</code>（标志位为<code>00</code>）的状态。</li>
<li>在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。</li>
<li>但一般的互联网后端服务都会存在<code>2个以上的线程竞争</code>，那么如果开启偏向锁，反而会加剧了获取锁的资源消耗;</li>
<li>偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：<ul>
<li><code>-XX:-UseBiasedLocking=false</code>：设置关闭偏向锁,关闭之后程序默认会进入轻量级锁状态；</li>
<li><code>-XX:BiasedLockingStartupDelay=0</code>：设置偏向锁的启动延迟为0（这个值默认为5秒）；</li>
</ul>
</li>
</ul>
<h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><p>第2个线程获取锁时，CAS<code>自旋</code>等锁，升级为轻量级锁;</p>
<blockquote>
<p>自旋锁</p>
</blockquote>
<p>轻量级锁在加锁过程中，用到了自旋锁，所谓自旋：当有另外一个线程来竞争锁时，争抢线程会在原地循环等待，而不是把该线程给阻塞，直到那个获得锁的线程释放锁之后，争抢线程就可以马上获得锁的。</p>
<blockquote>
<p>注意</p>
</blockquote>
<ul>
<li>锁在原地循环的时候，是会消耗cpu的。 所以，轻量级锁适用于那些同步代码块执行的很快的场景。 </li>
<li>自旋锁的使用，其实也是有一定的概率背景，在<code>大部分同步代码块执行的时间都是很短</code>的。所以通过看似无意义的循环反而能提升锁的性能。 但是自旋必须要有一定的条件控制，</li>
</ul>
<blockquote>
<p>自旋锁的jvm控制参数</p>
</blockquote>
<p><code>-XX:PreBlockSpin=10</code>：jdk1.6，默认启用，默认情况下自旋的次数是 10 次。</p>
<blockquote>
<p>自适应自旋锁</p>
</blockquote>
<p>在 JDK1.6 之后，引入了自适应自旋锁，自适应意味着自旋的次数不是固定不变的，而是根据以下2个数据来决定：</p>
<ul>
<li>同一个锁上一次自旋的时间</li>
<li>拥有锁线程的状态</li>
</ul>
<blockquote>
<p>自适应自旋锁是为了<code>最大的提高CPU的资源利用率</code>。</p>
</blockquote>
<p>eg：如果在同一个锁对象上，刚刚自旋等待成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。<br>如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。</p>
<p>轻量级锁的锁释放逻辑其实就是获得锁的逆向逻辑，通过 CAS 操作把线程栈帧中的 LockRecord 替换回到锁对象的 MarkWord 中，如果成功表示没有竞争。如果失败，表示当前锁存在竞争(3个线程)，那么轻量级锁就会膨胀成为重量级锁。</p>
<h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4><p>升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。</p>
<blockquote>
<p>sychronized总结</p>
<ol>
<li>默认无锁，执行一次CAS抢锁；</li>
<li>偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。</li>
<li>轻量级锁是通过用<code>CAS</code>操作和<code>自旋</code>来解决加锁问题，避免线程阻塞和唤醒而影响性能。</li>
<li>重量级锁是将除了拥有锁的线程以外的线程都<code>阻塞</code>。</li>
</ol>
</blockquote>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>主要与ReentrantLock比较</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>默认为非公平是锁，性能好；</li>
<li>关键词形式使用简单，不需要手动释放锁；</li>
<li>支持可重入；</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>不支持公平锁；</li>
<li>当多个线程尝试获取锁时，未获取到锁的线程不能外部中断，造成性能消耗；</li>
<li>在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReentrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReentrantLock的性能能维持常态；</li>
</ul>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>sychronized是悲观锁，悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。</p>
<h2 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h2><ul>
<li>HashTable,Vector都是直接使用sychronized关键词实现线程安全；</li>
</ul>
<h1 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h1><p>volatile是Java虚拟机提供的轻量级同步机制；</p>
<h2 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h2><ol>
<li><p>保证可见性<br> volatile的可见性可以理解为一种通知机制，一个线程修改工作内存并同步到主内存后，同时确保其他线程的工作内存也修改完成；<br> volatile实现内存可见性是通过<code>store</code>和<code>load</code>指令完成的；</p>
<ul>
<li>volatile变量进行写操作时：在写操作后加入一条store命令， 将工作内存中的共享变量值刷回到主内存；</li>
<li>volatile变量进行读操作时：在读操作前加入一条load命令， 从主内存中读取共享变量；</li>
</ul>
</li>
<li><p>不保证原子性<br> volatile不保证原子性和<code>JMM</code>的实现原理有关。</p>
<p>在多线程运行环境下，因为存在线程切换，如果volatile变量不上锁，变量的工作内存和主内存的值是不能保证是一致的，<br>可能在当前线程执行store操作的时候，别的线程已经执行过load&amp;store了，那么这个时候就会发生值值覆盖（线程不安全）；</p>
</li>
<li><p>禁止指令重排<br> 内存屏障（Memory Barrier），一种CPU指令；<br> 通过插入内存屏障<code>禁止在内存屏障的前后执行指令重排优化</code>，保证特定操作的执行顺序，保证某些变量的内存可见性；</p>
</li>
</ol>
<h2 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>轻量级锁，损耗低</li>
<li>保证可见性和有序性</li>
</ul>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>volatile只能作用于变量层次，无法作用语句层次（加锁等确保）</li>
<li>不能保证原子性（线程安全）</li>
<li>频繁更改、改变或写入volatile字段有可能导致性能为题。（volatile字段未修改时，读取没有性能问题的）</li>
</ul>
<h2 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li>volatile不能修饰<code>写入操作依赖当前值的变量</code>。声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count = count+1”;</li>
<li>状态标识：volatile适合幂等操作，比如设置状态，不管别的线程设置为多少，以当前线程设置的值为准，覆盖不影响业务逻辑;</li>
<li>一次性安全发布：在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。这就是造成著名的<code>双重检查锁定</code>（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行<code>读</code>操作，产生的问题是可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象。</li>
</ul>
<blockquote>
<p>Lazy单例模式的DCL实现<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</span><br><span class="line">    <span class="comment">//volatile标识可见性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> VolatileTest instance = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//DLC双重检查加锁实现</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> VolatileTest <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//其他线程可能更改instance</span></span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (VolatileTest<span class="class">.<span class="keyword">class</span>) </span>&#123;</span><br><span class="line">                <span class="comment">//其他线程可能在上锁前更改instance</span></span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> VolatileTest();</span><br><span class="line">                    <span class="comment">//此时如果instance没有设置volatile保证有序性，其他线程可能读取到一个部分构造的对象</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>DLC代码过于复杂，可以采用延迟初始化占位（Holder）类模式实现<code>final class InstanceHolder</code>解决单例初始化问题更优，且不需要同步锁的损耗；<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">VolatileTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//延迟初始化实现:内部静态类只有在调用时才会加载</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">InstanceHolder</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">InstanceHolder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//JVM在类的初始化阶段给出的线程安全性保证</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> VolatileTest instance = <span class="keyword">new</span> VolatileTest();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//公有实例化方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> VolatileTest <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> InstanceHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="使用案例-1"><a href="#使用案例-1" class="headerlink" title="使用案例"></a>使用案例</h2><ul>
<li>volatile可配合Unsafe类实现CAS后保证当前工作内存的变量的实时性;</li>
<li>ConcurrentHashMap中通过<code>volatile</code>来保证hash表数据的可见性：<code>transient volatile Node&lt;K,V&gt;[] table</code>；</li>
</ul>
<h1 id="ReentranLock可重入锁"><a href="#ReentranLock可重入锁" class="headerlink" title="ReentranLock可重入锁"></a>ReentranLock可重入锁</h1><blockquote>
<p>关键词：互斥锁、可重入锁、公平锁/非公平锁<br>ReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。</p>
</blockquote>
<h2 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="ReentrantLock_classmap.jpg" alt="ReentrantLock_类图"><br>ReentrantLock基于AQS中的互斥锁实现;</p>
<blockquote>
<p>Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。<br>AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。</p>
<p>todo 后面另起章节解说juc.locks源码</p>
</blockquote>
<h2 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h3><ul>
<li>ReentrantLock支持可重入；</li>
<li>ReentrantLock支持指定时间中断/外部中断；</li>
<li>ReentrantLock支持非公平/公平锁（构造函数）；</li>
<li>ReentrantLock支持线程的精确唤醒（Condtion）；</li>
<li>ReentrantLock支持查看锁的状态，锁是否被锁上了；</li>
<li>ReentrantLock支持查看当前有多少线程在等待锁；</li>
</ul>
<h3 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>ReentrantLock语法比sychronized繁琐，相比synchronized可以减少嵌套；</li>
<li>ReentrantLock使用比sychronized繁琐，不能像sychronized可以直接修饰方法来加锁；</li>
<li>ReentrantLock需要手动释放锁；</li>
</ul>
<h2 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li><p>在需要时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者轮询锁时，采用ReentrantLock ；</p>
</li>
<li><p>在资源竞争非常激烈的情况下，synchronized的性能一下子能下降好几十倍，而ReentrantLock确还能维持常态；在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的，因为在资源竞争不激烈的情形下，ReentrantLock性能稍微比synchronized差点点；</p>
</li>
<li><p>ReentrantLock 具有可伸缩性的好处，应当在高度竞争的情况下使用它，但是大多数 synchronized 块几乎从来没有出现过争用，所以可以把高度争用放在一边。</p>
<blockquote>
<p>建议首先考虑 synchronized ，直到确实证明 synchronized 不合适再考虑ReentrantLock。</p>
</blockquote>
</li>
</ul>
<h2 id="使用案例-2"><a href="#使用案例-2" class="headerlink" title="使用案例"></a>使用案例</h2><ul>
<li><code>ArrayBlockingQueue</code>中用ReentrantLock来控制队列的读写安全，有1把锁（可设置是否公平），notEmpty，notFull2个Condition来实现队列put和take的阻塞；</li>
<li><code>LinkedBlockingQueue</code>中用ReentrantLock来控制队列的读写安全，有takeLock，putLock2把锁，notEmpty，notFull2个Condition来实现队列put和take的阻塞；</li>
<li><code>CopyOnWriteArrayList</code>利于ReentrantLock来包含数组的更新操作；</li>
</ul>
<h1 id="ReentranReadWriteLock可重入读写锁"><a href="#ReentranReadWriteLock可重入读写锁" class="headerlink" title="ReentranReadWriteLock可重入读写锁"></a>ReentranReadWriteLock可重入读写锁</h1><p>ReentranReadWriteLock提供了readLock和writeLock两种锁的操作机制，一个资源可以被多个线程同时读，或者被一个线程写，但是不能同时存在读和写线程。</p>
<p><code>读锁</code>可以共享，多个线程可以同时拥有读锁，类似于MySQL的共享锁（S锁）；</p>
<p><code>写锁</code>却只能只有一个线程拥有，而且获取写锁的时候，其他线程都已经释放了读锁，而且在该线程获取写锁之后，其他线程不能再获取读锁，类似于MySQL的互斥锁（X锁）。</p>
<h2 id="实现原理-3"><a href="#实现原理-3" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="ReentrantLock_classmap.jpg" alt="ReentranReadWriteLock_类图"></p>
<p>实现原理与ReentrantLock一样，都是基于AQS实现；</p>
<blockquote>
<p>todo 后续补充源码解析</p>
<p>注意点</p>
</blockquote>
<ul>
<li><code>读锁离开了写锁就没有了意义</code>：如果有一线程在读取数据时，此时恰好有另一线程，正以写锁的方式在修改该数据，此时读取数据的线程如果加了读锁，将被阻塞，直到另一线程的写锁被释放才能继续读，而如果读取数据的线程未加读锁，那么它的读将不被阻塞，就有可能读入被修改前的数据；</li>
<li><code>重入</code>：此锁允许 reader 和 writer 按照 ReentrantLock的方式重新获取读取锁或写入锁。在写入线程保持的所有写入锁都已经释放后，才允许重入 reader 使用它们。此外，writer 可以获取读取锁，但反过来则不成立；</li>
<li><code>锁降级</code>：重入还允许从写锁降级为读锁，其实现方式是：先获取写锁，然后获取读锁，最后释放写锁。但<code>从读锁升级到写锁是不可能的</code>；</li>
</ul>
<h2 id="优缺点-3"><a href="#优缺点-3" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h3><ul>
<li>在某些读远远大于写的场景中，读写锁能够提供比排它锁<code>更好的并发量和吞吐量</code>：与之前的互斥锁（同一时刻只允许一个线程进行访问）相比，读写锁维护了一对锁，一个读锁，一个写锁。读写锁在同一时刻允许多个线程进行读操作，但是写线程访问过程中，所有的读线程和其他写线程均被阻塞。如此，并发性有了很大的提升。</li>
<li><strong>公平性选择</strong>：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平；</li>
<li><strong>重入性</strong>：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁；</li>
<li><strong>锁降级</strong>：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁；</li>
</ul>
<h3 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h3><p>同ReentrantLock的缺点</p>
<h2 id="适用场景-3"><a href="#适用场景-3" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li>读多写少的情况下可以使用ReentrantReadWriteLock获得比更高的并发性能；</li>
</ul>
<h2 id="使用案例-3"><a href="#使用案例-3" class="headerlink" title="使用案例"></a>使用案例</h2><ul>
<li><code>javax.swing.plaf.nimbus.ImageCache</code>使用<code>ReentrantReadWriteLock</code>来控制缓存<code>LinkedHashMap</code>对象的并发访问；</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="">《深入理解Java虚拟机-JVM高级特性与最佳实践》</a></li>
<li><a href="https://blog.csdn.net/godleading/article/details/78259842">Linux内核中的各种锁</a></li>
</ul>
]]></content>
      <categories>
        <category>后端技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Web开发常用协议</title>
    <url>/2017/09/16/Web%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>整理常用网络协议OSI七层协议，TCP-IP协议组，UDP，Socket，WebSocket，Http，Https，三次握手，长连接</p>
<hr>
<a id="more"></a>
<h2 id="Web开发常用协议"><a href="#Web开发常用协议" class="headerlink" title="Web开发常用协议"></a>Web开发常用协议</h2><h1 id="OSI七层协议体系"><a href="#OSI七层协议体系" class="headerlink" title="OSI七层协议体系"></a>OSI七层协议体系</h1><blockquote>
<p>OSI 模型(Open System Interconnection model)：是一个由国际标准化组织提出的概念模型,试图提供一个各种不同的计算机和网络在世界范围内实现互联的标准框架。它将计算机网络体系结构划分为七层，每层都可以提供抽象良好的接口。</p>
</blockquote>
<p>OSI 模型各层间关系和通讯时的数据流向如图所示：<br><img src="ISO七层协议1.png" alt="ISO七层协议1"><br><img src="ISO七层协议2.png" alt="ISO七层协议2"><br><img src="ISO七层协议3.png" alt="ISO七层协议3"><br><img src="ISO七层协议4.png" alt="ISO七层协议4"><br>特点：<br>1.OSI模型每层都有自己的功能集；<br>2.层与层之间相互独立又相互依靠；<br>3.上层依赖于下层，下层为上层提供服务。<br>了解 OSI 模型有助于理解实际上互联网络的工业标准-TCP/IP 协议。</p>
<h2 id="物理层-Physical"><a href="#物理层-Physical" class="headerlink" title="物理层 Physical"></a>物理层 Physical</h2><p><img src="物理层.png" alt="物理层"></p>
<blockquote>
<p>设备：Hub集线器</p>
<ul>
<li>整台设备在同一个冲突域 (collision domain)</li>
<li>整台设备都在同一个广播域( broadcast domain)</li>
<li>设备共享带宽</li>
</ul>
<p>WAN、LAN的物理层实现</p>
<ul>
<li>物理层标准规定了信号、连接器和电缆要求。</li>
<li>接口及连接器、线缆</li>
</ul>
</blockquote>
<p>物理拓扑：物理层负责最后将信息编码成电流脉冲或其它信号用于网上传输；</p>
<ul>
<li>功能：<br><code>eg：RJ45等将数据转化成0和1；</code></li>
</ul>
<h2 id="数据链路层-DataLink"><a href="#数据链路层-DataLink" class="headerlink" title="数据链路层 DataLink"></a>数据链路层 DataLink</h2><p><img src="数据链路层.png" alt="数据链路层"></p>
<blockquote>
<p>设备：交换机</p>
<ul>
<li>每个端口是一个冲突域</li>
<li>整台交换机属于一个广播域【一个网段(vlan)就是一个广播域】</li>
<li>全双工</li>
<li>工作原理：根据MAC地址表转发数据帧，如果地址未知，则广播</li>
</ul>
</blockquote>
<p>成帧：数据链路层通过物理网络链路提供数据传输。</p>
<ul>
<li>功能：<br>不同的数据链路层定义了不同的网络和协议特征，其中包括物理编址、网络拓扑结构、错误校验、数据帧序列以及流控；<br><code>可以简单的理解为：规定了0和1的分包形式，确定了网络数据包的形式；</code><h2 id="网络层-Network"><a href="#网络层-Network" class="headerlink" title="网络层 Network"></a>网络层 Network</h2><img src="网络层.png" alt="网络层"><br>路由选择：网络层负责在源和终点之间建立连接;<br>可以理解为，此处需要确定计算机的位置，怎么确定？IPv4，IPv6！<blockquote>
<p>设备：路由器（Router）</p>
<ul>
<li>广播、组播隔绝</li>
<li>寻址及转发，选择到达目的网络的最佳路径</li>
<li>流量管理</li>
<li>连接广域网(WAN)</li>
</ul>
</blockquote>
</li>
</ul>
<blockquote>
<p>设备：网桥</p>
<ul>
<li>数据链路层包含：MAC及LLC子层</li>
<li>逻辑地址：MAC地址</li>
<li>以太网工作在数据链路层（我们平常使用的局域网就是以太网）</li>
<li>以太网标准：Ethernet-II 及802.3</li>
</ul>
</blockquote>
<h2 id="传输层-Transportation"><a href="#传输层-Transportation" class="headerlink" title="传输层 Transportation"></a>传输层 Transportation</h2><p><img src="传输层.png" alt="传输层"><br>传输层向高层提供可靠的<code>端到端</code>的网络数据流服务。</p>
<ul>
<li>功能：将数据进行分段并重组为数据流。位于传输层的服务将来自上层应用的数据进行分段和重组，并将他们合并到一个数据流中。他们提供了端到端的数据传输服务，并可在互联网上的发送主机和目标主机之间建立逻辑连接。<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3>数据的完整性由传输层确保。流量控制可避免作为发送方的主机让作为接收方的主机的缓冲区溢出。<ol>
<li>收到数据后，向发送方进行确认；</li>
<li>重传所有未得到确认的数据断；</li>
<li>数据段到达目的地后，按正确的顺序排列他们；</li>
<li>确保数据流量不超过处理能力，以避免拥塞、过载和数据丢失；<h3 id="面向连接的通信"><a href="#面向连接的通信" class="headerlink" title="面向连接的通信"></a>面向连接的通信</h3>在可靠的传输操作中，要传输数据的设备建立一个到远程设备的面向连接的通信会话。</li>
</ol>
<ul>
<li>传输设备首先与其对等系统建立面向连接的会话，这称为呼叫或<code>三方握手</code>，</li>
<li>然后传输数据。</li>
<li>传输完毕后，将进行呼叫终止，以拆除虚电路。<h3 id="窗口技术"><a href="#窗口技术" class="headerlink" title="窗口技术"></a>窗口技术</h3>传输方发送每个数据段后都必须等待确认，传输速度都变得缓慢。<br>然而，从发送方传输数据到处理完毕来自接收方的确认之间有一段时间，发送方可以利用这段时间传输更多的数据。<br>在收到确认前，传输方可发送的数据段的数量（以字节为单位）。称为<code>窗口</code>；<br>窗口大小控制了一方传输给另一方的<code>信息量</code>。<code>TCP/IP以字节数度量信息量</code>。</li>
</ul>
</li>
</ul>
<blockquote>
<p>对上层应用程序进行<code>多路复用，建立会话以及拆除虚电路</code>。可以理解为：每一个应用程序都会在网卡注册一个端口号，该层就是端口与端口的通信！</p>
</blockquote>
<h2 id="会话层-Session"><a href="#会话层-Session" class="headerlink" title="会话层 Session"></a>会话层 Session</h2><p><img src="会话层.png" alt="会话层"></p>
<ul>
<li>功能：负责<code>在表示层实体之间建立、管理和终止会话</code>。还对设备或节点之间的对话进行控制。协调和组织系统之间的通信。<br>3种不同的模式：单工、半双工、全双工。会话层的功能将不同应用程序的数据分离<h2 id="表示层-Presentation"><a href="#表示层-Presentation" class="headerlink" title="表示层 Presentation"></a>表示层 Presentation</h2><img src="表示层.png" alt="表示层"><br>表示层提供多种功能用于应用层数据编码和转化,以确保以一个系统应用层发送的信息可以被另一个系统应用层识别；<ul>
<li>功能：向应用层提供数据，并负责数据转换和代码格式化。该层是一个转换器，<code>提供编码和转换功能</code>。确保从一个系统的应用层传输而来的数据可以被另一个系统读取。<code>数据压缩、解压缩、加密和解密</code>等任务都和表示层有关。<br>可以理解为：解决不同系统之间的通信，<br><code>eg：Linux下的QQ和Windows下的QQ可以通信；</code><h2 id="应用层-Application"><a href="#应用层-Application" class="headerlink" title="应用层 Application"></a>应用层 Application</h2><img src="应用层.png" alt="应用层"><br>OSI 的应用层协议包括文件的传输、访问及管理协议(FTAM) ，以及文件虚拟终端协议(VIP)和公用管理系统信息(CMIP)等；<code>规定数据的传输协议,如文件、打印、消息、数据库和应用程序服务；</code></li>
</ul>
</li>
<li>功能：用户和计算机交流的场所，负责确定目标通信方的可用性，并判断是否有足够的资源进行想要的通信。</li>
</ul>
<p>常见的应用层协议：<br><img src="常见的应用层协议.png" alt="常见的应用层协议"><br>互联网分层结构的好处: 上层的变动完全不影响下层的结构。</p>
<h1 id="TCP-IP协议组"><a href="#TCP-IP协议组" class="headerlink" title="TCP/IP协议组"></a>TCP/IP协议组</h1><p><img src="OSI模型和TCP-IP模型的对比图.png" alt="OSI模型和TCP-IP模型的对比图"></p>
<blockquote>
<p>IP（<code>Internet Protocol</code>，网络之间互连的协议 ）在因特网中，它是能使连接到网上的所有计算机网络实现相互通信的一套规则，规定了计算机在因特网上进行通信时应当遵守的规则。任何厂家生产的计算机系统，只要遵守IP协议就可以与因特网互连互通。</p>
<p>TCP（<code>Transmission Control Protocol</code> 传输控制协议）是一种<code>面向连接的、可靠的、基于字节流的传输层通信协议</code>，由IETF的RFC 793定义。在简化的计算机网络OSI模型中，它完成第四层传输层所指定的功能。<br><img src="TCP-IP的分层.png" alt="TCP-IP的分层"><br>我们在学习网络知识的时候，都是参照OSI模型的，但在使用的时候，都是使用TCP/IP模型。</p>
</blockquote>
<p><img src="TCP-IP协议组.png" alt="TCP-IP协议组"></p>
<ul>
<li>TCP工作在网络OSI的七层模型中的第四层——Transport层，第四层的数据叫Segment。 </li>
<li>IP在第三层——Network层，在第三层上的数据叫Packet，</li>
<li>ARP在第二层——Data Link层；在第二层上的数据，我们把它叫Frame，</li>
</ul>
<p>数据从应用层发下来，会在每一层都会加上头部信息，进行封装，然后再发送到数据接收端。每个数据都会经过数据的封装和解封装的过程。<br><img src="TCP-IP协议组数据的封装和解封装的过程.png" alt="TCP-IP协议组数据的封装和解封装的过程"></p>
<h2 id="TCP协议头部格式"><a href="#TCP协议头部格式" class="headerlink" title="TCP协议头部格式"></a>TCP协议头部格式</h2><p><img src="TCP协议头部格式.png" alt="TCP协议头部格式"></p>
<ul>
<li><code>Source Port</code>和<code>Destination Port</code>:分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程，而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接；</li>
<li><code>Sequence Number</code>:用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号；主要用来解决网络报乱序的问题；</li>
<li><code>Acknowledgment Number</code>:32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志（下面介绍）为1时该确认序列号的字段才有效。主要用来解决不丢包的问题；</li>
<li><p><code>Offset</code>:给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit（最多能表示15个32bit的的字，即4*15=60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节；</p>
</li>
<li><p><code>TCP Flags</code>:TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次为URG，ACK，PSH，RST，SYN，FIN。每个标志位的意思如下：</p>
<ul>
<li><code>URG</code>：此标志表示TCP包的紧急指针域（后面马上就要说到）有效，用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据；</li>
<li><code>ACK</code>：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0；</li>
<li><code>PSH</code>：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队；</li>
<li><code>RST</code>：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包；</li>
<li><code>SYN</code>：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的<code>第一次握手</code>，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手；</li>
<li><code>FIN</code>： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的TCP数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。</li>
</ul>
</li>
<li><p><code>Window</code>:窗口大小，也就是有名的滑动窗口，用来进行流量控制；这是一个复杂的问题，这篇博文中并不会进行总结的；</p>
</li>
</ul>
<h2 id="3-Way-Handshake"><a href="#3-Way-Handshake" class="headerlink" title="3-Way Handshake"></a>3-Way Handshake</h2><p>TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。<br>在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。<br>三次握手的目的是<code>同步连接双方的序列号和确认号并交换 TCP窗口大小信息</code>。<br><img src="Alt text.png" alt="Alt text"> </p>
<ul>
<li>第一次握手：建立连接。<br>客户端发送连接请求报文段，将<code>SYN</code>位置为1，<code>Sequence Number</code>为x；然后，客户端进入<code>SYN_SENT</code>状态，等待服务器的确认；</li>
<li>第二次握手：服务器收到SYN报文段。<br>服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置<code>Acknowledgment Number</code>为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将<code>SYN</code>位置为1，<code>Sequence Number</code>为y；<br>服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入<code>SYN_RECV</code>状态；</li>
<li>第三次握手：客户端收到服务器的<code>SYN+ACK</code>报文段。然后将<code>Acknowledgment Number</code>设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入<code>ESTABLISHED</code>状态，完成TCP三次握手。</li>
</ul>
<p>完成了三次握手，客户端和服务器端就可以开始传送数据。</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>为什么要三次握手?<br>既然总结了TCP的三次握手，那为什么非要三次呢？怎么觉得两次就可以完成了。那TCP为什么非要进行三次连接呢？在谢希仁的《计算机网络》中是这样说的：<code>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</code><br>在书中同时举了一个例子，如下：<br>“已失效的连接请求报文段”的产生在这样一种情况下：<br>client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。<br>假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。<br>采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”</li>
</ol>
<p>防止了服务器端的一直等待而浪费资源。</p>
<ol>
<li><p>为什么是3次握手，不是2次握手?</p>
<blockquote>
<p>start of a TCP conversation between Alice and Bob:<br>Alice —-&gt; Bob    SYNchronize with my Initial Sequence Number of X<br>Alice &lt;—- Bob    I received your syn, I ACKnowledge that I am ready for [X+1]<br>Alice &lt;—- Bob    SYNchronize with my Initial Sequence Number of Y<br>Alice —-&gt; Bob    I received your syn, I ACKnowledge that I am ready for [Y+1]<br>如果是2次握手，只能单向通信（1个发syn，一个ack），而事实上TCP是全双工，双方都需要建立ISN（Initial Sequence Number ），彼此都需要知道对方的ISN</p>
</blockquote>
</li>
<li><p>3次握手，逻辑上是4次握手，是有序的2次互通信<br>TCP connection is <code>bidirectional</code>. What this means is that it actually is <code>a pair of one-way connections</code>. </p>
<ul>
<li>The initiator sends SYN, the responder sends ACK: </li>
<li>one simplex connection begins. </li>
<li>“Then” the responder sends SYN, the initiator sends ACK: </li>
<li>another simplex connection begins.<br>Two simplex connections form one <code>duplex TCP session</code></li>
</ul>
</li>
</ol>
<p>So logically there are <code>four steps</code> involved; but because SYN and ACK flags are different “fields” of TCP header, they can be set simultaneously - the second and the third steps (of the four) are combined, so technically there are <code>three packet</code> exchanges. Each simplex (half-)connection uses <code>2-way exchange,</code> as you proposed.</p>
<p>![2次握手(./1506390563056.png)<br>Each client will perform an active OPEN and then proceed through both the SYN-SENT and SYN-RECEIVED states until their SYNs are acknowledged. This means there isn’t a “three-way handshake” any more as shown. Instead, it is like two simultaneous “two-way handshakes”. Each client sends a SYN, receives the other’s SYN and ACKs it, and then waits for its own ACK. </p>
<h2 id="4-Way-Handshake"><a href="#4-Way-Handshake" class="headerlink" title="4-Way Handshake"></a>4-Way Handshake</h2><p>当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。</p>
<ul>
<li>第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机2发送一个<code>FIN</code>报文段；此时，主机1进入<code>FIN_WAIT_1</code>状态；这表示主机1没有数据要发送给主机2了；</li>
<li>第二次分手：主机2收到了主机1发送的<code>FIN</code>报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入<code>FIN_WAIT_2</code>状态；主机2告诉主机1，我“同意”你的关闭请求；</li>
<li>第三次分手：主机2向主机1发送<code>FIN</code>报文段，请求关闭连接，同时主机2进入<code>LAST_ACK</code>状态；</li>
<li>第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送<code>ACK</code>报文段，然后主机1进入<code>TIME_WAIT</code>状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。<br>至此，TCP的四次分手就这么愉快的完成了。</li>
</ul>
<blockquote>
<p>为什么要四次分手?<br>TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。<br>TCP是<code>全双工模式</code>，这就意味着，<br>当主机1发出<code>FIN</code>报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；<br>当主机2返回<code>ACK</code>报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；<br>当主机2也发送了<code>FIN</code>报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。<br>如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。</p>
<ul>
<li><code>FIN_WAIT_1</code>: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）</li>
<li><code>FIN_WAIT_2</code>：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）</li>
<li><code>CLOSE_WAIT</code>：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）</li>
<li><code>LAST_ACK</code>: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）</li>
<li><code>TIME_WAIT</code>: 表示收到了对方的FIN报文，并发送出了ACK报文，就等<code>2MSL</code>后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）</li>
<li><code>CLOSED</code>: 表示连接中断。</li>
</ul>
</blockquote>
<h2 id="TCP的优缺点"><a href="#TCP的优缺点" class="headerlink" title="TCP的优缺点"></a>TCP的优缺点</h2><p>从原理上，TCP的优势有：</p>
<ul>
<li>简单直接的长连接；</li>
<li>可靠的信息传输；</li>
<li>数据包的大小没有限制；</li>
</ul>
<p>TCP最糟糕的特性是它<code>对阻塞的控制</code>。<br>一般来说，TCP假定丢包是由于网络带宽不够造成的，所以发生这种情况的时候，TCP就会减少发包速度。</p>
<blockquote>
<p>在3G或WiFi下，一个数据包丢失了，你希望的是立马重发这个数据包，然而TCP的阻塞机制却完全是采用相反的方式来处理！</p>
</blockquote>
<p>而且没有任何办法能够绕过这个机制，因为这是TCP协议构建的基础。这就是为什么在3G或者WiFi环境下，ping值能够上升到000多毫秒的原因。</p>
<blockquote>
<p>一个采用TCP的游戏必须能够处理好突发的延迟问题（纸牌客户端就很典型，对突发性的一秒的延迟，玩家也不会产生什么抱怨）或者是拥有<code>缓解延迟问题</code>的好方法。<br>魔兽世界中是有多重连接的, 应该是UDP和TCP共用的, UDP用于不要求数据可靠的数据, TCP用于传输有可靠性要求的数据. 例如周围人物的动向，NPC移动，技能动画指令等则可以使用UDP，这个UDP并不保证可靠，但丢包影响不大。对于技能, 金钱，经验等重要的人物数据, 必须通过TCP保证.</p>
</blockquote>
<h1 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h1><p>UDP （User Datagram Protocol，用户数据报协议），是OSI（Open System Interconnection，开放式系统互联） 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，</p>
<p>UDP是基于数据包构建，这意味着在某些方面需要你完全颠覆在TCP下的观念。UDP只使用一个socket进行通信，不像TCP需要为每一个客户端建立一个socket连接。</p>
<blockquote>
<p>在选择使用协议的时候，选择UDP必须要谨慎。<br>在网络质量令人十分不满意的环境下，UDP协议数据包丢失会比较严重。<br>但是由于UDP的特性：它不属于连接型协议，因而具有资源消耗小，处理速度快的优点，所以通常音频、视频和普通数据在传送时使用UDP较多，因为它们即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。比如我们聊天用的ICQ和QQ就是使用的UDP协议。</p>
</blockquote>
<h2 id="那么到底是用UDP还是TCP呢？"><a href="#那么到底是用UDP还是TCP呢？" class="headerlink" title="那么到底是用UDP还是TCP呢？"></a>那么到底是用UDP还是TCP呢？</h2><ul>
<li>如果是由客户端间歇性的发起无状态的查询，并且偶尔发生延迟是可以容忍，那么使用<code>HTTP/HTTPS</code>吧。</li>
<li>如果客户端和服务器都可以独立发包，但是偶尔发生延迟可以容忍（比如：在线的纸牌游戏，许多MMO类的游戏），那么使用<code>TCP长连接</code>吧。</li>
<li>如果客户端和服务器都可以独立发包，而且无法忍受延迟（比如：大多数的多人动作类游戏，一些MMO类游戏），那么使用<code>UDP</code>吧。<blockquote>
<p>这些也应该考虑在内：你的MMO客户端也许首先使用HTTP去获取上一次的更新内容，然后使用UDP跟游戏服务器进行连接。</p>
</blockquote>
</li>
</ul>
<h1 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h1><p>网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。<br>建立网络通信连接至少要一对端口号(socket)。socket本质是编程接口(API)，对TCP/IP的封装，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口；</p>
<blockquote>
<p>HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。</p>
<p>Socket的英文原义是“孔”或“插座”。作为BSD UNIX的进程通信机制，取后一种意思。通常也称作”套接字”，用于描述IP地址和端口，是一个通信链的句柄，可以用来实现不同虚拟机或不同计算机之间的通信。在Internet上的主机一般运行了多个服务软件，同时提供几种服务。每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应于不同的服务。<br>Socket正如其英文原意那样，像一个多孔插座。一台主机犹如布满各种插座的房间，每个插座有一个编号，有的插座提供220伏交流电， 有的提供110伏交流电，有的则提供有线电视节目。 客户软件将插头插到不同编号的插座，就可以得到不同的服务。</p>
</blockquote>
<h1 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h1><h2 id="技术背景"><a href="#技术背景" class="headerlink" title="技术背景"></a>技术背景</h2><p>长久以来, 创建实现客户端和用户端之间双工通讯的web app都会造成HTTP轮询的滥用: 客户端向主机不断发送不同的HTTP呼叫来进行询问。<br>这会导致一系列的问题：</p>
<ol>
<li>服务器被迫为每个客户端使用许多不同的底层TCP连接：一个用于向客户端发送信息，其它用于接收每个传入消息。</li>
<li>有线协议有很高的开销，每一个客户端和服务器之间都有HTTP头。</li>
<li>客户端脚本被迫维护从传出连接到传入连接的映射来追踪回复。<br>一个更简单的解决方案是使用单个TCP连接双向通信。 这就是WebSocket协议所提供的功能。 结合WebSocket API ，WebSocket协议提供了一个用来替代HTTP轮询实现网页到远程主机的双向通信的方法。<br>WebSocket协议被设计来取代用HTTP作为传输层的双向通讯技术,这些技术只能牺牲效率和可依赖性其中一方来提高另一方，因为HTTP最初的目的不是为了双向通讯。（获得更多关于此的讨论可查阅RFC6202)</li>
</ol>
<blockquote>
<p>简单的说，WebSocket协议之前，双工通信是通过多个http链接来实现，这导致了效率低下。WebSocket解决了这个问题。</p>
</blockquote>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>WebSocket目标是为基于浏览器的、需要和服务器进行<code>双向通信</code>的（服务器不能依赖于打开多个HTTP连接（例如，使用XMLHttpRequest或iframe和长轮询））应用程序提供一种通信机制。</p>
<p>WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。WebSocket通信协议于2011年被IETF定为标准RFC 6455，并被RFC7936所补充规范。</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>协议包括一个开放的握手以及随后的TCP层上的消息帧。</p>
<p>在实现websocket连线过程中，需要通过浏览器发出websocket连线请求，然后服务器发出回应，这个过程通常称为“握手” 。在 WebSocket API，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。在此WebSocket 协议中，为我们实现即时服务带来了两大好处：</p>
<ol>
<li>Header<br>互相沟通的Header是很小的-大概只有 2 Bytes</li>
<li>Server Push<br>服务器的推送，服务器不再被动的接收到浏览器的请求之后才返回数据，而是在有新数据时就主动推送给浏览器。</li>
</ol>
<h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p>超文本传输协议（英文：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的<code>应用层</code>协议。<br>HTTP是万维网的数据通信的基础。<br>设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。通过HTTP或者HTTPS协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>HTTP的发展是由蒂姆ï¿½伯纳斯-李于1989年在欧洲核子研究组织（CERN）所发起。<br>HTTP的标准制定由万维网协会（World Wide Web Consortium，W3C）和互联网工程任务组（Internet Engineering Task Force，IETF）进行协调，最终发布了一系列的RFC，其中最著名的是1999年6月公布的 RFC 2616，定义了HTTP协议中现今广泛使用的一个版本——HTTP 1.1。<br>2014年12月，互联网工程任务组（IETF）的Hypertext Transfer Protocol Bis（httpbis）工作小组将HTTP/2标准提议递交至IESG进行讨论，于2015年2月17日被批准。<br> HTTP/2标准于2015年5月以RFC 7540正式发表，取代HTTP 1.1成为HTTP的实现标准。</p>
<p><a href="http://www.ruanyifeng.com/blog/2016/08/http.html">Http协议</a><br><a href="http://www.ruanyifeng.com/blog/2016/08/http.html">http://www.ruanyifeng.com/blog/2016/08/http.html</a></p>
<p><a href="http://www.jianshu.com/p/80e25cb1d81a">http://www.jianshu.com/p/80e25cb1d81a</a></p>
<h1 id="SSL"><a href="#SSL" class="headerlink" title="SSL"></a>SSL</h1><p>[]</p>
<h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><h2 id="密码（Cipher）"><a href="#密码（Cipher）" class="headerlink" title="密码（Cipher）"></a>密码（Cipher）</h2><p>Java 1.2内置了一个叫做”JCE”(Java Crytography Extension)的系统。它主要负责Java内部的密钥和证书的管理。<br>众所周知，我们要给一段信息加密或者解密，就必须要有密钥。这就好比开门或者锁门，你得有一把钥匙。<br>这个密钥可以用Java带的KeyGenerator 或者 KeyPairGenerator生成。前者用于生成对称密钥，后者用于生成分对称密钥。</p>
<pre><code>* 对称加密（symmetric cryptography）_ 使用相同的key加密和解密
* 非对称加密（asymmetric cryptography）— 使用不同的keys加密和解密。keys通常分为公钥和私钥。
</code></pre><p>公钥也许分布广泛，但是私钥只有它的服务器知道。<br>在一个安全的非对称加密方案中，当使用公钥加密一段信息后，只有配对的私钥可以解密这一段信息。因此，即使黑客拿到了公钥加密信息，他也不能解密这一段信息。因为他没有配对的私钥。所以说，使用非对称加密传输的信息是安全的。</p>
<h2 id="证书（Certificate）"><a href="#证书（Certificate）" class="headerlink" title="证书（Certificate）"></a>证书（Certificate）</h2><p>生活中，假设你要买钻石然后进入了一家钻石店。你怎么能够知道钻石是真的。对于多数人来说，他们没有钻石相关的知识，是很难分辨钻石的真假的。但是，如果这家店有美国政府发布的的钻石营业执照，你就能确定这家店卖的是真的钻石。<br>证书在计算机世界好比上面说的营业执照，它可能有另一些密钥——另一个证书（假设是“B”）。这个密钥正是我需要的，而“B”则是证明这个证书是可信赖的凭证。<br>你可能会问:我怎么知道“B”是可信的。这是一个好问题。<br>Android在手机里内置了将近150份CA（certificate agent 代理证明机构）根证书。他们就好像美国的首席法官(like the chief justice in u.s)，在整个世界都是被认可的。<br>“B”内置了内另一个证书（C），因此我们会检查“C”是否是可信的。。。查询整条证书链，如果在这条证书链的末端或者根证书，正是我们在手机中内置的150份预设的证书之一，我们就确信原证书是合法的。</p>
<blockquote>
<p>P.S. : 证书有很多格式。</p>
<pre><code>* “x.509”：x.509 证书通常用于包含公钥。
* “PKCS12”：PKCS12证书同时包含私钥和公钥。因此，PKCS12证书需要密码开启。
</code></pre><h2 id="HTTPs"><a href="#HTTPs" class="headerlink" title="HTTPs"></a>HTTPs</h2><p>最后，讲讲“https”部分。之所以前面介绍“密码”和“证书”两部分，是因为HTTPs包含它们。<br>HTTPs（HTTP over SSL）被设计用于在互联网中安全通信。</p>
<h3 id="何如安全通信？"><a href="#何如安全通信？" class="headerlink" title="何如安全通信？"></a>何如安全通信？</h3><p>怎么才能建立安全的通信呢？首先想到的是加密。我给需要传输的数据加密，然后将数据和“加密用的密钥”传给服务器，服务器就能使用这个k密钥解密传输的数据了。<br><img src="对称加密.png" alt="对称加密"><br>让我们想象这样一个场景：黑客拦截了这次通信，这意味着加密用的密钥和加密的数据都被盗取了。如果黑客有密钥，解密这段加密的数据就不是什么难事了。好了，你的数据泄露了。</p>
<h3 id="非对称加密（Asymmetric-Cryptography）如何呢？"><a href="#非对称加密（Asymmetric-Cryptography）如何呢？" class="headerlink" title="非对称加密（Asymmetric Cryptography）如何呢？"></a>非对称加密（Asymmetric Cryptography）如何呢？</h3><p>上一个方法一点也不安全，我们考虑下一个，非对称加密有怎么样呢？<br>这是一个很棒的想法。你使用服务器提供的公钥加密信息。因为服务器是唯一知道这个与公钥配对的私钥的，这意味着只有服务器能够解密这段加密的信息。这样，即使是黑客拦截了这段消息，它没有配对的私钥，也无法解密这段信息。因此，数据是安全的。<br>不足之处就是，非对称加密较对称加密来说，需要花费更长的时间来完成加解密的工作。出于用户体验的考虑，给一大串数据执行非对称加解密，并不是一个理想的方案。</p>
<h3 id="最终的方案"><a href="#最终的方案" class="headerlink" title="最终的方案"></a>最终的方案</h3><p>先前两个方案都失败了。有没有综合两个方案优势的方案呢？下面这个方案就是你需要的。<br><img src="HTTPS.png" alt="HTTPS "><br>上图很清楚的展示了HTTPS的执行加解密的过程</p>
<pre><code>1. [server] 生成配对的公钥和私钥，我们称它为“Key”和“KeyPri”；
2. [server] 服务器将“KeyPub”传给客户端；
3. [Client] 生成对称秘钥(&quot;key2&quot;),然后用key2加密信息；
4. [Client] 使用“KeyPub”加密“key2”。因为只有服务器知道“keyPri”,所以“key2”是安全的；
5. [Client]传递加密后的数据和加密的key给服务器；
6. [Server] 用“KeyPri”解密这个key，拿到“key2”；
7. [Server]用“key2”解密加密后的数据。数据安全的到达来了服务器（Now the data arrieve（？arrive） in Server safely）。
</code></pre></blockquote>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>因为对称加密比非对称加密快，因此HTTPS<code>使用对称加密给数据加密</code>，<code>使用非对称加密加密对称加密生成的密钥</code>，从而确保数据传输的安全性。使用这种方法，加密就变的即快速又安全了。<br>总之，理解HTTPS的工作原理是非常重要。这样在现实工作生活中就可以使用这种思想保证你的数据安全。</p>
<h1 id="HTTP长连接-短连接"><a href="#HTTP长连接-短连接" class="headerlink" title="HTTP长连接/短连接"></a>HTTP长连接/短连接</h1><p>HTTP连接方式的进化史：</p>
<h2 id="HTTP-0-9时代：短连接"><a href="#HTTP-0-9时代：短连接" class="headerlink" title="HTTP/0.9时代：短连接"></a>HTTP/0.9时代：短连接</h2><p>每个HTTP请求都要经历一次DNS解析、三次握手、传输和四次挥手。反复创建和断开TCP连接的开销巨大，在现在看来，这种传输方式简直是糟糕透顶。</p>
<h2 id="HTTP-1-0时代：持久连接概念提出"><a href="#HTTP-1-0时代：持久连接概念提出" class="headerlink" title="HTTP/1.0时代：持久连接概念提出"></a>HTTP/1.0时代：持久连接概念提出</h2><p>人们认识到短连接的弊端，提出了持久连接的概念，在HTTP/1.0中得到了初步的支持。<br>持久连接，即一个TCP连接服务多次请求：客户端在请求header中携带<code>Connection: Keep-Alive</code>，即是在向服务端请求持久连接。如果服务端接受持久连接，则会在响应header中同样携带Connection: Keep-Alive，这样客户端便会继续使用同一个TCP连接发送接下来的若干请求。<br>（Keep-Alive的默认参数是[timout=5, max=100]，即一个TCP连接可以服务至多5秒内的100次请求）当服务端主动切断一个持久连接时（或服务端不支持持久连接），则会在header中携带Connection: Close，要求客户端停止使用这一连接。<br><img src="HTTP1.0时代持久连接概念提出.png" alt="HTTP1.0时代持久连接概念提出"></p>
<h2 id="HTTP-1-1时代：持久连接成为默认的连接方式；提出pipelining概念"><a href="#HTTP-1-1时代：持久连接成为默认的连接方式；提出pipelining概念" class="headerlink" title="HTTP/1.1时代：持久连接成为默认的连接方式；提出pipelining概念"></a>HTTP/1.1时代：持久连接成为默认的连接方式；提出pipelining概念</h2><p>HTTP/1.1开始，即使请求header中没有携带Connection: Keep-Alive，传输也会默认以持久连接的方式进行。<br>目前所有的浏览器都默认请求持久连接，几乎所有的HTTP服务端也都默认开启对持久连接的支持，短连接正式成为过去式。（HTTP/1.1的发布时间是1997年，最后一次对协议的补充是在1999年，我们可以夸张地说：HTTP短连接这个概念已经过时了近20年了。）<br>同时，持久连接的弊端被提出 —— <code>HOLB（Head of Line Blocking）</code>即持久连接下一个连接中的请求仍然是串行的，如果某个请求出现网络阻塞等问题，会导致同一条连接上的后续请求被阻塞。<br>所以HTTP/1.1中提出了<code>pipelining</code>概念，即客户端可以在一个请求发送完成后不等待响应便直接发起第二个请求，服务端在返回响应时会按请求到达的顺序依次返回，这样就极大地降低了延迟。<br><img src="HTTP1.1时代提出pipelining概念.png" alt="HTTP1.1时代提出pipelining概念"><br>然而pipelining并没有彻底解决HOLB，为了让同一个连接中的多个响应能够和多个请求匹配上，响应仍然是按请求的顺序串行返回的。所以pipelining并没有被广泛接受，几乎所有代理服务都不支持pipelining，部分浏览器不支持pipelining，支持的大部分也会将其默认关闭。</p>
<h2 id="SPDY和HTTP-2：multiplexing"><a href="#SPDY和HTTP-2：multiplexing" class="headerlink" title="SPDY和HTTP/2：multiplexing"></a>SPDY和HTTP/2：multiplexing</h2><p><code>multiplexing</code>即多路复用，在<code>SPDY</code>中提出，同时也在<code>HTTP/2</code>中实现。multiplexing技术能够让多个请求和响应的传输完全混杂在一起进行，通过<code>streamId</code>来互相区别。这彻底解决了<code>HOLB</code>问题，同时还允许给每个请求设置<code>优先级</code>，服务端会先响应优先级高的请求。<br><img src="SPDY和HTTP2-multiplexing.png" alt="SPDY和HTTP2-multiplexing"><br>现在Chrome、FireFox、Opera、IE、Safari的最新版本都支持SPDY，Nginx/Apache HTTPD/Jetty/Tomcat等服务端也都提供了对SPDY的支持。<br>另外，谷歌已经关闭SPDY项目，正式为HTTP/2让路。可以认为SPDY是HTTP/2的前身和探路者。</p>
<blockquote>
<p>SPDY（读作“SPeeDY”）是Google开发的<code>基于TCP的传输层协议</code>，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验。SPDY并不是一种用于替代HTTP的协议，而是<code>对HTTP协议的增强</code>。新协议的功能包括数据流的<code>多路复用</code>、<code>请求优先级</code>以及<code>HTTP报头压缩</code>。谷歌表示，引入SPDY协议后，在实验室测试中页面加载速度比原先快64%。</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.jellythink.com/archives/705">简析TCP的三次握手与四次分手</a></li>
<li><a href="http://blog.jobbole.com/64638/">游戏服务器：到底使用UDP还是TCP</a><br><a href="http://www.zcfy.cc/article/how-does-https-work-1280.html">HTTPS 是如何工作的？</a></li>
</ul>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>SparkOnK8S踩坑记录</title>
    <url>/2021/11/21/SparkOnK8S%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>dolphinscheduler的调度任务有spark，默认仅支持spark on yarn,<br>本文记录了折腾spark on k8s的踩坑过程，主要难点是镜像的制作，kerberos认证和hive的兼容</p>
<a id="more"></a>
<p><img src="sparkonk8s.png" alt="spark-on-k8s"></p>
<h1 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h1><h2 id="部署要求"><a href="#部署要求" class="headerlink" title="部署要求"></a>部署要求</h2><ul>
<li>实验版Spark 2.3+，正式版Spark 3.0+</li>
<li>Kubernetes 1.6+</li>
<li>具有Kubernetes pods的list, create, edit和delete权限</li>
<li>Kubernetes集群必须正确配置Kubernetes DNS</li>
</ul>
<h2 id="验证环境"><a href="#验证环境" class="headerlink" title="验证环境"></a>验证环境</h2><p>cdh版本:hadoop2.6.0-cdh5.16.1 </p>
<ul>
<li>hive：1.1.0</li>
<li>hadoop：２.6.0</li>
<li>spark：2.4.8/3.1.2</li>
</ul>
<h1 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h1><p>当我们通过<code>spark-submit</code>将Spark作业提交到Kubernetes集群时，会执行以下流程：<br><img src="https://spark.apache.org/docs/3.1.2/img/k8s-cluster-mode.png" alt="k8s-cluster-mode"></p>
<ul>
<li>Spark在<code>Kubernetes pod</code>中创建Spark <code>driver</code>;</li>
<li>Driver调用Kubernetes API创建<code>executor</code> pods，executor pods执行作业代码;</li>
<li>计算作业结束，<code>executor</code> pods回收并清理;</li>
<li><code>driver</code> pod处于completed状态，保留日志，直到Kubernetes GC或者手动清理;</li>
</ul>
<h1 id="制作docker镜像"><a href="#制作docker镜像" class="headerlink" title="制作docker镜像"></a>制作docker镜像</h1><p>由于cdh的包封装了很多再用的组件，所以先制作一个<code>cdh-base</code>的镜像。<br>后续还有<code>dolphinscheduler-worker</code>,<code>flink</code>,<code>spark</code>的镜像都基于<code>cdh-base</code>制作。</p>
<h2 id="cdh-base的镜像"><a href="#cdh-base的镜像" class="headerlink" title="cdh-base的镜像"></a>cdh-base的镜像</h2><p>坑：cdh的parcel包官方已不提供下载了,可以从网上找到一些别人下载分享的。<br>下载好后，上传到内部网盘,然后制作docker镜像并push到内部harbor仓库.<br><a href="cdh-base-dockerfile">Dockerfile</a><br><a href="cdh-base-clear.sh">clear.sh</a></p>
<h2 id="spark镜像"><a href="#spark镜像" class="headerlink" title="spark镜像"></a>spark镜像</h2><p>下载spark3.1.2的官方压缩包，里面自带dockerfile，主要修改基于cdh包制作</p>
<ul>
<li><a href="spark-dockerfile">Dockerfile</a></li>
<li><a href="spark-entrypoint.sh">entrypoint.sh</a></li>
</ul>
<p>entrypoint修改内容：</p>
<ul>
<li>根据环境变量<code>SPARK_VERSION</code>设置的spark版本设置<code>SPARK_HOME</code></li>
<li>加载Hosts</li>
<li>新增jars_ext到<code>SPARK_DIST_CLASSPATH</code></li>
<li>外部可通过<code>PYSPARK_PYTHON</code>设置pyspark的虚拟环境</li>
</ul>
<h1 id="配置K8S环境"><a href="#配置K8S环境" class="headerlink" title="配置K8S环境"></a>配置K8S环境</h1><p>需要运维新增namespace和service account和pvc</p>
<h2 id="Spark的PVC配置"><a href="#Spark的PVC配置" class="headerlink" title="Spark的PVC配置"></a>Spark的PVC配置</h2><h3 id="spark-pvc"><a href="#spark-pvc" class="headerlink" title="spark pvc"></a>spark pvc</h3><ul>
<li>spark-eventlog：spark执行事件日志</li>
<li>spark-config：spark和hdfs/minio/hive等服务的配置文件，host文件路径</li>
<li>spark-application：spark执行所需的资源,如jar,py,keytab等</li>
</ul>
<h3 id="mount-glusterfs-pvc"><a href="#mount-glusterfs-pvc" class="headerlink" title="mount glusterfs pvc"></a>mount glusterfs pvc</h3><p>spark-config<br><code>mount -t glusterfs -o backup-volfile-servers=glusterfs_ip  k8s_ip:spark-config /var/lib/dolphinscheduler/worker-data/spark-config</code></p>
<p>spark-application<br><code>mount -t glusterfs -o backup-volfile-servers=glusterfs_ip  k8s_ip:spark-application /var/lib/dolphinscheduler/worker-data/exec/process</code></p>
<p>spark-submit提交客户端需要mount spark的pvc的资源，保持简单（客户端的路径和pod内的路径一致）</p>
<h1 id="采集executor日志"><a href="#采集executor日志" class="headerlink" title="采集executor日志"></a>采集executor日志</h1><p><code>Spark On Yarn</code>，可以开启<code>yarn.log-aggregation-enable</code>将日志收集聚合到HDFS中，以供查看。<br><code>Spark On Kubernetes</code>，则缺少这种日志收集机制，我们只能通过Kubernetes pod的日志输出，来查看Spark的日志：</p>
<p>这个在k8s运维层解决即可，k8s通过fluent-bit会将pod日志都采集到es.</p>
<h1 id="访问driver-ui"><a href="#访问driver-ui" class="headerlink" title="访问driver ui"></a>访问driver ui</h1><ul>
<li>官方提供的port-forward方案，<code>kubectl -n spark port-forward podName 4000:4040</code>，这种比较原始，每个spark-submit都需要启动一个代理服务，适合测试，不适合生产环境</li>
<li><p>生产环境应类似部署独立的service和ingress提供外部访问,注意需要配置<code>spark.ui.proxyRedirectUri</code>参数为ingress的path</p>
</li>
<li><p><a href="spark-ui-ingress">spark-ui-ingress.yaml</a></p>
</li>
<li><a href="spark-ui-svc">spark-ui-svc.yaml</a></li>
</ul>
<h1 id="部署history-server"><a href="#部署history-server" class="headerlink" title="部署history-server"></a>部署history-server</h1><ol>
<li>spark程序开启eventlog，写入挂载的eventlog的pvc目录</li>
<li>部署<code>spark historyserver</code>查看，挂载eventlog的pvc目录</li>
</ol>
<h1 id="spark数据存储"><a href="#spark数据存储" class="headerlink" title="spark数据存储"></a>spark数据存储</h1><ul>
<li>s3a(minio):spark状态数据</li>
<li>hdfs：业务数据</li>
</ul>
<h2 id="S3A"><a href="#S3A" class="headerlink" title="S3A"></a>S3A</h2><p>在<code>$SPARK_HOME</code>内新增目录jars_ext，将扩展jar放入<code>spark-3.1.2-bin-hadoop2.7.tgz</code>对应的aws版本(这个版本不能向下兼容,版本不能搞错)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#&#x2F;usr&#x2F;lib&#x2F;cdh&#x2F;lib&#x2F;spark3&#x2F;jars_ext</span><br><span class="line">├── [ 11M]  aws-java-sdk-1.7.4.jar</span><br><span class="line">└── [123K]  hadoop-aws-2.7.7.jar</span><br></pre></td></tr></table></figure>
<p>然后在entrypoint.sh中加入<br><code>export SPARK_DIST_CLASSPATH=&quot;$SPARK_DIST_CLASSPATH:${SPARK_HOME}/jars_ext/*&quot;</code></p>
<p>spark-submit参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--conf spark.hadoop.fs.s3a.impl&#x3D;org.apache.hadoop.fs.s3a.S3AFileSystem \</span><br><span class="line">--conf spark.hadoop.fs.s3a.endpoint&#x3D;http:&#x2F;&#x2F;ip:port \</span><br><span class="line">--conf spark.hadoop.fs.s3a.access.key&#x3D;xxx \</span><br><span class="line">--conf spark.hadoop.fs.s3a.secret.key&#x3D;xxx</span><br></pre></td></tr></table></figure>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>hive和hdfs集成涉及</p>
<ul>
<li>python-venv:用于设置PYSPARK_PYTHON</li>
<li>配置文件：hdfs-site.xml,core-site.xml（可包含s3a配置）,hive-site.xml,yarn-site.xml(mapreduce计算依赖此配置)</li>
<li>认证文件：keytab,krb5.conf</li>
<li>数据文件：application提交的jar和py,zip依赖</li>
</ul>
<p>Spark 运行需要配置 Hadoop 的配置文件位置，如果 ClassPath 没有，则无法访问 HDFS<br><code>export HADOOP_CONF_DIR=/opt/spark/conf</code></p>
<p>hdfs测试脚本: <code>hdfs dfs -copyFromLocal people.json hdfs://ha/user/hive/examples/src/main/resources/people.json</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;run-example  \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;path \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path&#x3D;file:&#x2F;&#x2F;usr&#x2F;lib&#x2F;cdh&#x2F;lib&#x2F;hive&#x2F;lib&#x2F;*.jar \</span><br><span class="line">--verbose \</span><br><span class="line">sql.JavaSparkSQLExample</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;SPARK3_HOME&#125;&#x2F;bin&#x2F;run-example --verbose  \</span><br><span class="line">--master local \</span><br><span class="line">--conf spark.driver.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  \</span><br><span class="line">--conf spark.executor.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path&#x3D;file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hive&#x2F;lib&#x2F;*.jar,file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hadoop&#x2F;client&#x2F;*.jar  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;path  \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1  \</span><br><span class="line">--conf spark.kerberos.principal&#x3D;x  \</span><br><span class="line">--conf spark.kerberos.keytab&#x3D;&#x2F;dboard&#x2F;application&#x2F;2&#x2F;1963&#x2F;22621&#x2F;39887&#x2F;x.keytab  \</span><br><span class="line">--conf spark.files.fetchTimeout&#x3D;5m  \</span><br><span class="line">--conf spark.files.overwrite&#x3D;true  \</span><br><span class="line">--conf spark.driver.memory&#x3D;1048M  \</span><br><span class="line">--conf spark.executor.memory&#x3D;1024M  \</span><br><span class="line">--conf spark.executor.instances&#x3D;2  \</span><br><span class="line"> sql.JavaSparkSQLExample</span><br></pre></td></tr></table></figure>
<p>local测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;SPARK3_HOME&#125;&#x2F;bin&#x2F;spark-submit --verbose  \</span><br><span class="line">--master local \</span><br><span class="line">--conf spark.driver.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  \</span><br><span class="line">--conf spark.executor.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path&#x3D;file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hive&#x2F;lib&#x2F;*.jar,file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hadoop&#x2F;client&#x2F;*.jar  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;path  \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1  \</span><br><span class="line">--conf spark.kerberos.principal&#x3D;x  \</span><br><span class="line">--conf spark.kerberos.keytab&#x3D;&#x2F;dboard&#x2F;application&#x2F;2&#x2F;1963&#x2F;22621&#x2F;39887&#x2F;x.keytab  \</span><br><span class="line">--conf spark.files.fetchTimeout&#x3D;5m  \</span><br><span class="line">--conf spark.files.overwrite&#x3D;true  \</span><br><span class="line">--conf spark.driver.memory&#x3D;1048M  \</span><br><span class="line">--conf spark.executor.memory&#x3D;1024M  \</span><br><span class="line">--conf spark.executor.instances&#x3D;2  \</span><br><span class="line"> demo.py</span><br></pre></td></tr></table></figure></p>
<p>k8s测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export KUBECONFIG&#x3D;&#x2F;opt&#x2F;dolphinscheduler&#x2F;conf&#x2F;config&#x2F;kube_config.yaml</span><br><span class="line">$&#123;SPARK3_HOME&#125;&#x2F;bin&#x2F;spark-submit  --verbose  \</span><br><span class="line">--conf spark.driver.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  \</span><br><span class="line">--conf spark.executor.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot;  --master k8s:&#x2F;&#x2F;https:&#x2F;&#x2F;ip:6443 --deploy-mode cluster  \</span><br><span class="line">--conf spark.kubernetes.namespace&#x3D;dboard  \</span><br><span class="line">--conf spark.kubernetes.container.image&#x3D;harbor.dc.xxx-it.com&#x2F;x-bigdata&#x2F;spark:latest  \</span><br><span class="line">--conf spark.kubernetes.authenticate.driver.serviceAccountName&#x3D;dboard  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.SPARK_VERSION&#x3D;3  \</span><br><span class="line">--conf spark.executorEnv.SPARK_VERSION&#x3D;3  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path&#x3D;file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hive&#x2F;lib&#x2F;*.jar,file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hadoop&#x2F;client&#x2F;*.jar  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;path  \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-log.options.claimName&#x3D;dboard-log  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-log.mount.path&#x3D;&#x2F;dboard&#x2F;log&#x2F;spark-eventlog  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-log.mount.readOnly&#x3D;false  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-log.mount.subPath&#x3D;spark-eventlog  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-log.options.claimName&#x3D;dboard-log  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-log.mount.path&#x3D;&#x2F;dboard&#x2F;log&#x2F;spark-eventlog  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-log.mount.readOnly&#x3D;false  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-log.mount.subPath&#x3D;spark-eventlog  \</span><br><span class="line">--conf spark.eventLog.dir&#x3D;&#x2F;dboard&#x2F;log&#x2F;spark-eventlog  \</span><br><span class="line">--conf spark.eventLog.enabled&#x3D;true  \</span><br><span class="line">--conf spark.eventLog.compress&#x3D;true  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-config.options.claimName&#x3D;dboard-config  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-config.mount.path&#x3D;&#x2F;dboard&#x2F;config  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-config.mount.readOnly&#x3D;true  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-config.options.claimName&#x3D;dboard-config  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-config.mount.path&#x3D;&#x2F;dboard&#x2F;config  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-config.mount.readOnly&#x3D;true  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.HADOOP_CONF_DIR&#x3D;&#x2F;dboard&#x2F;config&#x2F;hadoop  \</span><br><span class="line">--conf spark.executorEnv.HADOOP_CONF_DIR&#x3D;&#x2F;dboard&#x2F;config&#x2F;hadoop  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.PYSPARK_PYTHON&#x3D;&#x2F;dboard&#x2F;config&#x2F;python-venv&#x2F;bin&#x2F;python  \</span><br><span class="line">--conf spark.executorEnv.PYSPARK_PYTHON&#x3D;&#x2F;dboard&#x2F;config&#x2F;python-venv&#x2F;bin&#x2F;python  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.HOSTS&#x3D;&#x2F;dboard&#x2F;config&#x2F;hosts  \</span><br><span class="line">--conf spark.executorEnv.HOSTS&#x3D;&#x2F;dboard&#x2F;config&#x2F;hosts  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-application.options.claimName&#x3D;dboard-application  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-application.mount.path&#x3D;&#x2F;dboard&#x2F;application  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.dboard-application.mount.readOnly&#x3D;false  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-application.options.claimName&#x3D;dboard-application  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-application.mount.path&#x3D;&#x2F;dboard&#x2F;application  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.dboard-application.mount.readOnly&#x3D;false  \</span><br><span class="line">--conf spark.kubernetes.kerberos.krb5.path&#x3D;&#x2F;etc&#x2F;krb5.conf  \</span><br><span class="line">--conf spark.kerberos.principal&#x3D;x  \</span><br><span class="line">--conf spark.kerberos.keytab&#x3D;&#x2F;dboard&#x2F;application&#x2F;2&#x2F;1963&#x2F;22621&#x2F;39887&#x2F;x.keytab  \</span><br><span class="line">--conf spark.kubernetes.file.upload.path&#x3D;s3a:&#x2F;dboard&#x2F;__SPARK_APP__  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.endpoint&#x3D;http:&#x2F;&#x2F;ip:32030  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.access.key&#x3D;DYaDwXsj8VRtWYPSbr7A  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.secret.key&#x3D;z7HAEhdyseNX9AVyzDLAJzEjZChJsnAf1f7VehE  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.impl&#x3D;org.apache.hadoop.fs.s3a.S3AFileSystem  \</span><br><span class="line">--conf spark.files.fetchTimeout&#x3D;5m  \</span><br><span class="line">--conf spark.files.overwrite&#x3D;true  \</span><br><span class="line">--conf spark.driver.memory&#x3D;2048M  \</span><br><span class="line">--conf spark.executor.memory&#x3D;1024M  \</span><br><span class="line">--conf spark.executor.instances&#x3D;2  \</span><br><span class="line">--conf spark.kubernetes.executor.request.cores&#x3D;2  \</span><br><span class="line">--conf spark.kubernetes.driver.request.cores&#x3D;1  \</span><br><span class="line">--conf spark.kubernetes.driver.pod.name&#x3D;spark-demo1    local:&#x2F;&#x2F;&#x2F;dboard&#x2F;application&#x2F;2&#x2F;1963&#x2F;22621&#x2F;39887&#x2F;demo.py</span><br></pre></td></tr></table></figure></p>
<h1 id="kerberos认证"><a href="#kerberos认证" class="headerlink" title="kerberos认证"></a>kerberos认证</h1><h2 id="手动kinit"><a href="#手动kinit" class="headerlink" title="手动kinit"></a>手动kinit</h2><p>在spark２.4.8尝试<br>自行编译spark代码集成hadoop２.6,hive-1.1.0</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./dev/make-distribution.sh \</span><br><span class="line">--name 2.6.0-cdh5.16.1 \</span><br><span class="line">--tgz \</span><br><span class="line">-Phadoop-2.6 \</span><br><span class="line">-Dhadoop.version=2.6.0-cdh5.16.1 \</span><br><span class="line">-Phive \</span><br><span class="line">-Phive-thriftserver \</span><br><span class="line">-Pyarn \</span><br><span class="line">-Pkubernetes \</span><br><span class="line">-Pexternal-jars \</span><br><span class="line">-DskipTests</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># entrypoint.sh do kerberos auth by environment variable</span></span><br><span class="line">rm -f /etc/krb5.conf</span><br><span class="line">ln -s <span class="variable">$&#123;KRB5_CONFIG&#125;</span> /etc/krb5.conf</span><br><span class="line">kinit -kt <span class="variable">$&#123;KEYTAB&#125;</span> <span class="variable">$PRINCIPAL</span></span><br><span class="line"><span class="comment"># scheduly update krb5 tgt</span></span><br><span class="line">crontab -l | &#123; cat; <span class="built_in">echo</span> <span class="string">"0 */10 * * *  kinit -kt <span class="variable">$&#123;KEYTAB&#125;</span> <span class="variable">$PRINCIPAL</span>"</span>; &#125; | crontab -</span><br><span class="line"></span><br><span class="line">spark-submit xxx</span><br></pre></td></tr></table></figure>
<blockquote>
<p>kerberos认证问题<br>通过spark.executorEnv传入环境变量(krb5.conf、keytab、principal)到Node，完成kerberos认证。<br>Pod内测试pyspark是能够正常执行hdfs和hive的操作；<br>pyspark用master(‘local’)模式代码也工作正常；<br>但是spark-submit的python代码在k8s集群的executor上spark.read操作hdfs文件报kerberos认证异常。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Job aborted due to stage failure: Task <span class="number">1</span> in stage <span class="number">1.0</span> failed <span class="number">4</span> times, most recent failure: Lost task <span class="number">1.3</span> in stage <span class="number">1.0</span> (TID <span class="number">5</span>, ip, executor <span class="number">2</span>): </span><br><span class="line">java.io.IOException: </span><br><span class="line">Failed on local exception: </span><br><span class="line">java.io.IOException: </span><br><span class="line">org.apache.hadoop.security.AccessControlException: </span><br><span class="line">Client cannot authenticate via:[TOKEN, KERBEROS]; Host Details : </span><br><span class="line">local host is: <span class="string">"pysparkapp-1631176344099-exec-2/ip"</span>; </span><br><span class="line">destination host is: <span class="string">"ip"</span>:<span class="number">8020</span>; </span><br><span class="line">trueat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:<span class="number">772</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client.call(Client.java:<span class="number">1508</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client.call(Client.java:<span class="number">1441</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:<span class="number">231</span>)</span><br><span class="line">trueat com.sun.proxy.$Proxy20.create(Unknown Source)</span><br><span class="line">trueat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:<span class="number">313</span>)</span><br><span class="line">trueat sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)</span><br><span class="line">trueat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">trueat java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">trueat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:<span class="number">258</span>)</span><br><span class="line">trueat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:<span class="number">104</span>)</span><br><span class="line">trueat com.sun.proxy.$Proxy21.create(Unknown Source)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:<span class="number">2146</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:<span class="number">1804</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:<span class="number">1728</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">7</span>.doCall(DistributedFileSystem.java:<span class="number">438</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">7</span>.doCall(DistributedFileSystem.java:<span class="number">434</span>)</span><br><span class="line">trueat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:<span class="number">81</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:<span class="number">434</span>)</span><br><span class="line">trueat org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:<span class="number">375</span>)</span><br><span class="line">trueat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<span class="number">926</span>)</span><br><span class="line">trueat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<span class="number">907</span>)</span><br><span class="line">trueat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:<span class="number">74</span>)</span><br><span class="line">trueat org.apache.parquet.hadoop.ParquetFileWriter.&lt;init&gt;(ParquetFileWriter.java:<span class="number">248</span>)</span><br><span class="line">trueat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:<span class="number">390</span>)</span><br><span class="line">trueat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:<span class="number">349</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.&lt;init&gt;(ParquetOutputWriter.scala:<span class="number">37</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$<span class="number">1</span>.newInstance(ParquetFileFormat.scala:<span class="number">151</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:<span class="number">120</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.&lt;init&gt;(FileFormatDataWriter.scala:<span class="number">108</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:<span class="number">240</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$<span class="number">1</span>.apply(FileFormatWriter.scala:<span class="number">174</span>)</span><br><span class="line">trueat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$<span class="number">1</span>.apply(FileFormatWriter.scala:<span class="number">173</span>)</span><br><span class="line">trueat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:<span class="number">90</span>)</span><br><span class="line">trueat org.apache.spark.scheduler.Task.run(Task.scala:<span class="number">123</span>)</span><br><span class="line">trueat org.apache.spark.executor.Executor$TaskRunner$$anonfun$<span class="number">10</span>.apply(Executor.scala:<span class="number">411</span>)</span><br><span class="line">trueat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:<span class="number">1360</span>)</span><br><span class="line">trueat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:<span class="number">417</span>)</span><br><span class="line">trueat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>)</span><br><span class="line">trueat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>)</span><br><span class="line">trueat java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line">Caused by: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:[TOKEN, KERBEROS]</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection$<span class="number">1</span>.run(Client.java:<span class="number">718</span>)</span><br><span class="line">trueat java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">trueat javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>)</span><br><span class="line">trueat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1924</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:<span class="number">681</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:<span class="number">769</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.access$<span class="number">3000</span>(Client.java:<span class="number">396</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client.getConnection(Client.java:<span class="number">1557</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client.call(Client.java:<span class="number">1480</span>)</span><br><span class="line">true... <span class="number">39</span> more</span><br><span class="line">Caused by: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:[TOKEN, KERBEROS]</span><br><span class="line">trueat org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:<span class="number">172</span>)</span><br><span class="line">trueat org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:<span class="number">396</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:<span class="number">594</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.access$<span class="number">2000</span>(Client.java:<span class="number">396</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection$<span class="number">2</span>.run(Client.java:<span class="number">761</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection$<span class="number">2</span>.run(Client.java:<span class="number">757</span>)</span><br><span class="line">trueat java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">trueat javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>)</span><br><span class="line">trueat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1924</span>)</span><br><span class="line">trueat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:<span class="number">756</span>)</span><br><span class="line">true... <span class="number">42</span> more</span><br><span class="line"></span><br><span class="line">Driver stacktrace:</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="DelegationTokenFetcher"><a href="#DelegationTokenFetcher" class="headerlink" title="DelegationTokenFetcher"></a>DelegationTokenFetcher</h2><blockquote>
<p>按这个方案尝试<br><a href="https://stackoverflow.com/questions/54181560/when-running-spark-on-kubernetes-to-access-kerberized-hadoop-cluster-how-do-you">when-running-spark-on-kubernetes-to-access-kerberized-hadoop-cluster-how-do-you</a></p>
</blockquote>
<p>First get the delegation token from hadoop using the below command .</p>
<ol>
<li>Do a kinit -kt with your keytab and principal</li>
<li>Execute the below to store the hdfs delegation token in a tmp path <code>spark-submit --class org.apache.hadoop.hdfs.tools.DelegationTokenFetcher &quot;&quot; --renewer null /tmp/spark.token</code></li>
<li>Do your actual spark submit with the adding this configuration . <code>--conf spark.executorEnv.HADOOP_TOKEN_FILE_LOCATION=/tmp/spark.token</code>\<br>The above is how yarn executors authenticate. Do the same for kubernetes executors too.<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.hadoop.hdfs.tools.DelegationTokenFetcher "" --renewer null /tmp/spark.token</span><br><span class="line">--conf spark.executorEnv.HADOOP_TOKEN_FILE_LOCATION=/tmp/spark.token \</span><br></pre></td></tr></table></figure>
container起来了然后一直在renew也不退出，也不继续执行代码…</li>
</ol>
<p><code>spark on k8s折腾2天，hdfs都好的，但是卡在没解决hive数据源的kerberos认证问题</code></p>
<p>放弃2.4了，升级３.1.2，基于cdh的包，lib下放入spark2和spark3的版本，做成镜像</p>
<h2 id="升级spark３"><a href="#升级spark３" class="headerlink" title="升级spark３"></a>升级spark３</h2><p>kerberos新增３个参数，支持kerberos认证，krb5Conf会写入executor的configMap<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--conf spark.kubernetes.kerberos.krb5.path&#x3D;&#x2F;spark&#x2F;application&#x2F;2&#x2F;1963&#x2F;20954&#x2F;37472&#x2F;hive_krb5.conf  \</span><br><span class="line">--conf spark.kerberos.principal&#x3D;hive  \</span><br><span class="line">--conf spark.kerberos.keytab&#x3D;&#x2F;spark&#x2F;application&#x2F;2&#x2F;1963&#x2F;20954&#x2F;37472&#x2F;hive.keytab  \</span><br></pre></td></tr></table></figure></p>
<h1 id="spark-hive版本兼容"><a href="#spark-hive版本兼容" class="headerlink" title="spark-hive版本兼容"></a>spark-hive版本兼容</h1><p>之前花了很大力气自己编译spark源码，兼容自己的hadoop和hive版本。</p>
<p>最后发现不需要这么整，Spark，对hive数据源做了很好的抽象，外部制定hive版本和jar包路径，spark内部HiveClient会记载对应的HiveConf和执行支持的Operation。</p>
<p>做了以下尝试：</p>
<ol>
<li>spark3.1.2版本修改源码，hive版本差异太大，尝试了下，错误太多，impossible mission；</li>
<li><code>dev/make-distribution.sh</code>直接修改编译的hadoop版本，编译不通过</li>
<li>在spark运行的时候，动态加载hive对应的版本包</li>
</ol>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">- </span>In Spark 3.0, we upgraded the built-in Hive from 1.2 to 2.3 and it brings following impacts:</span><br><span class="line"></span><br><span class="line"><span class="bullet">  * </span>You may need to set <span class="code">`spark.sql.hive.metastore.version`</span> and <span class="code">`spark.sql.hive.metastore.jars`</span> according to the version of the Hive metastore you want to connect to. </span><br><span class="line"><span class="bullet">  * </span>For example: set <span class="code">`spark.sql.hive.metastore.version`</span> to <span class="code">`1.2.1`</span> and <span class="code">`spark.sql.hive.metastore.jars`</span> to <span class="code">`maven`</span> if your Hive metastore version is 1.2.1.</span><br><span class="line"><span class="bullet">  * </span>You need to migrate your custom SerDes to Hive 2.3 or build your own Spark with <span class="code">`hive-1.2`</span> profile. See [<span class="string">HIVE-15167</span>](<span class="link">https://issues.apache.org/jira/browse/HIVE-15167</span>) for more details.</span><br><span class="line"></span><br><span class="line"><span class="bullet">  * </span>The decimal string representation can be different between Hive 1.2 and Hive 2.3 when using <span class="code">`TRANSFORM`</span> operator in SQL for script transformation, which depends on hive's behavior. In Hive 1.2, the string representation omits trailing zeroes. But in Hive 2.3, it is always padded to 18 digits with trailing zeroes if necessary.</span><br></pre></td></tr></table></figure>
<p>官方上面这段话，说可以自己编译hive-1.2，实际编译不了.<br>spark-3.0.2官方有提供编译的下载包，后续版本没有看到<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;dev&#x2F;make-distribution.sh --name 2.6.0-cdh5.16.1  --tgz  -Phive-1.2 -Phive-thriftserver -Pyarn  -Pkubernetes -Dhadoop.version&#x3D;2.6.0-cdh5.16.1</span><br></pre></td></tr></table></figure><br>这个<code>maven</code>模式，可以设置<code>spark.sql.maven.additionalRemoteRepositories</code>配置自定义maven仓库</p>
<p>根据官网的说明 ,spark从1.4.0 开始就能和不同的hive元数据进行交互，也就是说spark编译的hive内部版本和spark访问hive的元数据是独立的，可以配置不同的hive版本进行对应元数据的访问。</p>
<blockquote>
<p>interacting-with-different-versions-of-hive-metastore</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.sql.catalogImplementation hive</span><br><span class="line">spark.sql.hive.metastore.version 1.1.0</span><br><span class="line">spark.sql.hive.metastore.jars <span class="variable">$&#123;env:HADOOP_COMMON_HOME&#125;</span>/../hive/lib/*:<span class="variable">$&#123;env:HADOOP_COMMON_HOME&#125;</span>/client/*</span><br></pre></td></tr></table></figure>
<p>具体代码在org.apache.spark.sql.hive.HiveUtils和org.apache.spark.sql.hive.client.IsolatedClientLoader中,<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def hiveVersion(version: String): HiveVersion &#x3D; version match &#123;</span><br><span class="line">  case &quot;12&quot; | &quot;0.12&quot; | &quot;0.12.0&quot; &#x3D;&gt; hive.v12</span><br><span class="line">  case &quot;13&quot; | &quot;0.13&quot; | &quot;0.13.0&quot; | &quot;0.13.1&quot; &#x3D;&gt; hive.v13</span><br><span class="line">  case &quot;14&quot; | &quot;0.14&quot; | &quot;0.14.0&quot; &#x3D;&gt; hive.v14</span><br><span class="line">  case &quot;1.0&quot; | &quot;1.0.0&quot; | &quot;1.0.1&quot; &#x3D;&gt; hive.v1_0</span><br><span class="line">  case &quot;1.1&quot; | &quot;1.1.0&quot; | &quot;1.1.1&quot; &#x3D;&gt; hive.v1_1</span><br><span class="line">  case &quot;1.2&quot; | &quot;1.2.0&quot; | &quot;1.2.1&quot; | &quot;1.2.2&quot; &#x3D;&gt; hive.v1_2</span><br><span class="line">  case &quot;2.0&quot; | &quot;2.0.0&quot; | &quot;2.0.1&quot; &#x3D;&gt; hive.v2_0</span><br><span class="line">  case &quot;2.1&quot; | &quot;2.1.0&quot; | &quot;2.1.1&quot; &#x3D;&gt; hive.v2_1</span><br><span class="line">  case &quot;2.2&quot; | &quot;2.2.0&quot; &#x3D;&gt; hive.v2_2</span><br><span class="line">  case &quot;2.3&quot; | &quot;2.3.0&quot; | &quot;2.3.1&quot; | &quot;2.3.2&quot; | &quot;2.3.3&quot; | &quot;2.3.4&quot; | &quot;2.3.5&quot; | &quot;2.3.6&quot; | &quot;2.3.7&quot; &#x3D;&gt;</span><br><span class="line">    hive.v2_3</span><br><span class="line">  case &quot;3.0&quot; | &quot;3.0.0&quot; &#x3D;&gt; hive.v3_0</span><br><span class="line">  case &quot;3.1&quot; | &quot;3.1.0&quot; | &quot;3.1.1&quot; | &quot;3.1.2&quot; &#x3D;&gt; hive.v3_1</span><br><span class="line">  case version &#x3D;&gt;</span><br><span class="line">    throw new UnsupportedOperationException(s&quot;Unsupported Hive Metastore version ($version). &quot; +</span><br><span class="line">      s&quot;Please set $&#123;HiveUtils.HIVE_METASTORE_VERSION.key&#125; with a valid version.&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="测试路径"><a href="#测试路径" class="headerlink" title="测试路径"></a>测试路径</h2><ol>
<li>是基于withouthadoop还是with hadoop的版本？<ul>
<li><code>with hadoop</code>版本，必须是官方的，不能替换为其他hadoop版本。</li>
</ul>
</li>
<li>spark3.1.2的jars目录下的hive　jar是否需要删除？<ul>
<li>不需要，spark中HiveClient会自动加载对应版本的</li>
</ul>
</li>
<li>修改hive版本后，测试是否能加载jar…</li>
</ol>
<h2 id="测试HiveClasspath"><a href="#测试HiveClasspath" class="headerlink" title="测试HiveClasspath"></a>测试HiveClasspath</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/lib/cdh/lib/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(<span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin/hadoop classpath):<span class="variable">$SPARK_HOME</span>/jars </span><br><span class="line"></span><br><span class="line">./bin/spark-shell \</span><br><span class="line">--conf spark.sql.catalogImplementation=hive  \</span><br><span class="line">--conf spark.sql.warehouse.dir=/user/hive/warehouse  \</span><br><span class="line">--verbose \</span><br><span class="line">--conf spark.sql.hive.metastore.version=1.1.0  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars=path \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path=<span class="string">"file:///usr/lib/cdh/lib/hive/lib/*"</span> \</span><br><span class="line">--conf spark.driver.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">--conf spark.executor.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">sql.hive.JavaSparkHiveExample</span><br></pre></td></tr></table></figure>
<p>心里总是不停的问,\为什么就是不加载｀spark.sql.hive.metastore.jars.path｀目录下的jar…</p>
<p>通过以下spark-shell<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-shell \</span><br><span class="line">--verbose \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;classpath \</span><br><span class="line">--conf spark.driver.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot; \</span><br><span class="line">--conf spark.executor.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot; \</span><br><span class="line">sql.JavaSparkSQLExample</span><br></pre></td></tr></table></figure><br>定位问题用下面的代码救命.执行代码查看classpath<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.ClassLoader</span><br><span class="line">ClassLoader.getSystemClassLoader.asInstanceOf[java.net.URLClassLoader].getURLs.foreach(println)</span><br><span class="line"></span><br><span class="line">println(spark.version)</span><br><span class="line">println(org.apache.hadoop.util.VersionInfo.getVersion)</span><br><span class="line">println(org.apache.hadoop.hive.shims.ShimLoader.getMajorVersion)</span><br></pre></td></tr></table></figure></p>
<h2 id="spark2和spark3与hive集成区别"><a href="#spark2和spark3与hive集成区别" class="headerlink" title="spark2和spark3与hive集成区别"></a>spark2和spark3与hive集成区别</h2><ol>
<li>download <code>spark-3.1.2-bin-hadoop2.7.tgr.gz</code>,and prepare dir with <code>2.6.0-cdh5.16.1</code>, the hive version is <code>1.1.0</code></li>
<li>switch to a new user and set env to recover exist environment variable</li>
</ol>
<blockquote>
<p>主要是<code>spark.sql.hive.metastore.jars</code>不一样，看spark源码才能找到答案</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_CONF_DIR=/opt/cdh/lib/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> SPARK2_HOME=/opt/cdh/lib/spark2</span><br><span class="line"><span class="built_in">export</span> SPARK3_HOME=/opt/cdh/lib/spark3</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/tmp/dboard/dboard-config/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=</span><br><span class="line"><span class="comment"># run-example of spark 2:jars path is standard jvm class path , only support absolutely path or end with *</span></span><br><span class="line"><span class="variable">$SPARK2_HOME</span>/bin/run-example \</span><br><span class="line">--master <span class="built_in">local</span> \</span><br><span class="line">--verbose \</span><br><span class="line">--conf spark.sql.hive.metastore.version=1.1 \</span><br><span class="line">--conf spark.sql.hive.metastore.jars=<span class="string">"/opt/cdh/lib/hive/lib/*:/opt/cdh/lib/hadoop/client/*"</span> \</span><br><span class="line">--conf spark.driver.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">--conf spark.executor.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">--conf spark.kubernetes.driverEnv.SPARK_VERSION=2 \</span><br><span class="line">--conf spark.executorEnv.SPARK_VERSION=2 \</span><br><span class="line">sql.hive.JavaSparkHiveExample</span><br><span class="line"></span><br><span class="line"><span class="comment"># run-example of spark3: jars path is better than spark2,join by comma</span></span><br><span class="line"><span class="variable">$SPARK3_HOME</span>/bin/run-example \</span><br><span class="line">--master <span class="built_in">local</span> \</span><br><span class="line">--verbose \</span><br><span class="line">--conf spark.sql.hive.metastore.version=1.1 \</span><br><span class="line">--conf spark.sql.hive.metastore.jars=path \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path=<span class="string">"file:///opt/cdh/lib/hive/lib/*.jar,file:///opt/cdh/lib/hadoop/client/*.jar"</span> \</span><br><span class="line">--conf spark.driver.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">--conf spark.executor.extraJavaOptions=<span class="string">"-Dlog4j.debug"</span> \</span><br><span class="line">--conf spark.kubernetes.driverEnv.SPARK_VERSION=2 \</span><br><span class="line">--conf spark.executorEnv.SPARK_VERSION=2 \</span><br><span class="line">sql.hive.JavaSparkHiveExample</span><br></pre></td></tr></table></figure>
<p>基于<code>spark-3.1.2-bin-hadoop2.7</code>测试通过<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;run-example \</span><br><span class="line">--verbose \</span><br><span class="line">--conf spark.sql.hive.metastore.version&#x3D;1.1.1  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars&#x3D;path \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hive&#x2F;lib&#x2F;*.jar,file:&#x2F;&#x2F;&#x2F;opt&#x2F;cdh&#x2F;lib&#x2F;hadoop&#x2F;client&#x2F;*.jar&quot; \</span><br><span class="line">--conf spark.driver.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot; \</span><br><span class="line">--conf spark.executor.extraJavaOptions&#x3D;&quot;-Dlog4j.debug&quot; \</span><br><span class="line">sql.hive.JavaSparkHiveExample</span><br></pre></td></tr></table></figure><br>当这个日志出现的时候，我禁不住的留下了泪水-<em>-</em>-_-<br><code>21/09/12 14:53:39 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.1.0 using path:</code></p>
<h1 id="hosts配置"><a href="#hosts配置" class="headerlink" title="hosts配置"></a>hosts配置</h1><p>spark-sumit新增环境变量<code>HOSTS_FILE</code>,<br>HOSTS_FILE为<code>spark-config</code>中的pvc路径。<br>docker镜像的entrypoint中读取pvc中约定的host文件并追加到<code>/etc/hosts</code></p>
<h1 id="spark集成第三方数据源"><a href="#spark集成第三方数据源" class="headerlink" title="spark集成第三方数据源"></a>spark集成第三方数据源</h1><p>以下数据源可通过spark相关的jar包集成(放到<code>jars_ext</code>目录)，程序中配置连接参数就可以</p>
<ul>
<li>redis</li>
<li>elasticsearch</li>
<li>cassandra</li>
<li>jdbc:mysql/oracle</li>
</ul>
<h1 id="spark-submit示例"><a href="#spark-submit示例" class="headerlink" title="spark-submit示例"></a>spark-submit示例</h1><p>spark on k8s在dolphinscheduler的worker运行脚本<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">BASEDIR=$(<span class="built_in">cd</span> `dirname <span class="variable">$0</span>`; <span class="built_in">pwd</span>)</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$BASEDIR</span></span><br><span class="line"><span class="built_in">source</span> /opt/dolphinscheduler/conf/env/dolphinscheduler_env.sh</span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=/opt/dolphinscheduler/conf/config/kube_config.yaml</span><br><span class="line"><span class="variable">$&#123;SPARK3_HOME&#125;</span>/bin/spark-submit  \</span><br><span class="line">--master k8s://https://ip:6443  \</span><br><span class="line">--deploy-mode cluster  \</span><br><span class="line">--conf spark.kubernetes.namespace=spark  \</span><br><span class="line">--conf spark.kubernetes.container.image=bigdata/spark:0.1  \</span><br><span class="line">--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.SPARK_VERSION=3  \</span><br><span class="line">--conf spark.executorEnv.SPARK_VERSION=3  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars.path=file:///opt/cdh/lib/hive/lib/*.jar,file:///opt/cdh/lib/hadoop/client/*.jar  \</span><br><span class="line">--conf spark.sql.hive.metastore.jars=path  \</span><br><span class="line">--conf spark.sql.hive.metastore.version=1.1  \</span><br><span class="line"></span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-eventlog.options.claimName=spark-eventlog  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-eventlog.options.path=/spark/eventlog  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-eventlog.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-eventlog.mount.path=/spark/eventlog  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-eventlog.mount.readOnly=<span class="literal">false</span>  \</span><br><span class="line"></span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-eventlog.options.claimName=spark-eventlog  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-eventlog.options.path=/spark/eventlog  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-eventlog.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-eventlog.mount.path=/spark/eventlog  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-eventlog.mount.readOnly=<span class="literal">false</span>  \</span><br><span class="line">--conf spark.eventLog.dir=/spark/eventlog  \</span><br><span class="line">--conf spark.eventLog.enabled=<span class="literal">true</span>  \</span><br><span class="line">--conf spark.eventLog.compress=<span class="literal">true</span>  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-config.options.claimName=spark-config  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-config.options.path=/spark/config  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-config.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-config.mount.path=/spark/config  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-config.mount.readOnly=<span class="literal">true</span>  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-config.options.claimName=spark-config  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-config.options.path=/spark/config  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-config.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-config.mount.path=/spark/config  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-config.mount.readOnly=<span class="literal">true</span>  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.HADOOP_CONF_DIR=/spark/config/hadoop  \</span><br><span class="line">--conf spark.executorEnv.HADOOP_CONF_DIR=/spark/config/hadoop  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.PYSPARK_PYTHON=/spark/config/python-venv/bin/python  \</span><br><span class="line">--conf spark.executorEnv.PYSPARK_PYTHON=/spark/config/python-venv/bin/python  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.HOSTS=/spark/config/hosts  \</span><br><span class="line">--conf spark.executorEnv.HOSTS=/spark/config/hosts  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-application.options.claimName=spark-application  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-application.options.path=/spark/application  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-application.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-application.mount.path=/spark/application  \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-application.mount.readOnly=<span class="literal">false</span>  \</span><br><span class="line"></span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-application.options.claimName=spark-application  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-application.options.path=/spark/application  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-application.options.type=Directory  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-application.mount.path=/spark/application  \</span><br><span class="line">--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-application.mount.readOnly=<span class="literal">false</span>  \</span><br><span class="line"></span><br><span class="line">--conf spark.kubernetes.driverEnv.PRINCIPAL=hive  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.KRB5_CONFIG=/spark/application/2/1963/20954/37472/hive_krb5.conf  \</span><br><span class="line">--conf spark.kubernetes.driverEnv.KEYTAB=/spark/application/2/1963/20954/37472/hive.keytab  \</span><br><span class="line">--conf spark.executorEnv.PRINCIPAL=hive  \</span><br><span class="line">--conf spark.executorEnv.KRB5_CONFIG=/spark/application/2/1963/20954/37472/hive_krb5.conf  \</span><br><span class="line">--conf spark.executorEnv.KEYTAB=/spark/application/2/1963/20954/37472/hive.keytab  \</span><br><span class="line">--conf spark.kubernetes.kerberos.krb5.path=/spark/application/2/1963/20954/37472/hive_krb5.conf  \</span><br><span class="line">--conf spark.kerberos.principal=hive  \</span><br><span class="line">--conf spark.kerberos.keytab=/spark/application/2/1963/20954/37472/hive.keytab  \</span><br><span class="line">--conf spark.kubernetes.file.upload.path=s3a:/__SPARK_APP__  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.endpoint=http://ip:32030  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.access.key=xxx  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.secret.key=xxx  \</span><br><span class="line">--conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem  \</span><br><span class="line">--conf spark.files.fetchTimeout=5m  \</span><br><span class="line">--conf spark.files.overwrite=<span class="literal">true</span>  \</span><br><span class="line">--conf spark.driver.memory=1024m  \</span><br><span class="line">--conf spark.executor.memory=1024m  \</span><br><span class="line">--conf spark.executor.instances=2  \</span><br><span class="line">--conf spark.kubernetes.executor.request.cores=1  \</span><br><span class="line">--conf spark.kubernetes.driver.request.cores=1  \</span><br><span class="line">--conf spark.kubernetes.driver.pod.name=spark-1-1  \</span><br><span class="line">--name spark-debug-demo  \</span><br><span class="line">--py-files <span class="built_in">local</span>:///spark/application/2/1963/20954/37472/spark/spark_on_k8s/spark_utils.zip   \</span><br><span class="line"><span class="built_in">local</span>:///spark/application/2/1963/20954/37472/spark/pyspark_demo.py</span><br></pre></td></tr></table></figure></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://spark.apache.org/docs/3.1.2/sql-data-sources-hive-tables.html#interacting-with-different-versions-of-hive-metastore">spark3.1.2-interacting-with-different-versions-of-hive-metastore</a></li>
<li><a href="https://spark.apache.org/docs/2.4.8/sql-data-sources-hive-tables.html#interacting-with-different-versions-of-hive-metastore">spark2.4.8-interacting-with-different-versions-of-hive-metastore</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/setup-metastore-jars.html">hive-setup-metastore-jars</a></li>
<li><a href="https://spark.apache.org/docs/latest/hadoop-provided.html">spark-hadoop-provided</a></li>
<li><a href="https://archive.apache.org/dist/spark/spark-3.0.0/">spark-3.0-release</a></li>
<li><a href="https://spark.apache.org/docs/3.1.2/security.html#using-a-keytab">spark-using-a-keytab</a></li>
</ul>
]]></content>
      <tags>
        <tag>dolphinScheduler</tag>
        <tag>k8s</tag>
        <tag>cdh</tag>
        <tag>spark</tag>
      </tags>
  </entry>
</search>
