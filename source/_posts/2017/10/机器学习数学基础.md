---
title: 机器学习数学基础
date: 2017-10-03
tags: [AI,Machine Leaning]
categories: A0机器学习
---

@(A0机器学习)[AI, Machine Leaning]

记录机器学习数学概念/公式
- - -
<!-- more --> 

机器学习数学基础
---

# 线性代数

## Variance(方差)
>方差（Variance），应用数学里的专有名词。  
在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。方差越大，数据的分布越分散。  
一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量。  
说白了，就是将各个误差将之平方（而非取绝对值），使之肯定为正数，相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。  
继续延伸的话，方差的算术平方根称为该随机变量的标准差（此为相对各个数据点间）。

总体方差计算公式：  


## Bias(偏差)
偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，  
方差，是形容数据分散程度的，算是“无监督的”，客观的指标，    
偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。

## Standard Deviation(标准差)
>标准差（Standard Deviation，SD）又常称均方差，数学符号 σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。  
标准差定义：标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。  

标准差也被称为标准偏差，或者实验标准差，公式为  
![标准差公式](标准差公式.png)

## 正态分布

## 矩阵
### 矩阵的性质
* 不满足交换律
* 方阵：行列相等
* 单位矩阵：xx对角线都为1
* 逆矩阵：I*A=A*I=A
* 奇异矩阵/退化矩阵（singular/degenerate）：没有逆矩阵，如零矩阵（矩阵元素都为0）
### 矩阵的乘法
### 矩阵的转置（transpose）


# 微积分
## 导数

## 偏导数

## 梯度

## 微分

# 常用公式
* 假定函數（Hypothesis）：$$ h_	heta(x)=	heta_0+	heta_1x$$
参数：$	heta_0{,}	heta_1$

* 损失函数（Cost Function）：$$ J(	heta_0,	heta_1) = rac{1}{2m} \sum_{i=1}^m (h_	heta(x^{(i)})-y^{(i)})^2  $$
目标：$ argmin $ $ J(	heta_0,	heta_1) $ 

* 多元梯度下降算法
	* 假设函数：$$h_	heta(x)=	heta^Tx= 	heta_0x_0+	heta_1x_1+	heta_2x_2 +...+	heta_0x_n $$
	* 参数：$$	heta_0{,}	heta_1,...,	heta_n$$
	* 代价函数：$$J_(	heta)=J(	heta_0,	heta_1,...,	heta_n)=rac{1}{2m} \sum_{i=1}^m (h_	heta(x^{(i)})-y^{(i)})^2$$，	
	一元时，$x_j^{(i)}=x_0^{(1)}=1$
	* 梯度下降：Repeat { $$	heta_j :=	heta_j - lpha rac{\partial}{\partial	heta_j}J(	heta) =
	lpha  rac{1}{m} \sum_{i=1}^m (h_	heta(x^{(i)})-y^{(i)})⋅x_j^{(i)} $$ } ，同步更新每个$j=0,...m$
	$lpha$为学习率，定义了每次参数更新的幅度；

>Learning Rate:
If α is too small: slow convergence.
If α is too large: ￼may not decrease on every iteration and thus may not converge.